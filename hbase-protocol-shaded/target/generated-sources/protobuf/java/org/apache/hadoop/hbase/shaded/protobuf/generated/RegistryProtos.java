// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Registry.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class RegistryProtos {
  private RegistryProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface GetClusterIdRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetClusterIdRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   ** Request and response to get the clusterID for this cluster 
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetClusterIdRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetClusterIdRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetClusterIdRequest)
      GetClusterIdRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetClusterIdRequest.newBuilder() to construct.
    private GetClusterIdRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterIdRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetClusterIdRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     ** Request and response to get the clusterID for this cluster 
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetClusterIdRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetClusterIdRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetClusterIdRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetClusterIdRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetClusterIdRequest>() {
      @java.lang.Override
      public GetClusterIdRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetClusterIdResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetClusterIdResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return Whether the clusterId field is set.
     */
    boolean hasClusterId();
    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return The bytes for clusterId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.GetClusterIdResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetClusterIdResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetClusterIdResponse)
      GetClusterIdResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetClusterIdResponse.newBuilder() to construct.
    private GetClusterIdResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetClusterIdResponse() {
      clusterId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetClusterIdResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.Builder.class);
    }

    private int bitField0_;
    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object clusterId_ = "";
    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return Whether the clusterId field is set.
     */
    @java.lang.Override
    public boolean hasClusterId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          clusterId_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     ** Not set if cluster ID could not be determined. 
     * </pre>
     *
     * <code>optional string cluster_id = 1;</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse) obj;

      if (hasClusterId() != other.hasClusterId()) return false;
      if (hasClusterId()) {
        if (!getClusterId()
            .equals(other.getClusterId())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasClusterId()) {
        hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getClusterId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetClusterIdResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetClusterIdResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        clusterId_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetClusterIdResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.clusterId_ = clusterId_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance()) return this;
        if (other.hasClusterId()) {
          clusterId_ = other.clusterId_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                clusterId_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @return Whether the clusterId field is set.
       */
      public boolean hasClusterId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            clusterId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @return The bytes for clusterId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        clusterId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        clusterId_ = getDefaultInstance().getClusterId();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** Not set if cluster ID could not be determined. 
       * </pre>
       *
       * <code>optional string cluster_id = 1;</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        clusterId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetClusterIdResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetClusterIdResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetClusterIdResponse>() {
      @java.lang.Override
      public GetClusterIdResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetClusterIdResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetActiveMasterRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetActiveMasterRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   ** Request and response to get the currently active master name for this cluster 
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetActiveMasterRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetActiveMasterRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetActiveMasterRequest)
      GetActiveMasterRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetActiveMasterRequest.newBuilder() to construct.
    private GetActiveMasterRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetActiveMasterRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetActiveMasterRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     ** Request and response to get the currently active master name for this cluster 
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetActiveMasterRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetActiveMasterRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetActiveMasterRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetActiveMasterRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetActiveMasterRequest>() {
      @java.lang.Override
      public GetActiveMasterRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetActiveMasterResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetActiveMasterResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    boolean hasServerName();
    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GetActiveMasterResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetActiveMasterResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetActiveMasterResponse)
      GetActiveMasterResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetActiveMasterResponse.newBuilder() to construct.
    private GetActiveMasterResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetActiveMasterResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetActiveMasterResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    @java.lang.Override
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <pre>
     ** Not set if an active master could not be determined. 
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasServerName()) {
        if (!getServerName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerName());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse) obj;

      if (hasServerName() != other.hasServerName()) return false;
      if (hasServerName()) {
        if (!getServerName()
            .equals(other.getServerName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetActiveMasterResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetActiveMasterResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetActiveMasterResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.serverName_ = serverNameBuilder_ == null
              ? serverName_
              : serverNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasServerName()) {
          if (!getServerName().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getServerNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       * @return Whether the serverName field is set.
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       * @return The serverName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            serverName_ != null &&
            serverName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getServerNameBuilder().mergeFrom(value);
          } else {
            serverName_ = value;
          }
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        if (serverName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <pre>
       ** Not set if an active master could not be determined. 
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetActiveMasterResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetActiveMasterResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetActiveMasterResponse>() {
      @java.lang.Override
      public GetActiveMasterResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetActiveMasterResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  @java.lang.Deprecated public interface GetMastersRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetMastersRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   ** Request and response to get the current list of all registers master servers 
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetMastersRequest}
   */
  @java.lang.Deprecated @javax.annotation.Generated("proto") public static final class GetMastersRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetMastersRequest)
      GetMastersRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetMastersRequest.newBuilder() to construct.
    private GetMastersRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetMastersRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetMastersRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     ** Request and response to get the current list of all registers master servers 
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetMastersRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetMastersRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetMastersRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetMastersRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetMastersRequest>() {
      @java.lang.Override
      public GetMastersRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  @java.lang.Deprecated public interface GetMastersResponseEntryOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetMastersResponseEntry)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    /**
     * <code>required bool is_active = 2;</code>
     * @return Whether the isActive field is set.
     */
    boolean hasIsActive();
    /**
     * <code>required bool is_active = 2;</code>
     * @return The isActive.
     */
    boolean getIsActive();
  }
  /**
   * Protobuf type {@code hbase.pb.GetMastersResponseEntry}
   */
  @java.lang.Deprecated @javax.annotation.Generated("proto") public static final class GetMastersResponseEntry extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetMastersResponseEntry)
      GetMastersResponseEntryOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetMastersResponseEntry.newBuilder() to construct.
    private GetMastersResponseEntry(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetMastersResponseEntry() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetMastersResponseEntry();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponseEntry_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponseEntry_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    @java.lang.Override
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    public static final int IS_ACTIVE_FIELD_NUMBER = 2;
    private boolean isActive_ = false;
    /**
     * <code>required bool is_active = 2;</code>
     * @return Whether the isActive field is set.
     */
    @java.lang.Override
    public boolean hasIsActive() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bool is_active = 2;</code>
     * @return The isActive.
     */
    @java.lang.Override
    public boolean getIsActive() {
      return isActive_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasIsActive()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, isActive_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isActive_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry) obj;

      if (hasServerName() != other.hasServerName()) return false;
      if (hasServerName()) {
        if (!getServerName()
            .equals(other.getServerName())) return false;
      }
      if (hasIsActive() != other.hasIsActive()) return false;
      if (hasIsActive()) {
        if (getIsActive()
            != other.getIsActive()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (hasIsActive()) {
        hash = (37 * hash) + IS_ACTIVE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getIsActive());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetMastersResponseEntry}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetMastersResponseEntry)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponseEntry_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponseEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        isActive_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponseEntry_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.serverName_ = serverNameBuilder_ == null
              ? serverName_
              : serverNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.isActive_ = isActive_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (other.hasIsActive()) {
          setIsActive(other.getIsActive());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasServerName()) {
          return false;
        }
        if (!hasIsActive()) {
          return false;
        }
        if (!getServerName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getServerNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                isActive_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return Whether the serverName field is set.
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return The serverName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            serverName_ != null &&
            serverName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getServerNameBuilder().mergeFrom(value);
          } else {
            serverName_ = value;
          }
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        if (serverName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      private boolean isActive_ ;
      /**
       * <code>required bool is_active = 2;</code>
       * @return Whether the isActive field is set.
       */
      @java.lang.Override
      public boolean hasIsActive() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bool is_active = 2;</code>
       * @return The isActive.
       */
      @java.lang.Override
      public boolean getIsActive() {
        return isActive_;
      }
      /**
       * <code>required bool is_active = 2;</code>
       * @param value The isActive to set.
       * @return This builder for chaining.
       */
      public Builder setIsActive(boolean value) {

        isActive_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bool is_active = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsActive() {
        bitField0_ = (bitField0_ & ~0x00000002);
        isActive_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetMastersResponseEntry)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetMastersResponseEntry)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponseEntry>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetMastersResponseEntry>() {
      @java.lang.Override
      public GetMastersResponseEntry parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponseEntry> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponseEntry> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  @java.lang.Deprecated public interface GetMastersResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetMastersResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> 
        getMasterServersList();
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getMasterServers(int index);
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    int getMasterServersCount();
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder> 
        getMasterServersOrBuilderList();
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder getMasterServersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetMastersResponse}
   */
  @java.lang.Deprecated @javax.annotation.Generated("proto") public static final class GetMastersResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetMastersResponse)
      GetMastersResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetMastersResponse.newBuilder() to construct.
    private GetMastersResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetMastersResponse() {
      masterServers_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetMastersResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.Builder.class);
    }

    public static final int MASTER_SERVERS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> masterServers_;
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> getMasterServersList() {
      return masterServers_;
    }
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder> 
        getMasterServersOrBuilderList() {
      return masterServers_;
    }
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    @java.lang.Override
    public int getMasterServersCount() {
      return masterServers_.size();
    }
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getMasterServers(int index) {
      return masterServers_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder getMasterServersOrBuilder(
        int index) {
      return masterServers_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getMasterServersCount(); i++) {
        if (!getMasterServers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < masterServers_.size(); i++) {
        output.writeMessage(1, masterServers_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < masterServers_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, masterServers_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse) obj;

      if (!getMasterServersList()
          .equals(other.getMasterServersList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getMasterServersCount() > 0) {
        hash = (37 * hash) + MASTER_SERVERS_FIELD_NUMBER;
        hash = (53 * hash) + getMasterServersList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetMastersResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetMastersResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (masterServersBuilder_ == null) {
          masterServers_ = java.util.Collections.emptyList();
        } else {
          masterServers_ = null;
          masterServersBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMastersResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse result) {
        if (masterServersBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            masterServers_ = java.util.Collections.unmodifiableList(masterServers_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.masterServers_ = masterServers_;
        } else {
          result.masterServers_ = masterServersBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance()) return this;
        if (masterServersBuilder_ == null) {
          if (!other.masterServers_.isEmpty()) {
            if (masterServers_.isEmpty()) {
              masterServers_ = other.masterServers_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureMasterServersIsMutable();
              masterServers_.addAll(other.masterServers_);
            }
            onChanged();
          }
        } else {
          if (!other.masterServers_.isEmpty()) {
            if (masterServersBuilder_.isEmpty()) {
              masterServersBuilder_.dispose();
              masterServersBuilder_ = null;
              masterServers_ = other.masterServers_;
              bitField0_ = (bitField0_ & ~0x00000001);
              masterServersBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getMasterServersFieldBuilder() : null;
            } else {
              masterServersBuilder_.addAllMessages(other.masterServers_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getMasterServersCount(); i++) {
          if (!getMasterServers(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.PARSER,
                        extensionRegistry);
                if (masterServersBuilder_ == null) {
                  ensureMasterServersIsMutable();
                  masterServers_.add(m);
                } else {
                  masterServersBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> masterServers_ =
        java.util.Collections.emptyList();
      private void ensureMasterServersIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          masterServers_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry>(masterServers_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder> masterServersBuilder_;

      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> getMasterServersList() {
        if (masterServersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(masterServers_);
        } else {
          return masterServersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public int getMasterServersCount() {
        if (masterServersBuilder_ == null) {
          return masterServers_.size();
        } else {
          return masterServersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry getMasterServers(int index) {
        if (masterServersBuilder_ == null) {
          return masterServers_.get(index);
        } else {
          return masterServersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder setMasterServers(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry value) {
        if (masterServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterServersIsMutable();
          masterServers_.set(index, value);
          onChanged();
        } else {
          masterServersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder setMasterServers(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder builderForValue) {
        if (masterServersBuilder_ == null) {
          ensureMasterServersIsMutable();
          masterServers_.set(index, builderForValue.build());
          onChanged();
        } else {
          masterServersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder addMasterServers(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry value) {
        if (masterServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterServersIsMutable();
          masterServers_.add(value);
          onChanged();
        } else {
          masterServersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder addMasterServers(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry value) {
        if (masterServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterServersIsMutable();
          masterServers_.add(index, value);
          onChanged();
        } else {
          masterServersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder addMasterServers(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder builderForValue) {
        if (masterServersBuilder_ == null) {
          ensureMasterServersIsMutable();
          masterServers_.add(builderForValue.build());
          onChanged();
        } else {
          masterServersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder addMasterServers(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder builderForValue) {
        if (masterServersBuilder_ == null) {
          ensureMasterServersIsMutable();
          masterServers_.add(index, builderForValue.build());
          onChanged();
        } else {
          masterServersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder addAllMasterServers(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry> values) {
        if (masterServersBuilder_ == null) {
          ensureMasterServersIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, masterServers_);
          onChanged();
        } else {
          masterServersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder clearMasterServers() {
        if (masterServersBuilder_ == null) {
          masterServers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          masterServersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public Builder removeMasterServers(int index) {
        if (masterServersBuilder_ == null) {
          ensureMasterServersIsMutable();
          masterServers_.remove(index);
          onChanged();
        } else {
          masterServersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder getMasterServersBuilder(
          int index) {
        return getMasterServersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder getMasterServersOrBuilder(
          int index) {
        if (masterServersBuilder_ == null) {
          return masterServers_.get(index);  } else {
          return masterServersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder> 
           getMasterServersOrBuilderList() {
        if (masterServersBuilder_ != null) {
          return masterServersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(masterServers_);
        }
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder addMasterServersBuilder() {
        return getMasterServersFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder addMasterServersBuilder(
          int index) {
        return getMasterServersFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.GetMastersResponseEntry master_servers = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder> 
           getMasterServersBuilderList() {
        return getMasterServersFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder> 
          getMasterServersFieldBuilder() {
        if (masterServersBuilder_ == null) {
          masterServersBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponseEntryOrBuilder>(
                  masterServers_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          masterServers_ = null;
        }
        return masterServersBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetMastersResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetMastersResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetMastersResponse>() {
      @java.lang.Override
      public GetMastersResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMastersResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetMetaRegionLocationsRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetMetaRegionLocationsRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   ** Request and response to get the current list of meta region locations 
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetMetaRegionLocationsRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetMetaRegionLocationsRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetMetaRegionLocationsRequest)
      GetMetaRegionLocationsRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetMetaRegionLocationsRequest.newBuilder() to construct.
    private GetMetaRegionLocationsRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetMetaRegionLocationsRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetMetaRegionLocationsRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     ** Request and response to get the current list of meta region locations 
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetMetaRegionLocationsRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetMetaRegionLocationsRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetMetaRegionLocationsRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetMetaRegionLocationsRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetMetaRegionLocationsRequest>() {
      @java.lang.Override
      public GetMetaRegionLocationsRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetMetaRegionLocationsResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetMetaRegionLocationsResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> 
        getMetaLocationsList();
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getMetaLocations(int index);
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    int getMetaLocationsCount();
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getMetaLocationsOrBuilderList();
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getMetaLocationsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetMetaRegionLocationsResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetMetaRegionLocationsResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetMetaRegionLocationsResponse)
      GetMetaRegionLocationsResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetMetaRegionLocationsResponse.newBuilder() to construct.
    private GetMetaRegionLocationsResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetMetaRegionLocationsResponse() {
      metaLocations_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetMetaRegionLocationsResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.Builder.class);
    }

    public static final int META_LOCATIONS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> metaLocations_;
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getMetaLocationsList() {
      return metaLocations_;
    }
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getMetaLocationsOrBuilderList() {
      return metaLocations_;
    }
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    @java.lang.Override
    public int getMetaLocationsCount() {
      return metaLocations_.size();
    }
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getMetaLocations(int index) {
      return metaLocations_.get(index);
    }
    /**
     * <pre>
     ** Not set if meta region locations could not be determined. 
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getMetaLocationsOrBuilder(
        int index) {
      return metaLocations_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getMetaLocationsCount(); i++) {
        if (!getMetaLocations(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < metaLocations_.size(); i++) {
        output.writeMessage(1, metaLocations_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < metaLocations_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, metaLocations_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse) obj;

      if (!getMetaLocationsList()
          .equals(other.getMetaLocationsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getMetaLocationsCount() > 0) {
        hash = (37 * hash) + META_LOCATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMetaLocationsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetMetaRegionLocationsResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetMetaRegionLocationsResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (metaLocationsBuilder_ == null) {
          metaLocations_ = java.util.Collections.emptyList();
        } else {
          metaLocations_ = null;
          metaLocationsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse result) {
        if (metaLocationsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            metaLocations_ = java.util.Collections.unmodifiableList(metaLocations_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.metaLocations_ = metaLocations_;
        } else {
          result.metaLocations_ = metaLocationsBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance()) return this;
        if (metaLocationsBuilder_ == null) {
          if (!other.metaLocations_.isEmpty()) {
            if (metaLocations_.isEmpty()) {
              metaLocations_ = other.metaLocations_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureMetaLocationsIsMutable();
              metaLocations_.addAll(other.metaLocations_);
            }
            onChanged();
          }
        } else {
          if (!other.metaLocations_.isEmpty()) {
            if (metaLocationsBuilder_.isEmpty()) {
              metaLocationsBuilder_.dispose();
              metaLocationsBuilder_ = null;
              metaLocations_ = other.metaLocations_;
              bitField0_ = (bitField0_ & ~0x00000001);
              metaLocationsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getMetaLocationsFieldBuilder() : null;
            } else {
              metaLocationsBuilder_.addAllMessages(other.metaLocations_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getMetaLocationsCount(); i++) {
          if (!getMetaLocations(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.PARSER,
                        extensionRegistry);
                if (metaLocationsBuilder_ == null) {
                  ensureMetaLocationsIsMutable();
                  metaLocations_.add(m);
                } else {
                  metaLocationsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> metaLocations_ =
        java.util.Collections.emptyList();
      private void ensureMetaLocationsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          metaLocations_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation>(metaLocations_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> metaLocationsBuilder_;

      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getMetaLocationsList() {
        if (metaLocationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(metaLocations_);
        } else {
          return metaLocationsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public int getMetaLocationsCount() {
        if (metaLocationsBuilder_ == null) {
          return metaLocations_.size();
        } else {
          return metaLocationsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getMetaLocations(int index) {
        if (metaLocationsBuilder_ == null) {
          return metaLocations_.get(index);
        } else {
          return metaLocationsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder setMetaLocations(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (metaLocationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetaLocationsIsMutable();
          metaLocations_.set(index, value);
          onChanged();
        } else {
          metaLocationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder setMetaLocations(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (metaLocationsBuilder_ == null) {
          ensureMetaLocationsIsMutable();
          metaLocations_.set(index, builderForValue.build());
          onChanged();
        } else {
          metaLocationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder addMetaLocations(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (metaLocationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetaLocationsIsMutable();
          metaLocations_.add(value);
          onChanged();
        } else {
          metaLocationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder addMetaLocations(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (metaLocationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMetaLocationsIsMutable();
          metaLocations_.add(index, value);
          onChanged();
        } else {
          metaLocationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder addMetaLocations(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (metaLocationsBuilder_ == null) {
          ensureMetaLocationsIsMutable();
          metaLocations_.add(builderForValue.build());
          onChanged();
        } else {
          metaLocationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder addMetaLocations(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (metaLocationsBuilder_ == null) {
          ensureMetaLocationsIsMutable();
          metaLocations_.add(index, builderForValue.build());
          onChanged();
        } else {
          metaLocationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder addAllMetaLocations(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> values) {
        if (metaLocationsBuilder_ == null) {
          ensureMetaLocationsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, metaLocations_);
          onChanged();
        } else {
          metaLocationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder clearMetaLocations() {
        if (metaLocationsBuilder_ == null) {
          metaLocations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          metaLocationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public Builder removeMetaLocations(int index) {
        if (metaLocationsBuilder_ == null) {
          ensureMetaLocationsIsMutable();
          metaLocations_.remove(index);
          onChanged();
        } else {
          metaLocationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder getMetaLocationsBuilder(
          int index) {
        return getMetaLocationsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getMetaLocationsOrBuilder(
          int index) {
        if (metaLocationsBuilder_ == null) {
          return metaLocations_.get(index);  } else {
          return metaLocationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
           getMetaLocationsOrBuilderList() {
        if (metaLocationsBuilder_ != null) {
          return metaLocationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(metaLocations_);
        }
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addMetaLocationsBuilder() {
        return getMetaLocationsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addMetaLocationsBuilder(
          int index) {
        return getMetaLocationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <pre>
       ** Not set if meta region locations could not be determined. 
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionLocation meta_locations = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder> 
           getMetaLocationsBuilderList() {
        return getMetaLocationsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
          getMetaLocationsFieldBuilder() {
        if (metaLocationsBuilder_ == null) {
          metaLocationsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder>(
                  metaLocations_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          metaLocations_ = null;
        }
        return metaLocationsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetMetaRegionLocationsResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetMetaRegionLocationsResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetMetaRegionLocationsResponse>() {
      @java.lang.Override
      public GetMetaRegionLocationsResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetMetaRegionLocationsResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetBootstrapNodesRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetBootstrapNodesRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   ** Request and response to get the nodes which could be used to as ClientMetaService 
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetBootstrapNodesRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetBootstrapNodesRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetBootstrapNodesRequest)
      GetBootstrapNodesRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetBootstrapNodesRequest.newBuilder() to construct.
    private GetBootstrapNodesRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetBootstrapNodesRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetBootstrapNodesRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     ** Request and response to get the nodes which could be used to as ClientMetaService 
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetBootstrapNodesRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetBootstrapNodesRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetBootstrapNodesRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetBootstrapNodesRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetBootstrapNodesRequest>() {
      @java.lang.Override
      public GetBootstrapNodesRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetBootstrapNodesResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetBootstrapNodesResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> 
        getServerNameList();
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName(int index);
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    int getServerNameCount();
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getServerNameOrBuilderList();
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetBootstrapNodesResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetBootstrapNodesResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetBootstrapNodesResponse)
      GetBootstrapNodesResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetBootstrapNodesResponse.newBuilder() to construct.
    private GetBootstrapNodesResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetBootstrapNodesResponse() {
      serverName_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetBootstrapNodesResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.Builder.class);
    }

    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> serverName_;
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getServerNameList() {
      return serverName_;
    }
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getServerNameOrBuilderList() {
      return serverName_;
    }
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public int getServerNameCount() {
      return serverName_.size();
    }
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName(int index) {
      return serverName_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder(
        int index) {
      return serverName_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getServerNameCount(); i++) {
        if (!getServerName(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < serverName_.size(); i++) {
        output.writeMessage(1, serverName_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < serverName_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, serverName_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse) obj;

      if (!getServerNameList()
          .equals(other.getServerNameList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getServerNameCount() > 0) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerNameList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetBootstrapNodesResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetBootstrapNodesResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (serverNameBuilder_ == null) {
          serverName_ = java.util.Collections.emptyList();
        } else {
          serverName_ = null;
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse result) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            serverName_ = java.util.Collections.unmodifiableList(serverName_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.serverName_ = serverName_;
        } else {
          result.serverName_ = serverNameBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance()) return this;
        if (serverNameBuilder_ == null) {
          if (!other.serverName_.isEmpty()) {
            if (serverName_.isEmpty()) {
              serverName_ = other.serverName_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureServerNameIsMutable();
              serverName_.addAll(other.serverName_);
            }
            onChanged();
          }
        } else {
          if (!other.serverName_.isEmpty()) {
            if (serverNameBuilder_.isEmpty()) {
              serverNameBuilder_.dispose();
              serverNameBuilder_ = null;
              serverName_ = other.serverName_;
              bitField0_ = (bitField0_ & ~0x00000001);
              serverNameBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getServerNameFieldBuilder() : null;
            } else {
              serverNameBuilder_.addAllMessages(other.serverName_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getServerNameCount(); i++) {
          if (!getServerName(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER,
                        extensionRegistry);
                if (serverNameBuilder_ == null) {
                  ensureServerNameIsMutable();
                  serverName_.add(m);
                } else {
                  serverNameBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> serverName_ =
        java.util.Collections.emptyList();
      private void ensureServerNameIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          serverName_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName>(serverName_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;

      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getServerNameList() {
        if (serverNameBuilder_ == null) {
          return java.util.Collections.unmodifiableList(serverName_);
        } else {
          return serverNameBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public int getServerNameCount() {
        if (serverNameBuilder_ == null) {
          return serverName_.size();
        } else {
          return serverNameBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName(int index) {
        if (serverNameBuilder_ == null) {
          return serverName_.get(index);
        } else {
          return serverNameBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServerNameIsMutable();
          serverName_.set(index, value);
          onChanged();
        } else {
          serverNameBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          ensureServerNameIsMutable();
          serverName_.set(index, builderForValue.build());
          onChanged();
        } else {
          serverNameBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder addServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServerNameIsMutable();
          serverName_.add(value);
          onChanged();
        } else {
          serverNameBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder addServerName(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServerNameIsMutable();
          serverName_.add(index, value);
          onChanged();
        } else {
          serverNameBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder addServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          ensureServerNameIsMutable();
          serverName_.add(builderForValue.build());
          onChanged();
        } else {
          serverNameBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder addServerName(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          ensureServerNameIsMutable();
          serverName_.add(index, builderForValue.build());
          onChanged();
        } else {
          serverNameBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder addAllServerName(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> values) {
        if (serverNameBuilder_ == null) {
          ensureServerNameIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, serverName_);
          onChanged();
        } else {
          serverNameBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        if (serverNameBuilder_ == null) {
          serverName_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          serverNameBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder removeServerName(int index) {
        if (serverNameBuilder_ == null) {
          ensureServerNameIsMutable();
          serverName_.remove(index);
          onChanged();
        } else {
          serverNameBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder(
          int index) {
        return getServerNameFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder(
          int index) {
        if (serverNameBuilder_ == null) {
          return serverName_.get(index);  } else {
          return serverNameBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
           getServerNameOrBuilderList() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(serverName_);
        }
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addServerNameBuilder() {
        return getServerNameFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addServerNameBuilder(
          int index) {
        return getServerNameFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ServerName server_name = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder> 
           getServerNameBuilderList() {
        return getServerNameFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  serverName_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetBootstrapNodesResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetBootstrapNodesResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetBootstrapNodesResponse>() {
      @java.lang.Override
      public GetBootstrapNodesResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetBootstrapNodesResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  /**
   * <pre>
   **
   * Implements all the RPCs needed by clients to look up cluster meta information needed for
   * connection establishment.
   * </pre>
   *
   * Protobuf service {@code hbase.pb.ClientMetaService}
   */
  public static abstract class ClientMetaService
      implements org.apache.hbase.thirdparty.com.google.protobuf.Service {
    protected ClientMetaService() {}

    public interface Interface {
      /**
       * <pre>
       **
       * Get Cluster ID for this cluster.
       * </pre>
       *
       * <code>rpc GetClusterId(.hbase.pb.GetClusterIdRequest) returns (.hbase.pb.GetClusterIdResponse);</code>
       */
      public abstract void getClusterId(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse> done);

      /**
       * <pre>
       **
       * Get active master server name for this cluster. Retained for out of sync client and master
       * rolling upgrades. Newer clients switched to GetMasters RPC request.
       * </pre>
       *
       * <code>rpc GetActiveMaster(.hbase.pb.GetActiveMasterRequest) returns (.hbase.pb.GetActiveMasterResponse);</code>
       */
      public abstract void getActiveMaster(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse> done);

      /**
       * <pre>
       **
       * Get registered list of master servers in this cluster.
       * </pre>
       *
       * <code>rpc GetMasters(.hbase.pb.GetMastersRequest) returns (.hbase.pb.GetMastersResponse) { ... }</code>
       */
      public abstract void getMasters(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse> done);

      /**
       * <pre>
       **
       * Get current meta replicas' region locations.
       * </pre>
       *
       * <code>rpc GetMetaRegionLocations(.hbase.pb.GetMetaRegionLocationsRequest) returns (.hbase.pb.GetMetaRegionLocationsResponse);</code>
       */
      public abstract void getMetaRegionLocations(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse> done);

      /**
       * <pre>
       **
       * Get nodes which could be used as ClientMetaService
       * </pre>
       *
       * <code>rpc GetBootstrapNodes(.hbase.pb.GetBootstrapNodesRequest) returns (.hbase.pb.GetBootstrapNodesResponse);</code>
       */
      public abstract void getBootstrapNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse> done);

    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new ClientMetaService() {
        @java.lang.Override
        public  void getClusterId(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse> done) {
          impl.getClusterId(controller, request, done);
        }

        @java.lang.Override
        public  void getActiveMaster(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse> done) {
          impl.getActiveMaster(controller, request, done);
        }

        @java.lang.Override
        public  void getMasters(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse> done) {
          impl.getMasters(controller, request, done);
        }

        @java.lang.Override
        public  void getMetaRegionLocations(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse> done) {
          impl.getMetaRegionLocations(controller, request, done);
        }

        @java.lang.Override
        public  void getBootstrapNodes(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse> done) {
          impl.getBootstrapNodes(controller, request, done);
        }

      };
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new org.apache.hbase.thirdparty.com.google.protobuf.BlockingService() {
        public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message callBlockingMethod(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hbase.thirdparty.com.google.protobuf.Message request)
            throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.getClusterId(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest)request);
            case 1:
              return impl.getActiveMaster(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest)request);
            case 2:
              return impl.getMasters(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest)request);
            case 3:
              return impl.getMetaRegionLocations(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest)request);
            case 4:
              return impl.getBootstrapNodes(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getRequestPrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getResponsePrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

      };
    }

    /**
     * <pre>
     **
     * Get Cluster ID for this cluster.
     * </pre>
     *
     * <code>rpc GetClusterId(.hbase.pb.GetClusterIdRequest) returns (.hbase.pb.GetClusterIdResponse);</code>
     */
    public abstract void getClusterId(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse> done);

    /**
     * <pre>
     **
     * Get active master server name for this cluster. Retained for out of sync client and master
     * rolling upgrades. Newer clients switched to GetMasters RPC request.
     * </pre>
     *
     * <code>rpc GetActiveMaster(.hbase.pb.GetActiveMasterRequest) returns (.hbase.pb.GetActiveMasterResponse);</code>
     */
    public abstract void getActiveMaster(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse> done);

    /**
     * <pre>
     **
     * Get registered list of master servers in this cluster.
     * </pre>
     *
     * <code>rpc GetMasters(.hbase.pb.GetMastersRequest) returns (.hbase.pb.GetMastersResponse) { ... }</code>
     */
    public abstract void getMasters(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse> done);

    /**
     * <pre>
     **
     * Get current meta replicas' region locations.
     * </pre>
     *
     * <code>rpc GetMetaRegionLocations(.hbase.pb.GetMetaRegionLocationsRequest) returns (.hbase.pb.GetMetaRegionLocationsResponse);</code>
     */
    public abstract void getMetaRegionLocations(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse> done);

    /**
     * <pre>
     **
     * Get nodes which could be used as ClientMetaService
     * </pre>
     *
     * <code>rpc GetBootstrapNodes(.hbase.pb.GetBootstrapNodesRequest) returns (.hbase.pb.GetBootstrapNodesResponse);</code>
     */
    public abstract void getBootstrapNodes(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse> done);

    public static final
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.getDescriptor().getServices().get(0);
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }

    public final void callMethod(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hbase.thirdparty.com.google.protobuf.Message request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<
          org.apache.hbase.thirdparty.com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.getClusterId(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse>specializeCallback(
              done));
          return;
        case 1:
          this.getActiveMaster(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse>specializeCallback(
              done));
          return;
        case 2:
          this.getMasters(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse>specializeCallback(
              done));
          return;
        case 3:
          this.getMetaRegionLocations(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse>specializeCallback(
              done));
          return;
        case 4:
          this.getBootstrapNodes(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getRequestPrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getResponsePrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public static Stub newStub(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }

    @javax.annotation.Generated("proto") public static final class Stub extends org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.ClientMetaService implements Interface {
      private Stub(org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel;

      public org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }

      public  void getClusterId(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance()));
      }

      public  void getActiveMaster(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance()));
      }

      public  void getMasters(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance()));
      }

      public  void getMetaRegionLocations(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance()));
      }

      public  void getBootstrapNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance()));
      }
    }

    public static BlockingInterface newBlockingStub(
        org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }

    public interface BlockingInterface {
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse getClusterId(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse getActiveMaster(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse getMasters(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse getMetaRegionLocations(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse getBootstrapNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
    }

    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse getClusterId(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetClusterIdResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse getActiveMaster(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetActiveMasterResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse getMasters(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMastersResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse getMetaRegionLocations(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetMetaRegionLocationsResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse getBootstrapNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegistryProtos.GetBootstrapNodesResponse.getDefaultInstance());
      }

    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClientMetaService)
  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetClusterIdRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetClusterIdRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetClusterIdResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetClusterIdResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetActiveMasterRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetActiveMasterRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetActiveMasterResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetActiveMasterResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetMastersRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetMastersRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetMastersResponseEntry_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetMastersResponseEntry_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetMastersResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetMastersResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetMetaRegionLocationsRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetMetaRegionLocationsResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetBootstrapNodesRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetBootstrapNodesResponse_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\016Registry.proto\022\010hbase.pb\032\013HBase.proto\"" +
      "\025\n\023GetClusterIdRequest\"*\n\024GetClusterIdRe" +
      "sponse\022\022\n\ncluster_id\030\001 \001(\t\"\030\n\026GetActiveM" +
      "asterRequest\"D\n\027GetActiveMasterResponse\022" +
      ")\n\013server_name\030\001 \001(\0132\024.hbase.pb.ServerNa" +
      "me\"\027\n\021GetMastersRequest:\002\030\001\"[\n\027GetMaster" +
      "sResponseEntry\022)\n\013server_name\030\001 \002(\0132\024.hb" +
      "ase.pb.ServerName\022\021\n\tis_active\030\002 \002(\010:\002\030\001" +
      "\"S\n\022GetMastersResponse\0229\n\016master_servers" +
      "\030\001 \003(\0132!.hbase.pb.GetMastersResponseEntr" +
      "y:\002\030\001\"\037\n\035GetMetaRegionLocationsRequest\"R" +
      "\n\036GetMetaRegionLocationsResponse\0220\n\016meta" +
      "_locations\030\001 \003(\0132\030.hbase.pb.RegionLocati" +
      "on\"\032\n\030GetBootstrapNodesRequest\"F\n\031GetBoo" +
      "tstrapNodesResponse\022)\n\013server_name\030\001 \003(\013" +
      "2\024.hbase.pb.ServerName2\323\003\n\021ClientMetaSer" +
      "vice\022M\n\014GetClusterId\022\035.hbase.pb.GetClust" +
      "erIdRequest\032\036.hbase.pb.GetClusterIdRespo" +
      "nse\022V\n\017GetActiveMaster\022 .hbase.pb.GetAct" +
      "iveMasterRequest\032!.hbase.pb.GetActiveMas" +
      "terResponse\022L\n\nGetMasters\022\033.hbase.pb.Get" +
      "MastersRequest\032\034.hbase.pb.GetMastersResp" +
      "onse\"\003\210\002\001\022k\n\026GetMetaRegionLocations\022\'.hb" +
      "ase.pb.GetMetaRegionLocationsRequest\032(.h" +
      "base.pb.GetMetaRegionLocationsResponse\022\\" +
      "\n\021GetBootstrapNodes\022\".hbase.pb.GetBootst" +
      "rapNodesRequest\032#.hbase.pb.GetBootstrapN" +
      "odesResponseBK\n1org.apache.hadoop.hbase." +
      "shaded.protobuf.generatedB\016RegistryProto" +
      "sH\001\210\001\001\240\001\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
        });
    internal_static_hbase_pb_GetClusterIdRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_GetClusterIdRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetClusterIdRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetClusterIdResponse_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_GetClusterIdResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetClusterIdResponse_descriptor,
        new java.lang.String[] { "ClusterId", });
    internal_static_hbase_pb_GetActiveMasterRequest_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_GetActiveMasterRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetActiveMasterRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetActiveMasterResponse_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_GetActiveMasterResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetActiveMasterResponse_descriptor,
        new java.lang.String[] { "ServerName", });
    internal_static_hbase_pb_GetMastersRequest_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_GetMastersRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetMastersRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetMastersResponseEntry_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_GetMastersResponseEntry_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetMastersResponseEntry_descriptor,
        new java.lang.String[] { "ServerName", "IsActive", });
    internal_static_hbase_pb_GetMastersResponse_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_GetMastersResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetMastersResponse_descriptor,
        new java.lang.String[] { "MasterServers", });
    internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_GetMetaRegionLocationsRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetMetaRegionLocationsRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_GetMetaRegionLocationsResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetMetaRegionLocationsResponse_descriptor,
        new java.lang.String[] { "MetaLocations", });
    internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_GetBootstrapNodesRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetBootstrapNodesRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_GetBootstrapNodesResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetBootstrapNodesResponse_descriptor,
        new java.lang.String[] { "ServerName", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
