// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: MasterProcedure.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class MasterProcedureProtos {
  private MasterProcedureProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.CreateTableState}
   */
  public enum CreateTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    CREATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    CREATE_TABLE_WRITE_FS_LAYOUT(2),
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    CREATE_TABLE_ADD_TO_META(3),
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    CREATE_TABLE_ASSIGN_REGIONS(4),
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    CREATE_TABLE_UPDATE_DESC_CACHE(5),
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    CREATE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int CREATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CREATE_TABLE_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    public static final int CREATE_TABLE_ADD_TO_META_VALUE = 3;
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CREATE_TABLE_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CREATE_TABLE_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int CREATE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CreateTableState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_TABLE_PRE_OPERATION;
        case 2: return CREATE_TABLE_WRITE_FS_LAYOUT;
        case 3: return CREATE_TABLE_ADD_TO_META;
        case 4: return CREATE_TABLE_ASSIGN_REGIONS;
        case 5: return CREATE_TABLE_UPDATE_DESC_CACHE;
        case 6: return CREATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CreateTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateTableState>() {
            public CreateTableState findValueByNumber(int number) {
              return CreateTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final CreateTableState[] VALUES = values();

    public static CreateTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyTableState}
   */
  public enum ModifyTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    MODIFY_TABLE_PREPARE(1),
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    MODIFY_TABLE_PRE_OPERATION(2),
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    MODIFY_TABLE_REMOVE_REPLICA_COLUMN(4),
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    MODIFY_TABLE_DELETE_FS_LAYOUT(5),
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    MODIFY_TABLE_POST_OPERATION(6),
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    MODIFY_TABLE_REOPEN_ALL_REGIONS(7),
    /**
     * <code>MODIFY_TABLE_CLOSE_EXCESS_REPLICAS = 8;</code>
     */
    MODIFY_TABLE_CLOSE_EXCESS_REPLICAS(8),
    /**
     * <code>MODIFY_TABLE_ASSIGN_NEW_REPLICAS = 9;</code>
     */
    MODIFY_TABLE_ASSIGN_NEW_REPLICAS(9),
    ;

    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    public static final int MODIFY_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    public static final int MODIFY_TABLE_REMOVE_REPLICA_COLUMN_VALUE = 4;
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    public static final int MODIFY_TABLE_DELETE_FS_LAYOUT_VALUE = 5;
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int MODIFY_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    public static final int MODIFY_TABLE_REOPEN_ALL_REGIONS_VALUE = 7;
    /**
     * <code>MODIFY_TABLE_CLOSE_EXCESS_REPLICAS = 8;</code>
     */
    public static final int MODIFY_TABLE_CLOSE_EXCESS_REPLICAS_VALUE = 8;
    /**
     * <code>MODIFY_TABLE_ASSIGN_NEW_REPLICAS = 9;</code>
     */
    public static final int MODIFY_TABLE_ASSIGN_NEW_REPLICAS_VALUE = 9;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyTableState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_TABLE_PREPARE;
        case 2: return MODIFY_TABLE_PRE_OPERATION;
        case 3: return MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_TABLE_REMOVE_REPLICA_COLUMN;
        case 5: return MODIFY_TABLE_DELETE_FS_LAYOUT;
        case 6: return MODIFY_TABLE_POST_OPERATION;
        case 7: return MODIFY_TABLE_REOPEN_ALL_REGIONS;
        case 8: return MODIFY_TABLE_CLOSE_EXCESS_REPLICAS;
        case 9: return MODIFY_TABLE_ASSIGN_NEW_REPLICAS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>() {
            public ModifyTableState findValueByNumber(int number) {
              return ModifyTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ModifyTableState[] VALUES = values();

    public static ModifyTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.TruncateTableState}
   */
  public enum TruncateTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    TRUNCATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    TRUNCATE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    TRUNCATE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    TRUNCATE_TABLE_CREATE_FS_LAYOUT(4),
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    TRUNCATE_TABLE_ADD_TO_META(5),
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    TRUNCATE_TABLE_ASSIGN_REGIONS(6),
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    TRUNCATE_TABLE_POST_OPERATION(7),
    ;

    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int TRUNCATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int TRUNCATE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int TRUNCATE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    public static final int TRUNCATE_TABLE_CREATE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    public static final int TRUNCATE_TABLE_ADD_TO_META_VALUE = 5;
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    public static final int TRUNCATE_TABLE_ASSIGN_REGIONS_VALUE = 6;
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    public static final int TRUNCATE_TABLE_POST_OPERATION_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static TruncateTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static TruncateTableState forNumber(int value) {
      switch (value) {
        case 1: return TRUNCATE_TABLE_PRE_OPERATION;
        case 2: return TRUNCATE_TABLE_REMOVE_FROM_META;
        case 3: return TRUNCATE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return TRUNCATE_TABLE_CREATE_FS_LAYOUT;
        case 5: return TRUNCATE_TABLE_ADD_TO_META;
        case 6: return TRUNCATE_TABLE_ASSIGN_REGIONS;
        case 7: return TRUNCATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        TruncateTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>() {
            public TruncateTableState findValueByNumber(int number) {
              return TruncateTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final TruncateTableState[] VALUES = values();

    public static TruncateTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private TruncateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.TruncateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteTableState}
   */
  public enum DeleteTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    DELETE_TABLE_PRE_OPERATION(1),
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    DELETE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    DELETE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    DELETE_TABLE_UPDATE_DESC_CACHE(4),
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    DELETE_TABLE_UNASSIGN_REGIONS(5),
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    DELETE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int DELETE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int DELETE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int DELETE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    public static final int DELETE_TABLE_UPDATE_DESC_CACHE_VALUE = 4;
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    public static final int DELETE_TABLE_UNASSIGN_REGIONS_VALUE = 5;
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DELETE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DeleteTableState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_TABLE_PRE_OPERATION;
        case 2: return DELETE_TABLE_REMOVE_FROM_META;
        case 3: return DELETE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return DELETE_TABLE_UPDATE_DESC_CACHE;
        case 5: return DELETE_TABLE_UNASSIGN_REGIONS;
        case 6: return DELETE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DeleteTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>() {
            public DeleteTableState findValueByNumber(int number) {
              return DeleteTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final DeleteTableState[] VALUES = values();

    public static DeleteTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CreateNamespaceState}
   */
  public enum CreateNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    CREATE_NAMESPACE_PREPARE(1),
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    CREATE_NAMESPACE_CREATE_DIRECTORY(2),
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    CREATE_NAMESPACE_INSERT_INTO_NS_TABLE(3),
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    CREATE_NAMESPACE_UPDATE_ZK(4),
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    CREATE_NAMESPACE_SET_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int CREATE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    public static final int CREATE_NAMESPACE_CREATE_DIRECTORY_VALUE = 2;
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    public static final int CREATE_NAMESPACE_INSERT_INTO_NS_TABLE_VALUE = 3;
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    public static final int CREATE_NAMESPACE_UPDATE_ZK_VALUE = 4;
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int CREATE_NAMESPACE_SET_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CreateNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_NAMESPACE_PREPARE;
        case 2: return CREATE_NAMESPACE_CREATE_DIRECTORY;
        case 3: return CREATE_NAMESPACE_INSERT_INTO_NS_TABLE;
        case 4: return CREATE_NAMESPACE_UPDATE_ZK;
        case 5: return CREATE_NAMESPACE_SET_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CreateNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>() {
            public CreateNamespaceState findValueByNumber(int number) {
              return CreateNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final CreateNamespaceState[] VALUES = values();

    public static CreateNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyNamespaceState}
   */
  public enum ModifyNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    MODIFY_NAMESPACE_PREPARE(1),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    MODIFY_NAMESPACE_UPDATE_NS_TABLE(2),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    MODIFY_NAMESPACE_UPDATE_ZK(3),
    ;

    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int MODIFY_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_NS_TABLE_VALUE = 2;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_ZK_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_NAMESPACE_PREPARE;
        case 2: return MODIFY_NAMESPACE_UPDATE_NS_TABLE;
        case 3: return MODIFY_NAMESPACE_UPDATE_ZK;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>() {
            public ModifyNamespaceState findValueByNumber(int number) {
              return ModifyNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final ModifyNamespaceState[] VALUES = values();

    public static ModifyNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteNamespaceState}
   */
  public enum DeleteNamespaceState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    DELETE_NAMESPACE_PREPARE(1),
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    DELETE_NAMESPACE_DELETE_FROM_NS_TABLE(2),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    DELETE_NAMESPACE_REMOVE_FROM_ZK(3),
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    DELETE_NAMESPACE_DELETE_DIRECTORIES(4),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int DELETE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_FROM_NS_TABLE_VALUE = 2;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_FROM_ZK_VALUE = 3;
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_DIRECTORIES_VALUE = 4;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DeleteNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_NAMESPACE_PREPARE;
        case 2: return DELETE_NAMESPACE_DELETE_FROM_NS_TABLE;
        case 3: return DELETE_NAMESPACE_REMOVE_FROM_ZK;
        case 4: return DELETE_NAMESPACE_DELETE_DIRECTORIES;
        case 5: return DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DeleteNamespaceState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>() {
            public DeleteNamespaceState findValueByNumber(int number) {
              return DeleteNamespaceState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final DeleteNamespaceState[] VALUES = values();

    public static DeleteNamespaceState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.EnableTableState}
   */
  public enum EnableTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    ENABLE_TABLE_PREPARE(1),
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    ENABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    ENABLE_TABLE_SET_ENABLING_TABLE_STATE(3),
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    ENABLE_TABLE_MARK_REGIONS_ONLINE(4),
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    ENABLE_TABLE_SET_ENABLED_TABLE_STATE(5),
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    ENABLE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int ENABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int ENABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    public static final int ENABLE_TABLE_MARK_REGIONS_ONLINE_VALUE = 4;
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int ENABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static EnableTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static EnableTableState forNumber(int value) {
      switch (value) {
        case 1: return ENABLE_TABLE_PREPARE;
        case 2: return ENABLE_TABLE_PRE_OPERATION;
        case 3: return ENABLE_TABLE_SET_ENABLING_TABLE_STATE;
        case 4: return ENABLE_TABLE_MARK_REGIONS_ONLINE;
        case 5: return ENABLE_TABLE_SET_ENABLED_TABLE_STATE;
        case 6: return ENABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EnableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        EnableTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EnableTableState>() {
            public EnableTableState findValueByNumber(int number) {
              return EnableTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final EnableTableState[] VALUES = values();

    public static EnableTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private EnableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.EnableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DisableTableState}
   */
  public enum DisableTableState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    DISABLE_TABLE_PREPARE(1),
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    DISABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    DISABLE_TABLE_SET_DISABLING_TABLE_STATE(3),
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    DISABLE_TABLE_MARK_REGIONS_OFFLINE(4),
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    DISABLE_TABLE_SET_DISABLED_TABLE_STATE(5),
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    DISABLE_TABLE_POST_OPERATION(6),
    /**
     * <code>DISABLE_TABLE_ADD_REPLICATION_BARRIER = 7;</code>
     */
    DISABLE_TABLE_ADD_REPLICATION_BARRIER(7),
    ;

    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int DISABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int DISABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    public static final int DISABLE_TABLE_MARK_REGIONS_OFFLINE_VALUE = 4;
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DISABLE_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>DISABLE_TABLE_ADD_REPLICATION_BARRIER = 7;</code>
     */
    public static final int DISABLE_TABLE_ADD_REPLICATION_BARRIER_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DisableTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DisableTableState forNumber(int value) {
      switch (value) {
        case 1: return DISABLE_TABLE_PREPARE;
        case 2: return DISABLE_TABLE_PRE_OPERATION;
        case 3: return DISABLE_TABLE_SET_DISABLING_TABLE_STATE;
        case 4: return DISABLE_TABLE_MARK_REGIONS_OFFLINE;
        case 5: return DISABLE_TABLE_SET_DISABLED_TABLE_STATE;
        case 6: return DISABLE_TABLE_POST_OPERATION;
        case 7: return DISABLE_TABLE_ADD_REPLICATION_BARRIER;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DisableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DisableTableState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DisableTableState>() {
            public DisableTableState findValueByNumber(int number) {
              return DisableTableState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final DisableTableState[] VALUES = values();

    public static DisableTableState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DisableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DisableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CloneSnapshotState}
   */
  public enum CloneSnapshotState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLONE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    CLONE_SNAPSHOT_PRE_OPERATION(1),
    /**
     * <code>CLONE_SNAPSHOT_WRITE_FS_LAYOUT = 2;</code>
     */
    CLONE_SNAPSHOT_WRITE_FS_LAYOUT(2),
    /**
     * <code>CLONE_SNAPSHOT_ADD_TO_META = 3;</code>
     */
    CLONE_SNAPSHOT_ADD_TO_META(3),
    /**
     * <code>CLONE_SNAPSHOT_ASSIGN_REGIONS = 4;</code>
     */
    CLONE_SNAPSHOT_ASSIGN_REGIONS(4),
    /**
     * <code>CLONE_SNAPSHOT_UPDATE_DESC_CACHE = 5;</code>
     */
    CLONE_SNAPSHOT_UPDATE_DESC_CACHE(5),
    /**
     * <code>CLONE_SNAPSHOT_POST_OPERATION = 6;</code>
     */
    CLONE_SNAPSHOT_POST_OPERATION(6),
    /**
     * <code>CLONE_SNAPHOST_RESTORE_ACL = 7;</code>
     */
    CLONE_SNAPHOST_RESTORE_ACL(7),
    ;

    /**
     * <code>CLONE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    public static final int CLONE_SNAPSHOT_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CLONE_SNAPSHOT_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CLONE_SNAPSHOT_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CLONE_SNAPSHOT_ADD_TO_META = 3;</code>
     */
    public static final int CLONE_SNAPSHOT_ADD_TO_META_VALUE = 3;
    /**
     * <code>CLONE_SNAPSHOT_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CLONE_SNAPSHOT_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CLONE_SNAPSHOT_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CLONE_SNAPSHOT_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CLONE_SNAPSHOT_POST_OPERATION = 6;</code>
     */
    public static final int CLONE_SNAPSHOT_POST_OPERATION_VALUE = 6;
    /**
     * <code>CLONE_SNAPHOST_RESTORE_ACL = 7;</code>
     */
    public static final int CLONE_SNAPHOST_RESTORE_ACL_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CloneSnapshotState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CloneSnapshotState forNumber(int value) {
      switch (value) {
        case 1: return CLONE_SNAPSHOT_PRE_OPERATION;
        case 2: return CLONE_SNAPSHOT_WRITE_FS_LAYOUT;
        case 3: return CLONE_SNAPSHOT_ADD_TO_META;
        case 4: return CLONE_SNAPSHOT_ASSIGN_REGIONS;
        case 5: return CLONE_SNAPSHOT_UPDATE_DESC_CACHE;
        case 6: return CLONE_SNAPSHOT_POST_OPERATION;
        case 7: return CLONE_SNAPHOST_RESTORE_ACL;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloneSnapshotState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CloneSnapshotState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloneSnapshotState>() {
            public CloneSnapshotState findValueByNumber(int number) {
              return CloneSnapshotState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final CloneSnapshotState[] VALUES = values();

    public static CloneSnapshotState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CloneSnapshotState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CloneSnapshotState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RestoreSnapshotState}
   */
  public enum RestoreSnapshotState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>RESTORE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    RESTORE_SNAPSHOT_PRE_OPERATION(1),
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR = 2;</code>
     */
    RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR(2),
    /**
     * <code>RESTORE_SNAPSHOT_WRITE_FS_LAYOUT = 3;</code>
     */
    RESTORE_SNAPSHOT_WRITE_FS_LAYOUT(3),
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_META = 4;</code>
     */
    RESTORE_SNAPSHOT_UPDATE_META(4),
    /**
     * <code>RESTORE_SNAPSHOT_RESTORE_ACL = 5;</code>
     */
    RESTORE_SNAPSHOT_RESTORE_ACL(5),
    ;

    /**
     * <code>RESTORE_SNAPSHOT_PRE_OPERATION = 1;</code>
     */
    public static final int RESTORE_SNAPSHOT_PRE_OPERATION_VALUE = 1;
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR = 2;</code>
     */
    public static final int RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR_VALUE = 2;
    /**
     * <code>RESTORE_SNAPSHOT_WRITE_FS_LAYOUT = 3;</code>
     */
    public static final int RESTORE_SNAPSHOT_WRITE_FS_LAYOUT_VALUE = 3;
    /**
     * <code>RESTORE_SNAPSHOT_UPDATE_META = 4;</code>
     */
    public static final int RESTORE_SNAPSHOT_UPDATE_META_VALUE = 4;
    /**
     * <code>RESTORE_SNAPSHOT_RESTORE_ACL = 5;</code>
     */
    public static final int RESTORE_SNAPSHOT_RESTORE_ACL_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RestoreSnapshotState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RestoreSnapshotState forNumber(int value) {
      switch (value) {
        case 1: return RESTORE_SNAPSHOT_PRE_OPERATION;
        case 2: return RESTORE_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR;
        case 3: return RESTORE_SNAPSHOT_WRITE_FS_LAYOUT;
        case 4: return RESTORE_SNAPSHOT_UPDATE_META;
        case 5: return RESTORE_SNAPSHOT_RESTORE_ACL;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RestoreSnapshotState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RestoreSnapshotState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RestoreSnapshotState>() {
            public RestoreSnapshotState findValueByNumber(int number) {
              return RestoreSnapshotState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final RestoreSnapshotState[] VALUES = values();

    public static RestoreSnapshotState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RestoreSnapshotState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RestoreSnapshotState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DispatchMergingRegionsState}
   */
  public enum DispatchMergingRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISPATCH_MERGING_REGIONS_PREPARE = 1;</code>
     */
    DISPATCH_MERGING_REGIONS_PREPARE(1),
    /**
     * <code>DISPATCH_MERGING_REGIONS_PRE_OPERATION = 2;</code>
     */
    DISPATCH_MERGING_REGIONS_PRE_OPERATION(2),
    /**
     * <code>DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS = 3;</code>
     */
    DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS(3),
    /**
     * <code>DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS = 4;</code>
     */
    DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS(4),
    /**
     * <code>DISPATCH_MERGING_REGIONS_POST_OPERATION = 5;</code>
     */
    DISPATCH_MERGING_REGIONS_POST_OPERATION(5),
    ;

    /**
     * <code>DISPATCH_MERGING_REGIONS_PREPARE = 1;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>DISPATCH_MERGING_REGIONS_PRE_OPERATION = 2;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS = 3;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS_VALUE = 3;
    /**
     * <code>DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS = 4;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS_VALUE = 4;
    /**
     * <code>DISPATCH_MERGING_REGIONS_POST_OPERATION = 5;</code>
     */
    public static final int DISPATCH_MERGING_REGIONS_POST_OPERATION_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DispatchMergingRegionsState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DispatchMergingRegionsState forNumber(int value) {
      switch (value) {
        case 1: return DISPATCH_MERGING_REGIONS_PREPARE;
        case 2: return DISPATCH_MERGING_REGIONS_PRE_OPERATION;
        case 3: return DISPATCH_MERGING_REGIONS_MOVE_REGION_TO_SAME_RS;
        case 4: return DISPATCH_MERGING_REGIONS_DO_MERGE_IN_RS;
        case 5: return DISPATCH_MERGING_REGIONS_POST_OPERATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DispatchMergingRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        DispatchMergingRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DispatchMergingRegionsState>() {
            public DispatchMergingRegionsState findValueByNumber(int number) {
              return DispatchMergingRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final DispatchMergingRegionsState[] VALUES = values();

    public static DispatchMergingRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DispatchMergingRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DispatchMergingRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SplitTableRegionState}
   */
  public enum SplitTableRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SPLIT_TABLE_REGION_PREPARE = 1;</code>
     */
    SPLIT_TABLE_REGION_PREPARE(1),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION = 2;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION(2),
    /**
     * <code>SPLIT_TABLE_REGION_CLOSE_PARENT_REGION = 3;</code>
     */
    SPLIT_TABLE_REGION_CLOSE_PARENT_REGION(3),
    /**
     * <code>SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS = 4;</code>
     */
    SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS(4),
    /**
     * <code>SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE = 5;</code>
     */
    SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE(5),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META = 6;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META(6),
    /**
     * <code>SPLIT_TABLE_REGION_UPDATE_META = 7;</code>
     */
    SPLIT_TABLE_REGION_UPDATE_META(7),
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META = 8;</code>
     */
    SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META(8),
    /**
     * <code>SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS = 9;</code>
     */
    SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS(9),
    /**
     * <code>SPLIT_TABLE_REGION_POST_OPERATION = 10;</code>
     */
    SPLIT_TABLE_REGION_POST_OPERATION(10),
    /**
     * <code>SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 11;</code>
     */
    SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS(11),
    ;

    /**
     * <code>SPLIT_TABLE_REGION_PREPARE = 1;</code>
     */
    public static final int SPLIT_TABLE_REGION_PREPARE_VALUE = 1;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION = 2;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_VALUE = 2;
    /**
     * <code>SPLIT_TABLE_REGION_CLOSE_PARENT_REGION = 3;</code>
     */
    public static final int SPLIT_TABLE_REGION_CLOSE_PARENT_REGION_VALUE = 3;
    /**
     * <code>SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS = 4;</code>
     */
    public static final int SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS_VALUE = 4;
    /**
     * <code>SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE = 5;</code>
     */
    public static final int SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE_VALUE = 5;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META = 6;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META_VALUE = 6;
    /**
     * <code>SPLIT_TABLE_REGION_UPDATE_META = 7;</code>
     */
    public static final int SPLIT_TABLE_REGION_UPDATE_META_VALUE = 7;
    /**
     * <code>SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META = 8;</code>
     */
    public static final int SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META_VALUE = 8;
    /**
     * <code>SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS = 9;</code>
     */
    public static final int SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS_VALUE = 9;
    /**
     * <code>SPLIT_TABLE_REGION_POST_OPERATION = 10;</code>
     */
    public static final int SPLIT_TABLE_REGION_POST_OPERATION_VALUE = 10;
    /**
     * <code>SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 11;</code>
     */
    public static final int SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS_VALUE = 11;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SplitTableRegionState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static SplitTableRegionState forNumber(int value) {
      switch (value) {
        case 1: return SPLIT_TABLE_REGION_PREPARE;
        case 2: return SPLIT_TABLE_REGION_PRE_OPERATION;
        case 3: return SPLIT_TABLE_REGION_CLOSE_PARENT_REGION;
        case 4: return SPLIT_TABLE_REGION_CREATE_DAUGHTER_REGIONS;
        case 5: return SPLIT_TABLE_REGION_WRITE_MAX_SEQUENCE_ID_FILE;
        case 6: return SPLIT_TABLE_REGION_PRE_OPERATION_BEFORE_META;
        case 7: return SPLIT_TABLE_REGION_UPDATE_META;
        case 8: return SPLIT_TABLE_REGION_PRE_OPERATION_AFTER_META;
        case 9: return SPLIT_TABLE_REGION_OPEN_CHILD_REGIONS;
        case 10: return SPLIT_TABLE_REGION_POST_OPERATION;
        case 11: return SPLIT_TABLE_REGIONS_CHECK_CLOSED_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitTableRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SplitTableRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitTableRegionState>() {
            public SplitTableRegionState findValueByNumber(int number) {
              return SplitTableRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final SplitTableRegionState[] VALUES = values();

    public static SplitTableRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SplitTableRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SplitTableRegionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.MergeTableRegionsState}
   */
  public enum MergeTableRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MERGE_TABLE_REGIONS_PREPARE = 1;</code>
     */
    MERGE_TABLE_REGIONS_PREPARE(1),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_OPERATION = 2;</code>
     */
    MERGE_TABLE_REGIONS_PRE_OPERATION(2),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION = 3;</code>
     */
    MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION(3),
    /**
     * <code>MERGE_TABLE_REGIONS_CLOSE_REGIONS = 4;</code>
     */
    MERGE_TABLE_REGIONS_CLOSE_REGIONS(4),
    /**
     * <code>MERGE_TABLE_REGIONS_CREATE_MERGED_REGION = 5;</code>
     */
    MERGE_TABLE_REGIONS_CREATE_MERGED_REGION(5),
    /**
     * <code>MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE = 6;</code>
     */
    MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE(6),
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION = 7;</code>
     */
    MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION(7),
    /**
     * <code>MERGE_TABLE_REGIONS_UPDATE_META = 8;</code>
     */
    MERGE_TABLE_REGIONS_UPDATE_META(8),
    /**
     * <code>MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION = 9;</code>
     */
    MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION(9),
    /**
     * <code>MERGE_TABLE_REGIONS_OPEN_MERGED_REGION = 10;</code>
     */
    MERGE_TABLE_REGIONS_OPEN_MERGED_REGION(10),
    /**
     * <code>MERGE_TABLE_REGIONS_POST_OPERATION = 11;</code>
     */
    MERGE_TABLE_REGIONS_POST_OPERATION(11),
    /**
     * <code>MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 12;</code>
     */
    MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS(12),
    ;

    /**
     * <code>MERGE_TABLE_REGIONS_PREPARE = 1;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_OPERATION = 2;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION = 3;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION_VALUE = 3;
    /**
     * <code>MERGE_TABLE_REGIONS_CLOSE_REGIONS = 4;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CLOSE_REGIONS_VALUE = 4;
    /**
     * <code>MERGE_TABLE_REGIONS_CREATE_MERGED_REGION = 5;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CREATE_MERGED_REGION_VALUE = 5;
    /**
     * <code>MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE = 6;</code>
     */
    public static final int MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE_VALUE = 6;
    /**
     * <code>MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION = 7;</code>
     */
    public static final int MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION_VALUE = 7;
    /**
     * <code>MERGE_TABLE_REGIONS_UPDATE_META = 8;</code>
     */
    public static final int MERGE_TABLE_REGIONS_UPDATE_META_VALUE = 8;
    /**
     * <code>MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION = 9;</code>
     */
    public static final int MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION_VALUE = 9;
    /**
     * <code>MERGE_TABLE_REGIONS_OPEN_MERGED_REGION = 10;</code>
     */
    public static final int MERGE_TABLE_REGIONS_OPEN_MERGED_REGION_VALUE = 10;
    /**
     * <code>MERGE_TABLE_REGIONS_POST_OPERATION = 11;</code>
     */
    public static final int MERGE_TABLE_REGIONS_POST_OPERATION_VALUE = 11;
    /**
     * <code>MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS = 12;</code>
     */
    public static final int MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS_VALUE = 12;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MergeTableRegionsState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static MergeTableRegionsState forNumber(int value) {
      switch (value) {
        case 1: return MERGE_TABLE_REGIONS_PREPARE;
        case 2: return MERGE_TABLE_REGIONS_PRE_OPERATION;
        case 3: return MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION;
        case 4: return MERGE_TABLE_REGIONS_CLOSE_REGIONS;
        case 5: return MERGE_TABLE_REGIONS_CREATE_MERGED_REGION;
        case 6: return MERGE_TABLE_REGIONS_WRITE_MAX_SEQUENCE_ID_FILE;
        case 7: return MERGE_TABLE_REGIONS_PRE_MERGE_COMMIT_OPERATION;
        case 8: return MERGE_TABLE_REGIONS_UPDATE_META;
        case 9: return MERGE_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATION;
        case 10: return MERGE_TABLE_REGIONS_OPEN_MERGED_REGION;
        case 11: return MERGE_TABLE_REGIONS_POST_OPERATION;
        case 12: return MERGE_TABLE_REGIONS_CHECK_CLOSED_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MergeTableRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        MergeTableRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MergeTableRegionsState>() {
            public MergeTableRegionsState findValueByNumber(int number) {
              return MergeTableRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(13);
    }

    private static final MergeTableRegionsState[] VALUES = values();

    public static MergeTableRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MergeTableRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.MergeTableRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ServerCrashState}
   */
  public enum ServerCrashState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    SERVER_CRASH_START(1),
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_PROCESS_META(2),
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    SERVER_CRASH_GET_REGIONS(3),
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_NO_SPLIT_LOGS(4),
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    SERVER_CRASH_SPLIT_LOGS(5),
    /**
     * <pre>
     * Removed SERVER_CRASH_PREPARE_LOG_REPLAY = 6;
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    SERVER_CRASH_ASSIGN(8),
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    SERVER_CRASH_WAIT_ON_ASSIGN(9),
    /**
     * <code>SERVER_CRASH_SPLIT_META_LOGS = 10;</code>
     */
    SERVER_CRASH_SPLIT_META_LOGS(10),
    /**
     * <code>SERVER_CRASH_ASSIGN_META = 11;</code>
     */
    SERVER_CRASH_ASSIGN_META(11),
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR = 12;</code>
     */
    SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR(12),
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_WALS_DIR = 13;</code>
     */
    SERVER_CRASH_DELETE_SPLIT_WALS_DIR(13),
    /**
     * <code>SERVER_CRASH_CLAIM_REPLICATION_QUEUES = 14;</code>
     */
    SERVER_CRASH_CLAIM_REPLICATION_QUEUES(14),
    /**
     * <code>SERVER_CRASH_HANDLE_RIT2 = 20 [deprecated = true];</code>
     */
    @java.lang.Deprecated
    SERVER_CRASH_HANDLE_RIT2(20),
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    SERVER_CRASH_FINISH(100),
    ;

    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    public static final int SERVER_CRASH_START_VALUE = 1;
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2 [deprecated = true];</code>
     */
    @java.lang.Deprecated public static final int SERVER_CRASH_PROCESS_META_VALUE = 2;
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    public static final int SERVER_CRASH_GET_REGIONS_VALUE = 3;
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4 [deprecated = true];</code>
     */
    @java.lang.Deprecated public static final int SERVER_CRASH_NO_SPLIT_LOGS_VALUE = 4;
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    public static final int SERVER_CRASH_SPLIT_LOGS_VALUE = 5;
    /**
     * <pre>
     * Removed SERVER_CRASH_PREPARE_LOG_REPLAY = 6;
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    public static final int SERVER_CRASH_ASSIGN_VALUE = 8;
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    public static final int SERVER_CRASH_WAIT_ON_ASSIGN_VALUE = 9;
    /**
     * <code>SERVER_CRASH_SPLIT_META_LOGS = 10;</code>
     */
    public static final int SERVER_CRASH_SPLIT_META_LOGS_VALUE = 10;
    /**
     * <code>SERVER_CRASH_ASSIGN_META = 11;</code>
     */
    public static final int SERVER_CRASH_ASSIGN_META_VALUE = 11;
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR = 12;</code>
     */
    public static final int SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR_VALUE = 12;
    /**
     * <code>SERVER_CRASH_DELETE_SPLIT_WALS_DIR = 13;</code>
     */
    public static final int SERVER_CRASH_DELETE_SPLIT_WALS_DIR_VALUE = 13;
    /**
     * <code>SERVER_CRASH_CLAIM_REPLICATION_QUEUES = 14;</code>
     */
    public static final int SERVER_CRASH_CLAIM_REPLICATION_QUEUES_VALUE = 14;
    /**
     * <code>SERVER_CRASH_HANDLE_RIT2 = 20 [deprecated = true];</code>
     */
    @java.lang.Deprecated public static final int SERVER_CRASH_HANDLE_RIT2_VALUE = 20;
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    public static final int SERVER_CRASH_FINISH_VALUE = 100;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ServerCrashState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ServerCrashState forNumber(int value) {
      switch (value) {
        case 1: return SERVER_CRASH_START;
        case 2: return SERVER_CRASH_PROCESS_META;
        case 3: return SERVER_CRASH_GET_REGIONS;
        case 4: return SERVER_CRASH_NO_SPLIT_LOGS;
        case 5: return SERVER_CRASH_SPLIT_LOGS;
        case 8: return SERVER_CRASH_ASSIGN;
        case 9: return SERVER_CRASH_WAIT_ON_ASSIGN;
        case 10: return SERVER_CRASH_SPLIT_META_LOGS;
        case 11: return SERVER_CRASH_ASSIGN_META;
        case 12: return SERVER_CRASH_DELETE_SPLIT_META_WALS_DIR;
        case 13: return SERVER_CRASH_DELETE_SPLIT_WALS_DIR;
        case 14: return SERVER_CRASH_CLAIM_REPLICATION_QUEUES;
        case 20: return SERVER_CRASH_HANDLE_RIT2;
        case 100: return SERVER_CRASH_FINISH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ServerCrashState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>() {
            public ServerCrashState findValueByNumber(int number) {
              return ServerCrashState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(14);
    }

    private static final ServerCrashState[] VALUES = values();

    public static ServerCrashState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ServerCrashState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ServerCrashState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RecoverMetaState}
   */
  public enum RecoverMetaState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>RECOVER_META_PREPARE = 0;</code>
     */
    RECOVER_META_PREPARE(0),
    /**
     * <code>RECOVER_META_SPLIT_LOGS = 1;</code>
     */
    RECOVER_META_SPLIT_LOGS(1),
    /**
     * <code>RECOVER_META_ASSIGN_REGIONS = 2;</code>
     */
    RECOVER_META_ASSIGN_REGIONS(2),
    ;

    /**
     * <code>RECOVER_META_PREPARE = 0;</code>
     */
    public static final int RECOVER_META_PREPARE_VALUE = 0;
    /**
     * <code>RECOVER_META_SPLIT_LOGS = 1;</code>
     */
    public static final int RECOVER_META_SPLIT_LOGS_VALUE = 1;
    /**
     * <code>RECOVER_META_ASSIGN_REGIONS = 2;</code>
     */
    public static final int RECOVER_META_ASSIGN_REGIONS_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RecoverMetaState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RecoverMetaState forNumber(int value) {
      switch (value) {
        case 0: return RECOVER_META_PREPARE;
        case 1: return RECOVER_META_SPLIT_LOGS;
        case 2: return RECOVER_META_ASSIGN_REGIONS;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverMetaState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RecoverMetaState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RecoverMetaState>() {
            public RecoverMetaState findValueByNumber(int number) {
              return RecoverMetaState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(15);
    }

    private static final RecoverMetaState[] VALUES = values();

    public static RecoverMetaState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RecoverMetaState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RecoverMetaState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionTransitionState}
   */
  public enum RegionTransitionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_TRANSITION_QUEUE = 1;</code>
     */
    REGION_TRANSITION_QUEUE(1),
    /**
     * <code>REGION_TRANSITION_DISPATCH = 2;</code>
     */
    REGION_TRANSITION_DISPATCH(2),
    /**
     * <code>REGION_TRANSITION_FINISH = 3;</code>
     */
    REGION_TRANSITION_FINISH(3),
    ;

    /**
     * <code>REGION_TRANSITION_QUEUE = 1;</code>
     */
    public static final int REGION_TRANSITION_QUEUE_VALUE = 1;
    /**
     * <code>REGION_TRANSITION_DISPATCH = 2;</code>
     */
    public static final int REGION_TRANSITION_DISPATCH_VALUE = 2;
    /**
     * <code>REGION_TRANSITION_FINISH = 3;</code>
     */
    public static final int REGION_TRANSITION_FINISH_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionTransitionState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RegionTransitionState forNumber(int value) {
      switch (value) {
        case 1: return REGION_TRANSITION_QUEUE;
        case 2: return REGION_TRANSITION_DISPATCH;
        case 3: return REGION_TRANSITION_FINISH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionTransitionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionState>() {
            public RegionTransitionState findValueByNumber(int number) {
              return RegionTransitionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(16);
    }

    private static final RegionTransitionState[] VALUES = values();

    public static RegionTransitionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionTransitionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionTransitionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.MoveRegionState}
   */
  public enum MoveRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MOVE_REGION_PREPARE = 0;</code>
     */
    MOVE_REGION_PREPARE(0),
    /**
     * <code>MOVE_REGION_UNASSIGN = 1;</code>
     */
    MOVE_REGION_UNASSIGN(1),
    /**
     * <code>MOVE_REGION_ASSIGN = 2;</code>
     */
    MOVE_REGION_ASSIGN(2),
    ;

    /**
     * <code>MOVE_REGION_PREPARE = 0;</code>
     */
    public static final int MOVE_REGION_PREPARE_VALUE = 0;
    /**
     * <code>MOVE_REGION_UNASSIGN = 1;</code>
     */
    public static final int MOVE_REGION_UNASSIGN_VALUE = 1;
    /**
     * <code>MOVE_REGION_ASSIGN = 2;</code>
     */
    public static final int MOVE_REGION_ASSIGN_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MoveRegionState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static MoveRegionState forNumber(int value) {
      switch (value) {
        case 0: return MOVE_REGION_PREPARE;
        case 1: return MOVE_REGION_UNASSIGN;
        case 2: return MOVE_REGION_ASSIGN;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MoveRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        MoveRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MoveRegionState>() {
            public MoveRegionState findValueByNumber(int number) {
              return MoveRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(17);
    }

    private static final MoveRegionState[] VALUES = values();

    public static MoveRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MoveRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.MoveRegionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.GCRegionState}
   */
  public enum GCRegionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>GC_REGION_PREPARE = 1;</code>
     */
    GC_REGION_PREPARE(1),
    /**
     * <code>GC_REGION_ARCHIVE = 2;</code>
     */
    GC_REGION_ARCHIVE(2),
    /**
     * <code>GC_REGION_PURGE_METADATA = 3;</code>
     */
    GC_REGION_PURGE_METADATA(3),
    ;

    /**
     * <code>GC_REGION_PREPARE = 1;</code>
     */
    public static final int GC_REGION_PREPARE_VALUE = 1;
    /**
     * <code>GC_REGION_ARCHIVE = 2;</code>
     */
    public static final int GC_REGION_ARCHIVE_VALUE = 2;
    /**
     * <code>GC_REGION_PURGE_METADATA = 3;</code>
     */
    public static final int GC_REGION_PURGE_METADATA_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static GCRegionState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static GCRegionState forNumber(int value) {
      switch (value) {
        case 1: return GC_REGION_PREPARE;
        case 2: return GC_REGION_ARCHIVE;
        case 3: return GC_REGION_PURGE_METADATA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCRegionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        GCRegionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCRegionState>() {
            public GCRegionState findValueByNumber(int number) {
              return GCRegionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(18);
    }

    private static final GCRegionState[] VALUES = values();

    public static GCRegionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private GCRegionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.GCRegionState)
  }

  /**
   * <pre>
   * NOTE: This message is used by GCMergedRegionStateProcedure
   * AND GCMultipleMergedRegionStateProcedure.
   * </pre>
   *
   * Protobuf enum {@code hbase.pb.GCMergedRegionsState}
   */
  public enum GCMergedRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>GC_MERGED_REGIONS_PREPARE = 1;</code>
     */
    GC_MERGED_REGIONS_PREPARE(1),
    /**
     * <code>GC_MERGED_REGIONS_PURGE = 2;</code>
     */
    GC_MERGED_REGIONS_PURGE(2),
    /**
     * <code>GC_REGION_EDIT_METADATA = 3;</code>
     */
    GC_REGION_EDIT_METADATA(3),
    ;

    /**
     * <code>GC_MERGED_REGIONS_PREPARE = 1;</code>
     */
    public static final int GC_MERGED_REGIONS_PREPARE_VALUE = 1;
    /**
     * <code>GC_MERGED_REGIONS_PURGE = 2;</code>
     */
    public static final int GC_MERGED_REGIONS_PURGE_VALUE = 2;
    /**
     * <code>GC_REGION_EDIT_METADATA = 3;</code>
     */
    public static final int GC_REGION_EDIT_METADATA_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static GCMergedRegionsState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static GCMergedRegionsState forNumber(int value) {
      switch (value) {
        case 1: return GC_MERGED_REGIONS_PREPARE;
        case 2: return GC_MERGED_REGIONS_PURGE;
        case 3: return GC_REGION_EDIT_METADATA;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCMergedRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        GCMergedRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<GCMergedRegionsState>() {
            public GCMergedRegionsState findValueByNumber(int number) {
              return GCMergedRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(19);
    }

    private static final GCMergedRegionsState[] VALUES = values();

    public static GCMergedRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private GCMergedRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.GCMergedRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.PeerModificationState}
   */
  public enum PeerModificationState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PRE_PEER_MODIFICATION = 1;</code>
     */
    PRE_PEER_MODIFICATION(1),
    /**
     * <code>UPDATE_PEER_STORAGE = 2;</code>
     */
    UPDATE_PEER_STORAGE(2),
    /**
     * <code>REFRESH_PEER_ON_RS = 3;</code>
     */
    REFRESH_PEER_ON_RS(3),
    /**
     * <code>SERIAL_PEER_REOPEN_REGIONS = 4;</code>
     */
    SERIAL_PEER_REOPEN_REGIONS(4),
    /**
     * <code>SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID = 5;</code>
     */
    SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID(5),
    /**
     * <code>SERIAL_PEER_SET_PEER_ENABLED = 6;</code>
     */
    SERIAL_PEER_SET_PEER_ENABLED(6),
    /**
     * <code>SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS = 7;</code>
     */
    SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS(7),
    /**
     * <code>POST_PEER_MODIFICATION = 8;</code>
     */
    POST_PEER_MODIFICATION(8),
    ;

    /**
     * <code>PRE_PEER_MODIFICATION = 1;</code>
     */
    public static final int PRE_PEER_MODIFICATION_VALUE = 1;
    /**
     * <code>UPDATE_PEER_STORAGE = 2;</code>
     */
    public static final int UPDATE_PEER_STORAGE_VALUE = 2;
    /**
     * <code>REFRESH_PEER_ON_RS = 3;</code>
     */
    public static final int REFRESH_PEER_ON_RS_VALUE = 3;
    /**
     * <code>SERIAL_PEER_REOPEN_REGIONS = 4;</code>
     */
    public static final int SERIAL_PEER_REOPEN_REGIONS_VALUE = 4;
    /**
     * <code>SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID = 5;</code>
     */
    public static final int SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID_VALUE = 5;
    /**
     * <code>SERIAL_PEER_SET_PEER_ENABLED = 6;</code>
     */
    public static final int SERIAL_PEER_SET_PEER_ENABLED_VALUE = 6;
    /**
     * <code>SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS = 7;</code>
     */
    public static final int SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS_VALUE = 7;
    /**
     * <code>POST_PEER_MODIFICATION = 8;</code>
     */
    public static final int POST_PEER_MODIFICATION_VALUE = 8;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static PeerModificationState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static PeerModificationState forNumber(int value) {
      switch (value) {
        case 1: return PRE_PEER_MODIFICATION;
        case 2: return UPDATE_PEER_STORAGE;
        case 3: return REFRESH_PEER_ON_RS;
        case 4: return SERIAL_PEER_REOPEN_REGIONS;
        case 5: return SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID;
        case 6: return SERIAL_PEER_SET_PEER_ENABLED;
        case 7: return SERIAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS;
        case 8: return POST_PEER_MODIFICATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        PeerModificationState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationState>() {
            public PeerModificationState findValueByNumber(int number) {
              return PeerModificationState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(20);
    }

    private static final PeerModificationState[] VALUES = values();

    public static PeerModificationState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private PeerModificationState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.PeerModificationState)
  }

  /**
   * Protobuf enum {@code hbase.pb.PeerModificationType}
   */
  public enum PeerModificationType
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ADD_PEER = 1;</code>
     */
    ADD_PEER(1),
    /**
     * <code>REMOVE_PEER = 2;</code>
     */
    REMOVE_PEER(2),
    /**
     * <code>ENABLE_PEER = 3;</code>
     */
    ENABLE_PEER(3),
    /**
     * <code>DISABLE_PEER = 4;</code>
     */
    DISABLE_PEER(4),
    /**
     * <code>UPDATE_PEER_CONFIG = 5;</code>
     */
    UPDATE_PEER_CONFIG(5),
    ;

    /**
     * <code>ADD_PEER = 1;</code>
     */
    public static final int ADD_PEER_VALUE = 1;
    /**
     * <code>REMOVE_PEER = 2;</code>
     */
    public static final int REMOVE_PEER_VALUE = 2;
    /**
     * <code>ENABLE_PEER = 3;</code>
     */
    public static final int ENABLE_PEER_VALUE = 3;
    /**
     * <code>DISABLE_PEER = 4;</code>
     */
    public static final int DISABLE_PEER_VALUE = 4;
    /**
     * <code>UPDATE_PEER_CONFIG = 5;</code>
     */
    public static final int UPDATE_PEER_CONFIG_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static PeerModificationType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static PeerModificationType forNumber(int value) {
      switch (value) {
        case 1: return ADD_PEER;
        case 2: return REMOVE_PEER;
        case 3: return ENABLE_PEER;
        case 4: return DISABLE_PEER;
        case 5: return UPDATE_PEER_CONFIG;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        PeerModificationType> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<PeerModificationType>() {
            public PeerModificationType findValueByNumber(int number) {
              return PeerModificationType.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(21);
    }

    private static final PeerModificationType[] VALUES = values();

    public static PeerModificationType valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private PeerModificationType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.PeerModificationType)
  }

  /**
   * Protobuf enum {@code hbase.pb.ReopenTableRegionsState}
   */
  public enum ReopenTableRegionsState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REOPEN_TABLE_REGIONS_GET_REGIONS = 1;</code>
     */
    REOPEN_TABLE_REGIONS_GET_REGIONS(1),
    /**
     * <code>REOPEN_TABLE_REGIONS_REOPEN_REGIONS = 2;</code>
     */
    REOPEN_TABLE_REGIONS_REOPEN_REGIONS(2),
    /**
     * <code>REOPEN_TABLE_REGIONS_CONFIRM_REOPENED = 3;</code>
     */
    REOPEN_TABLE_REGIONS_CONFIRM_REOPENED(3),
    ;

    /**
     * <code>REOPEN_TABLE_REGIONS_GET_REGIONS = 1;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_GET_REGIONS_VALUE = 1;
    /**
     * <code>REOPEN_TABLE_REGIONS_REOPEN_REGIONS = 2;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_REOPEN_REGIONS_VALUE = 2;
    /**
     * <code>REOPEN_TABLE_REGIONS_CONFIRM_REOPENED = 3;</code>
     */
    public static final int REOPEN_TABLE_REGIONS_CONFIRM_REOPENED_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ReopenTableRegionsState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ReopenTableRegionsState forNumber(int value) {
      switch (value) {
        case 1: return REOPEN_TABLE_REGIONS_GET_REGIONS;
        case 2: return REOPEN_TABLE_REGIONS_REOPEN_REGIONS;
        case 3: return REOPEN_TABLE_REGIONS_CONFIRM_REOPENED;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReopenTableRegionsState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ReopenTableRegionsState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReopenTableRegionsState>() {
            public ReopenTableRegionsState findValueByNumber(int number) {
              return ReopenTableRegionsState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(22);
    }

    private static final ReopenTableRegionsState[] VALUES = values();

    public static ReopenTableRegionsState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ReopenTableRegionsState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ReopenTableRegionsState)
  }

  /**
   * Protobuf enum {@code hbase.pb.InitMetaState}
   */
  public enum InitMetaState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>INIT_META_WRITE_FS_LAYOUT = 1;</code>
     */
    INIT_META_WRITE_FS_LAYOUT(1),
    /**
     * <code>INIT_META_ASSIGN_META = 2;</code>
     */
    INIT_META_ASSIGN_META(2),
    ;

    /**
     * <code>INIT_META_WRITE_FS_LAYOUT = 1;</code>
     */
    public static final int INIT_META_WRITE_FS_LAYOUT_VALUE = 1;
    /**
     * <code>INIT_META_ASSIGN_META = 2;</code>
     */
    public static final int INIT_META_ASSIGN_META_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static InitMetaState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static InitMetaState forNumber(int value) {
      switch (value) {
        case 1: return INIT_META_WRITE_FS_LAYOUT;
        case 2: return INIT_META_ASSIGN_META;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<InitMetaState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        InitMetaState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<InitMetaState>() {
            public InitMetaState findValueByNumber(int number) {
              return InitMetaState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(23);
    }

    private static final InitMetaState[] VALUES = values();

    public static InitMetaState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private InitMetaState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.InitMetaState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionStateTransitionState}
   */
  public enum RegionStateTransitionState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE = 1;</code>
     */
    REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE(1),
    /**
     * <code>REGION_STATE_TRANSITION_OPEN = 2;</code>
     */
    REGION_STATE_TRANSITION_OPEN(2),
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_OPENED = 3;</code>
     */
    REGION_STATE_TRANSITION_CONFIRM_OPENED(3),
    /**
     * <code>REGION_STATE_TRANSITION_CLOSE = 4;</code>
     */
    REGION_STATE_TRANSITION_CLOSE(4),
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_CLOSED = 5;</code>
     */
    REGION_STATE_TRANSITION_CONFIRM_CLOSED(5),
    ;

    /**
     * <code>REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE = 1;</code>
     */
    public static final int REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE_VALUE = 1;
    /**
     * <code>REGION_STATE_TRANSITION_OPEN = 2;</code>
     */
    public static final int REGION_STATE_TRANSITION_OPEN_VALUE = 2;
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_OPENED = 3;</code>
     */
    public static final int REGION_STATE_TRANSITION_CONFIRM_OPENED_VALUE = 3;
    /**
     * <code>REGION_STATE_TRANSITION_CLOSE = 4;</code>
     */
    public static final int REGION_STATE_TRANSITION_CLOSE_VALUE = 4;
    /**
     * <code>REGION_STATE_TRANSITION_CONFIRM_CLOSED = 5;</code>
     */
    public static final int REGION_STATE_TRANSITION_CONFIRM_CLOSED_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionStateTransitionState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RegionStateTransitionState forNumber(int value) {
      switch (value) {
        case 1: return REGION_STATE_TRANSITION_GET_ASSIGN_CANDIDATE;
        case 2: return REGION_STATE_TRANSITION_OPEN;
        case 3: return REGION_STATE_TRANSITION_CONFIRM_OPENED;
        case 4: return REGION_STATE_TRANSITION_CLOSE;
        case 5: return REGION_STATE_TRANSITION_CONFIRM_CLOSED;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionStateTransitionState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionStateTransitionState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionStateTransitionState>() {
            public RegionStateTransitionState findValueByNumber(int number) {
              return RegionStateTransitionState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(24);
    }

    private static final RegionStateTransitionState[] VALUES = values();

    public static RegionStateTransitionState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionStateTransitionState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionStateTransitionState)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionTransitionType}
   */
  public enum RegionTransitionType
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ASSIGN = 1;</code>
     */
    ASSIGN(1),
    /**
     * <code>UNASSIGN = 2;</code>
     */
    UNASSIGN(2),
    /**
     * <code>MOVE = 3;</code>
     */
    MOVE(3),
    /**
     * <code>REOPEN = 4;</code>
     */
    REOPEN(4),
    ;

    /**
     * <code>ASSIGN = 1;</code>
     */
    public static final int ASSIGN_VALUE = 1;
    /**
     * <code>UNASSIGN = 2;</code>
     */
    public static final int UNASSIGN_VALUE = 2;
    /**
     * <code>MOVE = 3;</code>
     */
    public static final int MOVE_VALUE = 3;
    /**
     * <code>REOPEN = 4;</code>
     */
    public static final int REOPEN_VALUE = 4;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionTransitionType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RegionTransitionType forNumber(int value) {
      switch (value) {
        case 1: return ASSIGN;
        case 2: return UNASSIGN;
        case 3: return MOVE;
        case 4: return REOPEN;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionTransitionType> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionTransitionType>() {
            public RegionTransitionType findValueByNumber(int number) {
              return RegionTransitionType.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(25);
    }

    private static final RegionTransitionType[] VALUES = values();

    public static RegionTransitionType valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionTransitionType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionTransitionType)
  }

  /**
   * Protobuf enum {@code hbase.pb.RegionRemoteProcedureBaseState}
   */
  public enum RegionRemoteProcedureBaseState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    REGION_REMOTE_PROCEDURE_DISPATCH(1),
    /**
     * <code>REGION_REMOTE_PROCEDURE_REPORT_SUCCEED = 2;</code>
     */
    REGION_REMOTE_PROCEDURE_REPORT_SUCCEED(2),
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH_FAIL = 3;</code>
     */
    REGION_REMOTE_PROCEDURE_DISPATCH_FAIL(3),
    /**
     * <code>REGION_REMOTE_PROCEDURE_SERVER_CRASH = 4;</code>
     */
    REGION_REMOTE_PROCEDURE_SERVER_CRASH(4),
    ;

    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_DISPATCH_VALUE = 1;
    /**
     * <code>REGION_REMOTE_PROCEDURE_REPORT_SUCCEED = 2;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_REPORT_SUCCEED_VALUE = 2;
    /**
     * <code>REGION_REMOTE_PROCEDURE_DISPATCH_FAIL = 3;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_DISPATCH_FAIL_VALUE = 3;
    /**
     * <code>REGION_REMOTE_PROCEDURE_SERVER_CRASH = 4;</code>
     */
    public static final int REGION_REMOTE_PROCEDURE_SERVER_CRASH_VALUE = 4;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static RegionRemoteProcedureBaseState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static RegionRemoteProcedureBaseState forNumber(int value) {
      switch (value) {
        case 1: return REGION_REMOTE_PROCEDURE_DISPATCH;
        case 2: return REGION_REMOTE_PROCEDURE_REPORT_SUCCEED;
        case 3: return REGION_REMOTE_PROCEDURE_DISPATCH_FAIL;
        case 4: return REGION_REMOTE_PROCEDURE_SERVER_CRASH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionRemoteProcedureBaseState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        RegionRemoteProcedureBaseState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionRemoteProcedureBaseState>() {
            public RegionRemoteProcedureBaseState findValueByNumber(int number) {
              return RegionRemoteProcedureBaseState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(26);
    }

    private static final RegionRemoteProcedureBaseState[] VALUES = values();

    public static RegionRemoteProcedureBaseState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private RegionRemoteProcedureBaseState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.RegionRemoteProcedureBaseState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ServerRemoteProcedureState}
   */
  public enum ServerRemoteProcedureState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SERVER_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    SERVER_REMOTE_PROCEDURE_DISPATCH(1),
    /**
     * <code>SERVER_REMOTE_PROCEDURE_DISPATCH_FAIL = 2;</code>
     */
    SERVER_REMOTE_PROCEDURE_DISPATCH_FAIL(2),
    /**
     * <code>SERVER_REMOTE_PROCEDURE_REPORT_SUCCEED = 3;</code>
     */
    SERVER_REMOTE_PROCEDURE_REPORT_SUCCEED(3),
    /**
     * <code>SERVER_REMOTE_PROCEDURE_REPORT_FAILED = 4;</code>
     */
    SERVER_REMOTE_PROCEDURE_REPORT_FAILED(4),
    /**
     * <code>SERVER_REMOTE_PROCEDURE_SERVER_CRASH = 5;</code>
     */
    SERVER_REMOTE_PROCEDURE_SERVER_CRASH(5),
    ;

    /**
     * <code>SERVER_REMOTE_PROCEDURE_DISPATCH = 1;</code>
     */
    public static final int SERVER_REMOTE_PROCEDURE_DISPATCH_VALUE = 1;
    /**
     * <code>SERVER_REMOTE_PROCEDURE_DISPATCH_FAIL = 2;</code>
     */
    public static final int SERVER_REMOTE_PROCEDURE_DISPATCH_FAIL_VALUE = 2;
    /**
     * <code>SERVER_REMOTE_PROCEDURE_REPORT_SUCCEED = 3;</code>
     */
    public static final int SERVER_REMOTE_PROCEDURE_REPORT_SUCCEED_VALUE = 3;
    /**
     * <code>SERVER_REMOTE_PROCEDURE_REPORT_FAILED = 4;</code>
     */
    public static final int SERVER_REMOTE_PROCEDURE_REPORT_FAILED_VALUE = 4;
    /**
     * <code>SERVER_REMOTE_PROCEDURE_SERVER_CRASH = 5;</code>
     */
    public static final int SERVER_REMOTE_PROCEDURE_SERVER_CRASH_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ServerRemoteProcedureState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ServerRemoteProcedureState forNumber(int value) {
      switch (value) {
        case 1: return SERVER_REMOTE_PROCEDURE_DISPATCH;
        case 2: return SERVER_REMOTE_PROCEDURE_DISPATCH_FAIL;
        case 3: return SERVER_REMOTE_PROCEDURE_REPORT_SUCCEED;
        case 4: return SERVER_REMOTE_PROCEDURE_REPORT_FAILED;
        case 5: return SERVER_REMOTE_PROCEDURE_SERVER_CRASH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerRemoteProcedureState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ServerRemoteProcedureState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ServerRemoteProcedureState>() {
            public ServerRemoteProcedureState findValueByNumber(int number) {
              return ServerRemoteProcedureState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(27);
    }

    private static final ServerRemoteProcedureState[] VALUES = values();

    public static ServerRemoteProcedureState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ServerRemoteProcedureState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ServerRemoteProcedureState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SwitchRpcThrottleState}
   */
  public enum SwitchRpcThrottleState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>UPDATE_SWITCH_RPC_THROTTLE_STORAGE = 1;</code>
     */
    UPDATE_SWITCH_RPC_THROTTLE_STORAGE(1),
    /**
     * <code>SWITCH_RPC_THROTTLE_ON_RS = 2;</code>
     */
    SWITCH_RPC_THROTTLE_ON_RS(2),
    /**
     * <code>POST_SWITCH_RPC_THROTTLE = 3;</code>
     */
    POST_SWITCH_RPC_THROTTLE(3),
    ;

    /**
     * <code>UPDATE_SWITCH_RPC_THROTTLE_STORAGE = 1;</code>
     */
    public static final int UPDATE_SWITCH_RPC_THROTTLE_STORAGE_VALUE = 1;
    /**
     * <code>SWITCH_RPC_THROTTLE_ON_RS = 2;</code>
     */
    public static final int SWITCH_RPC_THROTTLE_ON_RS_VALUE = 2;
    /**
     * <code>POST_SWITCH_RPC_THROTTLE = 3;</code>
     */
    public static final int POST_SWITCH_RPC_THROTTLE_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SwitchRpcThrottleState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static SwitchRpcThrottleState forNumber(int value) {
      switch (value) {
        case 1: return UPDATE_SWITCH_RPC_THROTTLE_STORAGE;
        case 2: return SWITCH_RPC_THROTTLE_ON_RS;
        case 3: return POST_SWITCH_RPC_THROTTLE;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SwitchRpcThrottleState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SwitchRpcThrottleState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SwitchRpcThrottleState>() {
            public SwitchRpcThrottleState findValueByNumber(int number) {
              return SwitchRpcThrottleState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(28);
    }

    private static final SwitchRpcThrottleState[] VALUES = values();

    public static SwitchRpcThrottleState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SwitchRpcThrottleState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SwitchRpcThrottleState)
  }

  /**
   * Protobuf enum {@code hbase.pb.SplitWALState}
   */
  public enum SplitWALState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ACQUIRE_SPLIT_WAL_WORKER = 1;</code>
     */
    ACQUIRE_SPLIT_WAL_WORKER(1),
    /**
     * <code>DISPATCH_WAL_TO_WORKER = 2;</code>
     */
    DISPATCH_WAL_TO_WORKER(2),
    /**
     * <code>RELEASE_SPLIT_WORKER = 3;</code>
     */
    RELEASE_SPLIT_WORKER(3),
    ;

    /**
     * <code>ACQUIRE_SPLIT_WAL_WORKER = 1;</code>
     */
    public static final int ACQUIRE_SPLIT_WAL_WORKER_VALUE = 1;
    /**
     * <code>DISPATCH_WAL_TO_WORKER = 2;</code>
     */
    public static final int DISPATCH_WAL_TO_WORKER_VALUE = 2;
    /**
     * <code>RELEASE_SPLIT_WORKER = 3;</code>
     */
    public static final int RELEASE_SPLIT_WORKER_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SplitWALState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static SplitWALState forNumber(int value) {
      switch (value) {
        case 1: return ACQUIRE_SPLIT_WAL_WORKER;
        case 2: return DISPATCH_WAL_TO_WORKER;
        case 3: return RELEASE_SPLIT_WORKER;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitWALState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        SplitWALState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<SplitWALState>() {
            public SplitWALState findValueByNumber(int number) {
              return SplitWALState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(29);
    }

    private static final SplitWALState[] VALUES = values();

    public static SplitWALState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private SplitWALState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.SplitWALState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ClaimReplicationQueuesState}
   */
  public enum ClaimReplicationQueuesState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLAIM_REPLICATION_QUEUES_DISPATCH = 1;</code>
     */
    CLAIM_REPLICATION_QUEUES_DISPATCH(1),
    /**
     * <code>CLAIM_REPLICATION_QUEUES_FINISH = 2;</code>
     */
    CLAIM_REPLICATION_QUEUES_FINISH(2),
    ;

    /**
     * <code>CLAIM_REPLICATION_QUEUES_DISPATCH = 1;</code>
     */
    public static final int CLAIM_REPLICATION_QUEUES_DISPATCH_VALUE = 1;
    /**
     * <code>CLAIM_REPLICATION_QUEUES_FINISH = 2;</code>
     */
    public static final int CLAIM_REPLICATION_QUEUES_FINISH_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ClaimReplicationQueuesState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ClaimReplicationQueuesState forNumber(int value) {
      switch (value) {
        case 1: return CLAIM_REPLICATION_QUEUES_DISPATCH;
        case 2: return CLAIM_REPLICATION_QUEUES_FINISH;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ClaimReplicationQueuesState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ClaimReplicationQueuesState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ClaimReplicationQueuesState>() {
            public ClaimReplicationQueuesState findValueByNumber(int number) {
              return ClaimReplicationQueuesState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(30);
    }

    private static final ClaimReplicationQueuesState[] VALUES = values();

    public static ClaimReplicationQueuesState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ClaimReplicationQueuesState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ClaimReplicationQueuesState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyTableDescriptorState}
   */
  public enum ModifyTableDescriptorState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_TABLE_DESCRIPTOR_PREPARE = 1;</code>
     */
    MODIFY_TABLE_DESCRIPTOR_PREPARE(1),
    /**
     * <code>MODIFY_TABLE_DESCRIPTOR_UPDATE = 2;</code>
     */
    MODIFY_TABLE_DESCRIPTOR_UPDATE(2),
    ;

    /**
     * <code>MODIFY_TABLE_DESCRIPTOR_PREPARE = 1;</code>
     */
    public static final int MODIFY_TABLE_DESCRIPTOR_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_TABLE_DESCRIPTOR_UPDATE = 2;</code>
     */
    public static final int MODIFY_TABLE_DESCRIPTOR_UPDATE_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyTableDescriptorState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyTableDescriptorState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_TABLE_DESCRIPTOR_PREPARE;
        case 2: return MODIFY_TABLE_DESCRIPTOR_UPDATE;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableDescriptorState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyTableDescriptorState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyTableDescriptorState>() {
            public ModifyTableDescriptorState findValueByNumber(int number) {
              return ModifyTableDescriptorState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(31);
    }

    private static final ModifyTableDescriptorState[] VALUES = values();

    public static ModifyTableDescriptorState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyTableDescriptorState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyTableDescriptorState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyStoreFileTrackerState}
   */
  public enum ModifyStoreFileTrackerState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIGRATION = 1;</code>
     */
    MODIFY_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIGRATION(1),
    /**
     * <code>MODIFY_STORE_FILE_TRACKER_START_MIGRATION = 2;</code>
     */
    MODIFY_STORE_FILE_TRACKER_START_MIGRATION(2),
    /**
     * <code>MODIFY_STORE_FILE_TRACKER_FINISH_MIGRATION = 3;</code>
     */
    MODIFY_STORE_FILE_TRACKER_FINISH_MIGRATION(3),
    ;

    /**
     * <code>MODIFY_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIGRATION = 1;</code>
     */
    public static final int MODIFY_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIGRATION_VALUE = 1;
    /**
     * <code>MODIFY_STORE_FILE_TRACKER_START_MIGRATION = 2;</code>
     */
    public static final int MODIFY_STORE_FILE_TRACKER_START_MIGRATION_VALUE = 2;
    /**
     * <code>MODIFY_STORE_FILE_TRACKER_FINISH_MIGRATION = 3;</code>
     */
    public static final int MODIFY_STORE_FILE_TRACKER_FINISH_MIGRATION_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyStoreFileTrackerState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyStoreFileTrackerState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIGRATION;
        case 2: return MODIFY_STORE_FILE_TRACKER_START_MIGRATION;
        case 3: return MODIFY_STORE_FILE_TRACKER_FINISH_MIGRATION;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyStoreFileTrackerState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ModifyStoreFileTrackerState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ModifyStoreFileTrackerState>() {
            public ModifyStoreFileTrackerState findValueByNumber(int number) {
              return ModifyStoreFileTrackerState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(32);
    }

    private static final ModifyStoreFileTrackerState[] VALUES = values();

    public static ModifyStoreFileTrackerState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyStoreFileTrackerState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyStoreFileTrackerState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CloseExcessRegionReplicasProcedureState}
   */
  public enum CloseExcessRegionReplicasProcedureState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLOSE_EXCESS_REGION_REPLICAS_SCHEDULE = 1;</code>
     */
    CLOSE_EXCESS_REGION_REPLICAS_SCHEDULE(1),
    /**
     * <code>CLOSE_EXCESS_REGION_REPLICAS_CONFIRM = 2;</code>
     */
    CLOSE_EXCESS_REGION_REPLICAS_CONFIRM(2),
    ;

    /**
     * <code>CLOSE_EXCESS_REGION_REPLICAS_SCHEDULE = 1;</code>
     */
    public static final int CLOSE_EXCESS_REGION_REPLICAS_SCHEDULE_VALUE = 1;
    /**
     * <code>CLOSE_EXCESS_REGION_REPLICAS_CONFIRM = 2;</code>
     */
    public static final int CLOSE_EXCESS_REGION_REPLICAS_CONFIRM_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CloseExcessRegionReplicasProcedureState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CloseExcessRegionReplicasProcedureState forNumber(int value) {
      switch (value) {
        case 1: return CLOSE_EXCESS_REGION_REPLICAS_SCHEDULE;
        case 2: return CLOSE_EXCESS_REGION_REPLICAS_CONFIRM;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloseExcessRegionReplicasProcedureState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CloseExcessRegionReplicasProcedureState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloseExcessRegionReplicasProcedureState>() {
            public CloseExcessRegionReplicasProcedureState findValueByNumber(int number) {
              return CloseExcessRegionReplicasProcedureState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(33);
    }

    private static final CloseExcessRegionReplicasProcedureState[] VALUES = values();

    public static CloseExcessRegionReplicasProcedureState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CloseExcessRegionReplicasProcedureState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CloseExcessRegionReplicasProcedureState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CloseTableRegionsProcedureState}
   */
  public enum CloseTableRegionsProcedureState
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLOSE_TABLE_REGIONS_SCHEDULE = 1;</code>
     */
    CLOSE_TABLE_REGIONS_SCHEDULE(1),
    /**
     * <code>CLOSE_TABLE_REGIONS_CONFIRM = 2;</code>
     */
    CLOSE_TABLE_REGIONS_CONFIRM(2),
    ;

    /**
     * <code>CLOSE_TABLE_REGIONS_SCHEDULE = 1;</code>
     */
    public static final int CLOSE_TABLE_REGIONS_SCHEDULE_VALUE = 1;
    /**
     * <code>CLOSE_TABLE_REGIONS_CONFIRM = 2;</code>
     */
    public static final int CLOSE_TABLE_REGIONS_CONFIRM_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CloseTableRegionsProcedureState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CloseTableRegionsProcedureState forNumber(int value) {
      switch (value) {
        case 1: return CLOSE_TABLE_REGIONS_SCHEDULE;
        case 2: return CLOSE_TABLE_REGIONS_CONFIRM;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloseTableRegionsProcedureState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        CloseTableRegionsProcedureState> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CloseTableRegionsProcedureState>() {
            public CloseTableRegionsProcedureState findValueByNumber(int number) {
              return CloseTableRegionsProcedureState.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(34);
    }

    private static final CloseTableRegionsProcedureState[] VALUES = values();

    public static CloseTableRegionsProcedureState valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CloseTableRegionsProcedureState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CloseTableRegionsProcedureState)
  }

  public interface CreateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return Whether the tableSchema field is set.
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return The tableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CreateTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class CreateTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateTableStateData)
      CreateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateTableStateData.newBuilder() to construct.
    private CreateTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return Whether the tableSchema field is set.
     */
    @java.lang.Override
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return The tableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableSchema() != other.hasTableSchema()) return false;
      if (hasTableSchema()) {
        if (!getTableSchema()
            .equals(other.getTableSchema())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableSchema_ = tableSchemaBuilder_ == null
              ? tableSchema_
              : tableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       * @return Whether the tableSchema field is set.
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       * @return The tableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            tableSchema_ != null &&
            tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getTableSchemaBuilder().mergeFrom(value);
          } else {
            tableSchema_ = value;
          }
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        if (tableSchema_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder clearTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CreateTableStateData>() {
      @java.lang.Override
      public CreateTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return The unmodifiedTableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return Whether the deleteColumnFamilyInModify field is set.
     */
    boolean hasDeleteColumnFamilyInModify();
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return The deleteColumnFamilyInModify.
     */
    boolean getDeleteColumnFamilyInModify();

    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     * @return Whether the shouldCheckDescriptor field is set.
     */
    boolean hasShouldCheckDescriptor();
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     * @return The shouldCheckDescriptor.
     */
    boolean getShouldCheckDescriptor();

    /**
     * <code>optional bool reopen_regions = 6;</code>
     * @return Whether the reopenRegions field is set.
     */
    boolean hasReopenRegions();
    /**
     * <code>optional bool reopen_regions = 6;</code>
     * @return The reopenRegions.
     */
    boolean getReopenRegions();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class ModifyTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyTableStateData)
      ModifyTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyTableStateData.newBuilder() to construct.
    private ModifyTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    @java.lang.Override
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return The unmodifiedTableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    @java.lang.Override
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    public static final int DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER = 4;
    private boolean deleteColumnFamilyInModify_ = false;
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return Whether the deleteColumnFamilyInModify field is set.
     */
    @java.lang.Override
    public boolean hasDeleteColumnFamilyInModify() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return The deleteColumnFamilyInModify.
     */
    @java.lang.Override
    public boolean getDeleteColumnFamilyInModify() {
      return deleteColumnFamilyInModify_;
    }

    public static final int SHOULD_CHECK_DESCRIPTOR_FIELD_NUMBER = 5;
    private boolean shouldCheckDescriptor_ = false;
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     * @return Whether the shouldCheckDescriptor field is set.
     */
    @java.lang.Override
    public boolean hasShouldCheckDescriptor() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional bool should_check_descriptor = 5;</code>
     * @return The shouldCheckDescriptor.
     */
    @java.lang.Override
    public boolean getShouldCheckDescriptor() {
      return shouldCheckDescriptor_;
    }

    public static final int REOPEN_REGIONS_FIELD_NUMBER = 6;
    private boolean reopenRegions_ = false;
    /**
     * <code>optional bool reopen_regions = 6;</code>
     * @return Whether the reopenRegions field is set.
     */
    @java.lang.Override
    public boolean hasReopenRegions() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool reopen_regions = 6;</code>
     * @return The reopenRegions.
     */
    @java.lang.Override
    public boolean getReopenRegions() {
      return reopenRegions_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDeleteColumnFamilyInModify()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(4, deleteColumnFamilyInModify_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(5, shouldCheckDescriptor_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(6, reopenRegions_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, deleteColumnFamilyInModify_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, shouldCheckDescriptor_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, reopenRegions_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasUnmodifiedTableSchema() != other.hasUnmodifiedTableSchema()) return false;
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema())) return false;
      }
      if (hasModifiedTableSchema() != other.hasModifiedTableSchema()) return false;
      if (hasModifiedTableSchema()) {
        if (!getModifiedTableSchema()
            .equals(other.getModifiedTableSchema())) return false;
      }
      if (hasDeleteColumnFamilyInModify() != other.hasDeleteColumnFamilyInModify()) return false;
      if (hasDeleteColumnFamilyInModify()) {
        if (getDeleteColumnFamilyInModify()
            != other.getDeleteColumnFamilyInModify()) return false;
      }
      if (hasShouldCheckDescriptor() != other.hasShouldCheckDescriptor()) return false;
      if (hasShouldCheckDescriptor()) {
        if (getShouldCheckDescriptor()
            != other.getShouldCheckDescriptor()) return false;
      }
      if (hasReopenRegions() != other.hasReopenRegions()) return false;
      if (hasReopenRegions()) {
        if (getReopenRegions()
            != other.getReopenRegions()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (hasDeleteColumnFamilyInModify()) {
        hash = (37 * hash) + DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getDeleteColumnFamilyInModify());
      }
      if (hasShouldCheckDescriptor()) {
        hash = (37 * hash) + SHOULD_CHECK_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldCheckDescriptor());
      }
      if (hasReopenRegions()) {
        hash = (37 * hash) + REOPEN_REGIONS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getReopenRegions());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        unmodifiedTableSchema_ = null;
        if (unmodifiedTableSchemaBuilder_ != null) {
          unmodifiedTableSchemaBuilder_.dispose();
          unmodifiedTableSchemaBuilder_ = null;
        }
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        deleteColumnFamilyInModify_ = false;
        shouldCheckDescriptor_ = false;
        reopenRegions_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_ == null
              ? unmodifiedTableSchema_
              : unmodifiedTableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_ == null
              ? modifiedTableSchema_
              : modifiedTableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.deleteColumnFamilyInModify_ = deleteColumnFamilyInModify_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.shouldCheckDescriptor_ = shouldCheckDescriptor_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.reopenRegions_ = reopenRegions_;
          to_bitField0_ |= 0x00000020;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (other.hasDeleteColumnFamilyInModify()) {
          setDeleteColumnFamilyInModify(other.getDeleteColumnFamilyInModify());
        }
        if (other.hasShouldCheckDescriptor()) {
          setShouldCheckDescriptor(other.getShouldCheckDescriptor());
        }
        if (other.hasReopenRegions()) {
          setReopenRegions(other.getReopenRegions());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasModifiedTableSchema()) {
          return false;
        }
        if (!hasDeleteColumnFamilyInModify()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        if (!getModifiedTableSchema().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getUnmodifiedTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getModifiedTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                deleteColumnFamilyInModify_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 40: {
                shouldCheckDescriptor_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 48: {
                reopenRegions_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       * @return Whether the unmodifiedTableSchema field is set.
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       * @return The unmodifiedTableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            unmodifiedTableSchema_ != null &&
            unmodifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getUnmodifiedTableSchemaBuilder().mergeFrom(value);
          } else {
            unmodifiedTableSchema_ = value;
          }
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        if (unmodifiedTableSchema_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000002);
        unmodifiedTableSchema_ = null;
        if (unmodifiedTableSchemaBuilder_ != null) {
          unmodifiedTableSchemaBuilder_.dispose();
          unmodifiedTableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return Whether the modifiedTableSchema field is set.
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return The modifiedTableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            modifiedTableSchema_ != null &&
            modifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getModifiedTableSchemaBuilder().mergeFrom(value);
          } else {
            modifiedTableSchema_ = value;
          }
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        if (modifiedTableSchema_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000004);
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      private boolean deleteColumnFamilyInModify_ ;
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return Whether the deleteColumnFamilyInModify field is set.
       */
      @java.lang.Override
      public boolean hasDeleteColumnFamilyInModify() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return The deleteColumnFamilyInModify.
       */
      @java.lang.Override
      public boolean getDeleteColumnFamilyInModify() {
        return deleteColumnFamilyInModify_;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @param value The deleteColumnFamilyInModify to set.
       * @return This builder for chaining.
       */
      public Builder setDeleteColumnFamilyInModify(boolean value) {

        deleteColumnFamilyInModify_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearDeleteColumnFamilyInModify() {
        bitField0_ = (bitField0_ & ~0x00000008);
        deleteColumnFamilyInModify_ = false;
        onChanged();
        return this;
      }

      private boolean shouldCheckDescriptor_ ;
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       * @return Whether the shouldCheckDescriptor field is set.
       */
      @java.lang.Override
      public boolean hasShouldCheckDescriptor() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       * @return The shouldCheckDescriptor.
       */
      @java.lang.Override
      public boolean getShouldCheckDescriptor() {
        return shouldCheckDescriptor_;
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       * @param value The shouldCheckDescriptor to set.
       * @return This builder for chaining.
       */
      public Builder setShouldCheckDescriptor(boolean value) {

        shouldCheckDescriptor_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_check_descriptor = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearShouldCheckDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldCheckDescriptor_ = false;
        onChanged();
        return this;
      }

      private boolean reopenRegions_ ;
      /**
       * <code>optional bool reopen_regions = 6;</code>
       * @return Whether the reopenRegions field is set.
       */
      @java.lang.Override
      public boolean hasReopenRegions() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool reopen_regions = 6;</code>
       * @return The reopenRegions.
       */
      @java.lang.Override
      public boolean getReopenRegions() {
        return reopenRegions_;
      }
      /**
       * <code>optional bool reopen_regions = 6;</code>
       * @param value The reopenRegions to set.
       * @return This builder for chaining.
       */
      public Builder setReopenRegions(boolean value) {

        reopenRegions_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool reopen_regions = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearReopenRegions() {
        bitField0_ = (bitField0_ & ~0x00000020);
        reopenRegions_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyTableStateData>() {
      @java.lang.Override
      public ModifyTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TruncateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TruncateTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return Whether the preserveSplits field is set.
     */
    boolean hasPreserveSplits();
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return The preserveSplits.
     */
    boolean getPreserveSplits();

    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return Whether the tableSchema field is set.
     */
    boolean hasTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return The tableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.TruncateTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class TruncateTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TruncateTableStateData)
      TruncateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TruncateTableStateData.newBuilder() to construct.
    private TruncateTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TruncateTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TruncateTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int PRESERVE_SPLITS_FIELD_NUMBER = 2;
    private boolean preserveSplits_ = false;
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return Whether the preserveSplits field is set.
     */
    @java.lang.Override
    public boolean hasPreserveSplits() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return The preserveSplits.
     */
    @java.lang.Override
    public boolean getPreserveSplits() {
      return preserveSplits_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return Whether the tableSchema field is set.
     */
    @java.lang.Override
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return The tableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPreserveSplits()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasTableSchema()) {
        if (!getTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(5, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasPreserveSplits() != other.hasPreserveSplits()) return false;
      if (hasPreserveSplits()) {
        if (getPreserveSplits()
            != other.getPreserveSplits()) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasTableSchema() != other.hasTableSchema()) return false;
      if (hasTableSchema()) {
        if (!getTableSchema()
            .equals(other.getTableSchema())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasPreserveSplits()) {
        hash = (37 * hash) + PRESERVE_SPLITS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getPreserveSplits());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TruncateTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TruncateTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        preserveSplits_ = false;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.preserveSplits_ = preserveSplits_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.tableSchema_ = tableSchemaBuilder_ == null
              ? tableSchema_
              : tableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasPreserveSplits()) {
          setPreserveSplits(other.getPreserveSplits());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasPreserveSplits()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            return false;
          }
        }
        if (hasTableSchema()) {
          if (!getTableSchema().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                preserveSplits_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                input.readMessage(
                    getTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 42
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private boolean preserveSplits_ ;
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return Whether the preserveSplits field is set.
       */
      @java.lang.Override
      public boolean hasPreserveSplits() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return The preserveSplits.
       */
      @java.lang.Override
      public boolean getPreserveSplits() {
        return preserveSplits_;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @param value The preserveSplits to set.
       * @return This builder for chaining.
       */
      public Builder setPreserveSplits(boolean value) {

        preserveSplits_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearPreserveSplits() {
        bitField0_ = (bitField0_ & ~0x00000002);
        preserveSplits_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       * @return Whether the tableSchema field is set.
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       * @return The tableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            tableSchema_ != null &&
            tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getTableSchemaBuilder().mergeFrom(value);
          } else {
            tableSchema_ = value;
          }
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        if (tableSchema_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder clearTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000008);
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TruncateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TruncateTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<TruncateTableStateData>() {
      @java.lang.Override
      public TruncateTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<TruncateTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class DeleteTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteTableStateData)
      DeleteTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteTableStateData.newBuilder() to construct.
    private DeleteTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeleteTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DeleteTableStateData>() {
      @java.lang.Override
      public DeleteTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CreateNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public static final class CreateNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateNamespaceStateData)
      CreateNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateNamespaceStateData.newBuilder() to construct.
    private CreateNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateNamespaceStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateNamespaceStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    @java.lang.Override
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) obj;

      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_ == null
              ? namespaceDescriptor_
              : namespaceDescriptorBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getNamespaceDescriptorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            namespaceDescriptor_ != null &&
            namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            getNamespaceDescriptorBuilder().mergeFrom(value);
          } else {
            namespaceDescriptor_ = value;
          }
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        if (namespaceDescriptor_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CreateNamespaceStateData>() {
      @java.lang.Override
      public CreateNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CreateNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return Whether the unmodifiedNamespaceDescriptor field is set.
     */
    boolean hasUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return The unmodifiedNamespaceDescriptor.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public static final class ModifyNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyNamespaceStateData)
      ModifyNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyNamespaceStateData.newBuilder() to construct.
    private ModifyNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyNamespaceStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyNamespaceStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    @java.lang.Override
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    public static final int UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return Whether the unmodifiedNamespaceDescriptor field is set.
     */
    @java.lang.Override
    public boolean hasUnmodifiedNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return The unmodifiedNamespaceDescriptor.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getUnmodifiedNamespaceDescriptor());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedNamespaceDescriptor());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) obj;

      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (hasUnmodifiedNamespaceDescriptor() != other.hasUnmodifiedNamespaceDescriptor()) return false;
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor()
            .equals(other.getUnmodifiedNamespaceDescriptor())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        hash = (37 * hash) + UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
          getUnmodifiedNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        unmodifiedNamespaceDescriptor_ = null;
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          unmodifiedNamespaceDescriptorBuilder_.dispose();
          unmodifiedNamespaceDescriptorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_ == null
              ? namespaceDescriptor_
              : namespaceDescriptorBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptorBuilder_ == null
              ? unmodifiedNamespaceDescriptor_
              : unmodifiedNamespaceDescriptorBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        if (other.hasUnmodifiedNamespaceDescriptor()) {
          mergeUnmodifiedNamespaceDescriptor(other.getUnmodifiedNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedNamespaceDescriptor()) {
          if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getNamespaceDescriptorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getUnmodifiedNamespaceDescriptorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            namespaceDescriptor_ != null &&
            namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            getNamespaceDescriptorBuilder().mergeFrom(value);
          } else {
            namespaceDescriptor_ = value;
          }
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        if (namespaceDescriptor_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> unmodifiedNamespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       * @return Whether the unmodifiedNamespaceDescriptor field is set.
       */
      public boolean hasUnmodifiedNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       * @return The unmodifiedNamespaceDescriptor.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        } else {
          return unmodifiedNamespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedNamespaceDescriptor_ = value;
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = builderForValue.build();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder mergeUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            unmodifiedNamespaceDescriptor_ != null &&
            unmodifiedNamespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            getUnmodifiedNamespaceDescriptorBuilder().mergeFrom(value);
          } else {
            unmodifiedNamespaceDescriptor_ = value;
          }
        } else {
          unmodifiedNamespaceDescriptorBuilder_.mergeFrom(value);
        }
        if (unmodifiedNamespaceDescriptor_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder clearUnmodifiedNamespaceDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000002);
        unmodifiedNamespaceDescriptor_ = null;
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          unmodifiedNamespaceDescriptorBuilder_.dispose();
          unmodifiedNamespaceDescriptorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getUnmodifiedNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          return unmodifiedNamespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedNamespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getUnmodifiedNamespaceDescriptorFieldBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getUnmodifiedNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          unmodifiedNamespaceDescriptor_ = null;
        }
        return unmodifiedNamespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyNamespaceStateData>() {
      @java.lang.Override
      public ModifyNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteNamespaceStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string namespace_name = 1;</code>
     * @return Whether the namespaceName field is set.
     */
    boolean hasNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The namespaceName.
     */
    java.lang.String getNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The bytes for namespaceName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNamespaceNameBytes();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
   */
  @javax.annotation.Generated("proto") public static final class DeleteNamespaceStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteNamespaceStateData)
      DeleteNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteNamespaceStateData.newBuilder() to construct.
    private DeleteNamespaceStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteNamespaceStateData() {
      namespaceName_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeleteNamespaceStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object namespaceName_ = "";
    /**
     * <code>required string namespace_name = 1;</code>
     * @return Whether the namespaceName field is set.
     */
    @java.lang.Override
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The namespaceName.
     */
    @java.lang.Override
    public java.lang.String getNamespaceName() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          namespaceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The bytes for namespaceName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNamespaceNameBytes() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        namespaceName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    @java.lang.Override
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return The namespaceDescriptor.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getNamespaceDescriptor());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getNamespaceDescriptor());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) obj;

      if (hasNamespaceName() != other.hasNamespaceName()) return false;
      if (hasNamespaceName()) {
        if (!getNamespaceName()
            .equals(other.getNamespaceName())) return false;
      }
      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteNamespaceStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        namespaceName_ = "";
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.namespaceName_ = namespaceName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_ == null
              ? namespaceDescriptor_
              : namespaceDescriptorBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceName()) {
          namespaceName_ = other.namespaceName_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceName()) {
          return false;
        }
        if (hasNamespaceDescriptor()) {
          if (!getNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                namespaceName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getNamespaceDescriptorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object namespaceName_ = "";
      /**
       * <code>required string namespace_name = 1;</code>
       * @return Whether the namespaceName field is set.
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return The namespaceName.
       */
      public java.lang.String getNamespaceName() {
        java.lang.Object ref = namespaceName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            namespaceName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return The bytes for namespaceName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getNamespaceNameBytes() {
        java.lang.Object ref = namespaceName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          namespaceName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @param value The namespaceName to set.
       * @return This builder for chaining.
       */
      public Builder setNamespaceName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        namespaceName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearNamespaceName() {
        namespaceName_ = getDefaultInstance().getNamespaceName();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @param value The bytes for namespaceName to set.
       * @return This builder for chaining.
       */
      public Builder setNamespaceNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        namespaceName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            namespaceDescriptor_ != null &&
            namespaceDescriptor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            getNamespaceDescriptorBuilder().mergeFrom(value);
          } else {
            namespaceDescriptor_ = value;
          }
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        if (namespaceDescriptor_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder clearNamespaceDescriptor() {
        bitField0_ = (bitField0_ & ~0x00000002);
        namespaceDescriptor_ = null;
        if (namespaceDescriptorBuilder_ != null) {
          namespaceDescriptorBuilder_.dispose();
          namespaceDescriptorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteNamespaceStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DeleteNamespaceStateData>() {
      @java.lang.Override
      public DeleteNamespaceStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DeleteNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface EnableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.EnableTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
     *     See MasterProcedure.proto;l=170
     * @return Whether the skipTableStateCheck field is set.
     */
    @java.lang.Deprecated boolean hasSkipTableStateCheck();
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
     *     See MasterProcedure.proto;l=170
     * @return The skipTableStateCheck.
     */
    @java.lang.Deprecated boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.EnableTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class EnableTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.EnableTableStateData)
      EnableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use EnableTableStateData.newBuilder() to construct.
    private EnableTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private EnableTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new EnableTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_ = false;
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
     *     See MasterProcedure.proto;l=170
     * @return Whether the skipTableStateCheck field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * not used any more, always false
     * </pre>
     *
     * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
     *     See MasterProcedure.proto;l=170
     * @return The skipTableStateCheck.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasSkipTableStateCheck() != other.hasSkipTableStateCheck()) return false;
      if (hasSkipTableStateCheck()) {
        if (getSkipTableStateCheck()
            != other.getSkipTableStateCheck()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnableTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.EnableTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        skipTableStateCheck_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.skipTableStateCheck_ = skipTableStateCheck_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                skipTableStateCheck_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
       *     See MasterProcedure.proto;l=170
       * @return Whether the skipTableStateCheck field is set.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
       *     See MasterProcedure.proto;l=170
       * @return The skipTableStateCheck.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
       *     See MasterProcedure.proto;l=170
       * @param value The skipTableStateCheck to set.
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder setSkipTableStateCheck(boolean value) {

        skipTableStateCheck_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * not used any more, always false
       * </pre>
       *
       * <code>required bool skip_table_state_check = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.EnableTableStateData.skip_table_state_check is deprecated.
       *     See MasterProcedure.proto;l=170
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.EnableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnableTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<EnableTableStateData>() {
      @java.lang.Override
      public EnableTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnableTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DisableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DisableTableStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.DisableTableStateData}
   */
  @javax.annotation.Generated("proto") public static final class DisableTableStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DisableTableStateData)
      DisableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DisableTableStateData.newBuilder() to construct.
    private DisableTableStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DisableTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DisableTableStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_ = false;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    @java.lang.Override
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    @java.lang.Override
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasSkipTableStateCheck() != other.hasSkipTableStateCheck()) return false;
      if (hasSkipTableStateCheck()) {
        if (getSkipTableStateCheck()
            != other.getSkipTableStateCheck()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisableTableStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DisableTableStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        skipTableStateCheck_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.skipTableStateCheck_ = skipTableStateCheck_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                skipTableStateCheck_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return Whether the skipTableStateCheck field is set.
       */
      @java.lang.Override
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return The skipTableStateCheck.
       */
      @java.lang.Override
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @param value The skipTableStateCheck to set.
       * @return This builder for chaining.
       */
      public Builder setSkipTableStateCheck(boolean value) {

        skipTableStateCheck_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DisableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisableTableStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DisableTableStateData>() {
      @java.lang.Override
      public DisableTableStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisableTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RestoreParentToChildRegionsPairOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RestoreParentToChildRegionsPair)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string parent_region_name = 1;</code>
     * @return Whether the parentRegionName field is set.
     */
    boolean hasParentRegionName();
    /**
     * <code>required string parent_region_name = 1;</code>
     * @return The parentRegionName.
     */
    java.lang.String getParentRegionName();
    /**
     * <code>required string parent_region_name = 1;</code>
     * @return The bytes for parentRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getParentRegionNameBytes();

    /**
     * <code>required string child1_region_name = 2;</code>
     * @return Whether the child1RegionName field is set.
     */
    boolean hasChild1RegionName();
    /**
     * <code>required string child1_region_name = 2;</code>
     * @return The child1RegionName.
     */
    java.lang.String getChild1RegionName();
    /**
     * <code>required string child1_region_name = 2;</code>
     * @return The bytes for child1RegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild1RegionNameBytes();

    /**
     * <code>required string child2_region_name = 3;</code>
     * @return Whether the child2RegionName field is set.
     */
    boolean hasChild2RegionName();
    /**
     * <code>required string child2_region_name = 3;</code>
     * @return The child2RegionName.
     */
    java.lang.String getChild2RegionName();
    /**
     * <code>required string child2_region_name = 3;</code>
     * @return The bytes for child2RegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild2RegionNameBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.RestoreParentToChildRegionsPair}
   */
  @javax.annotation.Generated("proto") public static final class RestoreParentToChildRegionsPair extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RestoreParentToChildRegionsPair)
      RestoreParentToChildRegionsPairOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RestoreParentToChildRegionsPair.newBuilder() to construct.
    private RestoreParentToChildRegionsPair(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RestoreParentToChildRegionsPair() {
      parentRegionName_ = "";
      child1RegionName_ = "";
      child2RegionName_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RestoreParentToChildRegionsPair();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder.class);
    }

    private int bitField0_;
    public static final int PARENT_REGION_NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object parentRegionName_ = "";
    /**
     * <code>required string parent_region_name = 1;</code>
     * @return Whether the parentRegionName field is set.
     */
    @java.lang.Override
    public boolean hasParentRegionName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string parent_region_name = 1;</code>
     * @return The parentRegionName.
     */
    @java.lang.Override
    public java.lang.String getParentRegionName() {
      java.lang.Object ref = parentRegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          parentRegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string parent_region_name = 1;</code>
     * @return The bytes for parentRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getParentRegionNameBytes() {
      java.lang.Object ref = parentRegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        parentRegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CHILD1_REGION_NAME_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object child1RegionName_ = "";
    /**
     * <code>required string child1_region_name = 2;</code>
     * @return Whether the child1RegionName field is set.
     */
    @java.lang.Override
    public boolean hasChild1RegionName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string child1_region_name = 2;</code>
     * @return The child1RegionName.
     */
    @java.lang.Override
    public java.lang.String getChild1RegionName() {
      java.lang.Object ref = child1RegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          child1RegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string child1_region_name = 2;</code>
     * @return The bytes for child1RegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild1RegionNameBytes() {
      java.lang.Object ref = child1RegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        child1RegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CHILD2_REGION_NAME_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object child2RegionName_ = "";
    /**
     * <code>required string child2_region_name = 3;</code>
     * @return Whether the child2RegionName field is set.
     */
    @java.lang.Override
    public boolean hasChild2RegionName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required string child2_region_name = 3;</code>
     * @return The child2RegionName.
     */
    @java.lang.Override
    public java.lang.String getChild2RegionName() {
      java.lang.Object ref = child2RegionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          child2RegionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string child2_region_name = 3;</code>
     * @return The bytes for child2RegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getChild2RegionNameBytes() {
      java.lang.Object ref = child2RegionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        child2RegionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasParentRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasChild1RegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasChild2RegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, parentRegionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, child1RegionName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, child2RegionName_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, parentRegionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, child1RegionName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, child2RegionName_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair) obj;

      if (hasParentRegionName() != other.hasParentRegionName()) return false;
      if (hasParentRegionName()) {
        if (!getParentRegionName()
            .equals(other.getParentRegionName())) return false;
      }
      if (hasChild1RegionName() != other.hasChild1RegionName()) return false;
      if (hasChild1RegionName()) {
        if (!getChild1RegionName()
            .equals(other.getChild1RegionName())) return false;
      }
      if (hasChild2RegionName() != other.hasChild2RegionName()) return false;
      if (hasChild2RegionName()) {
        if (!getChild2RegionName()
            .equals(other.getChild2RegionName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasParentRegionName()) {
        hash = (37 * hash) + PARENT_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getParentRegionName().hashCode();
      }
      if (hasChild1RegionName()) {
        hash = (37 * hash) + CHILD1_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getChild1RegionName().hashCode();
      }
      if (hasChild2RegionName()) {
        hash = (37 * hash) + CHILD2_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getChild2RegionName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RestoreParentToChildRegionsPair}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RestoreParentToChildRegionsPair)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        parentRegionName_ = "";
        child1RegionName_ = "";
        child2RegionName_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.parentRegionName_ = parentRegionName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.child1RegionName_ = child1RegionName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.child2RegionName_ = child2RegionName_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance()) return this;
        if (other.hasParentRegionName()) {
          parentRegionName_ = other.parentRegionName_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasChild1RegionName()) {
          child1RegionName_ = other.child1RegionName_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasChild2RegionName()) {
          child2RegionName_ = other.child2RegionName_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasParentRegionName()) {
          return false;
        }
        if (!hasChild1RegionName()) {
          return false;
        }
        if (!hasChild2RegionName()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                parentRegionName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                child1RegionName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                child2RegionName_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object parentRegionName_ = "";
      /**
       * <code>required string parent_region_name = 1;</code>
       * @return Whether the parentRegionName field is set.
       */
      public boolean hasParentRegionName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       * @return The parentRegionName.
       */
      public java.lang.String getParentRegionName() {
        java.lang.Object ref = parentRegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            parentRegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       * @return The bytes for parentRegionName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getParentRegionNameBytes() {
        java.lang.Object ref = parentRegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          parentRegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       * @param value The parentRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setParentRegionName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        parentRegionName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearParentRegionName() {
        parentRegionName_ = getDefaultInstance().getParentRegionName();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string parent_region_name = 1;</code>
       * @param value The bytes for parentRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setParentRegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        parentRegionName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private java.lang.Object child1RegionName_ = "";
      /**
       * <code>required string child1_region_name = 2;</code>
       * @return Whether the child1RegionName field is set.
       */
      public boolean hasChild1RegionName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       * @return The child1RegionName.
       */
      public java.lang.String getChild1RegionName() {
        java.lang.Object ref = child1RegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            child1RegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       * @return The bytes for child1RegionName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getChild1RegionNameBytes() {
        java.lang.Object ref = child1RegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          child1RegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       * @param value The child1RegionName to set.
       * @return This builder for chaining.
       */
      public Builder setChild1RegionName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        child1RegionName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearChild1RegionName() {
        child1RegionName_ = getDefaultInstance().getChild1RegionName();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string child1_region_name = 2;</code>
       * @param value The bytes for child1RegionName to set.
       * @return This builder for chaining.
       */
      public Builder setChild1RegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        child1RegionName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object child2RegionName_ = "";
      /**
       * <code>required string child2_region_name = 3;</code>
       * @return Whether the child2RegionName field is set.
       */
      public boolean hasChild2RegionName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       * @return The child2RegionName.
       */
      public java.lang.String getChild2RegionName() {
        java.lang.Object ref = child2RegionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            child2RegionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       * @return The bytes for child2RegionName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getChild2RegionNameBytes() {
        java.lang.Object ref = child2RegionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          child2RegionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       * @param value The child2RegionName to set.
       * @return This builder for chaining.
       */
      public Builder setChild2RegionName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        child2RegionName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearChild2RegionName() {
        child2RegionName_ = getDefaultInstance().getChild2RegionName();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>required string child2_region_name = 3;</code>
       * @param value The bytes for child2RegionName to set.
       * @return This builder for chaining.
       */
      public Builder setChild2RegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        child2RegionName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreParentToChildRegionsPair)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreParentToChildRegionsPair)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RestoreParentToChildRegionsPair>() {
      @java.lang.Override
      public RestoreParentToChildRegionsPair parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreParentToChildRegionsPair> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloneSnapshotStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloneSnapshotStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return Whether the snapshot field is set.
     */
    boolean hasSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return The snapshot.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     * @return Whether the tableSchema field is set.
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     * @return The tableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> 
        getParentToChildRegionsPairListList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index);
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    int getParentToChildRegionsPairListCount();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index);

    /**
     * <code>optional bool restore_acl = 6;</code>
     * @return Whether the restoreAcl field is set.
     */
    boolean hasRestoreAcl();
    /**
     * <code>optional bool restore_acl = 6;</code>
     * @return The restoreAcl.
     */
    boolean getRestoreAcl();

    /**
     * <code>optional string customSFT = 7;</code>
     * @return Whether the customSFT field is set.
     */
    boolean hasCustomSFT();
    /**
     * <code>optional string customSFT = 7;</code>
     * @return The customSFT.
     */
    java.lang.String getCustomSFT();
    /**
     * <code>optional string customSFT = 7;</code>
     * @return The bytes for customSFT.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCustomSFTBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.CloneSnapshotStateData}
   */
  @javax.annotation.Generated("proto") public static final class CloneSnapshotStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloneSnapshotStateData)
      CloneSnapshotStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloneSnapshotStateData.newBuilder() to construct.
    private CloneSnapshotStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloneSnapshotStateData() {
      regionInfo_ = java.util.Collections.emptyList();
      parentToChildRegionsPairList_ = java.util.Collections.emptyList();
      customSFT_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloneSnapshotStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int SNAPSHOT_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return Whether the snapshot field is set.
     */
    @java.lang.Override
    public boolean hasSnapshot() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return The snapshot.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     * @return Whether the tableSchema field is set.
     */
    @java.lang.Override
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     * @return The tableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_;
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    @java.lang.Override
    public int getParentToChildRegionsPairListCount() {
      return parentToChildRegionsPairList_.size();
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
      return parentToChildRegionsPairList_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index) {
      return parentToChildRegionsPairList_.get(index);
    }

    public static final int RESTORE_ACL_FIELD_NUMBER = 6;
    private boolean restoreAcl_ = false;
    /**
     * <code>optional bool restore_acl = 6;</code>
     * @return Whether the restoreAcl field is set.
     */
    @java.lang.Override
    public boolean hasRestoreAcl() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool restore_acl = 6;</code>
     * @return The restoreAcl.
     */
    @java.lang.Override
    public boolean getRestoreAcl() {
      return restoreAcl_;
    }

    public static final int CUSTOMSFT_FIELD_NUMBER = 7;
    @SuppressWarnings("serial")
    private volatile java.lang.Object customSFT_ = "";
    /**
     * <code>optional string customSFT = 7;</code>
     * @return Whether the customSFT field is set.
     */
    @java.lang.Override
    public boolean hasCustomSFT() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional string customSFT = 7;</code>
     * @return The customSFT.
     */
    @java.lang.Override
    public java.lang.String getCustomSFT() {
      java.lang.Object ref = customSFT_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          customSFT_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string customSFT = 7;</code>
     * @return The bytes for customSFT.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCustomSFTBytes() {
      java.lang.Object ref = customSFT_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        customSFT_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSnapshot()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSnapshot().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
        if (!getParentToChildRegionsPairList(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(4, regionInfo_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        output.writeMessage(5, parentToChildRegionsPairList_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(6, restoreAcl_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 7, customSFT_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionInfo_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, parentToChildRegionsPairList_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, restoreAcl_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(7, customSFT_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasSnapshot() != other.hasSnapshot()) return false;
      if (hasSnapshot()) {
        if (!getSnapshot()
            .equals(other.getSnapshot())) return false;
      }
      if (hasTableSchema() != other.hasTableSchema()) return false;
      if (hasTableSchema()) {
        if (!getTableSchema()
            .equals(other.getTableSchema())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!getParentToChildRegionsPairListList()
          .equals(other.getParentToChildRegionsPairListList())) return false;
      if (hasRestoreAcl() != other.hasRestoreAcl()) return false;
      if (hasRestoreAcl()) {
        if (getRestoreAcl()
            != other.getRestoreAcl()) return false;
      }
      if (hasCustomSFT() != other.hasCustomSFT()) return false;
      if (hasCustomSFT()) {
        if (!getCustomSFT()
            .equals(other.getCustomSFT())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasSnapshot()) {
        hash = (37 * hash) + SNAPSHOT_FIELD_NUMBER;
        hash = (53 * hash) + getSnapshot().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (getParentToChildRegionsPairListCount() > 0) {
        hash = (37 * hash) + PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER;
        hash = (53 * hash) + getParentToChildRegionsPairListList().hashCode();
      }
      if (hasRestoreAcl()) {
        hash = (37 * hash) + RESTORE_ACL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRestoreAcl());
      }
      if (hasCustomSFT()) {
        hash = (37 * hash) + CUSTOMSFT_FIELD_NUMBER;
        hash = (53 * hash) + getCustomSFT().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloneSnapshotStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloneSnapshotStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getSnapshotFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
          getParentToChildRegionsPairListFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        snapshot_ = null;
        if (snapshotBuilder_ != null) {
          snapshotBuilder_.dispose();
          snapshotBuilder_ = null;
        }
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
        } else {
          parentToChildRegionsPairList_ = null;
          parentToChildRegionsPairListBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        restoreAcl_ = false;
        customSFT_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairList_;
        } else {
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairListBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.snapshot_ = snapshotBuilder_ == null
              ? snapshot_
              : snapshotBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.tableSchema_ = tableSchemaBuilder_ == null
              ? tableSchema_
              : tableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.restoreAcl_ = restoreAcl_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.customSFT_ = customSFT_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasSnapshot()) {
          mergeSnapshot(other.getSnapshot());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairList_.isEmpty()) {
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureParentToChildRegionsPairListIsMutable();
              parentToChildRegionsPairList_.addAll(other.parentToChildRegionsPairList_);
            }
            onChanged();
          }
        } else {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairListBuilder_.isEmpty()) {
              parentToChildRegionsPairListBuilder_.dispose();
              parentToChildRegionsPairListBuilder_ = null;
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000010);
              parentToChildRegionsPairListBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentToChildRegionsPairListFieldBuilder() : null;
            } else {
              parentToChildRegionsPairListBuilder_.addAllMessages(other.parentToChildRegionsPairList_);
            }
          }
        }
        if (other.hasRestoreAcl()) {
          setRestoreAcl(other.getRestoreAcl());
        }
        if (other.hasCustomSFT()) {
          customSFT_ = other.customSFT_;
          bitField0_ |= 0x00000040;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasSnapshot()) {
          return false;
        }
        if (!hasTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getSnapshot().isInitialized()) {
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
          if (!getParentToChildRegionsPairList(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getSnapshotFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 34
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.PARSER,
                        extensionRegistry);
                if (parentToChildRegionsPairListBuilder_ == null) {
                  ensureParentToChildRegionsPairListIsMutable();
                  parentToChildRegionsPairList_.add(m);
                } else {
                  parentToChildRegionsPairListBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 48: {
                restoreAcl_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 58: {
                customSFT_ = input.readBytes();
                bitField0_ |= 0x00000040;
                break;
              } // case 58
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> snapshotBuilder_;
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       * @return Whether the snapshot field is set.
       */
      public boolean hasSnapshot() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       * @return The snapshot.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
        if (snapshotBuilder_ == null) {
          return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        } else {
          return snapshotBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          snapshot_ = value;
        } else {
          snapshotBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder builderForValue) {
        if (snapshotBuilder_ == null) {
          snapshot_ = builderForValue.build();
        } else {
          snapshotBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder mergeSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            snapshot_ != null &&
            snapshot_ != org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance()) {
            getSnapshotBuilder().mergeFrom(value);
          } else {
            snapshot_ = value;
          }
        } else {
          snapshotBuilder_.mergeFrom(value);
        }
        if (snapshot_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder clearSnapshot() {
        bitField0_ = (bitField0_ & ~0x00000002);
        snapshot_ = null;
        if (snapshotBuilder_ != null) {
          snapshotBuilder_.dispose();
          snapshotBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder getSnapshotBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSnapshotFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
        if (snapshotBuilder_ != null) {
          return snapshotBuilder_.getMessageOrBuilder();
        } else {
          return snapshot_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> 
          getSnapshotFieldBuilder() {
        if (snapshotBuilder_ == null) {
          snapshotBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder>(
                  getSnapshot(),
                  getParentForChildren(),
                  isClean());
          snapshot_ = null;
        }
        return snapshotBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       * @return Whether the tableSchema field is set.
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       * @return The tableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            tableSchema_ != null &&
            tableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getTableSchemaBuilder().mergeFrom(value);
          } else {
            tableSchema_ = value;
          }
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        if (tableSchema_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public Builder clearTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000004);
        tableSchema_ = null;
        if (tableSchemaBuilder_ != null) {
          tableSchemaBuilder_.dispose();
          tableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000008;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000008) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_ =
        java.util.Collections.emptyList();
      private void ensureParentToChildRegionsPairListIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>(parentToChildRegionsPairList_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> parentToChildRegionsPairListBuilder_;

      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public int getParentToChildRegionsPairListCount() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.size();
        } else {
          return parentToChildRegionsPairListBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder addAllParentToChildRegionsPairList(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> values) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parentToChildRegionsPairList_);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder clearParentToChildRegionsPairList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public Builder removeParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.remove(index);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder getParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
          int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);  } else {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
           getParentToChildRegionsPairListOrBuilderList() {
        if (parentToChildRegionsPairListBuilder_ != null) {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder() {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder> 
           getParentToChildRegionsPairListBuilderList() {
        return getParentToChildRegionsPairListFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
          getParentToChildRegionsPairListFieldBuilder() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairListBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder>(
                  parentToChildRegionsPairList_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          parentToChildRegionsPairList_ = null;
        }
        return parentToChildRegionsPairListBuilder_;
      }

      private boolean restoreAcl_ ;
      /**
       * <code>optional bool restore_acl = 6;</code>
       * @return Whether the restoreAcl field is set.
       */
      @java.lang.Override
      public boolean hasRestoreAcl() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool restore_acl = 6;</code>
       * @return The restoreAcl.
       */
      @java.lang.Override
      public boolean getRestoreAcl() {
        return restoreAcl_;
      }
      /**
       * <code>optional bool restore_acl = 6;</code>
       * @param value The restoreAcl to set.
       * @return This builder for chaining.
       */
      public Builder setRestoreAcl(boolean value) {

        restoreAcl_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool restore_acl = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearRestoreAcl() {
        bitField0_ = (bitField0_ & ~0x00000020);
        restoreAcl_ = false;
        onChanged();
        return this;
      }

      private java.lang.Object customSFT_ = "";
      /**
       * <code>optional string customSFT = 7;</code>
       * @return Whether the customSFT field is set.
       */
      public boolean hasCustomSFT() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional string customSFT = 7;</code>
       * @return The customSFT.
       */
      public java.lang.String getCustomSFT() {
        java.lang.Object ref = customSFT_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            customSFT_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string customSFT = 7;</code>
       * @return The bytes for customSFT.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getCustomSFTBytes() {
        java.lang.Object ref = customSFT_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          customSFT_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string customSFT = 7;</code>
       * @param value The customSFT to set.
       * @return This builder for chaining.
       */
      public Builder setCustomSFT(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        customSFT_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional string customSFT = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearCustomSFT() {
        customSFT_ = getDefaultInstance().getCustomSFT();
        bitField0_ = (bitField0_ & ~0x00000040);
        onChanged();
        return this;
      }
      /**
       * <code>optional string customSFT = 7;</code>
       * @param value The bytes for customSFT to set.
       * @return This builder for chaining.
       */
      public Builder setCustomSFTBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        customSFT_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloneSnapshotStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloneSnapshotStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloneSnapshotStateData>() {
      @java.lang.Override
      public CloneSnapshotStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloneSnapshotStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloneSnapshotStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RestoreSnapshotStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RestoreSnapshotStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return Whether the snapshot field is set.
     */
    boolean hasSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return The snapshot.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot();
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForRestoreList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    int getRegionInfoForRestoreCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRestoreOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForRemoveList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    int getRegionInfoForRemoveCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRemoveOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoForAddList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    int getRegionInfoForAddCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForAddOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> 
        getParentToChildRegionsPairListList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index);
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    int getParentToChildRegionsPairListCount();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index);

    /**
     * <code>optional bool restore_acl = 8;</code>
     * @return Whether the restoreAcl field is set.
     */
    boolean hasRestoreAcl();
    /**
     * <code>optional bool restore_acl = 8;</code>
     * @return The restoreAcl.
     */
    boolean getRestoreAcl();
  }
  /**
   * Protobuf type {@code hbase.pb.RestoreSnapshotStateData}
   */
  @javax.annotation.Generated("proto") public static final class RestoreSnapshotStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RestoreSnapshotStateData)
      RestoreSnapshotStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RestoreSnapshotStateData.newBuilder() to construct.
    private RestoreSnapshotStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RestoreSnapshotStateData() {
      regionInfoForRestore_ = java.util.Collections.emptyList();
      regionInfoForRemove_ = java.util.Collections.emptyList();
      regionInfoForAdd_ = java.util.Collections.emptyList();
      parentToChildRegionsPairList_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RestoreSnapshotStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int SNAPSHOT_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return Whether the snapshot field is set.
     */
    @java.lang.Override
    public boolean hasSnapshot() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     * @return The snapshot.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }
    /**
     * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
      return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    @java.lang.Override
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    public static final int REGION_INFO_FOR_RESTORE_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRestore_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRestoreList() {
      return regionInfoForRestore_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRestoreOrBuilderList() {
      return regionInfoForRestore_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    @java.lang.Override
    public int getRegionInfoForRestoreCount() {
      return regionInfoForRestore_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index) {
      return regionInfoForRestore_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
        int index) {
      return regionInfoForRestore_.get(index);
    }

    public static final int REGION_INFO_FOR_REMOVE_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRemove_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRemoveList() {
      return regionInfoForRemove_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForRemoveOrBuilderList() {
      return regionInfoForRemove_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    @java.lang.Override
    public int getRegionInfoForRemoveCount() {
      return regionInfoForRemove_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index) {
      return regionInfoForRemove_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
        int index) {
      return regionInfoForRemove_.get(index);
    }

    public static final int REGION_INFO_FOR_ADD_FIELD_NUMBER = 6;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForAdd_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForAddList() {
      return regionInfoForAdd_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoForAddOrBuilderList() {
      return regionInfoForAdd_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    @java.lang.Override
    public int getRegionInfoForAddCount() {
      return regionInfoForAdd_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index) {
      return regionInfoForAdd_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
        int index) {
      return regionInfoForAdd_.get(index);
    }

    public static final int PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER = 7;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_;
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
        getParentToChildRegionsPairListOrBuilderList() {
      return parentToChildRegionsPairList_;
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    @java.lang.Override
    public int getParentToChildRegionsPairListCount() {
      return parentToChildRegionsPairList_.size();
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
      return parentToChildRegionsPairList_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
        int index) {
      return parentToChildRegionsPairList_.get(index);
    }

    public static final int RESTORE_ACL_FIELD_NUMBER = 8;
    private boolean restoreAcl_ = false;
    /**
     * <code>optional bool restore_acl = 8;</code>
     * @return Whether the restoreAcl field is set.
     */
    @java.lang.Override
    public boolean hasRestoreAcl() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool restore_acl = 8;</code>
     * @return The restoreAcl.
     */
    @java.lang.Override
    public boolean getRestoreAcl() {
      return restoreAcl_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSnapshot()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSnapshot().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoForRestoreCount(); i++) {
        if (!getRegionInfoForRestore(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoForRemoveCount(); i++) {
        if (!getRegionInfoForRemove(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoForAddCount(); i++) {
        if (!getRegionInfoForAdd(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
        if (!getParentToChildRegionsPairList(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getModifiedTableSchema());
      }
      for (int i = 0; i < regionInfoForRestore_.size(); i++) {
        output.writeMessage(4, regionInfoForRestore_.get(i));
      }
      for (int i = 0; i < regionInfoForRemove_.size(); i++) {
        output.writeMessage(5, regionInfoForRemove_.get(i));
      }
      for (int i = 0; i < regionInfoForAdd_.size(); i++) {
        output.writeMessage(6, regionInfoForAdd_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        output.writeMessage(7, parentToChildRegionsPairList_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(8, restoreAcl_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSnapshot());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getModifiedTableSchema());
      }
      for (int i = 0; i < regionInfoForRestore_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionInfoForRestore_.get(i));
      }
      for (int i = 0; i < regionInfoForRemove_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfoForRemove_.get(i));
      }
      for (int i = 0; i < regionInfoForAdd_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, regionInfoForAdd_.get(i));
      }
      for (int i = 0; i < parentToChildRegionsPairList_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, parentToChildRegionsPairList_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, restoreAcl_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasSnapshot() != other.hasSnapshot()) return false;
      if (hasSnapshot()) {
        if (!getSnapshot()
            .equals(other.getSnapshot())) return false;
      }
      if (hasModifiedTableSchema() != other.hasModifiedTableSchema()) return false;
      if (hasModifiedTableSchema()) {
        if (!getModifiedTableSchema()
            .equals(other.getModifiedTableSchema())) return false;
      }
      if (!getRegionInfoForRestoreList()
          .equals(other.getRegionInfoForRestoreList())) return false;
      if (!getRegionInfoForRemoveList()
          .equals(other.getRegionInfoForRemoveList())) return false;
      if (!getRegionInfoForAddList()
          .equals(other.getRegionInfoForAddList())) return false;
      if (!getParentToChildRegionsPairListList()
          .equals(other.getParentToChildRegionsPairListList())) return false;
      if (hasRestoreAcl() != other.hasRestoreAcl()) return false;
      if (hasRestoreAcl()) {
        if (getRestoreAcl()
            != other.getRestoreAcl()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasSnapshot()) {
        hash = (37 * hash) + SNAPSHOT_FIELD_NUMBER;
        hash = (53 * hash) + getSnapshot().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (getRegionInfoForRestoreCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_RESTORE_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForRestoreList().hashCode();
      }
      if (getRegionInfoForRemoveCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_REMOVE_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForRemoveList().hashCode();
      }
      if (getRegionInfoForAddCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FOR_ADD_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoForAddList().hashCode();
      }
      if (getParentToChildRegionsPairListCount() > 0) {
        hash = (37 * hash) + PARENT_TO_CHILD_REGIONS_PAIR_LIST_FIELD_NUMBER;
        hash = (53 * hash) + getParentToChildRegionsPairListList().hashCode();
      }
      if (hasRestoreAcl()) {
        hash = (37 * hash) + RESTORE_ACL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRestoreAcl());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RestoreSnapshotStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RestoreSnapshotStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getSnapshotFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
          getRegionInfoForRestoreFieldBuilder();
          getRegionInfoForRemoveFieldBuilder();
          getRegionInfoForAddFieldBuilder();
          getParentToChildRegionsPairListFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        snapshot_ = null;
        if (snapshotBuilder_ != null) {
          snapshotBuilder_.dispose();
          snapshotBuilder_ = null;
        }
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestore_ = java.util.Collections.emptyList();
        } else {
          regionInfoForRestore_ = null;
          regionInfoForRestoreBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemove_ = java.util.Collections.emptyList();
        } else {
          regionInfoForRemove_ = null;
          regionInfoForRemoveBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAdd_ = java.util.Collections.emptyList();
        } else {
          regionInfoForAdd_ = null;
          regionInfoForAddBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
        } else {
          parentToChildRegionsPairList_ = null;
          parentToChildRegionsPairListBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        restoreAcl_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)) {
            regionInfoForRestore_ = java.util.Collections.unmodifiableList(regionInfoForRestore_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionInfoForRestore_ = regionInfoForRestore_;
        } else {
          result.regionInfoForRestore_ = regionInfoForRestoreBuilder_.build();
        }
        if (regionInfoForRemoveBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            regionInfoForRemove_ = java.util.Collections.unmodifiableList(regionInfoForRemove_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfoForRemove_ = regionInfoForRemove_;
        } else {
          result.regionInfoForRemove_ = regionInfoForRemoveBuilder_.build();
        }
        if (regionInfoForAddBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0)) {
            regionInfoForAdd_ = java.util.Collections.unmodifiableList(regionInfoForAdd_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.regionInfoForAdd_ = regionInfoForAdd_;
        } else {
          result.regionInfoForAdd_ = regionInfoForAddBuilder_.build();
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (((bitField0_ & 0x00000040) != 0)) {
            parentToChildRegionsPairList_ = java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairList_;
        } else {
          result.parentToChildRegionsPairList_ = parentToChildRegionsPairListBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.snapshot_ = snapshotBuilder_ == null
              ? snapshot_
              : snapshotBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_ == null
              ? modifiedTableSchema_
              : modifiedTableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.restoreAcl_ = restoreAcl_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasSnapshot()) {
          mergeSnapshot(other.getSnapshot());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (regionInfoForRestoreBuilder_ == null) {
          if (!other.regionInfoForRestore_.isEmpty()) {
            if (regionInfoForRestore_.isEmpty()) {
              regionInfoForRestore_ = other.regionInfoForRestore_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionInfoForRestoreIsMutable();
              regionInfoForRestore_.addAll(other.regionInfoForRestore_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForRestore_.isEmpty()) {
            if (regionInfoForRestoreBuilder_.isEmpty()) {
              regionInfoForRestoreBuilder_.dispose();
              regionInfoForRestoreBuilder_ = null;
              regionInfoForRestore_ = other.regionInfoForRestore_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionInfoForRestoreBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForRestoreFieldBuilder() : null;
            } else {
              regionInfoForRestoreBuilder_.addAllMessages(other.regionInfoForRestore_);
            }
          }
        }
        if (regionInfoForRemoveBuilder_ == null) {
          if (!other.regionInfoForRemove_.isEmpty()) {
            if (regionInfoForRemove_.isEmpty()) {
              regionInfoForRemove_ = other.regionInfoForRemove_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoForRemoveIsMutable();
              regionInfoForRemove_.addAll(other.regionInfoForRemove_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForRemove_.isEmpty()) {
            if (regionInfoForRemoveBuilder_.isEmpty()) {
              regionInfoForRemoveBuilder_.dispose();
              regionInfoForRemoveBuilder_ = null;
              regionInfoForRemove_ = other.regionInfoForRemove_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoForRemoveBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForRemoveFieldBuilder() : null;
            } else {
              regionInfoForRemoveBuilder_.addAllMessages(other.regionInfoForRemove_);
            }
          }
        }
        if (regionInfoForAddBuilder_ == null) {
          if (!other.regionInfoForAdd_.isEmpty()) {
            if (regionInfoForAdd_.isEmpty()) {
              regionInfoForAdd_ = other.regionInfoForAdd_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureRegionInfoForAddIsMutable();
              regionInfoForAdd_.addAll(other.regionInfoForAdd_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfoForAdd_.isEmpty()) {
            if (regionInfoForAddBuilder_.isEmpty()) {
              regionInfoForAddBuilder_.dispose();
              regionInfoForAddBuilder_ = null;
              regionInfoForAdd_ = other.regionInfoForAdd_;
              bitField0_ = (bitField0_ & ~0x00000020);
              regionInfoForAddBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoForAddFieldBuilder() : null;
            } else {
              regionInfoForAddBuilder_.addAllMessages(other.regionInfoForAdd_);
            }
          }
        }
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairList_.isEmpty()) {
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureParentToChildRegionsPairListIsMutable();
              parentToChildRegionsPairList_.addAll(other.parentToChildRegionsPairList_);
            }
            onChanged();
          }
        } else {
          if (!other.parentToChildRegionsPairList_.isEmpty()) {
            if (parentToChildRegionsPairListBuilder_.isEmpty()) {
              parentToChildRegionsPairListBuilder_.dispose();
              parentToChildRegionsPairListBuilder_ = null;
              parentToChildRegionsPairList_ = other.parentToChildRegionsPairList_;
              bitField0_ = (bitField0_ & ~0x00000040);
              parentToChildRegionsPairListBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentToChildRegionsPairListFieldBuilder() : null;
            } else {
              parentToChildRegionsPairListBuilder_.addAllMessages(other.parentToChildRegionsPairList_);
            }
          }
        }
        if (other.hasRestoreAcl()) {
          setRestoreAcl(other.getRestoreAcl());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasSnapshot()) {
          return false;
        }
        if (!hasModifiedTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getSnapshot().isInitialized()) {
          return false;
        }
        if (!getModifiedTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoForRestoreCount(); i++) {
          if (!getRegionInfoForRestore(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoForRemoveCount(); i++) {
          if (!getRegionInfoForRemove(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoForAddCount(); i++) {
          if (!getRegionInfoForAdd(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getParentToChildRegionsPairListCount(); i++) {
          if (!getParentToChildRegionsPairList(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getSnapshotFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getModifiedTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoForRestoreBuilder_ == null) {
                  ensureRegionInfoForRestoreIsMutable();
                  regionInfoForRestore_.add(m);
                } else {
                  regionInfoForRestoreBuilder_.addMessage(m);
                }
                break;
              } // case 34
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoForRemoveBuilder_ == null) {
                  ensureRegionInfoForRemoveIsMutable();
                  regionInfoForRemove_.add(m);
                } else {
                  regionInfoForRemoveBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 50: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoForAddBuilder_ == null) {
                  ensureRegionInfoForAddIsMutable();
                  regionInfoForAdd_.add(m);
                } else {
                  regionInfoForAddBuilder_.addMessage(m);
                }
                break;
              } // case 50
              case 58: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.PARSER,
                        extensionRegistry);
                if (parentToChildRegionsPairListBuilder_ == null) {
                  ensureParentToChildRegionsPairListIsMutable();
                  parentToChildRegionsPairList_.add(m);
                } else {
                  parentToChildRegionsPairListBuilder_.addMessage(m);
                }
                break;
              } // case 58
              case 64: {
                restoreAcl_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> snapshotBuilder_;
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       * @return Whether the snapshot field is set.
       */
      public boolean hasSnapshot() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       * @return The snapshot.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription getSnapshot() {
        if (snapshotBuilder_ == null) {
          return snapshot_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        } else {
          return snapshotBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          snapshot_ = value;
        } else {
          snapshotBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder setSnapshot(
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder builderForValue) {
        if (snapshotBuilder_ == null) {
          snapshot_ = builderForValue.build();
        } else {
          snapshotBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder mergeSnapshot(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription value) {
        if (snapshotBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            snapshot_ != null &&
            snapshot_ != org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance()) {
            getSnapshotBuilder().mergeFrom(value);
          } else {
            snapshot_ = value;
          }
        } else {
          snapshotBuilder_.mergeFrom(value);
        }
        if (snapshot_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public Builder clearSnapshot() {
        bitField0_ = (bitField0_ & ~0x00000002);
        snapshot_ = null;
        if (snapshotBuilder_ != null) {
          snapshotBuilder_.dispose();
          snapshotBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder getSnapshotBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSnapshotFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder getSnapshotOrBuilder() {
        if (snapshotBuilder_ != null) {
          return snapshotBuilder_.getMessageOrBuilder();
        } else {
          return snapshot_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.getDefaultInstance() : snapshot_;
        }
      }
      /**
       * <code>required .hbase.pb.SnapshotDescription snapshot = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder> 
          getSnapshotFieldBuilder() {
        if (snapshotBuilder_ == null) {
          snapshotBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescriptionOrBuilder>(
                  getSnapshot(),
                  getParentForChildren(),
                  isClean());
          snapshot_ = null;
        }
        return snapshotBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return Whether the modifiedTableSchema field is set.
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return The modifiedTableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            modifiedTableSchema_ != null &&
            modifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getModifiedTableSchemaBuilder().mergeFrom(value);
          } else {
            modifiedTableSchema_ = value;
          }
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        if (modifiedTableSchema_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000004);
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRestore_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForRestoreIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          regionInfoForRestore_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForRestore_);
          bitField0_ |= 0x00000008;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForRestoreBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRestoreList() {
        if (regionInfoForRestoreBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForRestore_);
        } else {
          return regionInfoForRestoreBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public int getRegionInfoForRestoreCount() {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.size();
        } else {
          return regionInfoForRestoreBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRestore(int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.get(index);
        } else {
          return regionInfoForRestoreBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder setRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.set(index, value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder setRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRestoreBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(index, value);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addRegionInfoForRestore(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder addAllRegionInfoForRestore(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForRestore_);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder clearRegionInfoForRestore() {
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestore_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public Builder removeRegionInfoForRestore(int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          ensureRegionInfoForRestoreIsMutable();
          regionInfoForRestore_.remove(index);
          onChanged();
        } else {
          regionInfoForRestoreBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForRestoreBuilder(
          int index) {
        return getRegionInfoForRestoreFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRestoreOrBuilder(
          int index) {
        if (regionInfoForRestoreBuilder_ == null) {
          return regionInfoForRestore_.get(index);  } else {
          return regionInfoForRestoreBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForRestoreOrBuilderList() {
        if (regionInfoForRestoreBuilder_ != null) {
          return regionInfoForRestoreBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForRestore_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRestoreBuilder() {
        return getRegionInfoForRestoreFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRestoreBuilder(
          int index) {
        return getRegionInfoForRestoreFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_restore = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForRestoreBuilderList() {
        return getRegionInfoForRestoreFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForRestoreFieldBuilder() {
        if (regionInfoForRestoreBuilder_ == null) {
          regionInfoForRestoreBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForRestore_,
                  ((bitField0_ & 0x00000008) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfoForRestore_ = null;
        }
        return regionInfoForRestoreBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForRemove_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForRemoveIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          regionInfoForRemove_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForRemove_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForRemoveBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForRemoveList() {
        if (regionInfoForRemoveBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForRemove_);
        } else {
          return regionInfoForRemoveBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public int getRegionInfoForRemoveCount() {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.size();
        } else {
          return regionInfoForRemoveBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForRemove(int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.get(index);
        } else {
          return regionInfoForRemoveBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder setRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.set(index, value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder setRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForRemoveBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(index, value);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addRegionInfoForRemove(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder addAllRegionInfoForRemove(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForRemove_);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder clearRegionInfoForRemove() {
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemove_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public Builder removeRegionInfoForRemove(int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          ensureRegionInfoForRemoveIsMutable();
          regionInfoForRemove_.remove(index);
          onChanged();
        } else {
          regionInfoForRemoveBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForRemoveBuilder(
          int index) {
        return getRegionInfoForRemoveFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForRemoveOrBuilder(
          int index) {
        if (regionInfoForRemoveBuilder_ == null) {
          return regionInfoForRemove_.get(index);  } else {
          return regionInfoForRemoveBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForRemoveOrBuilderList() {
        if (regionInfoForRemoveBuilder_ != null) {
          return regionInfoForRemoveBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForRemove_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRemoveBuilder() {
        return getRegionInfoForRemoveFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForRemoveBuilder(
          int index) {
        return getRegionInfoForRemoveFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_remove = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForRemoveBuilderList() {
        return getRegionInfoForRemoveFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForRemoveFieldBuilder() {
        if (regionInfoForRemoveBuilder_ == null) {
          regionInfoForRemoveBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForRemove_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfoForRemove_ = null;
        }
        return regionInfoForRemoveBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfoForAdd_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoForAddIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          regionInfoForAdd_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfoForAdd_);
          bitField0_ |= 0x00000020;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoForAddBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoForAddList() {
        if (regionInfoForAddBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfoForAdd_);
        } else {
          return regionInfoForAddBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public int getRegionInfoForAddCount() {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.size();
        } else {
          return regionInfoForAddBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfoForAdd(int index) {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.get(index);
        } else {
          return regionInfoForAddBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder setRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.set(index, value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder setRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoForAddBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(index, value);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addRegionInfoForAdd(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoForAddBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder addAllRegionInfoForAdd(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfoForAdd_);
          onChanged();
        } else {
          regionInfoForAddBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder clearRegionInfoForAdd() {
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAdd_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          regionInfoForAddBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public Builder removeRegionInfoForAdd(int index) {
        if (regionInfoForAddBuilder_ == null) {
          ensureRegionInfoForAddIsMutable();
          regionInfoForAdd_.remove(index);
          onChanged();
        } else {
          regionInfoForAddBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoForAddBuilder(
          int index) {
        return getRegionInfoForAddFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoForAddOrBuilder(
          int index) {
        if (regionInfoForAddBuilder_ == null) {
          return regionInfoForAdd_.get(index);  } else {
          return regionInfoForAddBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoForAddOrBuilderList() {
        if (regionInfoForAddBuilder_ != null) {
          return regionInfoForAddBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfoForAdd_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForAddBuilder() {
        return getRegionInfoForAddFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoForAddBuilder(
          int index) {
        return getRegionInfoForAddFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info_for_add = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoForAddBuilderList() {
        return getRegionInfoForAddFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoForAddFieldBuilder() {
        if (regionInfoForAddBuilder_ == null) {
          regionInfoForAddBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfoForAdd_,
                  ((bitField0_ & 0x00000020) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfoForAdd_ = null;
        }
        return regionInfoForAddBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> parentToChildRegionsPairList_ =
        java.util.Collections.emptyList();
      private void ensureParentToChildRegionsPairListIsMutable() {
        if (!((bitField0_ & 0x00000040) != 0)) {
          parentToChildRegionsPairList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair>(parentToChildRegionsPairList_);
          bitField0_ |= 0x00000040;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> parentToChildRegionsPairListBuilder_;

      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> getParentToChildRegionsPairListList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public int getParentToChildRegionsPairListCount() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.size();
        } else {
          return parentToChildRegionsPairListBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair getParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);
        } else {
          return parentToChildRegionsPairListBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder setParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair value) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, value);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addParentToChildRegionsPairList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder builderForValue) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder addAllParentToChildRegionsPairList(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair> values) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parentToChildRegionsPairList_);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder clearParentToChildRegionsPairList() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public Builder removeParentToChildRegionsPairList(int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          ensureParentToChildRegionsPairListIsMutable();
          parentToChildRegionsPairList_.remove(index);
          onChanged();
        } else {
          parentToChildRegionsPairListBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder getParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder getParentToChildRegionsPairListOrBuilder(
          int index) {
        if (parentToChildRegionsPairListBuilder_ == null) {
          return parentToChildRegionsPairList_.get(index);  } else {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
           getParentToChildRegionsPairListOrBuilderList() {
        if (parentToChildRegionsPairListBuilder_ != null) {
          return parentToChildRegionsPairListBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parentToChildRegionsPairList_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder() {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder addParentToChildRegionsPairListBuilder(
          int index) {
        return getParentToChildRegionsPairListFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RestoreParentToChildRegionsPair parent_to_child_regions_pair_list = 7;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder> 
           getParentToChildRegionsPairListBuilderList() {
        return getParentToChildRegionsPairListFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder> 
          getParentToChildRegionsPairListFieldBuilder() {
        if (parentToChildRegionsPairListBuilder_ == null) {
          parentToChildRegionsPairListBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreParentToChildRegionsPairOrBuilder>(
                  parentToChildRegionsPairList_,
                  ((bitField0_ & 0x00000040) != 0),
                  getParentForChildren(),
                  isClean());
          parentToChildRegionsPairList_ = null;
        }
        return parentToChildRegionsPairListBuilder_;
      }

      private boolean restoreAcl_ ;
      /**
       * <code>optional bool restore_acl = 8;</code>
       * @return Whether the restoreAcl field is set.
       */
      @java.lang.Override
      public boolean hasRestoreAcl() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional bool restore_acl = 8;</code>
       * @return The restoreAcl.
       */
      @java.lang.Override
      public boolean getRestoreAcl() {
        return restoreAcl_;
      }
      /**
       * <code>optional bool restore_acl = 8;</code>
       * @param value The restoreAcl to set.
       * @return This builder for chaining.
       */
      public Builder setRestoreAcl(boolean value) {

        restoreAcl_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool restore_acl = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearRestoreAcl() {
        bitField0_ = (bitField0_ & ~0x00000080);
        restoreAcl_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RestoreSnapshotStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RestoreSnapshotStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RestoreSnapshotStateData>() {
      @java.lang.Override
      public RestoreSnapshotStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RestoreSnapshotStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RestoreSnapshotStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DispatchMergingRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DispatchMergingRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>optional bool forcible = 4;</code>
     * @return Whether the forcible field is set.
     */
    boolean hasForcible();
    /**
     * <code>optional bool forcible = 4;</code>
     * @return The forcible.
     */
    boolean getForcible();
  }
  /**
   * Protobuf type {@code hbase.pb.DispatchMergingRegionsStateData}
   */
  @javax.annotation.Generated("proto") public static final class DispatchMergingRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DispatchMergingRegionsStateData)
      DispatchMergingRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DispatchMergingRegionsStateData.newBuilder() to construct.
    private DispatchMergingRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DispatchMergingRegionsStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DispatchMergingRegionsStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int FORCIBLE_FIELD_NUMBER = 4;
    private boolean forcible_ = false;
    /**
     * <code>optional bool forcible = 4;</code>
     * @return Whether the forcible field is set.
     */
    @java.lang.Override
    public boolean hasForcible() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool forcible = 4;</code>
     * @return The forcible.
     */
    @java.lang.Override
    public boolean getForcible() {
      return forcible_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(4, forcible_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, forcible_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (hasForcible() != other.hasForcible()) return false;
      if (hasForcible()) {
        if (getForcible()
            != other.getForcible()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (hasForcible()) {
        hash = (37 * hash) + FORCIBLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForcible());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DispatchMergingRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DispatchMergingRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        forcible_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.forcible_ = forcible_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (other.hasForcible()) {
          setForcible(other.getForcible());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 32: {
                forcible_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private boolean forcible_ ;
      /**
       * <code>optional bool forcible = 4;</code>
       * @return Whether the forcible field is set.
       */
      @java.lang.Override
      public boolean hasForcible() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool forcible = 4;</code>
       * @return The forcible.
       */
      @java.lang.Override
      public boolean getForcible() {
        return forcible_;
      }
      /**
       * <code>optional bool forcible = 4;</code>
       * @param value The forcible to set.
       * @return This builder for chaining.
       */
      public Builder setForcible(boolean value) {

        forcible_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool forcible = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearForcible() {
        bitField0_ = (bitField0_ & ~0x00000008);
        forcible_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DispatchMergingRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DispatchMergingRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DispatchMergingRegionsStateData>() {
      @java.lang.Override
      public DispatchMergingRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DispatchMergingRegionsStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DispatchMergingRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitTableRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitTableRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     * @return Whether the parentRegionInfo field is set.
     */
    boolean hasParentRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     * @return The parentRegionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getChildRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    int getChildRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getChildRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.SplitTableRegionStateData}
   */
  @javax.annotation.Generated("proto") public static final class SplitTableRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitTableRegionStateData)
      SplitTableRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitTableRegionStateData.newBuilder() to construct.
    private SplitTableRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitTableRegionStateData() {
      childRegionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SplitTableRegionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int PARENT_REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentRegionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     * @return Whether the parentRegionInfo field is set.
     */
    @java.lang.Override
    public boolean hasParentRegionInfo() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     * @return The parentRegionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo() {
      return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder() {
      return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
    }

    public static final int CHILD_REGION_INFO_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> childRegionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getChildRegionInfoList() {
      return childRegionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getChildRegionInfoOrBuilderList() {
      return childRegionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    @java.lang.Override
    public int getChildRegionInfoCount() {
      return childRegionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index) {
      return childRegionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
        int index) {
      return childRegionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasParentRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getChildRegionInfoCount(); i++) {
        if (!getChildRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getParentRegionInfo());
      }
      for (int i = 0; i < childRegionInfo_.size(); i++) {
        output.writeMessage(3, childRegionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getParentRegionInfo());
      }
      for (int i = 0; i < childRegionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, childRegionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasParentRegionInfo() != other.hasParentRegionInfo()) return false;
      if (hasParentRegionInfo()) {
        if (!getParentRegionInfo()
            .equals(other.getParentRegionInfo())) return false;
      }
      if (!getChildRegionInfoList()
          .equals(other.getChildRegionInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasParentRegionInfo()) {
        hash = (37 * hash) + PARENT_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getParentRegionInfo().hashCode();
      }
      if (getChildRegionInfoCount() > 0) {
        hash = (37 * hash) + CHILD_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getChildRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitTableRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitTableRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getParentRegionInfoFieldBuilder();
          getChildRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        parentRegionInfo_ = null;
        if (parentRegionInfoBuilder_ != null) {
          parentRegionInfoBuilder_.dispose();
          parentRegionInfoBuilder_ = null;
        }
        if (childRegionInfoBuilder_ == null) {
          childRegionInfo_ = java.util.Collections.emptyList();
        } else {
          childRegionInfo_ = null;
          childRegionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result) {
        if (childRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            childRegionInfo_ = java.util.Collections.unmodifiableList(childRegionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.childRegionInfo_ = childRegionInfo_;
        } else {
          result.childRegionInfo_ = childRegionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.parentRegionInfo_ = parentRegionInfoBuilder_ == null
              ? parentRegionInfo_
              : parentRegionInfoBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasParentRegionInfo()) {
          mergeParentRegionInfo(other.getParentRegionInfo());
        }
        if (childRegionInfoBuilder_ == null) {
          if (!other.childRegionInfo_.isEmpty()) {
            if (childRegionInfo_.isEmpty()) {
              childRegionInfo_ = other.childRegionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureChildRegionInfoIsMutable();
              childRegionInfo_.addAll(other.childRegionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.childRegionInfo_.isEmpty()) {
            if (childRegionInfoBuilder_.isEmpty()) {
              childRegionInfoBuilder_.dispose();
              childRegionInfoBuilder_ = null;
              childRegionInfo_ = other.childRegionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              childRegionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getChildRegionInfoFieldBuilder() : null;
            } else {
              childRegionInfoBuilder_.addAllMessages(other.childRegionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasParentRegionInfo()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getParentRegionInfo().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getChildRegionInfoCount(); i++) {
          if (!getChildRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getParentRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (childRegionInfoBuilder_ == null) {
                  ensureChildRegionInfoIsMutable();
                  childRegionInfo_.add(m);
                } else {
                  childRegionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentRegionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentRegionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       * @return Whether the parentRegionInfo field is set.
       */
      public boolean hasParentRegionInfo() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       * @return The parentRegionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentRegionInfo() {
        if (parentRegionInfoBuilder_ == null) {
          return parentRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
        } else {
          return parentRegionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder setParentRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentRegionInfo_ = value;
        } else {
          parentRegionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder setParentRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfo_ = builderForValue.build();
        } else {
          parentRegionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder mergeParentRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            parentRegionInfo_ != null &&
            parentRegionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getParentRegionInfoBuilder().mergeFrom(value);
          } else {
            parentRegionInfo_ = value;
          }
        } else {
          parentRegionInfoBuilder_.mergeFrom(value);
        }
        if (parentRegionInfo_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public Builder clearParentRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000002);
        parentRegionInfo_ = null;
        if (parentRegionInfoBuilder_ != null) {
          parentRegionInfoBuilder_.dispose();
          parentRegionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getParentRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentRegionInfoOrBuilder() {
        if (parentRegionInfoBuilder_ != null) {
          return parentRegionInfoBuilder_.getMessageOrBuilder();
        } else {
          return parentRegionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentRegionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentRegionInfoFieldBuilder() {
        if (parentRegionInfoBuilder_ == null) {
          parentRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentRegionInfo(),
                  getParentForChildren(),
                  isClean());
          parentRegionInfo_ = null;
        }
        return parentRegionInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> childRegionInfo_ =
        java.util.Collections.emptyList();
      private void ensureChildRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          childRegionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(childRegionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> childRegionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getChildRegionInfoList() {
        if (childRegionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(childRegionInfo_);
        } else {
          return childRegionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public int getChildRegionInfoCount() {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.size();
        } else {
          return childRegionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getChildRegionInfo(int index) {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.get(index);
        } else {
          return childRegionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder setChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.set(index, value);
          onChanged();
        } else {
          childRegionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder setChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(value);
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (childRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(index, value);
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addChildRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          childRegionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder addAllChildRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, childRegionInfo_);
          onChanged();
        } else {
          childRegionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder clearChildRegionInfo() {
        if (childRegionInfoBuilder_ == null) {
          childRegionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          childRegionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public Builder removeChildRegionInfo(int index) {
        if (childRegionInfoBuilder_ == null) {
          ensureChildRegionInfoIsMutable();
          childRegionInfo_.remove(index);
          onChanged();
        } else {
          childRegionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getChildRegionInfoBuilder(
          int index) {
        return getChildRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getChildRegionInfoOrBuilder(
          int index) {
        if (childRegionInfoBuilder_ == null) {
          return childRegionInfo_.get(index);  } else {
          return childRegionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getChildRegionInfoOrBuilderList() {
        if (childRegionInfoBuilder_ != null) {
          return childRegionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(childRegionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addChildRegionInfoBuilder() {
        return getChildRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addChildRegionInfoBuilder(
          int index) {
        return getChildRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo child_region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getChildRegionInfoBuilderList() {
        return getChildRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getChildRegionInfoFieldBuilder() {
        if (childRegionInfoBuilder_ == null) {
          childRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  childRegionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          childRegionInfo_ = null;
        }
        return childRegionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitTableRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitTableRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitTableRegionStateData>() {
      @java.lang.Override
      public SplitTableRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitTableRegionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitTableRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MergeTableRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MergeTableRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);

    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     * @return Whether the mergedRegionInfo field is set.
     */
    boolean hasMergedRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     * @return The mergedRegionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder();

    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     * @return Whether the forcible field is set.
     */
    boolean hasForcible();
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     * @return The forcible.
     */
    boolean getForcible();
  }
  /**
   * Protobuf type {@code hbase.pb.MergeTableRegionsStateData}
   */
  @javax.annotation.Generated("proto") public static final class MergeTableRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MergeTableRegionsStateData)
      MergeTableRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MergeTableRegionsStateData.newBuilder() to construct.
    private MergeTableRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MergeTableRegionsStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MergeTableRegionsStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    @java.lang.Override
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    public static final int MERGED_REGION_INFO_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedRegionInfo_;
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     * @return Whether the mergedRegionInfo field is set.
     */
    @java.lang.Override
    public boolean hasMergedRegionInfo() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     * @return The mergedRegionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo() {
      return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
    }
    /**
     * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder() {
      return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
    }

    public static final int FORCIBLE_FIELD_NUMBER = 4;
    private boolean forcible_ = false;
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     * @return Whether the forcible field is set.
     */
    @java.lang.Override
    public boolean hasForcible() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool forcible = 4 [default = false];</code>
     * @return The forcible.
     */
    @java.lang.Override
    public boolean getForcible() {
      return forcible_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasMergedRegionInfo()) {
        if (!getMergedRegionInfo().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(2, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(3, getMergedRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(4, forcible_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, regionInfo_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getMergedRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, forcible_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (hasMergedRegionInfo() != other.hasMergedRegionInfo()) return false;
      if (hasMergedRegionInfo()) {
        if (!getMergedRegionInfo()
            .equals(other.getMergedRegionInfo())) return false;
      }
      if (hasForcible() != other.hasForcible()) return false;
      if (hasForcible()) {
        if (getForcible()
            != other.getForcible()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      if (hasMergedRegionInfo()) {
        hash = (37 * hash) + MERGED_REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getMergedRegionInfo().hashCode();
      }
      if (hasForcible()) {
        hash = (37 * hash) + FORCIBLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForcible());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MergeTableRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MergeTableRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getRegionInfoFieldBuilder();
          getMergedRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        mergedRegionInfo_ = null;
        if (mergedRegionInfoBuilder_ != null) {
          mergedRegionInfoBuilder_.dispose();
          mergedRegionInfoBuilder_ = null;
        }
        forcible_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.userInfo_ = userInfoBuilder_ == null
              ? userInfo_
              : userInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.mergedRegionInfo_ = mergedRegionInfoBuilder_ == null
              ? mergedRegionInfo_
              : mergedRegionInfoBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.forcible_ = forcible_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        if (other.hasMergedRegionInfo()) {
          mergeMergedRegionInfo(other.getMergedRegionInfo());
        }
        if (other.hasForcible()) {
          setForcible(other.getForcible());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        if (hasMergedRegionInfo()) {
          if (!getMergedRegionInfo().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getUserInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getMergedRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                forcible_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            userInfo_ != null &&
            userInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            getUserInfoBuilder().mergeFrom(value);
          } else {
            userInfo_ = value;
          }
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        if (userInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userInfo_ = null;
        if (userInfoBuilder_ != null) {
          userInfoBuilder_.dispose();
          userInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedRegionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedRegionInfoBuilder_;
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       * @return Whether the mergedRegionInfo field is set.
       */
      public boolean hasMergedRegionInfo() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       * @return The mergedRegionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedRegionInfo() {
        if (mergedRegionInfoBuilder_ == null) {
          return mergedRegionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
        } else {
          return mergedRegionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder setMergedRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedRegionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedRegionInfo_ = value;
        } else {
          mergedRegionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder setMergedRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfo_ = builderForValue.build();
        } else {
          mergedRegionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder mergeMergedRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedRegionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            mergedRegionInfo_ != null &&
            mergedRegionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getMergedRegionInfoBuilder().mergeFrom(value);
          } else {
            mergedRegionInfo_ = value;
          }
        } else {
          mergedRegionInfoBuilder_.mergeFrom(value);
        }
        if (mergedRegionInfo_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public Builder clearMergedRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000004);
        mergedRegionInfo_ = null;
        if (mergedRegionInfoBuilder_ != null) {
          mergedRegionInfoBuilder_.dispose();
          mergedRegionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedRegionInfoBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMergedRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedRegionInfoOrBuilder() {
        if (mergedRegionInfoBuilder_ != null) {
          return mergedRegionInfoBuilder_.getMessageOrBuilder();
        } else {
          return mergedRegionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedRegionInfo_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo merged_region_info = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedRegionInfoFieldBuilder() {
        if (mergedRegionInfoBuilder_ == null) {
          mergedRegionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedRegionInfo(),
                  getParentForChildren(),
                  isClean());
          mergedRegionInfo_ = null;
        }
        return mergedRegionInfoBuilder_;
      }

      private boolean forcible_ ;
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       * @return Whether the forcible field is set.
       */
      @java.lang.Override
      public boolean hasForcible() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       * @return The forcible.
       */
      @java.lang.Override
      public boolean getForcible() {
        return forcible_;
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       * @param value The forcible to set.
       * @return This builder for chaining.
       */
      public Builder setForcible(boolean value) {

        forcible_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool forcible = 4 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearForcible() {
        bitField0_ = (bitField0_ & ~0x00000008);
        forcible_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MergeTableRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MergeTableRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MergeTableRegionsStateData>() {
      @java.lang.Override
      public MergeTableRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MergeTableRegionsStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MergeTableRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ServerCrashStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ServerCrashStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsOnCrashedServerList();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index);
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    int getRegionsOnCrashedServerCount();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList();
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsAssignedList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    int getRegionsAssignedCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index);

    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return Whether the carryingMeta field is set.
     */
    boolean hasCarryingMeta();
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return The carryingMeta.
     */
    boolean getCarryingMeta();

    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return The shouldSplitWal.
     */
    boolean getShouldSplitWal();
  }
  /**
   * Protobuf type {@code hbase.pb.ServerCrashStateData}
   */
  @javax.annotation.Generated("proto") public static final class ServerCrashStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ServerCrashStateData)
      ServerCrashStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ServerCrashStateData.newBuilder() to construct.
    private ServerCrashStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ServerCrashStateData() {
      regionsOnCrashedServer_ = java.util.Collections.emptyList();
      regionsAssigned_ = java.util.Collections.emptyList();
      shouldSplitWal_ = true;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ServerCrashStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    @java.lang.Override
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    public static final int REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_;
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    @java.lang.Override
    public int getRegionsOnCrashedServerCount() {
      return regionsOnCrashedServer_.size();
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
      return regionsOnCrashedServer_.get(index);
    }
    /**
     * <pre>
     * optional bool DEPRECATED_distributed_log_replay = 2;
     * </pre>
     *
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index) {
      return regionsOnCrashedServer_.get(index);
    }

    public static final int REGIONS_ASSIGNED_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    @java.lang.Override
    public int getRegionsAssignedCount() {
      return regionsAssigned_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
      return regionsAssigned_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index) {
      return regionsAssigned_.get(index);
    }

    public static final int CARRYING_META_FIELD_NUMBER = 5;
    private boolean carryingMeta_ = false;
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return Whether the carryingMeta field is set.
     */
    @java.lang.Override
    public boolean hasCarryingMeta() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return The carryingMeta.
     */
    @java.lang.Override
    public boolean getCarryingMeta() {
      return carryingMeta_;
    }

    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 6;
    private boolean shouldSplitWal_ = true;
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    @java.lang.Override
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return The shouldSplitWal.
     */
    @java.lang.Override
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
        if (!getRegionsOnCrashedServer(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionsAssignedCount(); i++) {
        if (!getRegionsAssigned(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerName());
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        output.writeMessage(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        output.writeMessage(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(6, shouldSplitWal_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, shouldSplitWal_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) obj;

      if (hasServerName() != other.hasServerName()) return false;
      if (hasServerName()) {
        if (!getServerName()
            .equals(other.getServerName())) return false;
      }
      if (!getRegionsOnCrashedServerList()
          .equals(other.getRegionsOnCrashedServerList())) return false;
      if (!getRegionsAssignedList()
          .equals(other.getRegionsAssignedList())) return false;
      if (hasCarryingMeta() != other.hasCarryingMeta()) return false;
      if (hasCarryingMeta()) {
        if (getCarryingMeta()
            != other.getCarryingMeta()) return false;
      }
      if (hasShouldSplitWal() != other.hasShouldSplitWal()) return false;
      if (hasShouldSplitWal()) {
        if (getShouldSplitWal()
            != other.getShouldSplitWal()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (getRegionsOnCrashedServerCount() > 0) {
        hash = (37 * hash) + REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsOnCrashedServerList().hashCode();
      }
      if (getRegionsAssignedCount() > 0) {
        hash = (37 * hash) + REGIONS_ASSIGNED_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsAssignedList().hashCode();
      }
      if (hasCarryingMeta()) {
        hash = (37 * hash) + CARRYING_META_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCarryingMeta());
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldSplitWal());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ServerCrashStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ServerCrashStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
          getRegionsOnCrashedServerFieldBuilder();
          getRegionsAssignedFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
        } else {
          regionsOnCrashedServer_ = null;
          regionsOnCrashedServerBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
        } else {
          regionsAssigned_ = null;
          regionsAssignedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        carryingMeta_ = false;
        shouldSplitWal_ = true;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.regionsOnCrashedServer_ = regionsOnCrashedServer_;
        } else {
          result.regionsOnCrashedServer_ = regionsOnCrashedServerBuilder_.build();
        }
        if (regionsAssignedBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionsAssigned_ = regionsAssigned_;
        } else {
          result.regionsAssigned_ = regionsAssignedBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.serverName_ = serverNameBuilder_ == null
              ? serverName_
              : serverNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.carryingMeta_ = carryingMeta_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.shouldSplitWal_ = shouldSplitWal_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServer_.isEmpty()) {
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionsOnCrashedServerIsMutable();
              regionsOnCrashedServer_.addAll(other.regionsOnCrashedServer_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServerBuilder_.isEmpty()) {
              regionsOnCrashedServerBuilder_.dispose();
              regionsOnCrashedServerBuilder_ = null;
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionsOnCrashedServerBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsOnCrashedServerFieldBuilder() : null;
            } else {
              regionsOnCrashedServerBuilder_.addAllMessages(other.regionsOnCrashedServer_);
            }
          }
        }
        if (regionsAssignedBuilder_ == null) {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssigned_.isEmpty()) {
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionsAssignedIsMutable();
              regionsAssigned_.addAll(other.regionsAssigned_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssignedBuilder_.isEmpty()) {
              regionsAssignedBuilder_.dispose();
              regionsAssignedBuilder_ = null;
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionsAssignedBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsAssignedFieldBuilder() : null;
            } else {
              regionsAssignedBuilder_.addAllMessages(other.regionsAssigned_);
            }
          }
        }
        if (other.hasCarryingMeta()) {
          setCarryingMeta(other.getCarryingMeta());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasServerName()) {
          return false;
        }
        if (!getServerName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
          if (!getRegionsOnCrashedServer(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionsAssignedCount(); i++) {
          if (!getRegionsAssigned(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getServerNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionsOnCrashedServerBuilder_ == null) {
                  ensureRegionsOnCrashedServerIsMutable();
                  regionsOnCrashedServer_.add(m);
                } else {
                  regionsOnCrashedServerBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 34: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionsAssignedBuilder_ == null) {
                  ensureRegionsAssignedIsMutable();
                  regionsAssigned_.add(m);
                } else {
                  regionsAssignedBuilder_.addMessage(m);
                }
                break;
              } // case 34
              case 40: {
                carryingMeta_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 40
              case 48: {
                shouldSplitWal_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 48
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return Whether the serverName field is set.
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return The serverName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            serverName_ != null &&
            serverName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getServerNameBuilder().mergeFrom(value);
          } else {
            serverName_ = value;
          }
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        if (serverName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_ =
        java.util.Collections.emptyList();
      private void ensureRegionsOnCrashedServerIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionsOnCrashedServer_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsOnCrashedServerBuilder_;

      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        } else {
          return regionsOnCrashedServerBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public int getRegionsOnCrashedServerCount() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.size();
        } else {
          return regionsOnCrashedServerBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);
        } else {
          return regionsOnCrashedServerBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addAllRegionsOnCrashedServer(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsOnCrashedServer_);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder clearRegionsOnCrashedServer() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder removeRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.remove(index);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
          int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);  } else {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsOnCrashedServerOrBuilderList() {
        if (regionsOnCrashedServerBuilder_ != null) {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder() {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * optional bool DEPRECATED_distributed_log_replay = 2;
       * </pre>
       *
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsOnCrashedServerBuilderList() {
        return getRegionsOnCrashedServerFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsOnCrashedServerFieldBuilder() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsOnCrashedServer_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          regionsOnCrashedServer_ = null;
        }
        return regionsOnCrashedServerBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_ =
        java.util.Collections.emptyList();
      private void ensureRegionsAssignedIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionsAssigned_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsAssignedBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
        if (regionsAssignedBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        } else {
          return regionsAssignedBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public int getRegionsAssignedCount() {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.size();
        } else {
          return regionsAssignedBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);
        } else {
          return regionsAssignedBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addAllRegionsAssigned(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsAssigned_);
          onChanged();
        } else {
          regionsAssignedBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder clearRegionsAssigned() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionsAssignedBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder removeRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.remove(index);
          onChanged();
        } else {
          regionsAssignedBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
          int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);  } else {
          return regionsAssignedBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsAssignedOrBuilderList() {
        if (regionsAssignedBuilder_ != null) {
          return regionsAssignedBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder() {
        return getRegionsAssignedFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsAssignedBuilderList() {
        return getRegionsAssignedFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsAssignedFieldBuilder() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssignedBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsAssigned_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionsAssigned_ = null;
        }
        return regionsAssignedBuilder_;
      }

      private boolean carryingMeta_ ;
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return Whether the carryingMeta field is set.
       */
      @java.lang.Override
      public boolean hasCarryingMeta() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return The carryingMeta.
       */
      @java.lang.Override
      public boolean getCarryingMeta() {
        return carryingMeta_;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @param value The carryingMeta to set.
       * @return This builder for chaining.
       */
      public Builder setCarryingMeta(boolean value) {

        carryingMeta_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearCarryingMeta() {
        bitField0_ = (bitField0_ & ~0x00000008);
        carryingMeta_ = false;
        onChanged();
        return this;
      }

      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return Whether the shouldSplitWal field is set.
       */
      @java.lang.Override
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return The shouldSplitWal.
       */
      @java.lang.Override
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @param value The shouldSplitWal to set.
       * @return This builder for chaining.
       */
      public Builder setShouldSplitWal(boolean value) {

        shouldSplitWal_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ServerCrashStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ServerCrashStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ServerCrashStateData>() {
      @java.lang.Override
      public ServerCrashStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerCrashStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecoverMetaStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RecoverMetaStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     * @return Whether the failedMetaServer field is set.
     */
    boolean hasFailedMetaServer();
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     * @return The failedMetaServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer();
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder();

    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     * @return The shouldSplitWal.
     */
    boolean getShouldSplitWal();

    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     * @return Whether the replicaId field is set.
     */
    boolean hasReplicaId();
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     * @return The replicaId.
     */
    int getReplicaId();
  }
  /**
   * Protobuf type {@code hbase.pb.RecoverMetaStateData}
   */
  @javax.annotation.Generated("proto") public static final class RecoverMetaStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RecoverMetaStateData)
      RecoverMetaStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecoverMetaStateData.newBuilder() to construct.
    private RecoverMetaStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecoverMetaStateData() {
      shouldSplitWal_ = true;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RecoverMetaStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.Builder.class);
    }

    private int bitField0_;
    public static final int FAILED_META_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName failedMetaServer_;
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     * @return Whether the failedMetaServer field is set.
     */
    @java.lang.Override
    public boolean hasFailedMetaServer() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     * @return The failedMetaServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer() {
      return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
    }
    /**
     * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder() {
      return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
    }

    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 2;
    private boolean shouldSplitWal_ = true;
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    @java.lang.Override
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool should_split_wal = 2 [default = true];</code>
     * @return The shouldSplitWal.
     */
    @java.lang.Override
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    public static final int REPLICA_ID_FIELD_NUMBER = 3;
    private int replicaId_ = 0;
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     * @return Whether the replicaId field is set.
     */
    @java.lang.Override
    public boolean hasReplicaId() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional int32 replica_id = 3 [default = 0];</code>
     * @return The replicaId.
     */
    @java.lang.Override
    public int getReplicaId() {
      return replicaId_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasFailedMetaServer()) {
        if (!getFailedMetaServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getFailedMetaServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, shouldSplitWal_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeInt32(3, replicaId_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFailedMetaServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, shouldSplitWal_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, replicaId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData) obj;

      if (hasFailedMetaServer() != other.hasFailedMetaServer()) return false;
      if (hasFailedMetaServer()) {
        if (!getFailedMetaServer()
            .equals(other.getFailedMetaServer())) return false;
      }
      if (hasShouldSplitWal() != other.hasShouldSplitWal()) return false;
      if (hasShouldSplitWal()) {
        if (getShouldSplitWal()
            != other.getShouldSplitWal()) return false;
      }
      if (hasReplicaId() != other.hasReplicaId()) return false;
      if (hasReplicaId()) {
        if (getReplicaId()
            != other.getReplicaId()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFailedMetaServer()) {
        hash = (37 * hash) + FAILED_META_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getFailedMetaServer().hashCode();
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getShouldSplitWal());
      }
      if (hasReplicaId()) {
        hash = (37 * hash) + REPLICA_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReplicaId();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RecoverMetaStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RecoverMetaStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFailedMetaServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        failedMetaServer_ = null;
        if (failedMetaServerBuilder_ != null) {
          failedMetaServerBuilder_.dispose();
          failedMetaServerBuilder_ = null;
        }
        shouldSplitWal_ = true;
        replicaId_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RecoverMetaStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.failedMetaServer_ = failedMetaServerBuilder_ == null
              ? failedMetaServer_
              : failedMetaServerBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.shouldSplitWal_ = shouldSplitWal_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.replicaId_ = replicaId_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData.getDefaultInstance()) return this;
        if (other.hasFailedMetaServer()) {
          mergeFailedMetaServer(other.getFailedMetaServer());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        if (other.hasReplicaId()) {
          setReplicaId(other.getReplicaId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasFailedMetaServer()) {
          if (!getFailedMetaServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFailedMetaServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                shouldSplitWal_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                replicaId_ = input.readInt32();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName failedMetaServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> failedMetaServerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       * @return Whether the failedMetaServer field is set.
       */
      public boolean hasFailedMetaServer() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       * @return The failedMetaServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFailedMetaServer() {
        if (failedMetaServerBuilder_ == null) {
          return failedMetaServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
        } else {
          return failedMetaServerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder setFailedMetaServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (failedMetaServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          failedMetaServer_ = value;
        } else {
          failedMetaServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder setFailedMetaServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (failedMetaServerBuilder_ == null) {
          failedMetaServer_ = builderForValue.build();
        } else {
          failedMetaServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder mergeFailedMetaServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (failedMetaServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            failedMetaServer_ != null &&
            failedMetaServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getFailedMetaServerBuilder().mergeFrom(value);
          } else {
            failedMetaServer_ = value;
          }
        } else {
          failedMetaServerBuilder_.mergeFrom(value);
        }
        if (failedMetaServer_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public Builder clearFailedMetaServer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        failedMetaServer_ = null;
        if (failedMetaServerBuilder_ != null) {
          failedMetaServerBuilder_.dispose();
          failedMetaServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getFailedMetaServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFailedMetaServerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFailedMetaServerOrBuilder() {
        if (failedMetaServerBuilder_ != null) {
          return failedMetaServerBuilder_.getMessageOrBuilder();
        } else {
          return failedMetaServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : failedMetaServer_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName failed_meta_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFailedMetaServerFieldBuilder() {
        if (failedMetaServerBuilder_ == null) {
          failedMetaServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getFailedMetaServer(),
                  getParentForChildren(),
                  isClean());
          failedMetaServer_ = null;
        }
        return failedMetaServerBuilder_;
      }

      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       * @return Whether the shouldSplitWal field is set.
       */
      @java.lang.Override
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       * @return The shouldSplitWal.
       */
      @java.lang.Override
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       * @param value The shouldSplitWal to set.
       * @return This builder for chaining.
       */
      public Builder setShouldSplitWal(boolean value) {

        shouldSplitWal_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 2 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000002);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }

      private int replicaId_ ;
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       * @return Whether the replicaId field is set.
       */
      @java.lang.Override
      public boolean hasReplicaId() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       * @return The replicaId.
       */
      @java.lang.Override
      public int getReplicaId() {
        return replicaId_;
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       * @param value The replicaId to set.
       * @return This builder for chaining.
       */
      public Builder setReplicaId(int value) {

        replicaId_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 replica_id = 3 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearReplicaId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        replicaId_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RecoverMetaStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RecoverMetaStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RecoverMetaStateData>() {
      @java.lang.Override
      public RecoverMetaStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RecoverMetaStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RecoverMetaStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AssignRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.AssignRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return Whether the transitionState field is set.
     */
    boolean hasTransitionState();
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return The transitionState.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState();

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     * @return Whether the forceNewPlan field is set.
     */
    boolean hasForceNewPlan();
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     * @return The forceNewPlan.
     */
    boolean getForceNewPlan();

    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     * @return Whether the attempt field is set.
     */
    boolean hasAttempt();
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     * @return The attempt.
     */
    int getAttempt();
  }
  /**
   * Protobuf type {@code hbase.pb.AssignRegionStateData}
   */
  @javax.annotation.Generated("proto") public static final class AssignRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.AssignRegionStateData)
      AssignRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AssignRegionStateData.newBuilder() to construct.
    private AssignRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AssignRegionStateData() {
      transitionState_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new AssignRegionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TRANSITION_STATE_FIELD_NUMBER = 1;
    private int transitionState_ = 1;
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return Whether the transitionState field is set.
     */
    @java.lang.Override public boolean hasTransitionState() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return The transitionState.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(transitionState_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int FORCE_NEW_PLAN_FIELD_NUMBER = 3;
    private boolean forceNewPlan_ = false;
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     * @return Whether the forceNewPlan field is set.
     */
    @java.lang.Override
    public boolean hasForceNewPlan() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool force_new_plan = 3 [default = false];</code>
     * @return The forceNewPlan.
     */
    @java.lang.Override
    public boolean getForceNewPlan() {
      return forceNewPlan_;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>optional .hbase.pb.ServerName target_server = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int ATTEMPT_FIELD_NUMBER = 5;
    private int attempt_ = 0;
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     * @return Whether the attempt field is set.
     */
    @java.lang.Override
    public boolean hasAttempt() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 5;</code>
     * @return The attempt.
     */
    @java.lang.Override
    public int getAttempt() {
      return attempt_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTransitionState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTargetServer()) {
        if (!getTargetServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, forceNewPlan_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getTargetServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeInt32(5, attempt_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, forceNewPlan_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getTargetServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, attempt_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData) obj;

      if (hasTransitionState() != other.hasTransitionState()) return false;
      if (hasTransitionState()) {
        if (transitionState_ != other.transitionState_) return false;
      }
      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (hasForceNewPlan() != other.hasForceNewPlan()) return false;
      if (hasForceNewPlan()) {
        if (getForceNewPlan()
            != other.getForceNewPlan()) return false;
      }
      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (hasAttempt() != other.hasAttempt()) return false;
      if (hasAttempt()) {
        if (getAttempt()
            != other.getAttempt()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTransitionState()) {
        hash = (37 * hash) + TRANSITION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + transitionState_;
      }
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasForceNewPlan()) {
        hash = (37 * hash) + FORCE_NEW_PLAN_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForceNewPlan());
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasAttempt()) {
        hash = (37 * hash) + ATTEMPT_FIELD_NUMBER;
        hash = (53 * hash) + getAttempt();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AssignRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.AssignRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getTargetServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        transitionState_ = 1;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        forceNewPlan_ = false;
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        attempt_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AssignRegionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.transitionState_ = transitionState_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.forceNewPlan_ = forceNewPlan_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.attempt_ = attempt_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData.getDefaultInstance()) return this;
        if (other.hasTransitionState()) {
          setTransitionState(other.getTransitionState());
        }
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasForceNewPlan()) {
          setForceNewPlan(other.getForceNewPlan());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasAttempt()) {
          setAttempt(other.getAttempt());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTransitionState()) {
          return false;
        }
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        if (hasTargetServer()) {
          if (!getTargetServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  transitionState_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                forceNewPlan_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 40: {
                attempt_ = input.readInt32();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int transitionState_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return Whether the transitionState field is set.
       */
      @java.lang.Override public boolean hasTransitionState() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return The transitionState.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(transitionState_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @param value The transitionState to set.
       * @return This builder for chaining.
       */
      public Builder setTransitionState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        transitionState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTransitionState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        transitionState_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000002);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private boolean forceNewPlan_ ;
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       * @return Whether the forceNewPlan field is set.
       */
      @java.lang.Override
      public boolean hasForceNewPlan() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       * @return The forceNewPlan.
       */
      @java.lang.Override
      public boolean getForceNewPlan() {
        return forceNewPlan_;
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       * @param value The forceNewPlan to set.
       * @return This builder for chaining.
       */
      public Builder setForceNewPlan(boolean value) {

        forceNewPlan_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool force_new_plan = 3 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearForceNewPlan() {
        bitField0_ = (bitField0_ & ~0x00000004);
        forceNewPlan_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000008);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName target_server = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int attempt_ ;
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       * @return Whether the attempt field is set.
       */
      @java.lang.Override
      public boolean hasAttempt() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       * @return The attempt.
       */
      @java.lang.Override
      public int getAttempt() {
        return attempt_;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       * @param value The attempt to set.
       * @return This builder for chaining.
       */
      public Builder setAttempt(int value) {

        attempt_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearAttempt() {
        bitField0_ = (bitField0_ & ~0x00000010);
        attempt_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.AssignRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AssignRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<AssignRegionStateData>() {
      @java.lang.Override
      public AssignRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<AssignRegionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AssignRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UnassignRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UnassignRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return Whether the transitionState field is set.
     */
    boolean hasTransitionState();
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return The transitionState.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState();

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return Whether the destinationServer field is set.
     */
    boolean hasDestinationServer();
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return The destinationServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer();
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder();

    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     * @return Whether the hostingServer field is set.
     */
    boolean hasHostingServer();
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     * @return The hostingServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer();
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder();

    /**
     * <pre>
     * This parameter is ignored
     * </pre>
     *
     * <code>optional bool force = 4 [default = false];</code>
     * @return Whether the force field is set.
     */
    boolean hasForce();
    /**
     * <pre>
     * This parameter is ignored
     * </pre>
     *
     * <code>optional bool force = 4 [default = false];</code>
     * @return The force.
     */
    boolean getForce();

    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     * @return Whether the removeAfterUnassigning field is set.
     */
    boolean hasRemoveAfterUnassigning();
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     * @return The removeAfterUnassigning.
     */
    boolean getRemoveAfterUnassigning();

    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     * @return Whether the attempt field is set.
     */
    boolean hasAttempt();
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     * @return The attempt.
     */
    int getAttempt();
  }
  /**
   * Protobuf type {@code hbase.pb.UnassignRegionStateData}
   */
  @javax.annotation.Generated("proto") public static final class UnassignRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UnassignRegionStateData)
      UnassignRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UnassignRegionStateData.newBuilder() to construct.
    private UnassignRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UnassignRegionStateData() {
      transitionState_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UnassignRegionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TRANSITION_STATE_FIELD_NUMBER = 1;
    private int transitionState_ = 1;
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return Whether the transitionState field is set.
     */
    @java.lang.Override public boolean hasTransitionState() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
     * @return The transitionState.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(transitionState_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int DESTINATION_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return Whether the destinationServer field is set.
     */
    @java.lang.Override
    public boolean hasDestinationServer() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return The destinationServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }
    /**
     * <pre>
     * This is optional info; it is the servername we will
     * subsequently assign the region too... it may be null.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }

    public static final int HOSTING_SERVER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName hostingServer_;
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     * @return Whether the hostingServer field is set.
     */
    @java.lang.Override
    public boolean hasHostingServer() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     * @return The hostingServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer() {
      return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
    }
    /**
     * <pre>
     * This is the server currently hosting the Region, the
     * server we will send the unassign rpc too.
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder() {
      return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
    }

    public static final int FORCE_FIELD_NUMBER = 4;
    private boolean force_ = false;
    /**
     * <pre>
     * This parameter is ignored
     * </pre>
     *
     * <code>optional bool force = 4 [default = false];</code>
     * @return Whether the force field is set.
     */
    @java.lang.Override
    public boolean hasForce() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * This parameter is ignored
     * </pre>
     *
     * <code>optional bool force = 4 [default = false];</code>
     * @return The force.
     */
    @java.lang.Override
    public boolean getForce() {
      return force_;
    }

    public static final int REMOVE_AFTER_UNASSIGNING_FIELD_NUMBER = 6;
    private boolean removeAfterUnassigning_ = false;
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     * @return Whether the removeAfterUnassigning field is set.
     */
    @java.lang.Override
    public boolean hasRemoveAfterUnassigning() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
     * @return The removeAfterUnassigning.
     */
    @java.lang.Override
    public boolean getRemoveAfterUnassigning() {
      return removeAfterUnassigning_;
    }

    public static final int ATTEMPT_FIELD_NUMBER = 7;
    private int attempt_ = 0;
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     * @return Whether the attempt field is set.
     */
    @java.lang.Override
    public boolean hasAttempt() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <pre>
     * Current attempt index used for expotential backoff when stuck
     * </pre>
     *
     * <code>optional int32 attempt = 7;</code>
     * @return The attempt.
     */
    @java.lang.Override
    public int getAttempt() {
      return attempt_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTransitionState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasDestinationServer()) {
        if (!getDestinationServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasHostingServer()) {
        if (!getHostingServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(4, force_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(5, getHostingServer());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(6, removeAfterUnassigning_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeInt32(7, attempt_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, transitionState_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegionInfo());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, force_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getHostingServer());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, removeAfterUnassigning_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(7, attempt_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData) obj;

      if (hasTransitionState() != other.hasTransitionState()) return false;
      if (hasTransitionState()) {
        if (transitionState_ != other.transitionState_) return false;
      }
      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (hasDestinationServer() != other.hasDestinationServer()) return false;
      if (hasDestinationServer()) {
        if (!getDestinationServer()
            .equals(other.getDestinationServer())) return false;
      }
      if (hasHostingServer() != other.hasHostingServer()) return false;
      if (hasHostingServer()) {
        if (!getHostingServer()
            .equals(other.getHostingServer())) return false;
      }
      if (hasForce() != other.hasForce()) return false;
      if (hasForce()) {
        if (getForce()
            != other.getForce()) return false;
      }
      if (hasRemoveAfterUnassigning() != other.hasRemoveAfterUnassigning()) return false;
      if (hasRemoveAfterUnassigning()) {
        if (getRemoveAfterUnassigning()
            != other.getRemoveAfterUnassigning()) return false;
      }
      if (hasAttempt() != other.hasAttempt()) return false;
      if (hasAttempt()) {
        if (getAttempt()
            != other.getAttempt()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTransitionState()) {
        hash = (37 * hash) + TRANSITION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + transitionState_;
      }
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasDestinationServer()) {
        hash = (37 * hash) + DESTINATION_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getDestinationServer().hashCode();
      }
      if (hasHostingServer()) {
        hash = (37 * hash) + HOSTING_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getHostingServer().hashCode();
      }
      if (hasForce()) {
        hash = (37 * hash) + FORCE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForce());
      }
      if (hasRemoveAfterUnassigning()) {
        hash = (37 * hash) + REMOVE_AFTER_UNASSIGNING_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRemoveAfterUnassigning());
      }
      if (hasAttempt()) {
        hash = (37 * hash) + ATTEMPT_FIELD_NUMBER;
        hash = (53 * hash) + getAttempt();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UnassignRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UnassignRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getDestinationServerFieldBuilder();
          getHostingServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        transitionState_ = 1;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        hostingServer_ = null;
        if (hostingServerBuilder_ != null) {
          hostingServerBuilder_.dispose();
          hostingServerBuilder_ = null;
        }
        force_ = false;
        removeAfterUnassigning_ = false;
        attempt_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UnassignRegionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.transitionState_ = transitionState_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.destinationServer_ = destinationServerBuilder_ == null
              ? destinationServer_
              : destinationServerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.hostingServer_ = hostingServerBuilder_ == null
              ? hostingServer_
              : hostingServerBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.force_ = force_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.removeAfterUnassigning_ = removeAfterUnassigning_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.attempt_ = attempt_;
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData.getDefaultInstance()) return this;
        if (other.hasTransitionState()) {
          setTransitionState(other.getTransitionState());
        }
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasDestinationServer()) {
          mergeDestinationServer(other.getDestinationServer());
        }
        if (other.hasHostingServer()) {
          mergeHostingServer(other.getHostingServer());
        }
        if (other.hasForce()) {
          setForce(other.getForce());
        }
        if (other.hasRemoveAfterUnassigning()) {
          setRemoveAfterUnassigning(other.getRemoveAfterUnassigning());
        }
        if (other.hasAttempt()) {
          setAttempt(other.getAttempt());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTransitionState()) {
          return false;
        }
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        if (hasDestinationServer()) {
          if (!getDestinationServer().isInitialized()) {
            return false;
          }
        }
        if (hasHostingServer()) {
          if (!getHostingServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  transitionState_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getDestinationServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                force_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 32
              case 42: {
                input.readMessage(
                    getHostingServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 42
              case 48: {
                removeAfterUnassigning_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 56: {
                attempt_ = input.readInt32();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int transitionState_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return Whether the transitionState field is set.
       */
      @java.lang.Override public boolean hasTransitionState() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return The transitionState.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState getTransitionState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.forNumber(transitionState_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState.REGION_TRANSITION_QUEUE : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @param value The transitionState to set.
       * @return This builder for chaining.
       */
      public Builder setTransitionState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        transitionState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionState transition_state = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTransitionState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        transitionState_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000002);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> destinationServerBuilder_;
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       * @return Whether the destinationServer field is set.
       */
      public boolean hasDestinationServer() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       * @return The destinationServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
        if (destinationServerBuilder_ == null) {
          return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        } else {
          return destinationServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          destinationServer_ = value;
        } else {
          destinationServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = builderForValue.build();
        } else {
          destinationServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder mergeDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            destinationServer_ != null &&
            destinationServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getDestinationServerBuilder().mergeFrom(value);
          } else {
            destinationServer_ = value;
          }
        } else {
          destinationServerBuilder_.mergeFrom(value);
        }
        if (destinationServer_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder clearDestinationServer() {
        bitField0_ = (bitField0_ & ~0x00000004);
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getDestinationServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getDestinationServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
        if (destinationServerBuilder_ != null) {
          return destinationServerBuilder_.getMessageOrBuilder();
        } else {
          return destinationServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        }
      }
      /**
       * <pre>
       * This is optional info; it is the servername we will
       * subsequently assign the region too... it may be null.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDestinationServerFieldBuilder() {
        if (destinationServerBuilder_ == null) {
          destinationServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getDestinationServer(),
                  getParentForChildren(),
                  isClean());
          destinationServer_ = null;
        }
        return destinationServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName hostingServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> hostingServerBuilder_;
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       * @return Whether the hostingServer field is set.
       */
      public boolean hasHostingServer() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       * @return The hostingServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getHostingServer() {
        if (hostingServerBuilder_ == null) {
          return hostingServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
        } else {
          return hostingServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder setHostingServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (hostingServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          hostingServer_ = value;
        } else {
          hostingServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder setHostingServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (hostingServerBuilder_ == null) {
          hostingServer_ = builderForValue.build();
        } else {
          hostingServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder mergeHostingServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (hostingServerBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            hostingServer_ != null &&
            hostingServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getHostingServerBuilder().mergeFrom(value);
          } else {
            hostingServer_ = value;
          }
        } else {
          hostingServerBuilder_.mergeFrom(value);
        }
        if (hostingServer_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public Builder clearHostingServer() {
        bitField0_ = (bitField0_ & ~0x00000008);
        hostingServer_ = null;
        if (hostingServerBuilder_ != null) {
          hostingServerBuilder_.dispose();
          hostingServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getHostingServerBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getHostingServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getHostingServerOrBuilder() {
        if (hostingServerBuilder_ != null) {
          return hostingServerBuilder_.getMessageOrBuilder();
        } else {
          return hostingServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : hostingServer_;
        }
      }
      /**
       * <pre>
       * This is the server currently hosting the Region, the
       * server we will send the unassign rpc too.
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName hosting_server = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getHostingServerFieldBuilder() {
        if (hostingServerBuilder_ == null) {
          hostingServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getHostingServer(),
                  getParentForChildren(),
                  isClean());
          hostingServer_ = null;
        }
        return hostingServerBuilder_;
      }

      private boolean force_ ;
      /**
       * <pre>
       * This parameter is ignored
       * </pre>
       *
       * <code>optional bool force = 4 [default = false];</code>
       * @return Whether the force field is set.
       */
      @java.lang.Override
      public boolean hasForce() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * This parameter is ignored
       * </pre>
       *
       * <code>optional bool force = 4 [default = false];</code>
       * @return The force.
       */
      @java.lang.Override
      public boolean getForce() {
        return force_;
      }
      /**
       * <pre>
       * This parameter is ignored
       * </pre>
       *
       * <code>optional bool force = 4 [default = false];</code>
       * @param value The force to set.
       * @return This builder for chaining.
       */
      public Builder setForce(boolean value) {

        force_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This parameter is ignored
       * </pre>
       *
       * <code>optional bool force = 4 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearForce() {
        bitField0_ = (bitField0_ & ~0x00000010);
        force_ = false;
        onChanged();
        return this;
      }

      private boolean removeAfterUnassigning_ ;
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       * @return Whether the removeAfterUnassigning field is set.
       */
      @java.lang.Override
      public boolean hasRemoveAfterUnassigning() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       * @return The removeAfterUnassigning.
       */
      @java.lang.Override
      public boolean getRemoveAfterUnassigning() {
        return removeAfterUnassigning_;
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       * @param value The removeAfterUnassigning to set.
       * @return This builder for chaining.
       */
      public Builder setRemoveAfterUnassigning(boolean value) {

        removeAfterUnassigning_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool remove_after_unassigning = 6 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearRemoveAfterUnassigning() {
        bitField0_ = (bitField0_ & ~0x00000020);
        removeAfterUnassigning_ = false;
        onChanged();
        return this;
      }

      private int attempt_ ;
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       * @return Whether the attempt field is set.
       */
      @java.lang.Override
      public boolean hasAttempt() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       * @return The attempt.
       */
      @java.lang.Override
      public int getAttempt() {
        return attempt_;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       * @param value The attempt to set.
       * @return This builder for chaining.
       */
      public Builder setAttempt(int value) {

        attempt_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current attempt index used for expotential backoff when stuck
       * </pre>
       *
       * <code>optional int32 attempt = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearAttempt() {
        bitField0_ = (bitField0_ & ~0x00000040);
        attempt_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UnassignRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UnassignRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UnassignRegionStateData>() {
      @java.lang.Override
      public UnassignRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UnassignRegionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UnassignRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MoveRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MoveRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     * @return Whether the sourceServer field is set.
     */
    boolean hasSourceServer();
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     * @return The sourceServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer();
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder();

    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return Whether the destinationServer field is set.
     */
    boolean hasDestinationServer();
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return The destinationServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer();
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.MoveRegionStateData}
   */
  @javax.annotation.Generated("proto") public static final class MoveRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MoveRegionStateData)
      MoveRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MoveRegionStateData.newBuilder() to construct.
    private MoveRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MoveRegionStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MoveRegionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int SOURCE_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName sourceServer_;
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     * @return Whether the sourceServer field is set.
     */
    @java.lang.Override
    public boolean hasSourceServer() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     * @return The sourceServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer() {
      return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName source_server = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder() {
      return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
    }

    public static final int DESTINATION_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return Whether the destinationServer field is set.
     */
    @java.lang.Override
    public boolean hasDestinationServer() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     * @return The destinationServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }
    /**
     * <pre>
     * if destination server not specified, its selected with load balancer
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasSourceServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasRegionInfo()) {
        if (!getRegionInfo().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getSourceServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasDestinationServer()) {
        if (!getDestinationServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getSourceServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getDestinationServer());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getSourceServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getDestinationServer());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData) obj;

      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (hasSourceServer() != other.hasSourceServer()) return false;
      if (hasSourceServer()) {
        if (!getSourceServer()
            .equals(other.getSourceServer())) return false;
      }
      if (hasDestinationServer() != other.hasDestinationServer()) return false;
      if (hasDestinationServer()) {
        if (!getDestinationServer()
            .equals(other.getDestinationServer())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasSourceServer()) {
        hash = (37 * hash) + SOURCE_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getSourceServer().hashCode();
      }
      if (hasDestinationServer()) {
        hash = (37 * hash) + DESTINATION_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getDestinationServer().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MoveRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MoveRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
          getSourceServerFieldBuilder();
          getDestinationServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        sourceServer_ = null;
        if (sourceServerBuilder_ != null) {
          sourceServerBuilder_.dispose();
          sourceServerBuilder_ = null;
        }
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_MoveRegionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.sourceServer_ = sourceServerBuilder_ == null
              ? sourceServer_
              : sourceServerBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.destinationServer_ = destinationServerBuilder_ == null
              ? destinationServer_
              : destinationServerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasSourceServer()) {
          mergeSourceServer(other.getSourceServer());
        }
        if (other.hasDestinationServer()) {
          mergeDestinationServer(other.getDestinationServer());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasSourceServer()) {
          return false;
        }
        if (hasRegionInfo()) {
          if (!getRegionInfo().isInitialized()) {
            return false;
          }
        }
        if (!getSourceServer().isInitialized()) {
          return false;
        }
        if (hasDestinationServer()) {
          if (!getDestinationServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getSourceServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getDestinationServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionInfo region_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName sourceServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> sourceServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       * @return Whether the sourceServer field is set.
       */
      public boolean hasSourceServer() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       * @return The sourceServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getSourceServer() {
        if (sourceServerBuilder_ == null) {
          return sourceServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
        } else {
          return sourceServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder setSourceServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (sourceServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          sourceServer_ = value;
        } else {
          sourceServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder setSourceServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (sourceServerBuilder_ == null) {
          sourceServer_ = builderForValue.build();
        } else {
          sourceServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder mergeSourceServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (sourceServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            sourceServer_ != null &&
            sourceServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getSourceServerBuilder().mergeFrom(value);
          } else {
            sourceServer_ = value;
          }
        } else {
          sourceServerBuilder_.mergeFrom(value);
        }
        if (sourceServer_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public Builder clearSourceServer() {
        bitField0_ = (bitField0_ & ~0x00000002);
        sourceServer_ = null;
        if (sourceServerBuilder_ != null) {
          sourceServerBuilder_.dispose();
          sourceServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getSourceServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSourceServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getSourceServerOrBuilder() {
        if (sourceServerBuilder_ != null) {
          return sourceServerBuilder_.getMessageOrBuilder();
        } else {
          return sourceServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : sourceServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName source_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getSourceServerFieldBuilder() {
        if (sourceServerBuilder_ == null) {
          sourceServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getSourceServer(),
                  getParentForChildren(),
                  isClean());
          sourceServer_ = null;
        }
        return sourceServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> destinationServerBuilder_;
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       * @return Whether the destinationServer field is set.
       */
      public boolean hasDestinationServer() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       * @return The destinationServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
        if (destinationServerBuilder_ == null) {
          return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        } else {
          return destinationServerBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          destinationServer_ = value;
        } else {
          destinationServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder setDestinationServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = builderForValue.build();
        } else {
          destinationServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder mergeDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            destinationServer_ != null &&
            destinationServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getDestinationServerBuilder().mergeFrom(value);
          } else {
            destinationServer_ = value;
          }
        } else {
          destinationServerBuilder_.mergeFrom(value);
        }
        if (destinationServer_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public Builder clearDestinationServer() {
        bitField0_ = (bitField0_ & ~0x00000004);
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getDestinationServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getDestinationServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
        if (destinationServerBuilder_ != null) {
          return destinationServerBuilder_.getMessageOrBuilder();
        } else {
          return destinationServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        }
      }
      /**
       * <pre>
       * if destination server not specified, its selected with load balancer
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName destination_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDestinationServerFieldBuilder() {
        if (destinationServerBuilder_ == null) {
          destinationServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getDestinationServer(),
                  getParentForChildren(),
                  isClean());
          destinationServer_ = null;
        }
        return destinationServerBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MoveRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MoveRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MoveRegionStateData>() {
      @java.lang.Override
      public MoveRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MoveRegionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.MoveRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GCRegionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCRegionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCRegionStateData}
   */
  @javax.annotation.Generated("proto") public static final class GCRegionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCRegionStateData)
      GCRegionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCRegionStateData.newBuilder() to construct.
    private GCRegionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCRegionStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GCRegionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegionInfo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData) obj;

      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCRegionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCRegionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCRegionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCRegionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCRegionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCRegionStateData>() {
      @java.lang.Override
      public GCRegionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCRegionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCRegionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  @java.lang.Deprecated public interface GCMergedRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCMergedRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     * @return Whether the parentA field is set.
     */
    boolean hasParentA();
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     * @return The parentA.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA();
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     * @return Whether the parentB field is set.
     */
    boolean hasParentB();
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     * @return The parentB.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB();
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder();

    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     * @return Whether the mergedChild field is set.
     */
    boolean hasMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     * @return The mergedChild.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCMergedRegionsStateData}
   */
  @java.lang.Deprecated @javax.annotation.Generated("proto") public static final class GCMergedRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCMergedRegionsStateData)
      GCMergedRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCMergedRegionsStateData.newBuilder() to construct.
    private GCMergedRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCMergedRegionsStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GCMergedRegionsStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PARENT_A_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentA_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     * @return Whether the parentA field is set.
     */
    @java.lang.Override
    public boolean hasParentA() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     * @return The parentA.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA() {
      return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder() {
      return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
    }

    public static final int PARENT_B_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentB_;
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     * @return Whether the parentB field is set.
     */
    @java.lang.Override
    public boolean hasParentB() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     * @return The parentB.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB() {
      return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder() {
      return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
    }

    public static final int MERGED_CHILD_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     * @return Whether the mergedChild field is set.
     */
    @java.lang.Override
    public boolean hasMergedChild() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     * @return The mergedChild.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasParentA()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasParentB()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMergedChild()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentA().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getParentB().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getMergedChild().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getParentA());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getParentB());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getMergedChild());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getParentA());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getParentB());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getMergedChild());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData) obj;

      if (hasParentA() != other.hasParentA()) return false;
      if (hasParentA()) {
        if (!getParentA()
            .equals(other.getParentA())) return false;
      }
      if (hasParentB() != other.hasParentB()) return false;
      if (hasParentB()) {
        if (!getParentB()
            .equals(other.getParentB())) return false;
      }
      if (hasMergedChild() != other.hasMergedChild()) return false;
      if (hasMergedChild()) {
        if (!getMergedChild()
            .equals(other.getMergedChild())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasParentA()) {
        hash = (37 * hash) + PARENT_A_FIELD_NUMBER;
        hash = (53 * hash) + getParentA().hashCode();
      }
      if (hasParentB()) {
        hash = (37 * hash) + PARENT_B_FIELD_NUMBER;
        hash = (53 * hash) + getParentB().hashCode();
      }
      if (hasMergedChild()) {
        hash = (37 * hash) + MERGED_CHILD_FIELD_NUMBER;
        hash = (53 * hash) + getMergedChild().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCMergedRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCMergedRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getParentAFieldBuilder();
          getParentBFieldBuilder();
          getMergedChildFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        parentA_ = null;
        if (parentABuilder_ != null) {
          parentABuilder_.dispose();
          parentABuilder_ = null;
        }
        parentB_ = null;
        if (parentBBuilder_ != null) {
          parentBBuilder_.dispose();
          parentBBuilder_ = null;
        }
        mergedChild_ = null;
        if (mergedChildBuilder_ != null) {
          mergedChildBuilder_.dispose();
          mergedChildBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.parentA_ = parentABuilder_ == null
              ? parentA_
              : parentABuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.parentB_ = parentBBuilder_ == null
              ? parentB_
              : parentBBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.mergedChild_ = mergedChildBuilder_ == null
              ? mergedChild_
              : mergedChildBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData.getDefaultInstance()) return this;
        if (other.hasParentA()) {
          mergeParentA(other.getParentA());
        }
        if (other.hasParentB()) {
          mergeParentB(other.getParentB());
        }
        if (other.hasMergedChild()) {
          mergeMergedChild(other.getMergedChild());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasParentA()) {
          return false;
        }
        if (!hasParentB()) {
          return false;
        }
        if (!hasMergedChild()) {
          return false;
        }
        if (!getParentA().isInitialized()) {
          return false;
        }
        if (!getParentB().isInitialized()) {
          return false;
        }
        if (!getMergedChild().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getParentAFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getParentBFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getMergedChildFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentA_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentABuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       * @return Whether the parentA field is set.
       */
      public boolean hasParentA() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       * @return The parentA.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentA() {
        if (parentABuilder_ == null) {
          return parentA_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
        } else {
          return parentABuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder setParentA(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentABuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentA_ = value;
        } else {
          parentABuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder setParentA(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentABuilder_ == null) {
          parentA_ = builderForValue.build();
        } else {
          parentABuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder mergeParentA(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentABuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            parentA_ != null &&
            parentA_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getParentABuilder().mergeFrom(value);
          } else {
            parentA_ = value;
          }
        } else {
          parentABuilder_.mergeFrom(value);
        }
        if (parentA_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public Builder clearParentA() {
        bitField0_ = (bitField0_ & ~0x00000001);
        parentA_ = null;
        if (parentABuilder_ != null) {
          parentABuilder_.dispose();
          parentABuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentABuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getParentAFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentAOrBuilder() {
        if (parentABuilder_ != null) {
          return parentABuilder_.getMessageOrBuilder();
        } else {
          return parentA_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentA_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_a = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentAFieldBuilder() {
        if (parentABuilder_ == null) {
          parentABuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentA(),
                  getParentForChildren(),
                  isClean());
          parentA_ = null;
        }
        return parentABuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo parentB_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentBBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       * @return Whether the parentB field is set.
       */
      public boolean hasParentB() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       * @return The parentB.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParentB() {
        if (parentBBuilder_ == null) {
          return parentB_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
        } else {
          return parentBBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder setParentB(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentBBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parentB_ = value;
        } else {
          parentBBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder setParentB(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentBBuilder_ == null) {
          parentB_ = builderForValue.build();
        } else {
          parentBBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder mergeParentB(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentBBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            parentB_ != null &&
            parentB_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getParentBBuilder().mergeFrom(value);
          } else {
            parentB_ = value;
          }
        } else {
          parentBBuilder_.mergeFrom(value);
        }
        if (parentB_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public Builder clearParentB() {
        bitField0_ = (bitField0_ & ~0x00000002);
        parentB_ = null;
        if (parentBBuilder_ != null) {
          parentBBuilder_.dispose();
          parentBBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentBBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getParentBFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentBOrBuilder() {
        if (parentBBuilder_ != null) {
          return parentBBuilder_.getMessageOrBuilder();
        } else {
          return parentB_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : parentB_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo parent_b = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentBFieldBuilder() {
        if (parentBBuilder_ == null) {
          parentBBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getParentB(),
                  getParentForChildren(),
                  isClean());
          parentB_ = null;
        }
        return parentBBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedChildBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       * @return Whether the mergedChild field is set.
       */
      public boolean hasMergedChild() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       * @return The mergedChild.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
        if (mergedChildBuilder_ == null) {
          return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        } else {
          return mergedChildBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder setMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedChild_ = value;
        } else {
          mergedChildBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder setMergedChild(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = builderForValue.build();
        } else {
          mergedChildBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder mergeMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            mergedChild_ != null &&
            mergedChild_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getMergedChildBuilder().mergeFrom(value);
          } else {
            mergedChild_ = value;
          }
        } else {
          mergedChildBuilder_.mergeFrom(value);
        }
        if (mergedChild_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public Builder clearMergedChild() {
        bitField0_ = (bitField0_ & ~0x00000004);
        mergedChild_ = null;
        if (mergedChildBuilder_ != null) {
          mergedChildBuilder_.dispose();
          mergedChildBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedChildBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMergedChildFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
        if (mergedChildBuilder_ != null) {
          return mergedChildBuilder_.getMessageOrBuilder();
        } else {
          return mergedChild_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedChildFieldBuilder() {
        if (mergedChildBuilder_ == null) {
          mergedChildBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedChild(),
                  getParentForChildren(),
                  isClean());
          mergedChild_ = null;
        }
        return mergedChildBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCMergedRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCMergedRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCMergedRegionsStateData>() {
      @java.lang.Override
      public GCMergedRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMergedRegionsStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMergedRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GCMultipleMergedRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GCMultipleMergedRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getParentsList();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    int getParentsCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getParentsOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
        int index);

    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     * @return Whether the mergedChild field is set.
     */
    boolean hasMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     * @return The mergedChild.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild();
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GCMultipleMergedRegionsStateData}
   */
  @javax.annotation.Generated("proto") public static final class GCMultipleMergedRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GCMultipleMergedRegionsStateData)
      GCMultipleMergedRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GCMultipleMergedRegionsStateData.newBuilder() to construct.
    private GCMultipleMergedRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GCMultipleMergedRegionsStateData() {
      parents_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GCMultipleMergedRegionsStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PARENTS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> parents_;
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getParentsList() {
      return parents_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getParentsOrBuilderList() {
      return parents_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    @java.lang.Override
    public int getParentsCount() {
      return parents_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index) {
      return parents_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
        int index) {
      return parents_.get(index);
    }

    public static final int MERGED_CHILD_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     * @return Whether the mergedChild field is set.
     */
    @java.lang.Override
    public boolean hasMergedChild() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     * @return The mergedChild.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
      return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasMergedChild()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getParentsCount(); i++) {
        if (!getParents(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getMergedChild().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < parents_.size(); i++) {
        output.writeMessage(1, parents_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(2, getMergedChild());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < parents_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, parents_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getMergedChild());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData) obj;

      if (!getParentsList()
          .equals(other.getParentsList())) return false;
      if (hasMergedChild() != other.hasMergedChild()) return false;
      if (hasMergedChild()) {
        if (!getMergedChild()
            .equals(other.getMergedChild())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getParentsCount() > 0) {
        hash = (37 * hash) + PARENTS_FIELD_NUMBER;
        hash = (53 * hash) + getParentsList().hashCode();
      }
      if (hasMergedChild()) {
        hash = (37 * hash) + MERGED_CHILD_FIELD_NUMBER;
        hash = (53 * hash) + getMergedChild().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GCMultipleMergedRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GCMultipleMergedRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getParentsFieldBuilder();
          getMergedChildFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (parentsBuilder_ == null) {
          parents_ = java.util.Collections.emptyList();
        } else {
          parents_ = null;
          parentsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        mergedChild_ = null;
        if (mergedChildBuilder_ != null) {
          mergedChildBuilder_.dispose();
          mergedChildBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result) {
        if (parentsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            parents_ = java.util.Collections.unmodifiableList(parents_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.parents_ = parents_;
        } else {
          result.parents_ = parentsBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.mergedChild_ = mergedChildBuilder_ == null
              ? mergedChild_
              : mergedChildBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData.getDefaultInstance()) return this;
        if (parentsBuilder_ == null) {
          if (!other.parents_.isEmpty()) {
            if (parents_.isEmpty()) {
              parents_ = other.parents_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureParentsIsMutable();
              parents_.addAll(other.parents_);
            }
            onChanged();
          }
        } else {
          if (!other.parents_.isEmpty()) {
            if (parentsBuilder_.isEmpty()) {
              parentsBuilder_.dispose();
              parentsBuilder_ = null;
              parents_ = other.parents_;
              bitField0_ = (bitField0_ & ~0x00000001);
              parentsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getParentsFieldBuilder() : null;
            } else {
              parentsBuilder_.addAllMessages(other.parents_);
            }
          }
        }
        if (other.hasMergedChild()) {
          mergeMergedChild(other.getMergedChild());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasMergedChild()) {
          return false;
        }
        for (int i = 0; i < getParentsCount(); i++) {
          if (!getParents(i).isInitialized()) {
            return false;
          }
        }
        if (!getMergedChild().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (parentsBuilder_ == null) {
                  ensureParentsIsMutable();
                  parents_.add(m);
                } else {
                  parentsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getMergedChildFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> parents_ =
        java.util.Collections.emptyList();
      private void ensureParentsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          parents_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(parents_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> parentsBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getParentsList() {
        if (parentsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parents_);
        } else {
          return parentsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public int getParentsCount() {
        if (parentsBuilder_ == null) {
          return parents_.size();
        } else {
          return parentsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getParents(int index) {
        if (parentsBuilder_ == null) {
          return parents_.get(index);
        } else {
          return parentsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder setParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.set(index, value);
          onChanged();
        } else {
          parentsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder setParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.set(index, builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.add(value);
          onChanged();
        } else {
          parentsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (parentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParentsIsMutable();
          parents_.add(index, value);
          onChanged();
        } else {
          parentsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.add(builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addParents(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.add(index, builderForValue.build());
          onChanged();
        } else {
          parentsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder addAllParents(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, parents_);
          onChanged();
        } else {
          parentsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder clearParents() {
        if (parentsBuilder_ == null) {
          parents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          parentsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public Builder removeParents(int index) {
        if (parentsBuilder_ == null) {
          ensureParentsIsMutable();
          parents_.remove(index);
          onChanged();
        } else {
          parentsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getParentsBuilder(
          int index) {
        return getParentsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getParentsOrBuilder(
          int index) {
        if (parentsBuilder_ == null) {
          return parents_.get(index);  } else {
          return parentsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getParentsOrBuilderList() {
        if (parentsBuilder_ != null) {
          return parentsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parents_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addParentsBuilder() {
        return getParentsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addParentsBuilder(
          int index) {
        return getParentsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo parents = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getParentsBuilderList() {
        return getParentsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getParentsFieldBuilder() {
        if (parentsBuilder_ == null) {
          parentsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  parents_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          parents_ = null;
        }
        return parentsBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo mergedChild_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> mergedChildBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       * @return Whether the mergedChild field is set.
       */
      public boolean hasMergedChild() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       * @return The mergedChild.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getMergedChild() {
        if (mergedChildBuilder_ == null) {
          return mergedChild_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        } else {
          return mergedChildBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder setMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mergedChild_ = value;
        } else {
          mergedChildBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder setMergedChild(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (mergedChildBuilder_ == null) {
          mergedChild_ = builderForValue.build();
        } else {
          mergedChildBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder mergeMergedChild(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (mergedChildBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            mergedChild_ != null &&
            mergedChild_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getMergedChildBuilder().mergeFrom(value);
          } else {
            mergedChild_ = value;
          }
        } else {
          mergedChildBuilder_.mergeFrom(value);
        }
        if (mergedChild_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public Builder clearMergedChild() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mergedChild_ = null;
        if (mergedChildBuilder_ != null) {
          mergedChildBuilder_.dispose();
          mergedChildBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getMergedChildBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMergedChildFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getMergedChildOrBuilder() {
        if (mergedChildBuilder_ != null) {
          return mergedChildBuilder_.getMessageOrBuilder();
        } else {
          return mergedChild_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : mergedChild_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo merged_child = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getMergedChildFieldBuilder() {
        if (mergedChildBuilder_ == null) {
          mergedChildBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getMergedChild(),
                  getParentForChildren(),
                  isClean());
          mergedChild_ = null;
        }
        return mergedChildBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GCMultipleMergedRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GCMultipleMergedRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GCMultipleMergedRegionsStateData>() {
      @java.lang.Override
      public GCMultipleMergedRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GCMultipleMergedRegionsStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.GCMultipleMergedRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PeerModificationStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PeerModificationStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.PeerModificationStateData}
   */
  @javax.annotation.Generated("proto") public static final class PeerModificationStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PeerModificationStateData)
      PeerModificationStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PeerModificationStateData.newBuilder() to construct.
    private PeerModificationStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PeerModificationStateData() {
      peerId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PeerModificationStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object peerId_ = "";
    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    @java.lang.Override
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    @java.lang.Override
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData) obj;

      if (hasPeerId() != other.hasPeerId()) return false;
      if (hasPeerId()) {
        if (!getPeerId()
            .equals(other.getPeerId())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PeerModificationStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PeerModificationStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerId_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerModificationStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerId_ = peerId_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          peerId_ = other.peerId_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                peerId_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       * @return Whether the peerId field is set.
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The peerId.
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The bytes for peerId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPeerId() {
        peerId_ = getDefaultInstance().getPeerId();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The bytes for peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PeerModificationStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PeerModificationStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PeerModificationStateData>() {
      @java.lang.Override
      public PeerModificationStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerModificationStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RefreshPeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RefreshPeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return Whether the type field is set.
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return The type.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType();

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return Whether the state field is set.
     */
    boolean hasState();
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return The state.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState();

    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return Whether the error field is set.
     */
    boolean hasError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return The error.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RefreshPeerStateData}
   */
  @javax.annotation.Generated("proto") public static final class RefreshPeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RefreshPeerStateData)
      RefreshPeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RefreshPeerStateData.newBuilder() to construct.
    private RefreshPeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RefreshPeerStateData() {
      peerId_ = "";
      type_ = 1;
      state_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RefreshPeerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object peerId_ = "";
    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    @java.lang.Override
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    @java.lang.Override
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TYPE_FIELD_NUMBER = 2;
    private int type_ = 1;
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return Whether the type field is set.
     */
    @java.lang.Override public boolean hasType() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return The type.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STATE_FIELD_NUMBER = 5;
    private int state_ = 1;
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return Whether the state field is set.
     */
    @java.lang.Override public boolean hasState() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return The state.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int ERROR_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return Whether the error field is set.
     */
    @java.lang.Override
    public boolean hasError() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return The error.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, type_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(5, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(6, getError());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, type_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getError());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData) obj;

      if (hasPeerId() != other.hasPeerId()) return false;
      if (hasPeerId()) {
        if (!getPeerId()
            .equals(other.getPeerId())) return false;
      }
      if (hasType() != other.hasType()) return false;
      if (hasType()) {
        if (type_ != other.type_) return false;
      }
      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (hasState() != other.hasState()) return false;
      if (hasState()) {
        if (state_ != other.state_) return false;
      }
      if (hasError() != other.hasError()) return false;
      if (hasError()) {
        if (!getError()
            .equals(other.getError())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasError()) {
        hash = (37 * hash) + ERROR_FIELD_NUMBER;
        hash = (53 * hash) + getError().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RefreshPeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RefreshPeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
          getErrorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerId_ = "";
        type_ = 1;
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        state_ = 1;
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerId_ = peerId_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.type_ = type_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.state_ = state_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.error_ = errorBuilder_ == null
              ? error_
              : errorBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          peerId_ = other.peerId_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasError()) {
          mergeError(other.getError());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (!hasType()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                peerId_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(2, tmpRaw);
                } else {
                  type_ = tmpRaw;
                  bitField0_ |= 0x00000002;
                }
                break;
              } // case 16
              case 26: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 40: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(5, tmpRaw);
                } else {
                  state_ = tmpRaw;
                  bitField0_ |= 0x00000008;
                }
                break;
              } // case 40
              case 50: {
                input.readMessage(
                    getErrorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 50
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       * @return Whether the peerId field is set.
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The peerId.
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The bytes for peerId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPeerId() {
        peerId_ = getDefaultInstance().getPeerId();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The bytes for peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return Whether the type field is set.
       */
      @java.lang.Override public boolean hasType() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return The type.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @param value The type to set.
       * @return This builder for chaining.
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000004);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int state_ = 1;
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return Whether the state field is set.
       */
      @java.lang.Override public boolean hasState() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return The state.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> errorBuilder_;
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       * @return Whether the error field is set.
       */
      public boolean hasError() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       * @return The error.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
        if (errorBuilder_ == null) {
          return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        } else {
          return errorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder setError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          error_ = value;
        } else {
          errorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder setError(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder builderForValue) {
        if (errorBuilder_ == null) {
          error_ = builderForValue.build();
        } else {
          errorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder mergeError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            error_ != null &&
            error_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance()) {
            getErrorBuilder().mergeFrom(value);
          } else {
            error_ = value;
          }
        } else {
          errorBuilder_.mergeFrom(value);
        }
        if (error_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder clearError() {
        bitField0_ = (bitField0_ & ~0x00000010);
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder getErrorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getErrorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
        if (errorBuilder_ != null) {
          return errorBuilder_.getMessageOrBuilder();
        } else {
          return error_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> 
          getErrorFieldBuilder() {
        if (errorBuilder_ == null) {
          errorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder>(
                  getError(),
                  getParentForChildren(),
                  isClean());
          error_ = null;
        }
        return errorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RefreshPeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RefreshPeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RefreshPeerStateData>() {
      @java.lang.Override
      public RefreshPeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RefreshPeerParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RefreshPeerParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();

    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return Whether the type field is set.
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return The type.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType();

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RefreshPeerParameter}
   */
  @javax.annotation.Generated("proto") public static final class RefreshPeerParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RefreshPeerParameter)
      RefreshPeerParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RefreshPeerParameter.newBuilder() to construct.
    private RefreshPeerParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RefreshPeerParameter() {
      peerId_ = "";
      type_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RefreshPeerParameter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object peerId_ = "";
    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    @java.lang.Override
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    @java.lang.Override
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TYPE_FIELD_NUMBER = 2;
    private int type_ = 1;
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return Whether the type field is set.
     */
    @java.lang.Override public boolean hasType() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.PeerModificationType type = 2;</code>
     * @return The type.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, type_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTargetServer());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, type_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter) obj;

      if (hasPeerId() != other.hasPeerId()) return false;
      if (hasPeerId()) {
        if (!getPeerId()
            .equals(other.getPeerId())) return false;
      }
      if (hasType() != other.hasType()) return false;
      if (hasType()) {
        if (type_ != other.type_) return false;
      }
      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RefreshPeerParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RefreshPeerParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerId_ = "";
        type_ = 1;
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RefreshPeerParameter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerId_ = peerId_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.type_ = type_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          peerId_ = other.peerId_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        if (!hasType()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                peerId_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(2, tmpRaw);
                } else {
                  type_ = tmpRaw;
                  bitField0_ |= 0x00000002;
                }
                break;
              } // case 16
              case 26: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       * @return Whether the peerId field is set.
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The peerId.
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The bytes for peerId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPeerId() {
        peerId_ = getDefaultInstance().getPeerId();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The bytes for peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return Whether the type field is set.
       */
      @java.lang.Override public boolean hasType() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return The type.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.forNumber(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType.ADD_PEER : result;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @param value The type to set.
       * @return This builder for chaining.
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerModificationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.PeerModificationType type = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000004);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RefreshPeerParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RefreshPeerParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RefreshPeerParameter>() {
      @java.lang.Override
      public RefreshPeerParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RefreshPeerParameter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RefreshPeerParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PeerProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PeerProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    boolean hasPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    java.lang.String getPeerId();
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.PeerProcedureStateData}
   */
  @javax.annotation.Generated("proto") public static final class PeerProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PeerProcedureStateData)
      PeerProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PeerProcedureStateData.newBuilder() to construct.
    private PeerProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PeerProcedureStateData() {
      peerId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PeerProcedureStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_ID_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object peerId_ = "";
    /**
     * <code>required string peer_id = 1;</code>
     * @return Whether the peerId field is set.
     */
    @java.lang.Override
    public boolean hasPeerId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The peerId.
     */
    @java.lang.Override
    public java.lang.String getPeerId() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          peerId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string peer_id = 1;</code>
     * @return The bytes for peerId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getPeerIdBytes() {
      java.lang.Object ref = peerId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        peerId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, peerId_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, peerId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData) obj;

      if (hasPeerId() != other.hasPeerId()) return false;
      if (hasPeerId()) {
        if (!getPeerId()
            .equals(other.getPeerId())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerId()) {
        hash = (37 * hash) + PEER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getPeerId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PeerProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PeerProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerId_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_PeerProcedureStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerId_ = peerId_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData.getDefaultInstance()) return this;
        if (other.hasPeerId()) {
          peerId_ = other.peerId_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerId()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                peerId_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object peerId_ = "";
      /**
       * <code>required string peer_id = 1;</code>
       * @return Whether the peerId field is set.
       */
      public boolean hasPeerId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The peerId.
       */
      public java.lang.String getPeerId() {
        java.lang.Object ref = peerId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            peerId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return The bytes for peerId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPeerIdBytes() {
        java.lang.Object ref = peerId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          peerId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPeerId() {
        peerId_ = getDefaultInstance().getPeerId();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string peer_id = 1;</code>
       * @param value The bytes for peerId to set.
       * @return This builder for chaining.
       */
      public Builder setPeerIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        peerId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PeerProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PeerProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PeerProcedureStateData>() {
      @java.lang.Override
      public PeerProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PeerProcedureStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.PeerProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AddPeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.AddPeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    boolean hasPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();

    /**
     * <code>required bool enabled = 2;</code>
     * @return Whether the enabled field is set.
     */
    boolean hasEnabled();
    /**
     * <code>required bool enabled = 2;</code>
     * @return The enabled.
     */
    boolean getEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.AddPeerStateData}
   */
  @javax.annotation.Generated("proto") public static final class AddPeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.AddPeerStateData)
      AddPeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AddPeerStateData.newBuilder() to construct.
    private AddPeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AddPeerStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new AddPeerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    @java.lang.Override
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    public static final int ENABLED_FIELD_NUMBER = 2;
    private boolean enabled_ = false;
    /**
     * <code>required bool enabled = 2;</code>
     * @return Whether the enabled field is set.
     */
    @java.lang.Override
    public boolean hasEnabled() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bool enabled = 2;</code>
     * @return The enabled.
     */
    @java.lang.Override
    public boolean getEnabled() {
      return enabled_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerConfig()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getPeerConfig().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, enabled_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, enabled_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData) obj;

      if (hasPeerConfig() != other.hasPeerConfig()) return false;
      if (hasPeerConfig()) {
        if (!getPeerConfig()
            .equals(other.getPeerConfig())) return false;
      }
      if (hasEnabled() != other.hasEnabled()) return false;
      if (hasEnabled()) {
        if (getEnabled()
            != other.getEnabled()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      if (hasEnabled()) {
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getEnabled());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AddPeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.AddPeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        enabled_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddPeerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerConfig_ = peerConfigBuilder_ == null
              ? peerConfig_
              : peerConfigBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.enabled_ = enabled_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        if (other.hasEnabled()) {
          setEnabled(other.getEnabled());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerConfig()) {
          return false;
        }
        if (!hasEnabled()) {
          return false;
        }
        if (!getPeerConfig().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getPeerConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                enabled_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return Whether the peerConfig field is set.
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return The peerConfig.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            peerConfig_ != null &&
            peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            getPeerConfigBuilder().mergeFrom(value);
          } else {
            peerConfig_ = value;
          }
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        if (peerConfig_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }

      private boolean enabled_ ;
      /**
       * <code>required bool enabled = 2;</code>
       * @return Whether the enabled field is set.
       */
      @java.lang.Override
      public boolean hasEnabled() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bool enabled = 2;</code>
       * @return The enabled.
       */
      @java.lang.Override
      public boolean getEnabled() {
        return enabled_;
      }
      /**
       * <code>required bool enabled = 2;</code>
       * @param value The enabled to set.
       * @return This builder for chaining.
       */
      public Builder setEnabled(boolean value) {

        enabled_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bool enabled = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnabled() {
        bitField0_ = (bitField0_ & ~0x00000002);
        enabled_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.AddPeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AddPeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<AddPeerStateData>() {
      @java.lang.Override
      public AddPeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<AddPeerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.AddPeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdatePeerConfigStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdatePeerConfigStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    boolean hasPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();

    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     * @return Whether the oldPeerConfig field is set.
     */
    boolean hasOldPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     * @return The oldPeerConfig.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder();

    /**
     * <code>required bool enabled = 3;</code>
     * @return Whether the enabled field is set.
     */
    boolean hasEnabled();
    /**
     * <code>required bool enabled = 3;</code>
     * @return The enabled.
     */
    boolean getEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.UpdatePeerConfigStateData}
   */
  @javax.annotation.Generated("proto") public static final class UpdatePeerConfigStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdatePeerConfigStateData)
      UpdatePeerConfigStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdatePeerConfigStateData.newBuilder() to construct.
    private UpdatePeerConfigStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdatePeerConfigStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UpdatePeerConfigStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    @java.lang.Override
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    public static final int OLD_PEER_CONFIG_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer oldPeerConfig_;
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     * @return Whether the oldPeerConfig field is set.
     */
    @java.lang.Override
    public boolean hasOldPeerConfig() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     * @return The oldPeerConfig.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig() {
      return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder() {
      return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
    }

    public static final int ENABLED_FIELD_NUMBER = 3;
    private boolean enabled_ = false;
    /**
     * <code>required bool enabled = 3;</code>
     * @return Whether the enabled field is set.
     */
    @java.lang.Override
    public boolean hasEnabled() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bool enabled = 3;</code>
     * @return The enabled.
     */
    @java.lang.Override
    public boolean getEnabled() {
      return enabled_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPeerConfig()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getPeerConfig().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasOldPeerConfig()) {
        if (!getOldPeerConfig().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getOldPeerConfig());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, enabled_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getOldPeerConfig());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, enabled_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData) obj;

      if (hasPeerConfig() != other.hasPeerConfig()) return false;
      if (hasPeerConfig()) {
        if (!getPeerConfig()
            .equals(other.getPeerConfig())) return false;
      }
      if (hasOldPeerConfig() != other.hasOldPeerConfig()) return false;
      if (hasOldPeerConfig()) {
        if (!getOldPeerConfig()
            .equals(other.getOldPeerConfig())) return false;
      }
      if (hasEnabled() != other.hasEnabled()) return false;
      if (hasEnabled()) {
        if (getEnabled()
            != other.getEnabled()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      if (hasOldPeerConfig()) {
        hash = (37 * hash) + OLD_PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getOldPeerConfig().hashCode();
      }
      if (hasEnabled()) {
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getEnabled());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdatePeerConfigStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdatePeerConfigStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
          getOldPeerConfigFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        oldPeerConfig_ = null;
        if (oldPeerConfigBuilder_ != null) {
          oldPeerConfigBuilder_.dispose();
          oldPeerConfigBuilder_ = null;
        }
        enabled_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerConfig_ = peerConfigBuilder_ == null
              ? peerConfig_
              : peerConfigBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.oldPeerConfig_ = oldPeerConfigBuilder_ == null
              ? oldPeerConfig_
              : oldPeerConfigBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.enabled_ = enabled_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        if (other.hasOldPeerConfig()) {
          mergeOldPeerConfig(other.getOldPeerConfig());
        }
        if (other.hasEnabled()) {
          setEnabled(other.getEnabled());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPeerConfig()) {
          return false;
        }
        if (!hasEnabled()) {
          return false;
        }
        if (!getPeerConfig().isInitialized()) {
          return false;
        }
        if (hasOldPeerConfig()) {
          if (!getOldPeerConfig().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getPeerConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getOldPeerConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                enabled_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return Whether the peerConfig field is set.
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return The peerConfig.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            peerConfig_ != null &&
            peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            getPeerConfigBuilder().mergeFrom(value);
          } else {
            peerConfig_ = value;
          }
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        if (peerConfig_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>required .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer oldPeerConfig_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> oldPeerConfigBuilder_;
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       * @return Whether the oldPeerConfig field is set.
       */
      public boolean hasOldPeerConfig() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       * @return The oldPeerConfig.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getOldPeerConfig() {
        if (oldPeerConfigBuilder_ == null) {
          return oldPeerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
        } else {
          return oldPeerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder setOldPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (oldPeerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldPeerConfig_ = value;
        } else {
          oldPeerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder setOldPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfig_ = builderForValue.build();
        } else {
          oldPeerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder mergeOldPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (oldPeerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            oldPeerConfig_ != null &&
            oldPeerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            getOldPeerConfigBuilder().mergeFrom(value);
          } else {
            oldPeerConfig_ = value;
          }
        } else {
          oldPeerConfigBuilder_.mergeFrom(value);
        }
        if (oldPeerConfig_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public Builder clearOldPeerConfig() {
        bitField0_ = (bitField0_ & ~0x00000002);
        oldPeerConfig_ = null;
        if (oldPeerConfigBuilder_ != null) {
          oldPeerConfigBuilder_.dispose();
          oldPeerConfigBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getOldPeerConfigBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getOldPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getOldPeerConfigOrBuilder() {
        if (oldPeerConfigBuilder_ != null) {
          return oldPeerConfigBuilder_.getMessageOrBuilder();
        } else {
          return oldPeerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : oldPeerConfig_;
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer old_peer_config = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getOldPeerConfigFieldBuilder() {
        if (oldPeerConfigBuilder_ == null) {
          oldPeerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getOldPeerConfig(),
                  getParentForChildren(),
                  isClean());
          oldPeerConfig_ = null;
        }
        return oldPeerConfigBuilder_;
      }

      private boolean enabled_ ;
      /**
       * <code>required bool enabled = 3;</code>
       * @return Whether the enabled field is set.
       */
      @java.lang.Override
      public boolean hasEnabled() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bool enabled = 3;</code>
       * @return The enabled.
       */
      @java.lang.Override
      public boolean getEnabled() {
        return enabled_;
      }
      /**
       * <code>required bool enabled = 3;</code>
       * @param value The enabled to set.
       * @return This builder for chaining.
       */
      public Builder setEnabled(boolean value) {

        enabled_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bool enabled = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnabled() {
        bitField0_ = (bitField0_ & ~0x00000004);
        enabled_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdatePeerConfigStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdatePeerConfigStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdatePeerConfigStateData>() {
      @java.lang.Override
      public UpdatePeerConfigStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdatePeerConfigStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.UpdatePeerConfigStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RemovePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RemovePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    boolean hasPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig();
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RemovePeerStateData}
   */
  @javax.annotation.Generated("proto") public static final class RemovePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RemovePeerStateData)
      RemovePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RemovePeerStateData.newBuilder() to construct.
    private RemovePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RemovePeerStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RemovePeerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int PEER_CONFIG_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return Whether the peerConfig field is set.
     */
    @java.lang.Override
    public boolean hasPeerConfig() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     * @return The peerConfig.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }
    /**
     * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
      return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasPeerConfig()) {
        if (!getPeerConfig().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getPeerConfig());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPeerConfig());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData) obj;

      if (hasPeerConfig() != other.hasPeerConfig()) return false;
      if (hasPeerConfig()) {
        if (!getPeerConfig()
            .equals(other.getPeerConfig())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPeerConfig()) {
        hash = (37 * hash) + PEER_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getPeerConfig().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RemovePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RemovePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPeerConfigFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RemovePeerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.peerConfig_ = peerConfigBuilder_ == null
              ? peerConfig_
              : peerConfigBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData.getDefaultInstance()) return this;
        if (other.hasPeerConfig()) {
          mergePeerConfig(other.getPeerConfig());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasPeerConfig()) {
          if (!getPeerConfig().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getPeerConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer peerConfig_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> peerConfigBuilder_;
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return Whether the peerConfig field is set.
       */
      public boolean hasPeerConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       * @return The peerConfig.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer getPeerConfig() {
        if (peerConfigBuilder_ == null) {
          return peerConfig_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        } else {
          return peerConfigBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          peerConfig_ = value;
        } else {
          peerConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder setPeerConfig(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder builderForValue) {
        if (peerConfigBuilder_ == null) {
          peerConfig_ = builderForValue.build();
        } else {
          peerConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder mergePeerConfig(org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer value) {
        if (peerConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            peerConfig_ != null &&
            peerConfig_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance()) {
            getPeerConfigBuilder().mergeFrom(value);
          } else {
            peerConfig_ = value;
          }
        } else {
          peerConfigBuilder_.mergeFrom(value);
        }
        if (peerConfig_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public Builder clearPeerConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        peerConfig_ = null;
        if (peerConfigBuilder_ != null) {
          peerConfigBuilder_.dispose();
          peerConfigBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder getPeerConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPeerConfigFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder getPeerConfigOrBuilder() {
        if (peerConfigBuilder_ != null) {
          return peerConfigBuilder_.getMessageOrBuilder();
        } else {
          return peerConfig_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.getDefaultInstance() : peerConfig_;
        }
      }
      /**
       * <code>optional .hbase.pb.ReplicationPeer peer_config = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder> 
          getPeerConfigFieldBuilder() {
        if (peerConfigBuilder_ == null) {
          peerConfigBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeer.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.ReplicationPeerOrBuilder>(
                  getPeerConfig(),
                  getParentForChildren(),
                  isClean());
          peerConfig_ = null;
        }
        return peerConfigBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RemovePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RemovePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RemovePeerStateData>() {
      @java.lang.Override
      public RemovePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemovePeerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RemovePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface EnablePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.EnablePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.EnablePeerStateData}
   */
  @javax.annotation.Generated("proto") public static final class EnablePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.EnablePeerStateData)
      EnablePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use EnablePeerStateData.newBuilder() to construct.
    private EnablePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private EnablePeerStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new EnablePeerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnablePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.EnablePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnablePeerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.EnablePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnablePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<EnablePeerStateData>() {
      @java.lang.Override
      public EnablePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<EnablePeerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.EnablePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DisablePeerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DisablePeerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.DisablePeerStateData}
   */
  @javax.annotation.Generated("proto") public static final class DisablePeerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DisablePeerStateData)
      DisablePeerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DisablePeerStateData.newBuilder() to construct.
    private DisablePeerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DisablePeerStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DisablePeerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisablePeerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DisablePeerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisablePeerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DisablePeerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisablePeerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DisablePeerStateData>() {
      @java.lang.Override
      public DisablePeerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DisablePeerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.DisablePeerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReopenTableRegionsStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ReopenTableRegionsStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> 
        getRegionList();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index);
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    int getRegionCount();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
        int index);

    /**
     * <code>repeated bytes region_names = 3;</code>
     * @return A list containing the regionNames.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getRegionNamesList();
    /**
     * <code>repeated bytes region_names = 3;</code>
     * @return The count of regionNames.
     */
    int getRegionNamesCount();
    /**
     * <code>repeated bytes region_names = 3;</code>
     * @param index The index of the element to return.
     * @return The regionNames at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionNames(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ReopenTableRegionsStateData}
   */
  @javax.annotation.Generated("proto") public static final class ReopenTableRegionsStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ReopenTableRegionsStateData)
      ReopenTableRegionsStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReopenTableRegionsStateData.newBuilder() to construct.
    private ReopenTableRegionsStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReopenTableRegionsStateData() {
      region_ = java.util.Collections.emptyList();
      regionNames_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ReopenTableRegionsStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> region_;
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getRegionList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
        getRegionOrBuilderList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    @java.lang.Override
    public int getRegionCount() {
      return region_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index) {
      return region_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
        int index) {
      return region_.get(index);
    }

    public static final int REGION_NAMES_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> regionNames_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <code>repeated bytes region_names = 3;</code>
     * @return A list containing the regionNames.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getRegionNamesList() {
      return regionNames_;
    }
    /**
     * <code>repeated bytes region_names = 3;</code>
     * @return The count of regionNames.
     */
    public int getRegionNamesCount() {
      return regionNames_.size();
    }
    /**
     * <code>repeated bytes region_names = 3;</code>
     * @param index The index of the element to return.
     * @return The regionNames at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionNames(int index) {
      return regionNames_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionCount(); i++) {
        if (!getRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      for (int i = 0; i < region_.size(); i++) {
        output.writeMessage(2, region_.get(i));
      }
      for (int i = 0; i < regionNames_.size(); i++) {
        output.writeBytes(3, regionNames_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      for (int i = 0; i < region_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, region_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < regionNames_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(regionNames_.get(i));
        }
        size += dataSize;
        size += 1 * getRegionNamesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getRegionList()
          .equals(other.getRegionList())) return false;
      if (!getRegionNamesList()
          .equals(other.getRegionNamesList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionCount() > 0) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionList().hashCode();
      }
      if (getRegionNamesCount() > 0) {
        hash = (37 * hash) + REGION_NAMES_FIELD_NUMBER;
        hash = (53 * hash) + getRegionNamesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ReopenTableRegionsStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ReopenTableRegionsStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
        } else {
          region_ = null;
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        regionNames_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            region_ = java.util.Collections.unmodifiableList(region_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          regionNames_.makeImmutable();
          result.regionNames_ = regionNames_;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionBuilder_ == null) {
          if (!other.region_.isEmpty()) {
            if (region_.isEmpty()) {
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureRegionIsMutable();
              region_.addAll(other.region_);
            }
            onChanged();
          }
        } else {
          if (!other.region_.isEmpty()) {
            if (regionBuilder_.isEmpty()) {
              regionBuilder_.dispose();
              regionBuilder_ = null;
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000002);
              regionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionFieldBuilder() : null;
            } else {
              regionBuilder_.addAllMessages(other.region_);
            }
          }
        }
        if (!other.regionNames_.isEmpty()) {
          if (regionNames_.isEmpty()) {
            regionNames_ = other.regionNames_;
            regionNames_.makeImmutable();
            bitField0_ |= 0x00000004;
          } else {
            ensureRegionNamesIsMutable();
            regionNames_.addAll(other.regionNames_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionCount(); i++) {
          if (!getRegion(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.PARSER,
                        extensionRegistry);
                if (regionBuilder_ == null) {
                  ensureRegionIsMutable();
                  region_.add(m);
                } else {
                  regionBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 26: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureRegionNamesIsMutable();
                regionNames_.add(v);
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> region_ =
        java.util.Collections.emptyList();
      private void ensureRegionIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          region_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation>(region_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> regionBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> getRegionList() {
        if (regionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(region_);
        } else {
          return regionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public int getRegionCount() {
        if (regionBuilder_ == null) {
          return region_.size();
        } else {
          return regionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation getRegion(int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);
        } else {
          return regionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.set(index, value);
          onChanged();
        } else {
          regionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(value);
          onChanged();
        } else {
          regionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(index, value);
          onChanged();
        } else {
          regionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder addAllRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation> values) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, region_);
          onChanged();
        } else {
          regionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public Builder removeRegion(int index) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.remove(index);
          onChanged();
        } else {
          regionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder getRegionBuilder(
          int index) {
        return getRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder getRegionOrBuilder(
          int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);  } else {
          return regionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
           getRegionOrBuilderList() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(region_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addRegionBuilder() {
        return getRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder addRegionBuilder(
          int index) {
        return getRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLocation region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder> 
           getRegionBuilderList() {
        return getRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocation.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionLocationOrBuilder>(
                  region_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> regionNames_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureRegionNamesIsMutable() {
        if (!regionNames_.isModifiable()) {
          regionNames_ = makeMutableCopy(regionNames_);
        }
        bitField0_ |= 0x00000004;
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @return A list containing the regionNames.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getRegionNamesList() {
        regionNames_.makeImmutable();
        return regionNames_;
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @return The count of regionNames.
       */
      public int getRegionNamesCount() {
        return regionNames_.size();
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @param index The index of the element to return.
       * @return The regionNames at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionNames(int index) {
        return regionNames_.get(index);
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @param index The index to set the value at.
       * @param value The regionNames to set.
       * @return This builder for chaining.
       */
      public Builder setRegionNames(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureRegionNamesIsMutable();
        regionNames_.set(index, value);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @param value The regionNames to add.
       * @return This builder for chaining.
       */
      public Builder addRegionNames(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureRegionNamesIsMutable();
        regionNames_.add(value);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @param values The regionNames to add.
       * @return This builder for chaining.
       */
      public Builder addAllRegionNames(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureRegionNamesIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, regionNames_);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes region_names = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionNames() {
        regionNames_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ReopenTableRegionsStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ReopenTableRegionsStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ReopenTableRegionsStateData>() {
      @java.lang.Override
      public ReopenTableRegionsStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReopenTableRegionsStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ReopenTableRegionsStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InitMetaStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.InitMetaStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.InitMetaStateData}
   */
  @javax.annotation.Generated("proto") public static final class InitMetaStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.InitMetaStateData)
      InitMetaStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InitMetaStateData.newBuilder() to construct.
    private InitMetaStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InitMetaStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new InitMetaStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.InitMetaStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.InitMetaStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_InitMetaStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.InitMetaStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.InitMetaStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<InitMetaStateData>() {
      @java.lang.Override
      public InitMetaStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<InitMetaStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.InitMetaStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionStateTransitionStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionStateTransitionStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     * @return Whether the type field is set.
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     * @return The type.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType();

    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     * @return Whether the assignCandidate field is set.
     */
    boolean hasAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     * @return The assignCandidate.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder();

    /**
     * <code>required bool force_new_plan = 3;</code>
     * @return Whether the forceNewPlan field is set.
     */
    boolean hasForceNewPlan();
    /**
     * <code>required bool force_new_plan = 3;</code>
     * @return The forceNewPlan.
     */
    boolean getForceNewPlan();
  }
  /**
   * Protobuf type {@code hbase.pb.RegionStateTransitionStateData}
   */
  @javax.annotation.Generated("proto") public static final class RegionStateTransitionStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionStateTransitionStateData)
      RegionStateTransitionStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionStateTransitionStateData.newBuilder() to construct.
    private RegionStateTransitionStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionStateTransitionStateData() {
      type_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionStateTransitionStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TYPE_FIELD_NUMBER = 1;
    private int type_ = 1;
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     * @return Whether the type field is set.
     */
    @java.lang.Override public boolean hasType() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
     * @return The type.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.forNumber(type_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.ASSIGN : result;
    }

    public static final int ASSIGN_CANDIDATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     * @return Whether the assignCandidate field is set.
     */
    @java.lang.Override
    public boolean hasAssignCandidate() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     * @return The assignCandidate.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }

    public static final int FORCE_NEW_PLAN_FIELD_NUMBER = 3;
    private boolean forceNewPlan_ = false;
    /**
     * <code>required bool force_new_plan = 3;</code>
     * @return Whether the forceNewPlan field is set.
     */
    @java.lang.Override
    public boolean hasForceNewPlan() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bool force_new_plan = 3;</code>
     * @return The forceNewPlan.
     */
    @java.lang.Override
    public boolean getForceNewPlan() {
      return forceNewPlan_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasForceNewPlan()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasAssignCandidate()) {
        if (!getAssignCandidate().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getAssignCandidate());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, forceNewPlan_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getAssignCandidate());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, forceNewPlan_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData) obj;

      if (hasType() != other.hasType()) return false;
      if (hasType()) {
        if (type_ != other.type_) return false;
      }
      if (hasAssignCandidate() != other.hasAssignCandidate()) return false;
      if (hasAssignCandidate()) {
        if (!getAssignCandidate()
            .equals(other.getAssignCandidate())) return false;
      }
      if (hasForceNewPlan() != other.hasForceNewPlan()) return false;
      if (hasForceNewPlan()) {
        if (getForceNewPlan()
            != other.getForceNewPlan()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasAssignCandidate()) {
        hash = (37 * hash) + ASSIGN_CANDIDATE_FIELD_NUMBER;
        hash = (53 * hash) + getAssignCandidate().hashCode();
      }
      if (hasForceNewPlan()) {
        hash = (37 * hash) + FORCE_NEW_PLAN_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getForceNewPlan());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RegionStateTransitionStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionStateTransitionStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAssignCandidateFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        type_ = 1;
        assignCandidate_ = null;
        if (assignCandidateBuilder_ != null) {
          assignCandidateBuilder_.dispose();
          assignCandidateBuilder_ = null;
        }
        forceNewPlan_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.type_ = type_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.assignCandidate_ = assignCandidateBuilder_ == null
              ? assignCandidate_
              : assignCandidateBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.forceNewPlan_ = forceNewPlan_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasAssignCandidate()) {
          mergeAssignCandidate(other.getAssignCandidate());
        }
        if (other.hasForceNewPlan()) {
          setForceNewPlan(other.getForceNewPlan());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasType()) {
          return false;
        }
        if (!hasForceNewPlan()) {
          return false;
        }
        if (hasAssignCandidate()) {
          if (!getAssignCandidate().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  type_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getAssignCandidateFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                forceNewPlan_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int type_ = 1;
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       * @return Whether the type field is set.
       */
      @java.lang.Override public boolean hasType() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       * @return The type.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType getType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.forNumber(type_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType.ASSIGN : result;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       * @param value The type to set.
       * @return This builder for chaining.
       */
      public Builder setType(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionTransitionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionTransitionType type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> assignCandidateBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       * @return Whether the assignCandidate field is set.
       */
      public boolean hasAssignCandidate() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       * @return The assignCandidate.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        } else {
          return assignCandidateBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder setAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          assignCandidate_ = value;
        } else {
          assignCandidateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder setAssignCandidate(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = builderForValue.build();
        } else {
          assignCandidateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder mergeAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            assignCandidate_ != null &&
            assignCandidate_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getAssignCandidateBuilder().mergeFrom(value);
          } else {
            assignCandidate_ = value;
          }
        } else {
          assignCandidateBuilder_.mergeFrom(value);
        }
        if (assignCandidate_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public Builder clearAssignCandidate() {
        bitField0_ = (bitField0_ & ~0x00000002);
        assignCandidate_ = null;
        if (assignCandidateBuilder_ != null) {
          assignCandidateBuilder_.dispose();
          assignCandidateBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getAssignCandidateBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAssignCandidateFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
        if (assignCandidateBuilder_ != null) {
          return assignCandidateBuilder_.getMessageOrBuilder();
        } else {
          return assignCandidate_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getAssignCandidateFieldBuilder() {
        if (assignCandidateBuilder_ == null) {
          assignCandidateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getAssignCandidate(),
                  getParentForChildren(),
                  isClean());
          assignCandidate_ = null;
        }
        return assignCandidateBuilder_;
      }

      private boolean forceNewPlan_ ;
      /**
       * <code>required bool force_new_plan = 3;</code>
       * @return Whether the forceNewPlan field is set.
       */
      @java.lang.Override
      public boolean hasForceNewPlan() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       * @return The forceNewPlan.
       */
      @java.lang.Override
      public boolean getForceNewPlan() {
        return forceNewPlan_;
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       * @param value The forceNewPlan to set.
       * @return This builder for chaining.
       */
      public Builder setForceNewPlan(boolean value) {

        forceNewPlan_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bool force_new_plan = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearForceNewPlan() {
        bitField0_ = (bitField0_ & ~0x00000004);
        forceNewPlan_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionStateTransitionStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionStateTransitionStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionStateTransitionStateData>() {
      @java.lang.Override
      public RegionStateTransitionStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionStateTransitionStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionStateTransitionStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionRemoteProcedureBaseStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionRemoteProcedureBaseStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion();
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <pre>
     * state is actually 'required' but we can't set it as 'required' here else it breaks old
     * Messages; see HBASE-22074.
     * </pre>
     *
     * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     * @return Whether the state field is set.
     */
    boolean hasState();
    /**
     * <pre>
     * state is actually 'required' but we can't set it as 'required' here else it breaks old
     * Messages; see HBASE-22074.
     * </pre>
     *
     * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     * @return The state.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState();

    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     * @return Whether the transitionCode field is set.
     */
    boolean hasTransitionCode();
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     * @return The transitionCode.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode();

    /**
     * <code>optional int64 seq_id = 5;</code>
     * @return Whether the seqId field is set.
     */
    boolean hasSeqId();
    /**
     * <code>optional int64 seq_id = 5;</code>
     * @return The seqId.
     */
    long getSeqId();
  }
  /**
   * Protobuf type {@code hbase.pb.RegionRemoteProcedureBaseStateData}
   */
  @javax.annotation.Generated("proto") public static final class RegionRemoteProcedureBaseStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionRemoteProcedureBaseStateData)
      RegionRemoteProcedureBaseStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionRemoteProcedureBaseStateData.newBuilder() to construct.
    private RegionRemoteProcedureBaseStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionRemoteProcedureBaseStateData() {
      state_ = 1;
      transitionCode_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionRemoteProcedureBaseStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STATE_FIELD_NUMBER = 3;
    private int state_ = 1;
    /**
     * <pre>
     * state is actually 'required' but we can't set it as 'required' here else it breaks old
     * Messages; see HBASE-22074.
     * </pre>
     *
     * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     * @return Whether the state field is set.
     */
    @java.lang.Override public boolean hasState() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * state is actually 'required' but we can't set it as 'required' here else it breaks old
     * Messages; see HBASE-22074.
     * </pre>
     *
     * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
     * @return The state.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.forNumber(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.REGION_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int TRANSITION_CODE_FIELD_NUMBER = 4;
    private int transitionCode_ = 0;
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     * @return Whether the transitionCode field is set.
     */
    @java.lang.Override public boolean hasTransitionCode() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
     * @return The transitionCode.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode result = org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.forNumber(transitionCode_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.OPENED : result;
    }

    public static final int SEQ_ID_FIELD_NUMBER = 5;
    private long seqId_ = 0L;
    /**
     * <code>optional int64 seq_id = 5;</code>
     * @return Whether the seqId field is set.
     */
    @java.lang.Override
    public boolean hasSeqId() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional int64 seq_id = 5;</code>
     * @return The seqId.
     */
    @java.lang.Override
    public long getSeqId() {
      return seqId_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTargetServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeEnum(3, state_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(4, transitionCode_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeInt64(5, seqId_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTargetServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, state_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, transitionCode_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, seqId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (hasState() != other.hasState()) return false;
      if (hasState()) {
        if (state_ != other.state_) return false;
      }
      if (hasTransitionCode() != other.hasTransitionCode()) return false;
      if (hasTransitionCode()) {
        if (transitionCode_ != other.transitionCode_) return false;
      }
      if (hasSeqId() != other.hasSeqId()) return false;
      if (hasSeqId()) {
        if (getSeqId()
            != other.getSeqId()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasTransitionCode()) {
        hash = (37 * hash) + TRANSITION_CODE_FIELD_NUMBER;
        hash = (53 * hash) + transitionCode_;
      }
      if (hasSeqId()) {
        hash = (37 * hash) + SEQ_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getSeqId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RegionRemoteProcedureBaseStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionRemoteProcedureBaseStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getTargetServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        state_ = 1;
        transitionCode_ = 0;
        seqId_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.state_ = state_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.transitionCode_ = transitionCode_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.seqId_ = seqId_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasTransitionCode()) {
          setTransitionCode(other.getTransitionCode());
        }
        if (other.hasSeqId()) {
          setSeqId(other.getSeqId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(3, tmpRaw);
                } else {
                  state_ = tmpRaw;
                  bitField0_ |= 0x00000004;
                }
                break;
              } // case 24
              case 32: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(4, tmpRaw);
                } else {
                  transitionCode_ = tmpRaw;
                  bitField0_ |= 0x00000008;
                }
                break;
              } // case 32
              case 40: {
                seqId_ = input.readInt64();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000002);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int state_ = 1;
      /**
       * <pre>
       * state is actually 'required' but we can't set it as 'required' here else it breaks old
       * Messages; see HBASE-22074.
       * </pre>
       *
       * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       * @return Whether the state field is set.
       */
      @java.lang.Override public boolean hasState() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * state is actually 'required' but we can't set it as 'required' here else it breaks old
       * Messages; see HBASE-22074.
       * </pre>
       *
       * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       * @return The state.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.forNumber(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState.REGION_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <pre>
       * state is actually 'required' but we can't set it as 'required' here else it breaks old
       * Messages; see HBASE-22074.
       * </pre>
       *
       * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * state is actually 'required' but we can't set it as 'required' here else it breaks old
       * Messages; see HBASE-22074.
       * </pre>
       *
       * <code>optional .hbase.pb.RegionRemoteProcedureBaseState state = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000004);
        state_ = 1;
        onChanged();
        return this;
      }

      private int transitionCode_ = 0;
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       * @return Whether the transitionCode field is set.
       */
      @java.lang.Override public boolean hasTransitionCode() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       * @return The transitionCode.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode getTransitionCode() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode result = org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.forNumber(transitionCode_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode.OPENED : result;
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       * @param value The transitionCode to set.
       * @return This builder for chaining.
       */
      public Builder setTransitionCode(org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.RegionStateTransition.TransitionCode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        transitionCode_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionStateTransition.TransitionCode transition_code = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearTransitionCode() {
        bitField0_ = (bitField0_ & ~0x00000008);
        transitionCode_ = 0;
        onChanged();
        return this;
      }

      private long seqId_ ;
      /**
       * <code>optional int64 seq_id = 5;</code>
       * @return Whether the seqId field is set.
       */
      @java.lang.Override
      public boolean hasSeqId() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       * @return The seqId.
       */
      @java.lang.Override
      public long getSeqId() {
        return seqId_;
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       * @param value The seqId to set.
       * @return This builder for chaining.
       */
      public Builder setSeqId(long value) {

        seqId_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 seq_id = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearSeqId() {
        bitField0_ = (bitField0_ & ~0x00000010);
        seqId_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionRemoteProcedureBaseStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionRemoteProcedureBaseStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionRemoteProcedureBaseStateData>() {
      @java.lang.Override
      public RegionRemoteProcedureBaseStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionRemoteProcedureBaseStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.RegionRemoteProcedureBaseStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface OpenRegionProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.OpenRegionProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.OpenRegionProcedureStateData}
   */
  @javax.annotation.Generated("proto") public static final class OpenRegionProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.OpenRegionProcedureStateData)
      OpenRegionProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenRegionProcedureStateData.newBuilder() to construct.
    private OpenRegionProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenRegionProcedureStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new OpenRegionProcedureStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.OpenRegionProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.OpenRegionProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.OpenRegionProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.OpenRegionProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<OpenRegionProcedureStateData>() {
      @java.lang.Override
      public OpenRegionProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionProcedureStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.OpenRegionProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseRegionProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseRegionProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     * @return Whether the assignCandidate field is set.
     */
    boolean hasAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     * @return The assignCandidate.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate();
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CloseRegionProcedureStateData}
   */
  @javax.annotation.Generated("proto") public static final class CloseRegionProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseRegionProcedureStateData)
      CloseRegionProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseRegionProcedureStateData.newBuilder() to construct.
    private CloseRegionProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseRegionProcedureStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseRegionProcedureStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int ASSIGN_CANDIDATE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     * @return Whether the assignCandidate field is set.
     */
    @java.lang.Override
    public boolean hasAssignCandidate() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     * @return The assignCandidate.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }
    /**
     * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
      return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasAssignCandidate()) {
        if (!getAssignCandidate().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getAssignCandidate());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getAssignCandidate());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData) obj;

      if (hasAssignCandidate() != other.hasAssignCandidate()) return false;
      if (hasAssignCandidate()) {
        if (!getAssignCandidate()
            .equals(other.getAssignCandidate())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAssignCandidate()) {
        hash = (37 * hash) + ASSIGN_CANDIDATE_FIELD_NUMBER;
        hash = (53 * hash) + getAssignCandidate().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloseRegionProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseRegionProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAssignCandidateFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        assignCandidate_ = null;
        if (assignCandidateBuilder_ != null) {
          assignCandidateBuilder_.dispose();
          assignCandidateBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.assignCandidate_ = assignCandidateBuilder_ == null
              ? assignCandidate_
              : assignCandidateBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData.getDefaultInstance()) return this;
        if (other.hasAssignCandidate()) {
          mergeAssignCandidate(other.getAssignCandidate());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasAssignCandidate()) {
          if (!getAssignCandidate().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getAssignCandidateFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName assignCandidate_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> assignCandidateBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       * @return Whether the assignCandidate field is set.
       */
      public boolean hasAssignCandidate() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       * @return The assignCandidate.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getAssignCandidate() {
        if (assignCandidateBuilder_ == null) {
          return assignCandidate_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        } else {
          return assignCandidateBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder setAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          assignCandidate_ = value;
        } else {
          assignCandidateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder setAssignCandidate(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (assignCandidateBuilder_ == null) {
          assignCandidate_ = builderForValue.build();
        } else {
          assignCandidateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder mergeAssignCandidate(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (assignCandidateBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            assignCandidate_ != null &&
            assignCandidate_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getAssignCandidateBuilder().mergeFrom(value);
          } else {
            assignCandidate_ = value;
          }
        } else {
          assignCandidateBuilder_.mergeFrom(value);
        }
        if (assignCandidate_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public Builder clearAssignCandidate() {
        bitField0_ = (bitField0_ & ~0x00000001);
        assignCandidate_ = null;
        if (assignCandidateBuilder_ != null) {
          assignCandidateBuilder_.dispose();
          assignCandidateBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getAssignCandidateBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAssignCandidateFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getAssignCandidateOrBuilder() {
        if (assignCandidateBuilder_ != null) {
          return assignCandidateBuilder_.getMessageOrBuilder();
        } else {
          return assignCandidate_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : assignCandidate_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName assign_candidate = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getAssignCandidateFieldBuilder() {
        if (assignCandidateBuilder_ == null) {
          assignCandidateBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getAssignCandidate(),
                  getParentForChildren(),
                  isClean());
          assignCandidate_ = null;
        }
        return assignCandidateBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseRegionProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseRegionProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseRegionProcedureStateData>() {
      @java.lang.Override
      public CloseRegionProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionProcedureStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseRegionProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SwitchRpcThrottleStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SwitchRpcThrottleStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     * @return Whether the rpcThrottleEnabled field is set.
     */
    boolean hasRpcThrottleEnabled();
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     * @return The rpcThrottleEnabled.
     */
    boolean getRpcThrottleEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.SwitchRpcThrottleStateData}
   */
  @javax.annotation.Generated("proto") public static final class SwitchRpcThrottleStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SwitchRpcThrottleStateData)
      SwitchRpcThrottleStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SwitchRpcThrottleStateData.newBuilder() to construct.
    private SwitchRpcThrottleStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SwitchRpcThrottleStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SwitchRpcThrottleStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.Builder.class);
    }

    private int bitField0_;
    public static final int RPC_THROTTLE_ENABLED_FIELD_NUMBER = 1;
    private boolean rpcThrottleEnabled_ = false;
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     * @return Whether the rpcThrottleEnabled field is set.
     */
    @java.lang.Override
    public boolean hasRpcThrottleEnabled() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool rpc_throttle_enabled = 1;</code>
     * @return The rpcThrottleEnabled.
     */
    @java.lang.Override
    public boolean getRpcThrottleEnabled() {
      return rpcThrottleEnabled_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRpcThrottleEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, rpcThrottleEnabled_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, rpcThrottleEnabled_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData) obj;

      if (hasRpcThrottleEnabled() != other.hasRpcThrottleEnabled()) return false;
      if (hasRpcThrottleEnabled()) {
        if (getRpcThrottleEnabled()
            != other.getRpcThrottleEnabled()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRpcThrottleEnabled()) {
        hash = (37 * hash) + RPC_THROTTLE_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRpcThrottleEnabled());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SwitchRpcThrottleStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SwitchRpcThrottleStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        rpcThrottleEnabled_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.rpcThrottleEnabled_ = rpcThrottleEnabled_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData.getDefaultInstance()) return this;
        if (other.hasRpcThrottleEnabled()) {
          setRpcThrottleEnabled(other.getRpcThrottleEnabled());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRpcThrottleEnabled()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                rpcThrottleEnabled_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean rpcThrottleEnabled_ ;
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       * @return Whether the rpcThrottleEnabled field is set.
       */
      @java.lang.Override
      public boolean hasRpcThrottleEnabled() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       * @return The rpcThrottleEnabled.
       */
      @java.lang.Override
      public boolean getRpcThrottleEnabled() {
        return rpcThrottleEnabled_;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       * @param value The rpcThrottleEnabled to set.
       * @return This builder for chaining.
       */
      public Builder setRpcThrottleEnabled(boolean value) {

        rpcThrottleEnabled_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRpcThrottleEnabled() {
        bitField0_ = (bitField0_ & ~0x00000001);
        rpcThrottleEnabled_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SwitchRpcThrottleStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SwitchRpcThrottleStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SwitchRpcThrottleStateData>() {
      @java.lang.Override
      public SwitchRpcThrottleStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SwitchRpcThrottleRemoteStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SwitchRpcThrottleRemoteStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     * @return Whether the rpcThrottleEnabled field is set.
     */
    boolean hasRpcThrottleEnabled();
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     * @return The rpcThrottleEnabled.
     */
    boolean getRpcThrottleEnabled();

    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
     * @return Whether the state field is set.
     */
    boolean hasState();
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
     * @return The state.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState();

    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     * @return Whether the error field is set.
     */
    boolean hasError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     * @return The error.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SwitchRpcThrottleRemoteStateData}
   */
  @javax.annotation.Generated("proto") public static final class SwitchRpcThrottleRemoteStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SwitchRpcThrottleRemoteStateData)
      SwitchRpcThrottleRemoteStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SwitchRpcThrottleRemoteStateData.newBuilder() to construct.
    private SwitchRpcThrottleRemoteStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SwitchRpcThrottleRemoteStateData() {
      state_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SwitchRpcThrottleRemoteStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TARGET_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int RPC_THROTTLE_ENABLED_FIELD_NUMBER = 2;
    private boolean rpcThrottleEnabled_ = false;
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     * @return Whether the rpcThrottleEnabled field is set.
     */
    @java.lang.Override
    public boolean hasRpcThrottleEnabled() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bool rpc_throttle_enabled = 2;</code>
     * @return The rpcThrottleEnabled.
     */
    @java.lang.Override
    public boolean getRpcThrottleEnabled() {
      return rpcThrottleEnabled_;
    }

    public static final int STATE_FIELD_NUMBER = 3;
    private int state_ = 1;
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
     * @return Whether the state field is set.
     */
    @java.lang.Override public boolean hasState() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
     * @return The state.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int ERROR_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     * @return Whether the error field is set.
     */
    @java.lang.Override
    public boolean hasError() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     * @return The error.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRpcThrottleEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTargetServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, rpcThrottleEnabled_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeEnum(3, state_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getError());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTargetServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, rpcThrottleEnabled_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, state_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getError());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData) obj;

      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (hasRpcThrottleEnabled() != other.hasRpcThrottleEnabled()) return false;
      if (hasRpcThrottleEnabled()) {
        if (getRpcThrottleEnabled()
            != other.getRpcThrottleEnabled()) return false;
      }
      if (hasState() != other.hasState()) return false;
      if (hasState()) {
        if (state_ != other.state_) return false;
      }
      if (hasError() != other.hasError()) return false;
      if (hasError()) {
        if (!getError()
            .equals(other.getError())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasRpcThrottleEnabled()) {
        hash = (37 * hash) + RPC_THROTTLE_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRpcThrottleEnabled());
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasError()) {
        hash = (37 * hash) + ERROR_FIELD_NUMBER;
        hash = (53 * hash) + getError().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SwitchRpcThrottleRemoteStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SwitchRpcThrottleRemoteStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTargetServerFieldBuilder();
          getErrorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        rpcThrottleEnabled_ = false;
        state_ = 1;
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.rpcThrottleEnabled_ = rpcThrottleEnabled_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.state_ = state_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.error_ = errorBuilder_ == null
              ? error_
              : errorBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData.getDefaultInstance()) return this;
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasRpcThrottleEnabled()) {
          setRpcThrottleEnabled(other.getRpcThrottleEnabled());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasError()) {
          mergeError(other.getError());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTargetServer()) {
          return false;
        }
        if (!hasRpcThrottleEnabled()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                rpcThrottleEnabled_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(3, tmpRaw);
                } else {
                  state_ = tmpRaw;
                  bitField0_ |= 0x00000004;
                }
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getErrorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private boolean rpcThrottleEnabled_ ;
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       * @return Whether the rpcThrottleEnabled field is set.
       */
      @java.lang.Override
      public boolean hasRpcThrottleEnabled() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       * @return The rpcThrottleEnabled.
       */
      @java.lang.Override
      public boolean getRpcThrottleEnabled() {
        return rpcThrottleEnabled_;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       * @param value The rpcThrottleEnabled to set.
       * @return This builder for chaining.
       */
      public Builder setRpcThrottleEnabled(boolean value) {

        rpcThrottleEnabled_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bool rpc_throttle_enabled = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearRpcThrottleEnabled() {
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcThrottleEnabled_ = false;
        onChanged();
        return this;
      }

      private int state_ = 1;
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
       * @return Whether the state field is set.
       */
      @java.lang.Override public boolean hasState() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
       * @return The state.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000004);
        state_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> errorBuilder_;
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       * @return Whether the error field is set.
       */
      public boolean hasError() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       * @return The error.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
        if (errorBuilder_ == null) {
          return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        } else {
          return errorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public Builder setError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          error_ = value;
        } else {
          errorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public Builder setError(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder builderForValue) {
        if (errorBuilder_ == null) {
          error_ = builderForValue.build();
        } else {
          errorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public Builder mergeError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            error_ != null &&
            error_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance()) {
            getErrorBuilder().mergeFrom(value);
          } else {
            error_ = value;
          }
        } else {
          errorBuilder_.mergeFrom(value);
        }
        if (error_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public Builder clearError() {
        bitField0_ = (bitField0_ & ~0x00000008);
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder getErrorBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getErrorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
        if (errorBuilder_ != null) {
          return errorBuilder_.getMessageOrBuilder();
        } else {
          return error_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> 
          getErrorFieldBuilder() {
        if (errorBuilder_ == null) {
          errorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder>(
                  getError(),
                  getParentForChildren(),
                  isClean());
          error_ = null;
        }
        return errorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SwitchRpcThrottleRemoteStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SwitchRpcThrottleRemoteStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SwitchRpcThrottleRemoteStateData>() {
      @java.lang.Override
      public SwitchRpcThrottleRemoteStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SwitchRpcThrottleRemoteStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SwitchRpcThrottleRemoteStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALParameter}
   */
  @javax.annotation.Generated("proto") public static final class SplitWALParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALParameter)
      SplitWALParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALParameter.newBuilder() to construct.
    private SplitWALParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALParameter() {
      walPath_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SplitWALParameter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object walPath_ = "";
    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    @java.lang.Override
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    @java.lang.Override
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter) obj;

      if (hasWalPath() != other.hasWalPath()) return false;
      if (hasWalPath()) {
        if (!getWalPath()
            .equals(other.getWalPath())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        walPath_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALParameter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.walPath_ = walPath_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          walPath_ = other.walPath_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                walPath_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       * @return Whether the walPath field is set.
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The walPath.
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The bytes for walPath.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearWalPath() {
        walPath_ = getDefaultInstance().getWalPath();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The bytes for walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALParameter>() {
      @java.lang.Override
      public SplitWALParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALParameter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return Whether the crashedServer field is set.
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return The crashedServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     * @return Whether the worker field is set.
     */
    boolean hasWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     * @return The worker.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker();
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALData}
   */
  @javax.annotation.Generated("proto") public static final class SplitWALData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALData)
      SplitWALDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALData.newBuilder() to construct.
    private SplitWALData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALData() {
      walPath_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SplitWALData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object walPath_ = "";
    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    @java.lang.Override
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    @java.lang.Override
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CRASHED_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return Whether the crashedServer field is set.
     */
    @java.lang.Override
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return The crashedServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int WORKER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     * @return Whether the worker field is set.
     */
    @java.lang.Override
    public boolean hasWorker() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     * @return The worker.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }
    /**
     * <code>optional .hbase.pb.ServerName worker = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasWorker()) {
        if (!getWorker().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getWorker());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWorker());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData) obj;

      if (hasWalPath() != other.hasWalPath()) return false;
      if (hasWalPath()) {
        if (!getWalPath()
            .equals(other.getWalPath())) return false;
      }
      if (hasCrashedServer() != other.hasCrashedServer()) return false;
      if (hasCrashedServer()) {
        if (!getCrashedServer()
            .equals(other.getCrashedServer())) return false;
      }
      if (hasWorker() != other.hasWorker()) return false;
      if (hasWorker()) {
        if (!getWorker()
            .equals(other.getWorker())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasWorker()) {
        hash = (37 * hash) + WORKER_FIELD_NUMBER;
        hash = (53 * hash) + getWorker().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
          getWorkerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        walPath_ = "";
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        worker_ = null;
        if (workerBuilder_ != null) {
          workerBuilder_.dispose();
          workerBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.walPath_ = walPath_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.crashedServer_ = crashedServerBuilder_ == null
              ? crashedServer_
              : crashedServerBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.worker_ = workerBuilder_ == null
              ? worker_
              : workerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          walPath_ = other.walPath_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasWorker()) {
          mergeWorker(other.getWorker());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        if (!hasCrashedServer()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        if (hasWorker()) {
          if (!getWorker().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                walPath_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getCrashedServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getWorkerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       * @return Whether the walPath field is set.
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The walPath.
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The bytes for walPath.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearWalPath() {
        walPath_ = getDefaultInstance().getWalPath();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The bytes for walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       * @return Whether the crashedServer field is set.
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       * @return The crashedServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            crashedServer_ != null &&
            crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getCrashedServerBuilder().mergeFrom(value);
          } else {
            crashedServer_ = value;
          }
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        if (crashedServer_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder clearCrashedServer() {
        bitField0_ = (bitField0_ & ~0x00000002);
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> workerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       * @return Whether the worker field is set.
       */
      public boolean hasWorker() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       * @return The worker.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
        if (workerBuilder_ == null) {
          return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        } else {
          return workerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          worker_ = value;
        } else {
          workerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (workerBuilder_ == null) {
          worker_ = builderForValue.build();
        } else {
          workerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder mergeWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            worker_ != null &&
            worker_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getWorkerBuilder().mergeFrom(value);
          } else {
            worker_ = value;
          }
        } else {
          workerBuilder_.mergeFrom(value);
        }
        if (worker_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder clearWorker() {
        bitField0_ = (bitField0_ & ~0x00000004);
        worker_ = null;
        if (workerBuilder_ != null) {
          workerBuilder_.dispose();
          workerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getWorkerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWorkerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
        if (workerBuilder_ != null) {
          return workerBuilder_.getMessageOrBuilder();
        } else {
          return worker_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName worker = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getWorkerFieldBuilder() {
        if (workerBuilder_ == null) {
          workerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getWorker(),
                  getParentForChildren(),
                  isClean());
          worker_ = null;
        }
        return workerBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALData>() {
      @java.lang.Override
      public SplitWALData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SplitWALRemoteDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SplitWALRemoteData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    boolean hasWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    java.lang.String getWalPath();
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes();

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return Whether the crashedServer field is set.
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return The crashedServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     * @return Whether the worker field is set.
     */
    boolean hasWorker();
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     * @return The worker.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker();
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder();

    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
     * @return Whether the state field is set.
     */
    boolean hasState();
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
     * @return The state.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState();

    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     * @return Whether the error field is set.
     */
    boolean hasError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     * @return The error.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SplitWALRemoteData}
   */
  @javax.annotation.Generated("proto") public static final class SplitWALRemoteData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SplitWALRemoteData)
      SplitWALRemoteDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SplitWALRemoteData.newBuilder() to construct.
    private SplitWALRemoteData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SplitWALRemoteData() {
      walPath_ = "";
      state_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SplitWALRemoteData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.Builder.class);
    }

    private int bitField0_;
    public static final int WAL_PATH_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object walPath_ = "";
    /**
     * <code>required string wal_path = 1;</code>
     * @return Whether the walPath field is set.
     */
    @java.lang.Override
    public boolean hasWalPath() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The walPath.
     */
    @java.lang.Override
    public java.lang.String getWalPath() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          walPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string wal_path = 1;</code>
     * @return The bytes for walPath.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWalPathBytes() {
      java.lang.Object ref = walPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        walPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CRASHED_SERVER_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return Whether the crashedServer field is set.
     */
    @java.lang.Override
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     * @return The crashedServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int WORKER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     * @return Whether the worker field is set.
     */
    @java.lang.Override
    public boolean hasWorker() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     * @return The worker.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }
    /**
     * <code>required .hbase.pb.ServerName worker = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
      return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
    }

    public static final int STATE_FIELD_NUMBER = 4;
    private int state_ = 1;
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
     * @return Whether the state field is set.
     */
    @java.lang.Override public boolean hasState() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
     * @return The state.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int ERROR_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     * @return Whether the error field is set.
     */
    @java.lang.Override
    public boolean hasError() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     * @return The error.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasWalPath()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasWorker()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getWorker().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, walPath_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getWorker());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(4, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(5, getError());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, walPath_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCrashedServer());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWorker());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getError());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData) obj;

      if (hasWalPath() != other.hasWalPath()) return false;
      if (hasWalPath()) {
        if (!getWalPath()
            .equals(other.getWalPath())) return false;
      }
      if (hasCrashedServer() != other.hasCrashedServer()) return false;
      if (hasCrashedServer()) {
        if (!getCrashedServer()
            .equals(other.getCrashedServer())) return false;
      }
      if (hasWorker() != other.hasWorker()) return false;
      if (hasWorker()) {
        if (!getWorker()
            .equals(other.getWorker())) return false;
      }
      if (hasState() != other.hasState()) return false;
      if (hasState()) {
        if (state_ != other.state_) return false;
      }
      if (hasError() != other.hasError()) return false;
      if (hasError()) {
        if (!getError()
            .equals(other.getError())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasWalPath()) {
        hash = (37 * hash) + WAL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getWalPath().hashCode();
      }
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasWorker()) {
        hash = (37 * hash) + WORKER_FIELD_NUMBER;
        hash = (53 * hash) + getWorker().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasError()) {
        hash = (37 * hash) + ERROR_FIELD_NUMBER;
        hash = (53 * hash) + getError().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SplitWALRemoteData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SplitWALRemoteData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
          getWorkerFieldBuilder();
          getErrorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        walPath_ = "";
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        worker_ = null;
        if (workerBuilder_ != null) {
          workerBuilder_.dispose();
          workerBuilder_ = null;
        }
        state_ = 1;
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_SplitWALRemoteData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.walPath_ = walPath_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.crashedServer_ = crashedServerBuilder_ == null
              ? crashedServer_
              : crashedServerBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.worker_ = workerBuilder_ == null
              ? worker_
              : workerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.state_ = state_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.error_ = errorBuilder_ == null
              ? error_
              : errorBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData.getDefaultInstance()) return this;
        if (other.hasWalPath()) {
          walPath_ = other.walPath_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasWorker()) {
          mergeWorker(other.getWorker());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasError()) {
          mergeError(other.getError());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasWalPath()) {
          return false;
        }
        if (!hasCrashedServer()) {
          return false;
        }
        if (!hasWorker()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        if (!getWorker().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                walPath_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getCrashedServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getWorkerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(4, tmpRaw);
                } else {
                  state_ = tmpRaw;
                  bitField0_ |= 0x00000008;
                }
                break;
              } // case 32
              case 42: {
                input.readMessage(
                    getErrorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object walPath_ = "";
      /**
       * <code>required string wal_path = 1;</code>
       * @return Whether the walPath field is set.
       */
      public boolean hasWalPath() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The walPath.
       */
      public java.lang.String getWalPath() {
        java.lang.Object ref = walPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            walPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return The bytes for walPath.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWalPathBytes() {
        java.lang.Object ref = walPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          walPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPath(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearWalPath() {
        walPath_ = getDefaultInstance().getWalPath();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string wal_path = 1;</code>
       * @param value The bytes for walPath to set.
       * @return This builder for chaining.
       */
      public Builder setWalPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        walPath_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       * @return Whether the crashedServer field is set.
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       * @return The crashedServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            crashedServer_ != null &&
            crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getCrashedServerBuilder().mergeFrom(value);
          } else {
            crashedServer_ = value;
          }
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        if (crashedServer_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public Builder clearCrashedServer() {
        bitField0_ = (bitField0_ & ~0x00000002);
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName worker_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> workerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       * @return Whether the worker field is set.
       */
      public boolean hasWorker() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       * @return The worker.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getWorker() {
        if (workerBuilder_ == null) {
          return worker_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        } else {
          return workerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          worker_ = value;
        } else {
          workerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder setWorker(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (workerBuilder_ == null) {
          worker_ = builderForValue.build();
        } else {
          workerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder mergeWorker(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (workerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            worker_ != null &&
            worker_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getWorkerBuilder().mergeFrom(value);
          } else {
            worker_ = value;
          }
        } else {
          workerBuilder_.mergeFrom(value);
        }
        if (worker_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public Builder clearWorker() {
        bitField0_ = (bitField0_ & ~0x00000004);
        worker_ = null;
        if (workerBuilder_ != null) {
          workerBuilder_.dispose();
          workerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getWorkerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWorkerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getWorkerOrBuilder() {
        if (workerBuilder_ != null) {
          return workerBuilder_.getMessageOrBuilder();
        } else {
          return worker_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : worker_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName worker = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getWorkerFieldBuilder() {
        if (workerBuilder_ == null) {
          workerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getWorker(),
                  getParentForChildren(),
                  isClean());
          worker_ = null;
        }
        return workerBuilder_;
      }

      private int state_ = 1;
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
       * @return Whether the state field is set.
       */
      @java.lang.Override public boolean hasState() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
       * @return The state.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> errorBuilder_;
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       * @return Whether the error field is set.
       */
      public boolean hasError() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       * @return The error.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
        if (errorBuilder_ == null) {
          return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        } else {
          return errorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public Builder setError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          error_ = value;
        } else {
          errorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public Builder setError(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder builderForValue) {
        if (errorBuilder_ == null) {
          error_ = builderForValue.build();
        } else {
          errorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public Builder mergeError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            error_ != null &&
            error_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance()) {
            getErrorBuilder().mergeFrom(value);
          } else {
            error_ = value;
          }
        } else {
          errorBuilder_.mergeFrom(value);
        }
        if (error_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public Builder clearError() {
        bitField0_ = (bitField0_ & ~0x00000010);
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder getErrorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getErrorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
        if (errorBuilder_ != null) {
          return errorBuilder_.getMessageOrBuilder();
        } else {
          return error_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> 
          getErrorFieldBuilder() {
        if (errorBuilder_ == null) {
          errorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder>(
                  getError(),
                  getParentForChildren(),
                  isClean());
          error_ = null;
        }
        return errorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SplitWALRemoteData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SplitWALRemoteData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SplitWALRemoteData>() {
      @java.lang.Override
      public SplitWALRemoteData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SplitWALRemoteData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.SplitWALRemoteData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClaimReplicationQueuesStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClaimReplicationQueuesStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ClaimReplicationQueuesStateData}
   */
  @javax.annotation.Generated("proto") public static final class ClaimReplicationQueuesStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClaimReplicationQueuesStateData)
      ClaimReplicationQueuesStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClaimReplicationQueuesStateData.newBuilder() to construct.
    private ClaimReplicationQueuesStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClaimReplicationQueuesStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClaimReplicationQueuesStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueuesStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.Builder.class);
    }

    private int bitField0_;
    public static final int CRASHED_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    @java.lang.Override
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCrashedServer());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCrashedServer());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData) obj;

      if (hasCrashedServer() != other.hasCrashedServer()) return false;
      if (hasCrashedServer()) {
        if (!getCrashedServer()
            .equals(other.getCrashedServer())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClaimReplicationQueuesStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClaimReplicationQueuesStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueuesStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.crashedServer_ = crashedServerBuilder_ == null
              ? crashedServer_
              : crashedServerBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData.getDefaultInstance()) return this;
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCrashedServer()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCrashedServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return Whether the crashedServer field is set.
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return The crashedServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            crashedServer_ != null &&
            crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getCrashedServerBuilder().mergeFrom(value);
          } else {
            crashedServer_ = value;
          }
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        if (crashedServer_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder clearCrashedServer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClaimReplicationQueuesStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClaimReplicationQueuesStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueuesStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClaimReplicationQueuesStateData>() {
      @java.lang.Override
      public ClaimReplicationQueuesStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueuesStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueuesStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueuesStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClaimReplicationQueueRemoteStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClaimReplicationQueueRemoteStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>required string queue = 2;</code>
     * @return Whether the queue field is set.
     */
    boolean hasQueue();
    /**
     * <code>required string queue = 2;</code>
     * @return The queue.
     */
    java.lang.String getQueue();
    /**
     * <code>required string queue = 2;</code>
     * @return The bytes for queue.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    boolean hasTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer();
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder();

    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return Whether the state field is set.
     */
    boolean hasState();
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return The state.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState();

    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return Whether the error field is set.
     */
    boolean hasError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return The error.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError();
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ClaimReplicationQueueRemoteStateData}
   */
  @javax.annotation.Generated("proto") public static final class ClaimReplicationQueueRemoteStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClaimReplicationQueueRemoteStateData)
      ClaimReplicationQueueRemoteStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClaimReplicationQueueRemoteStateData.newBuilder() to construct.
    private ClaimReplicationQueueRemoteStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClaimReplicationQueueRemoteStateData() {
      queue_ = "";
      state_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClaimReplicationQueueRemoteStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.Builder.class);
    }

    private int bitField0_;
    public static final int CRASHED_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    @java.lang.Override
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int QUEUE_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object queue_ = "";
    /**
     * <code>required string queue = 2;</code>
     * @return Whether the queue field is set.
     */
    @java.lang.Override
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string queue = 2;</code>
     * @return The queue.
     */
    @java.lang.Override
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string queue = 2;</code>
     * @return The bytes for queue.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TARGET_SERVER_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return Whether the targetServer field is set.
     */
    @java.lang.Override
    public boolean hasTargetServer() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     * @return The targetServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName target_server = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
      return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
    }

    public static final int STATE_FIELD_NUMBER = 5;
    private int state_ = 1;
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return Whether the state field is set.
     */
    @java.lang.Override public boolean hasState() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
     * @return The state.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
    }

    public static final int ERROR_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return Whether the error field is set.
     */
    @java.lang.Override
    public boolean hasError() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     * @return The error.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }
    /**
     * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
      return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQueue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTargetServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTargetServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCrashedServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, queue_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(5, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(6, getError());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCrashedServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, queue_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTargetServer());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, state_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getError());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData) obj;

      if (hasCrashedServer() != other.hasCrashedServer()) return false;
      if (hasCrashedServer()) {
        if (!getCrashedServer()
            .equals(other.getCrashedServer())) return false;
      }
      if (hasQueue() != other.hasQueue()) return false;
      if (hasQueue()) {
        if (!getQueue()
            .equals(other.getQueue())) return false;
      }
      if (hasTargetServer() != other.hasTargetServer()) return false;
      if (hasTargetServer()) {
        if (!getTargetServer()
            .equals(other.getTargetServer())) return false;
      }
      if (hasState() != other.hasState()) return false;
      if (hasState()) {
        if (state_ != other.state_) return false;
      }
      if (hasError() != other.hasError()) return false;
      if (hasError()) {
        if (!getError()
            .equals(other.getError())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasTargetServer()) {
        hash = (37 * hash) + TARGET_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getTargetServer().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasError()) {
        hash = (37 * hash) + ERROR_FIELD_NUMBER;
        hash = (53 * hash) + getError().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClaimReplicationQueueRemoteStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClaimReplicationQueueRemoteStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
          getTargetServerFieldBuilder();
          getErrorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        queue_ = "";
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        state_ = 1;
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.crashedServer_ = crashedServerBuilder_ == null
              ? crashedServer_
              : crashedServerBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.queue_ = queue_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.targetServer_ = targetServerBuilder_ == null
              ? targetServer_
              : targetServerBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.state_ = state_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.error_ = errorBuilder_ == null
              ? error_
              : errorBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData.getDefaultInstance()) return this;
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasQueue()) {
          queue_ = other.queue_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasTargetServer()) {
          mergeTargetServer(other.getTargetServer());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasError()) {
          mergeError(other.getError());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCrashedServer()) {
          return false;
        }
        if (!hasQueue()) {
          return false;
        }
        if (!hasTargetServer()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        if (!getTargetServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCrashedServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                queue_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getTargetServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 40: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(5, tmpRaw);
                } else {
                  state_ = tmpRaw;
                  bitField0_ |= 0x00000008;
                }
                break;
              } // case 40
              case 50: {
                input.readMessage(
                    getErrorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 50
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return Whether the crashedServer field is set.
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return The crashedServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            crashedServer_ != null &&
            crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getCrashedServerBuilder().mergeFrom(value);
          } else {
            crashedServer_ = value;
          }
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        if (crashedServer_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder clearCrashedServer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private java.lang.Object queue_ = "";
      /**
       * <code>required string queue = 2;</code>
       * @return Whether the queue field is set.
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string queue = 2;</code>
       * @return The queue.
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string queue = 2;</code>
       * @return The bytes for queue.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string queue = 2;</code>
       * @param value The queue to set.
       * @return This builder for chaining.
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        queue_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string queue = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearQueue() {
        queue_ = getDefaultInstance().getQueue();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string queue = 2;</code>
       * @param value The bytes for queue to set.
       * @return This builder for chaining.
       */
      public Builder setQueueBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        queue_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName targetServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> targetServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return Whether the targetServer field is set.
       */
      public boolean hasTargetServer() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       * @return The targetServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getTargetServer() {
        if (targetServerBuilder_ == null) {
          return targetServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        } else {
          return targetServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          targetServer_ = value;
        } else {
          targetServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder setTargetServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (targetServerBuilder_ == null) {
          targetServer_ = builderForValue.build();
        } else {
          targetServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder mergeTargetServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (targetServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            targetServer_ != null &&
            targetServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getTargetServerBuilder().mergeFrom(value);
          } else {
            targetServer_ = value;
          }
        } else {
          targetServerBuilder_.mergeFrom(value);
        }
        if (targetServer_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public Builder clearTargetServer() {
        bitField0_ = (bitField0_ & ~0x00000004);
        targetServer_ = null;
        if (targetServerBuilder_ != null) {
          targetServerBuilder_.dispose();
          targetServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getTargetServerBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTargetServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getTargetServerOrBuilder() {
        if (targetServerBuilder_ != null) {
          return targetServerBuilder_.getMessageOrBuilder();
        } else {
          return targetServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : targetServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName target_server = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getTargetServerFieldBuilder() {
        if (targetServerBuilder_ == null) {
          targetServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getTargetServer(),
                  getParentForChildren(),
                  isClean());
          targetServer_ = null;
        }
        return targetServerBuilder_;
      }

      private int state_ = 1;
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return Whether the state field is set.
       */
      @java.lang.Override public boolean hasState() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return The state.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState getState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState result = org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.forNumber(state_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState.SERVER_REMOTE_PROCEDURE_DISPATCH : result;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ServerRemoteProcedureState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerRemoteProcedureState state = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage error_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> errorBuilder_;
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       * @return Whether the error field is set.
       */
      public boolean hasError() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       * @return The error.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage getError() {
        if (errorBuilder_ == null) {
          return error_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        } else {
          return errorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder setError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          error_ = value;
        } else {
          errorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder setError(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder builderForValue) {
        if (errorBuilder_ == null) {
          error_ = builderForValue.build();
        } else {
          errorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder mergeError(org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage value) {
        if (errorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            error_ != null &&
            error_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance()) {
            getErrorBuilder().mergeFrom(value);
          } else {
            error_ = value;
          }
        } else {
          errorBuilder_.mergeFrom(value);
        }
        if (error_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public Builder clearError() {
        bitField0_ = (bitField0_ & ~0x00000010);
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder getErrorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getErrorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder getErrorOrBuilder() {
        if (errorBuilder_ != null) {
          return errorBuilder_.getMessageOrBuilder();
        } else {
          return error_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.getDefaultInstance() : error_;
        }
      }
      /**
       * <code>optional .hbase.pb.ForeignExceptionMessage error = 6;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder> 
          getErrorFieldBuilder() {
        if (errorBuilder_ == null) {
          errorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessageOrBuilder>(
                  getError(),
                  getParentForChildren(),
                  isClean());
          error_ = null;
        }
        return errorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClaimReplicationQueueRemoteStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClaimReplicationQueueRemoteStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClaimReplicationQueueRemoteStateData>() {
      @java.lang.Override
      public ClaimReplicationQueueRemoteStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClaimReplicationQueueRemoteParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClaimReplicationQueueRemoteParameter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    boolean hasCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer();
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder();

    /**
     * <code>required string queue = 2;</code>
     * @return Whether the queue field is set.
     */
    boolean hasQueue();
    /**
     * <code>required string queue = 2;</code>
     * @return The queue.
     */
    java.lang.String getQueue();
    /**
     * <code>required string queue = 2;</code>
     * @return The bytes for queue.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.ClaimReplicationQueueRemoteParameter}
   */
  @javax.annotation.Generated("proto") public static final class ClaimReplicationQueueRemoteParameter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClaimReplicationQueueRemoteParameter)
      ClaimReplicationQueueRemoteParameterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClaimReplicationQueueRemoteParameter.newBuilder() to construct.
    private ClaimReplicationQueueRemoteParameter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClaimReplicationQueueRemoteParameter() {
      queue_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClaimReplicationQueueRemoteParameter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.Builder.class);
    }

    private int bitField0_;
    public static final int CRASHED_SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return Whether the crashedServer field is set.
     */
    @java.lang.Override
    public boolean hasCrashedServer() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     * @return The crashedServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }
    /**
     * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
      return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
    }

    public static final int QUEUE_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object queue_ = "";
    /**
     * <code>required string queue = 2;</code>
     * @return Whether the queue field is set.
     */
    @java.lang.Override
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string queue = 2;</code>
     * @return The queue.
     */
    @java.lang.Override
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string queue = 2;</code>
     * @return The bytes for queue.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCrashedServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQueue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCrashedServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCrashedServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, queue_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCrashedServer());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, queue_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter) obj;

      if (hasCrashedServer() != other.hasCrashedServer()) return false;
      if (hasCrashedServer()) {
        if (!getCrashedServer()
            .equals(other.getCrashedServer())) return false;
      }
      if (hasQueue() != other.hasQueue()) return false;
      if (hasQueue()) {
        if (!getQueue()
            .equals(other.getQueue())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCrashedServer()) {
        hash = (37 * hash) + CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getCrashedServer().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClaimReplicationQueueRemoteParameter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClaimReplicationQueueRemoteParameter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCrashedServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        queue_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.crashedServer_ = crashedServerBuilder_ == null
              ? crashedServer_
              : crashedServerBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.queue_ = queue_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter.getDefaultInstance()) return this;
        if (other.hasCrashedServer()) {
          mergeCrashedServer(other.getCrashedServer());
        }
        if (other.hasQueue()) {
          queue_ = other.queue_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCrashedServer()) {
          return false;
        }
        if (!hasQueue()) {
          return false;
        }
        if (!getCrashedServer().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCrashedServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                queue_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName crashedServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> crashedServerBuilder_;
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return Whether the crashedServer field is set.
       */
      public boolean hasCrashedServer() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       * @return The crashedServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getCrashedServer() {
        if (crashedServerBuilder_ == null) {
          return crashedServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        } else {
          return crashedServerBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          crashedServer_ = value;
        } else {
          crashedServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder setCrashedServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (crashedServerBuilder_ == null) {
          crashedServer_ = builderForValue.build();
        } else {
          crashedServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder mergeCrashedServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (crashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            crashedServer_ != null &&
            crashedServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getCrashedServerBuilder().mergeFrom(value);
          } else {
            crashedServer_ = value;
          }
        } else {
          crashedServerBuilder_.mergeFrom(value);
        }
        if (crashedServer_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public Builder clearCrashedServer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        crashedServer_ = null;
        if (crashedServerBuilder_ != null) {
          crashedServerBuilder_.dispose();
          crashedServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getCrashedServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCrashedServerFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getCrashedServerOrBuilder() {
        if (crashedServerBuilder_ != null) {
          return crashedServerBuilder_.getMessageOrBuilder();
        } else {
          return crashedServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : crashedServer_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName crashed_server = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getCrashedServerFieldBuilder() {
        if (crashedServerBuilder_ == null) {
          crashedServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getCrashedServer(),
                  getParentForChildren(),
                  isClean());
          crashedServer_ = null;
        }
        return crashedServerBuilder_;
      }

      private java.lang.Object queue_ = "";
      /**
       * <code>required string queue = 2;</code>
       * @return Whether the queue field is set.
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string queue = 2;</code>
       * @return The queue.
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string queue = 2;</code>
       * @return The bytes for queue.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string queue = 2;</code>
       * @param value The queue to set.
       * @return This builder for chaining.
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        queue_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string queue = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearQueue() {
        queue_ = getDefaultInstance().getQueue();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string queue = 2;</code>
       * @param value The bytes for queue to set.
       * @return This builder for chaining.
       */
      public Builder setQueueBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        queue_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClaimReplicationQueueRemoteParameter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClaimReplicationQueueRemoteParameter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteParameter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClaimReplicationQueueRemoteParameter>() {
      @java.lang.Override
      public ClaimReplicationQueueRemoteParameter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteParameter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClaimReplicationQueueRemoteParameter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ClaimReplicationQueueRemoteParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyTableDescriptorStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyTableDescriptorStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     * @return The modifiedTableSchema.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyTableDescriptorStateData}
   */
  @javax.annotation.Generated("proto") public static final class ModifyTableDescriptorStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyTableDescriptorStateData)
      ModifyTableDescriptorStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyTableDescriptorStateData.newBuilder() to construct.
    private ModifyTableDescriptorStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyTableDescriptorStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyTableDescriptorStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableDescriptorStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    @java.lang.Override
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     * @return The modifiedTableSchema.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasModifiedTableSchema()) {
        if (!getModifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getModifiedTableSchema());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getModifiedTableSchema());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasModifiedTableSchema() != other.hasModifiedTableSchema()) return false;
      if (hasModifiedTableSchema()) {
        if (!getModifiedTableSchema()
            .equals(other.getModifiedTableSchema())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyTableDescriptorStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyTableDescriptorStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableDescriptorStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_ == null
              ? modifiedTableSchema_
              : modifiedTableSchemaBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        if (hasModifiedTableSchema()) {
          if (!getModifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getModifiedTableSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       * @return Whether the modifiedTableSchema field is set.
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       * @return The modifiedTableSchema.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            modifiedTableSchema_ != null &&
            modifiedTableSchema_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            getModifiedTableSchemaBuilder().mergeFrom(value);
          } else {
            modifiedTableSchema_ = value;
          }
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        if (modifiedTableSchema_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public Builder clearModifiedTableSchema() {
        bitField0_ = (bitField0_ & ~0x00000002);
        modifiedTableSchema_ = null;
        if (modifiedTableSchemaBuilder_ != null) {
          modifiedTableSchemaBuilder_.dispose();
          modifiedTableSchemaBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema modified_table_schema = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyTableDescriptorStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyTableDescriptorStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableDescriptorStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyTableDescriptorStateData>() {
      @java.lang.Override
      public ModifyTableDescriptorStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableDescriptorStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyTableDescriptorStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyTableDescriptorStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyStoreFileTrackerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyStoreFileTrackerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required string dst_sft = 2;</code>
     * @return Whether the dstSft field is set.
     */
    boolean hasDstSft();
    /**
     * <code>required string dst_sft = 2;</code>
     * @return The dstSft.
     */
    java.lang.String getDstSft();
    /**
     * <code>required string dst_sft = 2;</code>
     * @return The bytes for dstSft.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getDstSftBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyStoreFileTrackerStateData}
   */
  @javax.annotation.Generated("proto") public static final class ModifyStoreFileTrackerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyStoreFileTrackerStateData)
      ModifyStoreFileTrackerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyStoreFileTrackerStateData.newBuilder() to construct.
    private ModifyStoreFileTrackerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyStoreFileTrackerStateData() {
      dstSft_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyStoreFileTrackerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyStoreFileTrackerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int DST_SFT_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object dstSft_ = "";
    /**
     * <code>required string dst_sft = 2;</code>
     * @return Whether the dstSft field is set.
     */
    @java.lang.Override
    public boolean hasDstSft() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string dst_sft = 2;</code>
     * @return The dstSft.
     */
    @java.lang.Override
    public java.lang.String getDstSft() {
      java.lang.Object ref = dstSft_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          dstSft_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string dst_sft = 2;</code>
     * @return The bytes for dstSft.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getDstSftBytes() {
      java.lang.Object ref = dstSft_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        dstSft_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDstSft()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, dstSft_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, dstSft_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasDstSft() != other.hasDstSft()) return false;
      if (hasDstSft()) {
        if (!getDstSft()
            .equals(other.getDstSft())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasDstSft()) {
        hash = (37 * hash) + DST_SFT_FIELD_NUMBER;
        hash = (53 * hash) + getDstSft().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyStoreFileTrackerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyStoreFileTrackerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyStoreFileTrackerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        dstSft_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.dstSft_ = dstSft_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasDstSft()) {
          dstSft_ = other.dstSft_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!hasDstSft()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                dstSft_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.lang.Object dstSft_ = "";
      /**
       * <code>required string dst_sft = 2;</code>
       * @return Whether the dstSft field is set.
       */
      public boolean hasDstSft() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string dst_sft = 2;</code>
       * @return The dstSft.
       */
      public java.lang.String getDstSft() {
        java.lang.Object ref = dstSft_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            dstSft_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string dst_sft = 2;</code>
       * @return The bytes for dstSft.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getDstSftBytes() {
        java.lang.Object ref = dstSft_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          dstSft_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string dst_sft = 2;</code>
       * @param value The dstSft to set.
       * @return This builder for chaining.
       */
      public Builder setDstSft(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        dstSft_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string dst_sft = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDstSft() {
        dstSft_ = getDefaultInstance().getDstSft();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string dst_sft = 2;</code>
       * @param value The bytes for dstSft to set.
       * @return This builder for chaining.
       */
      public Builder setDstSftBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        dstSft_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyStoreFileTrackerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyStoreFileTrackerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyStoreFileTrackerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyStoreFileTrackerStateData>() {
      @java.lang.Override
      public ModifyStoreFileTrackerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyStoreFileTrackerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyStoreFileTrackerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyStoreFileTrackerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyColumnFamilyStoreFileTrackerStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData}
   */
  @javax.annotation.Generated("proto") public static final class ModifyColumnFamilyStoreFileTrackerStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData)
      ModifyColumnFamilyStoreFileTrackerStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyColumnFamilyStoreFileTrackerStateData.newBuilder() to construct.
    private ModifyColumnFamilyStoreFileTrackerStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyColumnFamilyStoreFileTrackerStateData() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyColumnFamilyStoreFileTrackerStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.Builder.class);
    }

    private int bitField0_;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, family_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData) obj;

      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFamily()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyColumnFamilyStoreFileTrackerStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyColumnFamilyStoreFileTrackerStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ModifyColumnFamilyStoreFileTrackerStateData>() {
      @java.lang.Override
      public ModifyColumnFamilyStoreFileTrackerStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyColumnFamilyStoreFileTrackerStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ModifyColumnFamilyStoreFileTrackerStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStoreFileTrackerStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseExcessRegionReplicasProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseExcessRegionReplicasProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required uint32 new_replica_count = 2;</code>
     * @return Whether the newReplicaCount field is set.
     */
    boolean hasNewReplicaCount();
    /**
     * <code>required uint32 new_replica_count = 2;</code>
     * @return The newReplicaCount.
     */
    int getNewReplicaCount();
  }
  /**
   * Protobuf type {@code hbase.pb.CloseExcessRegionReplicasProcedureStateData}
   */
  @javax.annotation.Generated("proto") public static final class CloseExcessRegionReplicasProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseExcessRegionReplicasProcedureStateData)
      CloseExcessRegionReplicasProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseExcessRegionReplicasProcedureStateData.newBuilder() to construct.
    private CloseExcessRegionReplicasProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseExcessRegionReplicasProcedureStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseExcessRegionReplicasProcedureStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int NEW_REPLICA_COUNT_FIELD_NUMBER = 2;
    private int newReplicaCount_ = 0;
    /**
     * <code>required uint32 new_replica_count = 2;</code>
     * @return Whether the newReplicaCount field is set.
     */
    @java.lang.Override
    public boolean hasNewReplicaCount() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required uint32 new_replica_count = 2;</code>
     * @return The newReplicaCount.
     */
    @java.lang.Override
    public int getNewReplicaCount() {
      return newReplicaCount_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasNewReplicaCount()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt32(2, newReplicaCount_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, newReplicaCount_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasNewReplicaCount() != other.hasNewReplicaCount()) return false;
      if (hasNewReplicaCount()) {
        if (getNewReplicaCount()
            != other.getNewReplicaCount()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasNewReplicaCount()) {
        hash = (37 * hash) + NEW_REPLICA_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getNewReplicaCount();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloseExcessRegionReplicasProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseExcessRegionReplicasProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        newReplicaCount_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.newReplicaCount_ = newReplicaCount_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasNewReplicaCount()) {
          setNewReplicaCount(other.getNewReplicaCount());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!hasNewReplicaCount()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                newReplicaCount_ = input.readUInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private int newReplicaCount_ ;
      /**
       * <code>required uint32 new_replica_count = 2;</code>
       * @return Whether the newReplicaCount field is set.
       */
      @java.lang.Override
      public boolean hasNewReplicaCount() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required uint32 new_replica_count = 2;</code>
       * @return The newReplicaCount.
       */
      @java.lang.Override
      public int getNewReplicaCount() {
        return newReplicaCount_;
      }
      /**
       * <code>required uint32 new_replica_count = 2;</code>
       * @param value The newReplicaCount to set.
       * @return This builder for chaining.
       */
      public Builder setNewReplicaCount(int value) {

        newReplicaCount_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required uint32 new_replica_count = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearNewReplicaCount() {
        bitField0_ = (bitField0_ & ~0x00000002);
        newReplicaCount_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseExcessRegionReplicasProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseExcessRegionReplicasProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseExcessRegionReplicasProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseExcessRegionReplicasProcedureStateData>() {
      @java.lang.Override
      public CloseExcessRegionReplicasProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseExcessRegionReplicasProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseExcessRegionReplicasProcedureStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseExcessRegionReplicasProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseTableRegionsProcedureStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseTableRegionsProcedureStateData)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CloseTableRegionsProcedureStateData}
   */
  @javax.annotation.Generated("proto") public static final class CloseTableRegionsProcedureStateData extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseTableRegionsProcedureStateData)
      CloseTableRegionsProcedureStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseTableRegionsProcedureStateData.newBuilder() to construct.
    private CloseTableRegionsProcedureStateData(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseTableRegionsProcedureStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseTableRegionsProcedureStateData();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseTableRegionsProcedureStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData other = (org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloseTableRegionsProcedureStateData}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseTableRegionsProcedureStateData)
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateDataOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseTableRegionsProcedureStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.class, org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData result = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseTableRegionsProcedureStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseTableRegionsProcedureStateData)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseTableRegionsProcedureStateData>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseTableRegionsProcedureStateData>() {
      @java.lang.Override
      public CloseTableRegionsProcedureStateData parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseTableRegionsProcedureStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseTableRegionsProcedureStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProcedureProtos.CloseTableRegionsProcedureStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TruncateTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnableTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisableTableStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloneSnapshotStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RestoreSnapshotStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitTableRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MergeTableRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ServerCrashStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RecoverMetaStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AssignRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UnassignRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MoveRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCRegionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCMergedRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PeerModificationStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RefreshPeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RefreshPeerParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PeerProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AddPeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RemovePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnablePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisablePeerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_InitMetaStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionStateTransitionStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SplitWALRemoteData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClaimReplicationQueuesStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyTableDescriptorStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyStoreFileTrackerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseTableRegionsProcedureStateData_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\025MasterProcedure.proto\022\010hbase.pb\032\013HBase" +
      ".proto\032\tRPC.proto\032\016Snapshot.proto\032\021Repli" +
      "cation.proto\032\030RegionServerStatus.proto\032\023" +
      "ErrorHandling.proto\"\234\001\n\024CreateTableState" +
      "Data\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserI" +
      "nformation\022+\n\014table_schema\030\002 \002(\0132\025.hbase" +
      ".pb.TableSchema\022)\n\013region_info\030\003 \003(\0132\024.h" +
      "base.pb.RegionInfo\"\223\002\n\024ModifyTableStateD" +
      "ata\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserIn" +
      "formation\0226\n\027unmodified_table_schema\030\002 \001" +
      "(\0132\025.hbase.pb.TableSchema\0224\n\025modified_ta" +
      "ble_schema\030\003 \002(\0132\025.hbase.pb.TableSchema\022" +
      "&\n\036delete_column_family_in_modify\030\004 \002(\010\022" +
      "\037\n\027should_check_descriptor\030\005 \001(\010\022\026\n\016reop" +
      "en_regions\030\006 \001(\010\"\340\001\n\026TruncateTableStateD" +
      "ata\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserIn" +
      "formation\022\027\n\017preserve_splits\030\002 \002(\010\022\'\n\nta" +
      "ble_name\030\003 \001(\0132\023.hbase.pb.TableName\022+\n\014t" +
      "able_schema\030\004 \001(\0132\025.hbase.pb.TableSchema" +
      "\022)\n\013region_info\030\005 \003(\0132\024.hbase.pb.RegionI" +
      "nfo\"\230\001\n\024DeleteTableStateData\022,\n\tuser_inf" +
      "o\030\001 \002(\0132\031.hbase.pb.UserInformation\022\'\n\nta" +
      "ble_name\030\002 \002(\0132\023.hbase.pb.TableName\022)\n\013r" +
      "egion_info\030\003 \003(\0132\024.hbase.pb.RegionInfo\"W" +
      "\n\030CreateNamespaceStateData\022;\n\024namespace_" +
      "descriptor\030\001 \002(\0132\035.hbase.pb.NamespaceDes" +
      "criptor\"\237\001\n\030ModifyNamespaceStateData\022;\n\024" +
      "namespace_descriptor\030\001 \002(\0132\035.hbase.pb.Na" +
      "mespaceDescriptor\022F\n\037unmodified_namespac" +
      "e_descriptor\030\002 \001(\0132\035.hbase.pb.NamespaceD" +
      "escriptor\"o\n\030DeleteNamespaceStateData\022\026\n" +
      "\016namespace_name\030\001 \002(\t\022;\n\024namespace_descr" +
      "iptor\030\002 \001(\0132\035.hbase.pb.NamespaceDescript" +
      "or\"\221\001\n\024EnableTableStateData\022,\n\tuser_info" +
      "\030\001 \002(\0132\031.hbase.pb.UserInformation\022\'\n\ntab" +
      "le_name\030\002 \002(\0132\023.hbase.pb.TableName\022\"\n\026sk" +
      "ip_table_state_check\030\003 \002(\010B\002\030\001\"\216\001\n\025Disab" +
      "leTableStateData\022,\n\tuser_info\030\001 \002(\0132\031.hb" +
      "ase.pb.UserInformation\022\'\n\ntable_name\030\002 \002" +
      "(\0132\023.hbase.pb.TableName\022\036\n\026skip_table_st" +
      "ate_check\030\003 \002(\010\"u\n\037RestoreParentToChildR" +
      "egionsPair\022\032\n\022parent_region_name\030\001 \002(\t\022\032" +
      "\n\022child1_region_name\030\002 \002(\t\022\032\n\022child2_reg" +
      "ion_name\030\003 \002(\t\"\315\002\n\026CloneSnapshotStateDat" +
      "a\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInfo" +
      "rmation\022/\n\010snapshot\030\002 \002(\0132\035.hbase.pb.Sna" +
      "pshotDescription\022+\n\014table_schema\030\003 \002(\0132\025" +
      ".hbase.pb.TableSchema\022)\n\013region_info\030\004 \003" +
      "(\0132\024.hbase.pb.RegionInfo\022T\n!parent_to_ch" +
      "ild_regions_pair_list\030\005 \003(\0132).hbase.pb.R" +
      "estoreParentToChildRegionsPair\022\023\n\013restor" +
      "e_acl\030\006 \001(\010\022\021\n\tcustomSFT\030\007 \001(\t\"\272\003\n\030Resto" +
      "reSnapshotStateData\022,\n\tuser_info\030\001 \002(\0132\031" +
      ".hbase.pb.UserInformation\022/\n\010snapshot\030\002 " +
      "\002(\0132\035.hbase.pb.SnapshotDescription\0224\n\025mo" +
      "dified_table_schema\030\003 \002(\0132\025.hbase.pb.Tab" +
      "leSchema\0225\n\027region_info_for_restore\030\004 \003(" +
      "\0132\024.hbase.pb.RegionInfo\0224\n\026region_info_f" +
      "or_remove\030\005 \003(\0132\024.hbase.pb.RegionInfo\0221\n" +
      "\023region_info_for_add\030\006 \003(\0132\024.hbase.pb.Re" +
      "gionInfo\022T\n!parent_to_child_regions_pair" +
      "_list\030\007 \003(\0132).hbase.pb.RestoreParentToCh" +
      "ildRegionsPair\022\023\n\013restore_acl\030\010 \001(\010\"\265\001\n\037" +
      "DispatchMergingRegionsStateData\022,\n\tuser_" +
      "info\030\001 \002(\0132\031.hbase.pb.UserInformation\022\'\n" +
      "\ntable_name\030\002 \002(\0132\023.hbase.pb.TableName\022)" +
      "\n\013region_info\030\003 \003(\0132\024.hbase.pb.RegionInf" +
      "o\022\020\n\010forcible\030\004 \001(\010\"\254\001\n\031SplitTableRegion" +
      "StateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb." +
      "UserInformation\0220\n\022parent_region_info\030\002 " +
      "\002(\0132\024.hbase.pb.RegionInfo\022/\n\021child_regio" +
      "n_info\030\003 \003(\0132\024.hbase.pb.RegionInfo\"\300\001\n\032M" +
      "ergeTableRegionsStateData\022,\n\tuser_info\030\001" +
      " \002(\0132\031.hbase.pb.UserInformation\022)\n\013regio" +
      "n_info\030\002 \003(\0132\024.hbase.pb.RegionInfo\0220\n\022me" +
      "rged_region_info\030\003 \001(\0132\024.hbase.pb.Region" +
      "Info\022\027\n\010forcible\030\004 \001(\010:\005false\"\341\001\n\024Server" +
      "CrashStateData\022)\n\013server_name\030\001 \002(\0132\024.hb" +
      "ase.pb.ServerName\0227\n\031regions_on_crashed_" +
      "server\030\003 \003(\0132\024.hbase.pb.RegionInfo\022.\n\020re" +
      "gions_assigned\030\004 \003(\0132\024.hbase.pb.RegionIn" +
      "fo\022\025\n\rcarrying_meta\030\005 \001(\010\022\036\n\020should_spli" +
      "t_wal\030\006 \001(\010:\004true\"\177\n\024RecoverMetaStateDat" +
      "a\0220\n\022failed_meta_server\030\001 \001(\0132\024.hbase.pb" +
      ".ServerName\022\036\n\020should_split_wal\030\002 \001(\010:\004t" +
      "rue\022\025\n\nreplica_id\030\003 \001(\005:\0010\"\332\001\n\025AssignReg" +
      "ionStateData\0229\n\020transition_state\030\001 \002(\0162\037" +
      ".hbase.pb.RegionTransitionState\022)\n\013regio" +
      "n_info\030\002 \002(\0132\024.hbase.pb.RegionInfo\022\035\n\016fo" +
      "rce_new_plan\030\003 \001(\010:\005false\022+\n\rtarget_serv" +
      "er\030\004 \001(\0132\024.hbase.pb.ServerName\022\017\n\007attemp" +
      "t\030\005 \001(\005\"\257\002\n\027UnassignRegionStateData\0229\n\020t" +
      "ransition_state\030\001 \002(\0162\037.hbase.pb.RegionT" +
      "ransitionState\022)\n\013region_info\030\002 \002(\0132\024.hb" +
      "ase.pb.RegionInfo\0220\n\022destination_server\030" +
      "\003 \001(\0132\024.hbase.pb.ServerName\022,\n\016hosting_s" +
      "erver\030\005 \001(\0132\024.hbase.pb.ServerName\022\024\n\005for" +
      "ce\030\004 \001(\010:\005false\022\'\n\030remove_after_unassign" +
      "ing\030\006 \001(\010:\005false\022\017\n\007attempt\030\007 \001(\005\"\237\001\n\023Mo" +
      "veRegionStateData\022)\n\013region_info\030\001 \001(\0132\024" +
      ".hbase.pb.RegionInfo\022+\n\rsource_server\030\002 " +
      "\002(\0132\024.hbase.pb.ServerName\0220\n\022destination" +
      "_server\030\003 \001(\0132\024.hbase.pb.ServerName\">\n\021G" +
      "CRegionStateData\022)\n\013region_info\030\001 \002(\0132\024." +
      "hbase.pb.RegionInfo\"\232\001\n\030GCMergedRegionsS" +
      "tateData\022&\n\010parent_a\030\001 \002(\0132\024.hbase.pb.Re" +
      "gionInfo\022&\n\010parent_b\030\002 \002(\0132\024.hbase.pb.Re" +
      "gionInfo\022*\n\014merged_child\030\003 \002(\0132\024.hbase.p" +
      "b.RegionInfo:\002\030\001\"u\n GCMultipleMergedRegi" +
      "onsStateData\022%\n\007parents\030\001 \003(\0132\024.hbase.pb" +
      ".RegionInfo\022*\n\014merged_child\030\002 \002(\0132\024.hbas" +
      "e.pb.RegionInfo\",\n\031PeerModificationState" +
      "Data\022\017\n\007peer_id\030\001 \002(\t\"\351\001\n\024RefreshPeerSta" +
      "teData\022\017\n\007peer_id\030\001 \002(\t\022,\n\004type\030\002 \002(\0162\036." +
      "hbase.pb.PeerModificationType\022+\n\rtarget_" +
      "server\030\003 \002(\0132\024.hbase.pb.ServerName\0223\n\005st" +
      "ate\030\005 \001(\0162$.hbase.pb.ServerRemoteProcedu" +
      "reState\0220\n\005error\030\006 \001(\0132!.hbase.pb.Foreig" +
      "nExceptionMessage\"\202\001\n\024RefreshPeerParamet" +
      "er\022\017\n\007peer_id\030\001 \002(\t\022,\n\004type\030\002 \002(\0162\036.hbas" +
      "e.pb.PeerModificationType\022+\n\rtarget_serv" +
      "er\030\003 \002(\0132\024.hbase.pb.ServerName\")\n\026PeerPr" +
      "ocedureStateData\022\017\n\007peer_id\030\001 \002(\t\"S\n\020Add" +
      "PeerStateData\022.\n\013peer_config\030\001 \002(\0132\031.hba" +
      "se.pb.ReplicationPeer\022\017\n\007enabled\030\002 \002(\010\"\220" +
      "\001\n\031UpdatePeerConfigStateData\022.\n\013peer_con" +
      "fig\030\001 \002(\0132\031.hbase.pb.ReplicationPeer\0222\n\017" +
      "old_peer_config\030\002 \001(\0132\031.hbase.pb.Replica" +
      "tionPeer\022\017\n\007enabled\030\003 \002(\010\"E\n\023RemovePeerS" +
      "tateData\022.\n\013peer_config\030\001 \001(\0132\031.hbase.pb" +
      ".ReplicationPeer\"\025\n\023EnablePeerStateData\"" +
      "\026\n\024DisablePeerStateData\"\206\001\n\033ReopenTableR" +
      "egionsStateData\022\'\n\ntable_name\030\001 \002(\0132\023.hb" +
      "ase.pb.TableName\022(\n\006region\030\002 \003(\0132\030.hbase" +
      ".pb.RegionLocation\022\024\n\014region_names\030\003 \003(\014" +
      "\"\023\n\021InitMetaStateData\"\226\001\n\036RegionStateTra" +
      "nsitionStateData\022,\n\004type\030\001 \002(\0162\036.hbase.p" +
      "b.RegionTransitionType\022.\n\020assign_candida" +
      "te\030\002 \001(\0132\024.hbase.pb.ServerName\022\026\n\016force_" +
      "new_plan\030\003 \002(\010\"\211\002\n\"RegionRemoteProcedure" +
      "BaseStateData\022$\n\006region\030\001 \002(\0132\024.hbase.pb" +
      ".RegionInfo\022+\n\rtarget_server\030\002 \002(\0132\024.hba" +
      "se.pb.ServerName\0227\n\005state\030\003 \001(\0162(.hbase." +
      "pb.RegionRemoteProcedureBaseState\022G\n\017tra" +
      "nsition_code\030\004 \001(\0162..hbase.pb.RegionStat" +
      "eTransition.TransitionCode\022\016\n\006seq_id\030\005 \001" +
      "(\003\"\036\n\034OpenRegionProcedureStateData\"O\n\035Cl" +
      "oseRegionProcedureStateData\022.\n\020assign_ca" +
      "ndidate\030\001 \001(\0132\024.hbase.pb.ServerName\":\n\032S" +
      "witchRpcThrottleStateData\022\034\n\024rpc_throttl" +
      "e_enabled\030\001 \002(\010\"\324\001\n SwitchRpcThrottleRem" +
      "oteStateData\022+\n\rtarget_server\030\001 \002(\0132\024.hb" +
      "ase.pb.ServerName\022\034\n\024rpc_throttle_enable" +
      "d\030\002 \002(\010\0223\n\005state\030\003 \001(\0162$.hbase.pb.Server" +
      "RemoteProcedureState\0220\n\005error\030\004 \001(\0132!.hb" +
      "ase.pb.ForeignExceptionMessage\"%\n\021SplitW" +
      "ALParameter\022\020\n\010wal_path\030\001 \002(\t\"t\n\014SplitWA" +
      "LData\022\020\n\010wal_path\030\001 \002(\t\022,\n\016crashed_serve" +
      "r\030\002 \002(\0132\024.hbase.pb.ServerName\022$\n\006worker\030" +
      "\003 \001(\0132\024.hbase.pb.ServerName\"\341\001\n\022SplitWAL" +
      "RemoteData\022\020\n\010wal_path\030\001 \002(\t\022,\n\016crashed_" +
      "server\030\002 \002(\0132\024.hbase.pb.ServerName\022$\n\006wo" +
      "rker\030\003 \002(\0132\024.hbase.pb.ServerName\0223\n\005stat" +
      "e\030\004 \001(\0162$.hbase.pb.ServerRemoteProcedure" +
      "State\0220\n\005error\030\005 \001(\0132!.hbase.pb.ForeignE" +
      "xceptionMessage\"O\n\037ClaimReplicationQueue" +
      "sStateData\022,\n\016crashed_server\030\001 \002(\0132\024.hba" +
      "se.pb.ServerName\"\367\001\n$ClaimReplicationQue" +
      "ueRemoteStateData\022,\n\016crashed_server\030\001 \002(" +
      "\0132\024.hbase.pb.ServerName\022\r\n\005queue\030\002 \002(\t\022+" +
      "\n\rtarget_server\030\003 \002(\0132\024.hbase.pb.ServerN" +
      "ame\0223\n\005state\030\005 \001(\0162$.hbase.pb.ServerRemo" +
      "teProcedureState\0220\n\005error\030\006 \001(\0132!.hbase." +
      "pb.ForeignExceptionMessage\"c\n$ClaimRepli" +
      "cationQueueRemoteParameter\022,\n\016crashed_se" +
      "rver\030\001 \002(\0132\024.hbase.pb.ServerName\022\r\n\005queu" +
      "e\030\002 \002(\t\"\177\n\036ModifyTableDescriptorStateDat" +
      "a\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.TableNa" +
      "me\0224\n\025modified_table_schema\030\002 \001(\0132\025.hbas" +
      "e.pb.TableSchema\"[\n\037ModifyStoreFileTrack" +
      "erStateData\022\'\n\ntable_name\030\001 \002(\0132\023.hbase." +
      "pb.TableName\022\017\n\007dst_sft\030\002 \002(\t\"=\n+ModifyC" +
      "olumnFamilyStoreFileTrackerStateData\022\016\n\006" +
      "family\030\001 \002(\014\"q\n+CloseExcessRegionReplica" +
      "sProcedureStateData\022\'\n\ntable_name\030\001 \002(\0132" +
      "\023.hbase.pb.TableName\022\031\n\021new_replica_coun" +
      "t\030\002 \002(\r\"N\n#CloseTableRegionsProcedureSta" +
      "teData\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.Ta" +
      "bleName*\330\001\n\020CreateTableState\022\036\n\032CREATE_T" +
      "ABLE_PRE_OPERATION\020\001\022 \n\034CREATE_TABLE_WRI" +
      "TE_FS_LAYOUT\020\002\022\034\n\030CREATE_TABLE_ADD_TO_ME" +
      "TA\020\003\022\037\n\033CREATE_TABLE_ASSIGN_REGIONS\020\004\022\"\n" +
      "\036CREATE_TABLE_UPDATE_DESC_CACHE\020\005\022\037\n\033CRE" +
      "ATE_TABLE_POST_OPERATION\020\006*\325\002\n\020ModifyTab" +
      "leState\022\030\n\024MODIFY_TABLE_PREPARE\020\001\022\036\n\032MOD" +
      "IFY_TABLE_PRE_OPERATION\020\002\022(\n$MODIFY_TABL" +
      "E_UPDATE_TABLE_DESCRIPTOR\020\003\022&\n\"MODIFY_TA" +
      "BLE_REMOVE_REPLICA_COLUMN\020\004\022!\n\035MODIFY_TA" +
      "BLE_DELETE_FS_LAYOUT\020\005\022\037\n\033MODIFY_TABLE_P" +
      "OST_OPERATION\020\006\022#\n\037MODIFY_TABLE_REOPEN_A" +
      "LL_REGIONS\020\007\022&\n\"MODIFY_TABLE_CLOSE_EXCES" +
      "S_REPLICAS\020\010\022$\n MODIFY_TABLE_ASSIGN_NEW_" +
      "REPLICAS\020\t*\212\002\n\022TruncateTableState\022 \n\034TRU" +
      "NCATE_TABLE_PRE_OPERATION\020\001\022#\n\037TRUNCATE_" +
      "TABLE_REMOVE_FROM_META\020\002\022\"\n\036TRUNCATE_TAB" +
      "LE_CLEAR_FS_LAYOUT\020\003\022#\n\037TRUNCATE_TABLE_C" +
      "REATE_FS_LAYOUT\020\004\022\036\n\032TRUNCATE_TABLE_ADD_" +
      "TO_META\020\005\022!\n\035TRUNCATE_TABLE_ASSIGN_REGIO" +
      "NS\020\006\022!\n\035TRUNCATE_TABLE_POST_OPERATION\020\007*" +
      "\337\001\n\020DeleteTableState\022\036\n\032DELETE_TABLE_PRE" +
      "_OPERATION\020\001\022!\n\035DELETE_TABLE_REMOVE_FROM" +
      "_META\020\002\022 \n\034DELETE_TABLE_CLEAR_FS_LAYOUT\020" +
      "\003\022\"\n\036DELETE_TABLE_UPDATE_DESC_CACHE\020\004\022!\n" +
      "\035DELETE_TABLE_UNASSIGN_REGIONS\020\005\022\037\n\033DELE" +
      "TE_TABLE_POST_OPERATION\020\006*\320\001\n\024CreateName" +
      "spaceState\022\034\n\030CREATE_NAMESPACE_PREPARE\020\001" +
      "\022%\n!CREATE_NAMESPACE_CREATE_DIRECTORY\020\002\022" +
      ")\n%CREATE_NAMESPACE_INSERT_INTO_NS_TABLE" +
      "\020\003\022\036\n\032CREATE_NAMESPACE_UPDATE_ZK\020\004\022(\n$CR" +
      "EATE_NAMESPACE_SET_NAMESPACE_QUOTA\020\005*z\n\024" +
      "ModifyNamespaceState\022\034\n\030MODIFY_NAMESPACE" +
      "_PREPARE\020\001\022$\n MODIFY_NAMESPACE_UPDATE_NS" +
      "_TABLE\020\002\022\036\n\032MODIFY_NAMESPACE_UPDATE_ZK\020\003" +
      "*\332\001\n\024DeleteNamespaceState\022\034\n\030DELETE_NAME" +
      "SPACE_PREPARE\020\001\022)\n%DELETE_NAMESPACE_DELE" +
      "TE_FROM_NS_TABLE\020\002\022#\n\037DELETE_NAMESPACE_R" +
      "EMOVE_FROM_ZK\020\003\022\'\n#DELETE_NAMESPACE_DELE" +
      "TE_DIRECTORIES\020\004\022+\n\'DELETE_NAMESPACE_REM" +
      "OVE_NAMESPACE_QUOTA\020\005*\350\001\n\020EnableTableSta" +
      "te\022\030\n\024ENABLE_TABLE_PREPARE\020\001\022\036\n\032ENABLE_T" +
      "ABLE_PRE_OPERATION\020\002\022)\n%ENABLE_TABLE_SET" +
      "_ENABLING_TABLE_STATE\020\003\022$\n ENABLE_TABLE_" +
      "MARK_REGIONS_ONLINE\020\004\022(\n$ENABLE_TABLE_SE" +
      "T_ENABLED_TABLE_STATE\020\005\022\037\n\033ENABLE_TABLE_" +
      "POST_OPERATION\020\006*\235\002\n\021DisableTableState\022\031" +
      "\n\025DISABLE_TABLE_PREPARE\020\001\022\037\n\033DISABLE_TAB" +
      "LE_PRE_OPERATION\020\002\022+\n\'DISABLE_TABLE_SET_" +
      "DISABLING_TABLE_STATE\020\003\022&\n\"DISABLE_TABLE" +
      "_MARK_REGIONS_OFFLINE\020\004\022*\n&DISABLE_TABLE" +
      "_SET_DISABLED_TABLE_STATE\020\005\022 \n\034DISABLE_T" +
      "ABLE_POST_OPERATION\020\006\022)\n%DISABLE_TABLE_A" +
      "DD_REPLICATION_BARRIER\020\007*\206\002\n\022CloneSnapsh" +
      "otState\022 \n\034CLONE_SNAPSHOT_PRE_OPERATION\020" +
      "\001\022\"\n\036CLONE_SNAPSHOT_WRITE_FS_LAYOUT\020\002\022\036\n" +
      "\032CLONE_SNAPSHOT_ADD_TO_META\020\003\022!\n\035CLONE_S" +
      "NAPSHOT_ASSIGN_REGIONS\020\004\022$\n CLONE_SNAPSH" +
      "OT_UPDATE_DESC_CACHE\020\005\022!\n\035CLONE_SNAPSHOT" +
      "_POST_OPERATION\020\006\022\036\n\032CLONE_SNAPHOST_REST" +
      "ORE_ACL\020\007*\322\001\n\024RestoreSnapshotState\022\"\n\036RE" +
      "STORE_SNAPSHOT_PRE_OPERATION\020\001\022,\n(RESTOR" +
      "E_SNAPSHOT_UPDATE_TABLE_DESCRIPTOR\020\002\022$\n " +
      "RESTORE_SNAPSHOT_WRITE_FS_LAYOUT\020\003\022 \n\034RE" +
      "STORE_SNAPSHOT_UPDATE_META\020\004\022 \n\034RESTORE_" +
      "SNAPSHOT_RESTORE_ACL\020\005*\376\001\n\033DispatchMergi" +
      "ngRegionsState\022$\n DISPATCH_MERGING_REGIO" +
      "NS_PREPARE\020\001\022*\n&DISPATCH_MERGING_REGIONS" +
      "_PRE_OPERATION\020\002\0223\n/DISPATCH_MERGING_REG" +
      "IONS_MOVE_REGION_TO_SAME_RS\020\003\022+\n\'DISPATC" +
      "H_MERGING_REGIONS_DO_MERGE_IN_RS\020\004\022+\n\'DI" +
      "SPATCH_MERGING_REGIONS_POST_OPERATION\020\005*" +
      "\363\003\n\025SplitTableRegionState\022\036\n\032SPLIT_TABLE" +
      "_REGION_PREPARE\020\001\022$\n SPLIT_TABLE_REGION_" +
      "PRE_OPERATION\020\002\022*\n&SPLIT_TABLE_REGION_CL" +
      "OSE_PARENT_REGION\020\003\022.\n*SPLIT_TABLE_REGIO" +
      "N_CREATE_DAUGHTER_REGIONS\020\004\0221\n-SPLIT_TAB" +
      "LE_REGION_WRITE_MAX_SEQUENCE_ID_FILE\020\005\0220" +
      "\n,SPLIT_TABLE_REGION_PRE_OPERATION_BEFOR" +
      "E_META\020\006\022\"\n\036SPLIT_TABLE_REGION_UPDATE_ME" +
      "TA\020\007\022/\n+SPLIT_TABLE_REGION_PRE_OPERATION" +
      "_AFTER_META\020\010\022)\n%SPLIT_TABLE_REGION_OPEN" +
      "_CHILD_REGIONS\020\t\022%\n!SPLIT_TABLE_REGION_P" +
      "OST_OPERATION\020\n\022,\n(SPLIT_TABLE_REGIONS_C" +
      "HECK_CLOSED_REGIONS\020\013*\246\004\n\026MergeTableRegi" +
      "onsState\022\037\n\033MERGE_TABLE_REGIONS_PREPARE\020" +
      "\001\022%\n!MERGE_TABLE_REGIONS_PRE_OPERATION\020\002" +
      "\022+\n\'MERGE_TABLE_REGIONS_PRE_MERGE_OPERAT" +
      "ION\020\003\022%\n!MERGE_TABLE_REGIONS_CLOSE_REGIO" +
      "NS\020\004\022,\n(MERGE_TABLE_REGIONS_CREATE_MERGE" +
      "D_REGION\020\005\0222\n.MERGE_TABLE_REGIONS_WRITE_" +
      "MAX_SEQUENCE_ID_FILE\020\006\0222\n.MERGE_TABLE_RE" +
      "GIONS_PRE_MERGE_COMMIT_OPERATION\020\007\022#\n\037ME" +
      "RGE_TABLE_REGIONS_UPDATE_META\020\010\0223\n/MERGE" +
      "_TABLE_REGIONS_POST_MERGE_COMMIT_OPERATI" +
      "ON\020\t\022*\n&MERGE_TABLE_REGIONS_OPEN_MERGED_" +
      "REGION\020\n\022&\n\"MERGE_TABLE_REGIONS_POST_OPE" +
      "RATION\020\013\022,\n(MERGE_TABLE_REGIONS_CHECK_CL" +
      "OSED_REGIONS\020\014*\341\003\n\020ServerCrashState\022\026\n\022S" +
      "ERVER_CRASH_START\020\001\022!\n\031SERVER_CRASH_PROC" +
      "ESS_META\020\002\032\002\010\001\022\034\n\030SERVER_CRASH_GET_REGIO" +
      "NS\020\003\022\"\n\032SERVER_CRASH_NO_SPLIT_LOGS\020\004\032\002\010\001" +
      "\022\033\n\027SERVER_CRASH_SPLIT_LOGS\020\005\022\027\n\023SERVER_" +
      "CRASH_ASSIGN\020\010\022\037\n\033SERVER_CRASH_WAIT_ON_A" +
      "SSIGN\020\t\022 \n\034SERVER_CRASH_SPLIT_META_LOGS\020" +
      "\n\022\034\n\030SERVER_CRASH_ASSIGN_META\020\013\022+\n\'SERVE" +
      "R_CRASH_DELETE_SPLIT_META_WALS_DIR\020\014\022&\n\"" +
      "SERVER_CRASH_DELETE_SPLIT_WALS_DIR\020\r\022)\n%" +
      "SERVER_CRASH_CLAIM_REPLICATION_QUEUES\020\016\022" +
      " \n\030SERVER_CRASH_HANDLE_RIT2\020\024\032\002\010\001\022\027\n\023SER" +
      "VER_CRASH_FINISH\020d*j\n\020RecoverMetaState\022\030" +
      "\n\024RECOVER_META_PREPARE\020\000\022\033\n\027RECOVER_META" +
      "_SPLIT_LOGS\020\001\022\037\n\033RECOVER_META_ASSIGN_REG" +
      "IONS\020\002*r\n\025RegionTransitionState\022\033\n\027REGIO" +
      "N_TRANSITION_QUEUE\020\001\022\036\n\032REGION_TRANSITIO" +
      "N_DISPATCH\020\002\022\034\n\030REGION_TRANSITION_FINISH" +
      "\020\003*\\\n\017MoveRegionState\022\027\n\023MOVE_REGION_PRE" +
      "PARE\020\000\022\030\n\024MOVE_REGION_UNASSIGN\020\001\022\026\n\022MOVE" +
      "_REGION_ASSIGN\020\002*[\n\rGCRegionState\022\025\n\021GC_" +
      "REGION_PREPARE\020\001\022\025\n\021GC_REGION_ARCHIVE\020\002\022" +
      "\034\n\030GC_REGION_PURGE_METADATA\020\003*o\n\024GCMerge" +
      "dRegionsState\022\035\n\031GC_MERGED_REGIONS_PREPA" +
      "RE\020\001\022\033\n\027GC_MERGED_REGIONS_PURGE\020\002\022\033\n\027GC_" +
      "REGION_EDIT_METADATA\020\003*\234\002\n\025PeerModificat" +
      "ionState\022\031\n\025PRE_PEER_MODIFICATION\020\001\022\027\n\023U" +
      "PDATE_PEER_STORAGE\020\002\022\026\n\022REFRESH_PEER_ON_" +
      "RS\020\003\022\036\n\032SERIAL_PEER_REOPEN_REGIONS\020\004\022)\n%" +
      "SERIAL_PEER_UPDATE_LAST_PUSHED_SEQ_ID\020\005\022" +
      " \n\034SERIAL_PEER_SET_PEER_ENABLED\020\006\022.\n*SER" +
      "IAL_PEER_ENABLE_PEER_REFRESH_PEER_ON_RS\020" +
      "\007\022\032\n\026POST_PEER_MODIFICATION\020\010*p\n\024PeerMod" +
      "ificationType\022\014\n\010ADD_PEER\020\001\022\017\n\013REMOVE_PE" +
      "ER\020\002\022\017\n\013ENABLE_PEER\020\003\022\020\n\014DISABLE_PEER\020\004\022" +
      "\026\n\022UPDATE_PEER_CONFIG\020\005*\223\001\n\027ReopenTableR" +
      "egionsState\022$\n REOPEN_TABLE_REGIONS_GET_" +
      "REGIONS\020\001\022\'\n#REOPEN_TABLE_REGIONS_REOPEN" +
      "_REGIONS\020\002\022)\n%REOPEN_TABLE_REGIONS_CONFI" +
      "RM_REOPENED\020\003*I\n\rInitMetaState\022\035\n\031INIT_M" +
      "ETA_WRITE_FS_LAYOUT\020\001\022\031\n\025INIT_META_ASSIG" +
      "N_META\020\002*\353\001\n\032RegionStateTransitionState\022" +
      "0\n,REGION_STATE_TRANSITION_GET_ASSIGN_CA" +
      "NDIDATE\020\001\022 \n\034REGION_STATE_TRANSITION_OPE" +
      "N\020\002\022*\n&REGION_STATE_TRANSITION_CONFIRM_O" +
      "PENED\020\003\022!\n\035REGION_STATE_TRANSITION_CLOSE" +
      "\020\004\022*\n&REGION_STATE_TRANSITION_CONFIRM_CL" +
      "OSED\020\005*F\n\024RegionTransitionType\022\n\n\006ASSIGN" +
      "\020\001\022\014\n\010UNASSIGN\020\002\022\010\n\004MOVE\020\003\022\n\n\006REOPEN\020\004*\307" +
      "\001\n\036RegionRemoteProcedureBaseState\022$\n REG" +
      "ION_REMOTE_PROCEDURE_DISPATCH\020\001\022*\n&REGIO" +
      "N_REMOTE_PROCEDURE_REPORT_SUCCEED\020\002\022)\n%R" +
      "EGION_REMOTE_PROCEDURE_DISPATCH_FAIL\020\003\022(" +
      "\n$REGION_REMOTE_PROCEDURE_SERVER_CRASH\020\004" +
      "*\356\001\n\032ServerRemoteProcedureState\022$\n SERVE" +
      "R_REMOTE_PROCEDURE_DISPATCH\020\001\022)\n%SERVER_" +
      "REMOTE_PROCEDURE_DISPATCH_FAIL\020\002\022*\n&SERV" +
      "ER_REMOTE_PROCEDURE_REPORT_SUCCEED\020\003\022)\n%" +
      "SERVER_REMOTE_PROCEDURE_REPORT_FAILED\020\004\022" +
      "(\n$SERVER_REMOTE_PROCEDURE_SERVER_CRASH\020" +
      "\005*}\n\026SwitchRpcThrottleState\022&\n\"UPDATE_SW" +
      "ITCH_RPC_THROTTLE_STORAGE\020\001\022\035\n\031SWITCH_RP" +
      "C_THROTTLE_ON_RS\020\002\022\034\n\030POST_SWITCH_RPC_TH" +
      "ROTTLE\020\003*c\n\rSplitWALState\022\034\n\030ACQUIRE_SPL" +
      "IT_WAL_WORKER\020\001\022\032\n\026DISPATCH_WAL_TO_WORKE" +
      "R\020\002\022\030\n\024RELEASE_SPLIT_WORKER\020\003*i\n\033ClaimRe" +
      "plicationQueuesState\022%\n!CLAIM_REPLICATIO" +
      "N_QUEUES_DISPATCH\020\001\022#\n\037CLAIM_REPLICATION" +
      "_QUEUES_FINISH\020\002*e\n\032ModifyTableDescripto" +
      "rState\022#\n\037MODIFY_TABLE_DESCRIPTOR_PREPAR" +
      "E\020\001\022\"\n\036MODIFY_TABLE_DESCRIPTOR_UPDATE\020\002*" +
      "\265\001\n\033ModifyStoreFileTrackerState\0227\n3MODIF" +
      "Y_STORE_FILE_TRACKER_FINISH_PREVIOUS_MIG" +
      "RATION\020\001\022-\n)MODIFY_STORE_FILE_TRACKER_ST" +
      "ART_MIGRATION\020\002\022.\n*MODIFY_STORE_FILE_TRA" +
      "CKER_FINISH_MIGRATION\020\003*~\n\'CloseExcessRe" +
      "gionReplicasProcedureState\022)\n%CLOSE_EXCE" +
      "SS_REGION_REPLICAS_SCHEDULE\020\001\022(\n$CLOSE_E" +
      "XCESS_REGION_REPLICAS_CONFIRM\020\002*d\n\037Close" +
      "TableRegionsProcedureState\022 \n\034CLOSE_TABL" +
      "E_REGIONS_SCHEDULE\020\001\022\037\n\033CLOSE_TABLE_REGI" +
      "ONS_CONFIRM\020\002BR\n1org.apache.hadoop.hbase" +
      ".shaded.protobuf.generatedB\025MasterProced" +
      "ureProtosH\001\210\001\001\240\001\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.getDescriptor(),
        });
    internal_static_hbase_pb_CreateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_ModifyTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "UnmodifiedTableSchema", "ModifiedTableSchema", "DeleteColumnFamilyInModify", "ShouldCheckDescriptor", "ReopenRegions", });
    internal_static_hbase_pb_TruncateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TruncateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "PreserveSplits", "TableName", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_DeleteTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", });
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", });
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", "UnmodifiedNamespaceDescriptor", });
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceName", "NamespaceDescriptor", });
    internal_static_hbase_pb_EnableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_EnableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_DisableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DisableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_RestoreParentToChildRegionsPair_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RestoreParentToChildRegionsPair_descriptor,
        new java.lang.String[] { "ParentRegionName", "Child1RegionName", "Child2RegionName", });
    internal_static_hbase_pb_CloneSnapshotStateData_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_CloneSnapshotStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloneSnapshotStateData_descriptor,
        new java.lang.String[] { "UserInfo", "Snapshot", "TableSchema", "RegionInfo", "ParentToChildRegionsPairList", "RestoreAcl", "CustomSFT", });
    internal_static_hbase_pb_RestoreSnapshotStateData_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_RestoreSnapshotStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RestoreSnapshotStateData_descriptor,
        new java.lang.String[] { "UserInfo", "Snapshot", "ModifiedTableSchema", "RegionInfoForRestore", "RegionInfoForRemove", "RegionInfoForAdd", "ParentToChildRegionsPairList", "RestoreAcl", });
    internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_DispatchMergingRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DispatchMergingRegionsStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", "Forcible", });
    internal_static_hbase_pb_SplitTableRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hbase_pb_SplitTableRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitTableRegionStateData_descriptor,
        new java.lang.String[] { "UserInfo", "ParentRegionInfo", "ChildRegionInfo", });
    internal_static_hbase_pb_MergeTableRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hbase_pb_MergeTableRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MergeTableRegionsStateData_descriptor,
        new java.lang.String[] { "UserInfo", "RegionInfo", "MergedRegionInfo", "Forcible", });
    internal_static_hbase_pb_ServerCrashStateData_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ServerCrashStateData_descriptor,
        new java.lang.String[] { "ServerName", "RegionsOnCrashedServer", "RegionsAssigned", "CarryingMeta", "ShouldSplitWal", });
    internal_static_hbase_pb_RecoverMetaStateData_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hbase_pb_RecoverMetaStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RecoverMetaStateData_descriptor,
        new java.lang.String[] { "FailedMetaServer", "ShouldSplitWal", "ReplicaId", });
    internal_static_hbase_pb_AssignRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hbase_pb_AssignRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_AssignRegionStateData_descriptor,
        new java.lang.String[] { "TransitionState", "RegionInfo", "ForceNewPlan", "TargetServer", "Attempt", });
    internal_static_hbase_pb_UnassignRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hbase_pb_UnassignRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UnassignRegionStateData_descriptor,
        new java.lang.String[] { "TransitionState", "RegionInfo", "DestinationServer", "HostingServer", "Force", "RemoveAfterUnassigning", "Attempt", });
    internal_static_hbase_pb_MoveRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hbase_pb_MoveRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MoveRegionStateData_descriptor,
        new java.lang.String[] { "RegionInfo", "SourceServer", "DestinationServer", });
    internal_static_hbase_pb_GCRegionStateData_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hbase_pb_GCRegionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCRegionStateData_descriptor,
        new java.lang.String[] { "RegionInfo", });
    internal_static_hbase_pb_GCMergedRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hbase_pb_GCMergedRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCMergedRegionsStateData_descriptor,
        new java.lang.String[] { "ParentA", "ParentB", "MergedChild", });
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hbase_pb_GCMultipleMergedRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GCMultipleMergedRegionsStateData_descriptor,
        new java.lang.String[] { "Parents", "MergedChild", });
    internal_static_hbase_pb_PeerModificationStateData_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hbase_pb_PeerModificationStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PeerModificationStateData_descriptor,
        new java.lang.String[] { "PeerId", });
    internal_static_hbase_pb_RefreshPeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hbase_pb_RefreshPeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RefreshPeerStateData_descriptor,
        new java.lang.String[] { "PeerId", "Type", "TargetServer", "State", "Error", });
    internal_static_hbase_pb_RefreshPeerParameter_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hbase_pb_RefreshPeerParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RefreshPeerParameter_descriptor,
        new java.lang.String[] { "PeerId", "Type", "TargetServer", });
    internal_static_hbase_pb_PeerProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hbase_pb_PeerProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PeerProcedureStateData_descriptor,
        new java.lang.String[] { "PeerId", });
    internal_static_hbase_pb_AddPeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hbase_pb_AddPeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_AddPeerStateData_descriptor,
        new java.lang.String[] { "PeerConfig", "Enabled", });
    internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hbase_pb_UpdatePeerConfigStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdatePeerConfigStateData_descriptor,
        new java.lang.String[] { "PeerConfig", "OldPeerConfig", "Enabled", });
    internal_static_hbase_pb_RemovePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hbase_pb_RemovePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RemovePeerStateData_descriptor,
        new java.lang.String[] { "PeerConfig", });
    internal_static_hbase_pb_EnablePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hbase_pb_EnablePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_EnablePeerStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_DisablePeerStateData_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hbase_pb_DisablePeerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DisablePeerStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hbase_pb_ReopenTableRegionsStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ReopenTableRegionsStateData_descriptor,
        new java.lang.String[] { "TableName", "Region", "RegionNames", });
    internal_static_hbase_pb_InitMetaStateData_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hbase_pb_InitMetaStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_InitMetaStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_RegionStateTransitionStateData_descriptor =
      getDescriptor().getMessageTypes().get(34);
    internal_static_hbase_pb_RegionStateTransitionStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionStateTransitionStateData_descriptor,
        new java.lang.String[] { "Type", "AssignCandidate", "ForceNewPlan", });
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor =
      getDescriptor().getMessageTypes().get(35);
    internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionRemoteProcedureBaseStateData_descriptor,
        new java.lang.String[] { "Region", "TargetServer", "State", "TransitionCode", "SeqId", });
    internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(36);
    internal_static_hbase_pb_OpenRegionProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_OpenRegionProcedureStateData_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(37);
    internal_static_hbase_pb_CloseRegionProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseRegionProcedureStateData_descriptor,
        new java.lang.String[] { "AssignCandidate", });
    internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor =
      getDescriptor().getMessageTypes().get(38);
    internal_static_hbase_pb_SwitchRpcThrottleStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SwitchRpcThrottleStateData_descriptor,
        new java.lang.String[] { "RpcThrottleEnabled", });
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor =
      getDescriptor().getMessageTypes().get(39);
    internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SwitchRpcThrottleRemoteStateData_descriptor,
        new java.lang.String[] { "TargetServer", "RpcThrottleEnabled", "State", "Error", });
    internal_static_hbase_pb_SplitWALParameter_descriptor =
      getDescriptor().getMessageTypes().get(40);
    internal_static_hbase_pb_SplitWALParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALParameter_descriptor,
        new java.lang.String[] { "WalPath", });
    internal_static_hbase_pb_SplitWALData_descriptor =
      getDescriptor().getMessageTypes().get(41);
    internal_static_hbase_pb_SplitWALData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALData_descriptor,
        new java.lang.String[] { "WalPath", "CrashedServer", "Worker", });
    internal_static_hbase_pb_SplitWALRemoteData_descriptor =
      getDescriptor().getMessageTypes().get(42);
    internal_static_hbase_pb_SplitWALRemoteData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SplitWALRemoteData_descriptor,
        new java.lang.String[] { "WalPath", "CrashedServer", "Worker", "State", "Error", });
    internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor =
      getDescriptor().getMessageTypes().get(43);
    internal_static_hbase_pb_ClaimReplicationQueuesStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClaimReplicationQueuesStateData_descriptor,
        new java.lang.String[] { "CrashedServer", });
    internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor =
      getDescriptor().getMessageTypes().get(44);
    internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClaimReplicationQueueRemoteStateData_descriptor,
        new java.lang.String[] { "CrashedServer", "Queue", "TargetServer", "State", "Error", });
    internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor =
      getDescriptor().getMessageTypes().get(45);
    internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClaimReplicationQueueRemoteParameter_descriptor,
        new java.lang.String[] { "CrashedServer", "Queue", });
    internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor =
      getDescriptor().getMessageTypes().get(46);
    internal_static_hbase_pb_ModifyTableDescriptorStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyTableDescriptorStateData_descriptor,
        new java.lang.String[] { "TableName", "ModifiedTableSchema", });
    internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor =
      getDescriptor().getMessageTypes().get(47);
    internal_static_hbase_pb_ModifyStoreFileTrackerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyStoreFileTrackerStateData_descriptor,
        new java.lang.String[] { "TableName", "DstSft", });
    internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor =
      getDescriptor().getMessageTypes().get(48);
    internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyColumnFamilyStoreFileTrackerStateData_descriptor,
        new java.lang.String[] { "Family", });
    internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(49);
    internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseExcessRegionReplicasProcedureStateData_descriptor,
        new java.lang.String[] { "TableName", "NewReplicaCount", });
    internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor =
      getDescriptor().getMessageTypes().get(50);
    internal_static_hbase_pb_CloseTableRegionsProcedureStateData_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseTableRegionsProcedureStateData_descriptor,
        new java.lang.String[] { "TableName", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.ReplicationProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.RegionServerStatusProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.ErrorHandlingProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
