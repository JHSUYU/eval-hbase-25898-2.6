// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Client.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class ClientProtos {
  private ClientProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * <pre>
   **
   * Consistency defines the expected consistency level for an operation.
   * </pre>
   *
   * Protobuf enum {@code hbase.pb.Consistency}
   */
  public enum Consistency
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>STRONG = 0;</code>
     */
    STRONG(0),
    /**
     * <code>TIMELINE = 1;</code>
     */
    TIMELINE(1),
    ;

    /**
     * <code>STRONG = 0;</code>
     */
    public static final int STRONG_VALUE = 0;
    /**
     * <code>TIMELINE = 1;</code>
     */
    public static final int TIMELINE_VALUE = 1;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Consistency valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static Consistency forNumber(int value) {
      switch (value) {
        case 0: return STRONG;
        case 1: return TIMELINE;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Consistency>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        Consistency> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Consistency>() {
            public Consistency findValueByNumber(int number) {
              return Consistency.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final Consistency[] VALUES = values();

    public static Consistency valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Consistency(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.Consistency)
  }

  public interface AuthorizationsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Authorizations)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string label = 1;</code>
     * @return A list containing the label.
     */
    java.util.List<java.lang.String>
        getLabelList();
    /**
     * <code>repeated string label = 1;</code>
     * @return The count of label.
     */
    int getLabelCount();
    /**
     * <code>repeated string label = 1;</code>
     * @param index The index of the element to return.
     * @return The label at the given index.
     */
    java.lang.String getLabel(int index);
    /**
     * <code>repeated string label = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the label at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getLabelBytes(int index);
  }
  /**
   * <pre>
   **
   * The protocol buffer version of Authorizations.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Authorizations}
   */
  @javax.annotation.Generated("proto") public static final class Authorizations extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Authorizations)
      AuthorizationsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Authorizations.newBuilder() to construct.
    private Authorizations(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Authorizations() {
      label_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Authorizations();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Authorizations_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Authorizations_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.Builder.class);
    }

    public static final int LABEL_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList label_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string label = 1;</code>
     * @return A list containing the label.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getLabelList() {
      return label_;
    }
    /**
     * <code>repeated string label = 1;</code>
     * @return The count of label.
     */
    public int getLabelCount() {
      return label_.size();
    }
    /**
     * <code>repeated string label = 1;</code>
     * @param index The index of the element to return.
     * @return The label at the given index.
     */
    public java.lang.String getLabel(int index) {
      return label_.get(index);
    }
    /**
     * <code>repeated string label = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the label at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getLabelBytes(int index) {
      return label_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < label_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, label_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < label_.size(); i++) {
          dataSize += computeStringSizeNoTag(label_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getLabelList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations) obj;

      if (!getLabelList()
          .equals(other.getLabelList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getLabelCount() > 0) {
        hash = (37 * hash) + LABEL_FIELD_NUMBER;
        hash = (53 * hash) + getLabelList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The protocol buffer version of Authorizations.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Authorizations}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Authorizations)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.AuthorizationsOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Authorizations_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Authorizations_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        label_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Authorizations_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          label_.makeImmutable();
          result.label_ = label_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations.getDefaultInstance()) return this;
        if (!other.label_.isEmpty()) {
          if (label_.isEmpty()) {
            label_ = other.label_;
            bitField0_ |= 0x00000001;
          } else {
            ensureLabelIsMutable();
            label_.addAll(other.label_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureLabelIsMutable();
                label_.add(bs);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList label_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureLabelIsMutable() {
        if (!label_.isModifiable()) {
          label_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(label_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @return A list containing the label.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getLabelList() {
        label_.makeImmutable();
        return label_;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @return The count of label.
       */
      public int getLabelCount() {
        return label_.size();
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param index The index of the element to return.
       * @return The label at the given index.
       */
      public java.lang.String getLabel(int index) {
        return label_.get(index);
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the label at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getLabelBytes(int index) {
        return label_.getByteString(index);
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param index The index to set the value at.
       * @param value The label to set.
       * @return This builder for chaining.
       */
      public Builder setLabel(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureLabelIsMutable();
        label_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param value The label to add.
       * @return This builder for chaining.
       */
      public Builder addLabel(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureLabelIsMutable();
        label_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param values The label to add.
       * @return This builder for chaining.
       */
      public Builder addAllLabel(
          java.lang.Iterable<java.lang.String> values) {
        ensureLabelIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, label_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLabel() {
        label_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string label = 1;</code>
       * @param value The bytes of the label to add.
       * @return This builder for chaining.
       */
      public Builder addLabelBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureLabelIsMutable();
        label_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Authorizations)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Authorizations)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Authorizations>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Authorizations>() {
      @java.lang.Override
      public Authorizations parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Authorizations> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Authorizations> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Authorizations getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CellVisibilityOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CellVisibility)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string expression = 1;</code>
     * @return Whether the expression field is set.
     */
    boolean hasExpression();
    /**
     * <code>required string expression = 1;</code>
     * @return The expression.
     */
    java.lang.String getExpression();
    /**
     * <code>required string expression = 1;</code>
     * @return The bytes for expression.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getExpressionBytes();
  }
  /**
   * <pre>
   **
   * The protocol buffer version of CellVisibility.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.CellVisibility}
   */
  @javax.annotation.Generated("proto") public static final class CellVisibility extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CellVisibility)
      CellVisibilityOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CellVisibility.newBuilder() to construct.
    private CellVisibility(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CellVisibility() {
      expression_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CellVisibility();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CellVisibility_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CellVisibility_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.Builder.class);
    }

    private int bitField0_;
    public static final int EXPRESSION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object expression_ = "";
    /**
     * <code>required string expression = 1;</code>
     * @return Whether the expression field is set.
     */
    @java.lang.Override
    public boolean hasExpression() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string expression = 1;</code>
     * @return The expression.
     */
    @java.lang.Override
    public java.lang.String getExpression() {
      java.lang.Object ref = expression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          expression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string expression = 1;</code>
     * @return The bytes for expression.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getExpressionBytes() {
      java.lang.Object ref = expression_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        expression_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasExpression()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, expression_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, expression_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility) obj;

      if (hasExpression() != other.hasExpression()) return false;
      if (hasExpression()) {
        if (!getExpression()
            .equals(other.getExpression())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasExpression()) {
        hash = (37 * hash) + EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getExpression().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The protocol buffer version of CellVisibility.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.CellVisibility}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CellVisibility)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibilityOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CellVisibility_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CellVisibility_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        expression_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CellVisibility_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.expression_ = expression_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility.getDefaultInstance()) return this;
        if (other.hasExpression()) {
          expression_ = other.expression_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasExpression()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                expression_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object expression_ = "";
      /**
       * <code>required string expression = 1;</code>
       * @return Whether the expression field is set.
       */
      public boolean hasExpression() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string expression = 1;</code>
       * @return The expression.
       */
      public java.lang.String getExpression() {
        java.lang.Object ref = expression_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            expression_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string expression = 1;</code>
       * @return The bytes for expression.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getExpressionBytes() {
        java.lang.Object ref = expression_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          expression_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string expression = 1;</code>
       * @param value The expression to set.
       * @return This builder for chaining.
       */
      public Builder setExpression(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        expression_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string expression = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearExpression() {
        expression_ = getDefaultInstance().getExpression();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string expression = 1;</code>
       * @param value The bytes for expression to set.
       * @return This builder for chaining.
       */
      public Builder setExpressionBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        expression_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CellVisibility)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CellVisibility)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CellVisibility>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CellVisibility>() {
      @java.lang.Override
      public CellVisibility parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CellVisibility> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CellVisibility> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CellVisibility getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Column)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @return A list containing the qualifier.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getQualifierList();
    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @return The count of qualifier.
     */
    int getQualifierCount();
    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @param index The index of the element to return.
     * @return The qualifier at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier(int index);
  }
  /**
   * <pre>
   **
   * Container for a list of column qualifier names of a family.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Column}
   */
  @javax.annotation.Generated("proto") public static final class Column extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Column)
      ColumnOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Column.newBuilder() to construct.
    private Column(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Column() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      qualifier_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Column();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Column_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Column_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder.class);
    }

    private int bitField0_;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    public static final int QUALIFIER_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> qualifier_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @return A list containing the qualifier.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getQualifierList() {
      return qualifier_;
    }
    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @return The count of qualifier.
     */
    public int getQualifierCount() {
      return qualifier_.size();
    }
    /**
     * <code>repeated bytes qualifier = 2;</code>
     * @param index The index of the element to return.
     * @return The qualifier at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier(int index) {
      return qualifier_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, family_);
      }
      for (int i = 0; i < qualifier_.size(); i++) {
        output.writeBytes(2, qualifier_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < qualifier_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(qualifier_.get(i));
        }
        size += dataSize;
        size += 1 * getQualifierList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column) obj;

      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (!getQualifierList()
          .equals(other.getQualifierList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (getQualifierCount() > 0) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifierList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Container for a list of column qualifier names of a family.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Column}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Column)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Column_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Column_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        qualifier_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Column_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          qualifier_.makeImmutable();
          result.qualifier_ = qualifier_;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (!other.qualifier_.isEmpty()) {
          if (qualifier_.isEmpty()) {
            qualifier_ = other.qualifier_;
            qualifier_.makeImmutable();
            bitField0_ |= 0x00000002;
          } else {
            ensureQualifierIsMutable();
            qualifier_.addAll(other.qualifier_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFamily()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureQualifierIsMutable();
                qualifier_.add(v);
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> qualifier_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureQualifierIsMutable() {
        if (!qualifier_.isModifiable()) {
          qualifier_ = makeMutableCopy(qualifier_);
        }
        bitField0_ |= 0x00000002;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @return A list containing the qualifier.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getQualifierList() {
        qualifier_.makeImmutable();
        return qualifier_;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @return The count of qualifier.
       */
      public int getQualifierCount() {
        return qualifier_.size();
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @param index The index of the element to return.
       * @return The qualifier at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier(int index) {
        return qualifier_.get(index);
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @param index The index to set the value at.
       * @param value The qualifier to set.
       * @return This builder for chaining.
       */
      public Builder setQualifier(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQualifierIsMutable();
        qualifier_.set(index, value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @param value The qualifier to add.
       * @return This builder for chaining.
       */
      public Builder addQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQualifierIsMutable();
        qualifier_.add(value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @param values The qualifier to add.
       * @return This builder for chaining.
       */
      public Builder addAllQualifier(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureQualifierIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, qualifier_);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearQualifier() {
        qualifier_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Column)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Column)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Column>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Column>() {
      @java.lang.Override
      public Column parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Column> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Column> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Get)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow();

    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index);
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    int getColumnCount();
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();

    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     * @return Whether the timeRange field is set.
     */
    boolean hasTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     * @return The timeRange.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     * @return Whether the maxVersions field is set.
     */
    boolean hasMaxVersions();
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     * @return The maxVersions.
     */
    int getMaxVersions();

    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     * @return Whether the cacheBlocks field is set.
     */
    boolean hasCacheBlocks();
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     * @return The cacheBlocks.
     */
    boolean getCacheBlocks();

    /**
     * <code>optional uint32 store_limit = 8;</code>
     * @return Whether the storeLimit field is set.
     */
    boolean hasStoreLimit();
    /**
     * <code>optional uint32 store_limit = 8;</code>
     * @return The storeLimit.
     */
    int getStoreLimit();

    /**
     * <code>optional uint32 store_offset = 9;</code>
     * @return Whether the storeOffset field is set.
     */
    boolean hasStoreOffset();
    /**
     * <code>optional uint32 store_offset = 9;</code>
     * @return The storeOffset.
     */
    int getStoreOffset();

    /**
     * <pre>
     * The result isn't asked for, just check for
     * the existence.
     * </pre>
     *
     * <code>optional bool existence_only = 10 [default = false];</code>
     * @return Whether the existenceOnly field is set.
     */
    boolean hasExistenceOnly();
    /**
     * <pre>
     * The result isn't asked for, just check for
     * the existence.
     * </pre>
     *
     * <code>optional bool existence_only = 10 [default = false];</code>
     * @return The existenceOnly.
     */
    boolean getExistenceOnly();

    /**
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before. Deprecated. No longer used!
     * Since hbase-2.0.0 but left in place so can test
     * for Gets with this set and throw Exception.
     * </pre>
     *
     * <code>optional bool closest_row_before = 11 [default = false];</code>
     * @return Whether the closestRowBefore field is set.
     */
    boolean hasClosestRowBefore();
    /**
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before. Deprecated. No longer used!
     * Since hbase-2.0.0 but left in place so can test
     * for Gets with this set and throw Exception.
     * </pre>
     *
     * <code>optional bool closest_row_before = 11 [default = false];</code>
     * @return The closestRowBefore.
     */
    boolean getClosestRowBefore();

    /**
     * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
     * @return Whether the consistency field is set.
     */
    boolean hasConsistency();
    /**
     * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
     * @return The consistency.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency();

    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> 
        getCfTimeRangeList();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index);
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    int getCfTimeRangeCount();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
        getCfTimeRangeOrBuilderList();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
        int index);

    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 14;</code>
     * @return Whether the loadColumnFamiliesOnDemand field is set.
     */
    boolean hasLoadColumnFamiliesOnDemand();
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 14;</code>
     * @return The loadColumnFamiliesOnDemand.
     */
    boolean getLoadColumnFamiliesOnDemand();
  }
  /**
   * <pre>
   **
   * The protocol buffer version of Get.
   * Unless existence_only is specified, return all the requested data
   * for the row that matches exactly.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Get}
   */
  @javax.annotation.Generated("proto") public static final class Get extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Get)
      GetOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Get.newBuilder() to construct.
    private Get(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Get() {
      row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      maxVersions_ = 1;
      cacheBlocks_ = true;
      consistency_ = 0;
      cfTimeRange_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Get();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Get_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Get_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder.class);
    }

    private int bitField0_;
    public static final int ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    @java.lang.Override
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
      return row_;
    }

    public static final int COLUMN_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> column_;
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    @java.lang.Override
    public int getColumnCount() {
      return column_.size();
    }
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Column column = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }

    public static final int ATTRIBUTE_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    @java.lang.Override
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    public static final int FILTER_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    public static final int TIME_RANGE_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     * @return Whether the timeRange field is set.
     */
    @java.lang.Override
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     * @return The timeRange.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }

    public static final int MAX_VERSIONS_FIELD_NUMBER = 6;
    private int maxVersions_ = 1;
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     * @return Whether the maxVersions field is set.
     */
    @java.lang.Override
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     * @return The maxVersions.
     */
    @java.lang.Override
    public int getMaxVersions() {
      return maxVersions_;
    }

    public static final int CACHE_BLOCKS_FIELD_NUMBER = 7;
    private boolean cacheBlocks_ = true;
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     * @return Whether the cacheBlocks field is set.
     */
    @java.lang.Override
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     * @return The cacheBlocks.
     */
    @java.lang.Override
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }

    public static final int STORE_LIMIT_FIELD_NUMBER = 8;
    private int storeLimit_ = 0;
    /**
     * <code>optional uint32 store_limit = 8;</code>
     * @return Whether the storeLimit field is set.
     */
    @java.lang.Override
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional uint32 store_limit = 8;</code>
     * @return The storeLimit.
     */
    @java.lang.Override
    public int getStoreLimit() {
      return storeLimit_;
    }

    public static final int STORE_OFFSET_FIELD_NUMBER = 9;
    private int storeOffset_ = 0;
    /**
     * <code>optional uint32 store_offset = 9;</code>
     * @return Whether the storeOffset field is set.
     */
    @java.lang.Override
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional uint32 store_offset = 9;</code>
     * @return The storeOffset.
     */
    @java.lang.Override
    public int getStoreOffset() {
      return storeOffset_;
    }

    public static final int EXISTENCE_ONLY_FIELD_NUMBER = 10;
    private boolean existenceOnly_ = false;
    /**
     * <pre>
     * The result isn't asked for, just check for
     * the existence.
     * </pre>
     *
     * <code>optional bool existence_only = 10 [default = false];</code>
     * @return Whether the existenceOnly field is set.
     */
    @java.lang.Override
    public boolean hasExistenceOnly() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <pre>
     * The result isn't asked for, just check for
     * the existence.
     * </pre>
     *
     * <code>optional bool existence_only = 10 [default = false];</code>
     * @return The existenceOnly.
     */
    @java.lang.Override
    public boolean getExistenceOnly() {
      return existenceOnly_;
    }

    public static final int CLOSEST_ROW_BEFORE_FIELD_NUMBER = 11;
    private boolean closestRowBefore_ = false;
    /**
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before. Deprecated. No longer used!
     * Since hbase-2.0.0 but left in place so can test
     * for Gets with this set and throw Exception.
     * </pre>
     *
     * <code>optional bool closest_row_before = 11 [default = false];</code>
     * @return Whether the closestRowBefore field is set.
     */
    @java.lang.Override
    public boolean hasClosestRowBefore() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before. Deprecated. No longer used!
     * Since hbase-2.0.0 but left in place so can test
     * for Gets with this set and throw Exception.
     * </pre>
     *
     * <code>optional bool closest_row_before = 11 [default = false];</code>
     * @return The closestRowBefore.
     */
    @java.lang.Override
    public boolean getClosestRowBefore() {
      return closestRowBefore_;
    }

    public static final int CONSISTENCY_FIELD_NUMBER = 12;
    private int consistency_ = 0;
    /**
     * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
     * @return Whether the consistency field is set.
     */
    @java.lang.Override public boolean hasConsistency() {
      return ((bitField0_ & 0x00000200) != 0);
    }
    /**
     * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
     * @return The consistency.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(consistency_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.STRONG : result;
    }

    public static final int CF_TIME_RANGE_FIELD_NUMBER = 13;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> cfTimeRange_;
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> getCfTimeRangeList() {
      return cfTimeRange_;
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
        getCfTimeRangeOrBuilderList() {
      return cfTimeRange_;
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    @java.lang.Override
    public int getCfTimeRangeCount() {
      return cfTimeRange_.size();
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index) {
      return cfTimeRange_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
        int index) {
      return cfTimeRange_.get(index);
    }

    public static final int LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER = 14;
    private boolean loadColumnFamiliesOnDemand_ = false;
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 14;</code>
     * @return Whether the loadColumnFamiliesOnDemand field is set.
     */
    @java.lang.Override
    public boolean hasLoadColumnFamiliesOnDemand() {
      return ((bitField0_ & 0x00000400) != 0);
    }
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 14;</code>
     * @return The loadColumnFamiliesOnDemand.
     */
    @java.lang.Override
    public boolean getLoadColumnFamiliesOnDemand() {
      return loadColumnFamiliesOnDemand_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getCfTimeRangeCount(); i++) {
        if (!getCfTimeRange(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(4, getFilter());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(5, getTimeRange());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt32(6, maxVersions_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(7, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeUInt32(8, storeLimit_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeUInt32(9, storeOffset_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeBool(10, existenceOnly_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeBool(11, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        output.writeEnum(12, consistency_);
      }
      for (int i = 0; i < cfTimeRange_.size(); i++) {
        output.writeMessage(13, cfTimeRange_.get(i));
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        output.writeBool(14, loadColumnFamiliesOnDemand_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getFilter());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getTimeRange());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(6, maxVersions_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(8, storeLimit_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, storeOffset_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(10, existenceOnly_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(12, consistency_);
      }
      for (int i = 0; i < cfTimeRange_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, cfTimeRange_.get(i));
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(14, loadColumnFamiliesOnDemand_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get) obj;

      if (hasRow() != other.hasRow()) return false;
      if (hasRow()) {
        if (!getRow()
            .equals(other.getRow())) return false;
      }
      if (!getColumnList()
          .equals(other.getColumnList())) return false;
      if (!getAttributeList()
          .equals(other.getAttributeList())) return false;
      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (hasTimeRange() != other.hasTimeRange()) return false;
      if (hasTimeRange()) {
        if (!getTimeRange()
            .equals(other.getTimeRange())) return false;
      }
      if (hasMaxVersions() != other.hasMaxVersions()) return false;
      if (hasMaxVersions()) {
        if (getMaxVersions()
            != other.getMaxVersions()) return false;
      }
      if (hasCacheBlocks() != other.hasCacheBlocks()) return false;
      if (hasCacheBlocks()) {
        if (getCacheBlocks()
            != other.getCacheBlocks()) return false;
      }
      if (hasStoreLimit() != other.hasStoreLimit()) return false;
      if (hasStoreLimit()) {
        if (getStoreLimit()
            != other.getStoreLimit()) return false;
      }
      if (hasStoreOffset() != other.hasStoreOffset()) return false;
      if (hasStoreOffset()) {
        if (getStoreOffset()
            != other.getStoreOffset()) return false;
      }
      if (hasExistenceOnly() != other.hasExistenceOnly()) return false;
      if (hasExistenceOnly()) {
        if (getExistenceOnly()
            != other.getExistenceOnly()) return false;
      }
      if (hasClosestRowBefore() != other.hasClosestRowBefore()) return false;
      if (hasClosestRowBefore()) {
        if (getClosestRowBefore()
            != other.getClosestRowBefore()) return false;
      }
      if (hasConsistency() != other.hasConsistency()) return false;
      if (hasConsistency()) {
        if (consistency_ != other.consistency_) return false;
      }
      if (!getCfTimeRangeList()
          .equals(other.getCfTimeRangeList())) return false;
      if (hasLoadColumnFamiliesOnDemand() != other.hasLoadColumnFamiliesOnDemand()) return false;
      if (hasLoadColumnFamiliesOnDemand()) {
        if (getLoadColumnFamiliesOnDemand()
            != other.getLoadColumnFamiliesOnDemand()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAX_VERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHE_BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCacheBlocks());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STORE_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      if (hasExistenceOnly()) {
        hash = (37 * hash) + EXISTENCE_ONLY_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getExistenceOnly());
      }
      if (hasClosestRowBefore()) {
        hash = (37 * hash) + CLOSEST_ROW_BEFORE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getClosestRowBefore());
      }
      if (hasConsistency()) {
        hash = (37 * hash) + CONSISTENCY_FIELD_NUMBER;
        hash = (53 * hash) + consistency_;
      }
      if (getCfTimeRangeCount() > 0) {
        hash = (37 * hash) + CF_TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getCfTimeRangeList().hashCode();
      }
      if (hasLoadColumnFamiliesOnDemand()) {
        hash = (37 * hash) + LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getLoadColumnFamiliesOnDemand());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The protocol buffer version of Get.
     * Unless existence_only is specified, return all the requested data
     * for the row that matches exactly.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Get}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Get)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Get_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Get_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
          getCfTimeRangeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
        } else {
          column_ = null;
          columnBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
        } else {
          attribute_ = null;
          attributeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        maxVersions_ = 1;
        cacheBlocks_ = true;
        storeLimit_ = 0;
        storeOffset_ = 0;
        existenceOnly_ = false;
        closestRowBefore_ = false;
        consistency_ = 0;
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRange_ = java.util.Collections.emptyList();
        } else {
          cfTimeRange_ = null;
          cfTimeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00001000);
        loadColumnFamiliesOnDemand_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Get_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get result) {
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (cfTimeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00001000) != 0)) {
            cfTimeRange_ = java.util.Collections.unmodifiableList(cfTimeRange_);
            bitField0_ = (bitField0_ & ~0x00001000);
          }
          result.cfTimeRange_ = cfTimeRange_;
        } else {
          result.cfTimeRange_ = cfTimeRangeBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.row_ = row_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.timeRange_ = timeRangeBuilder_ == null
              ? timeRange_
              : timeRangeBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.maxVersions_ = maxVersions_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.cacheBlocks_ = cacheBlocks_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.storeLimit_ = storeLimit_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.storeOffset_ = storeOffset_;
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.existenceOnly_ = existenceOnly_;
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.closestRowBefore_ = closestRowBefore_;
          to_bitField0_ |= 0x00000100;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          result.consistency_ = consistency_;
          to_bitField0_ |= 0x00000200;
        }
        if (((from_bitField0_ & 0x00002000) != 0)) {
          result.loadColumnFamiliesOnDemand_ = loadColumnFamiliesOnDemand_;
          to_bitField0_ |= 0x00000400;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
              columnBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
              attributeBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        if (other.hasExistenceOnly()) {
          setExistenceOnly(other.getExistenceOnly());
        }
        if (other.hasClosestRowBefore()) {
          setClosestRowBefore(other.getClosestRowBefore());
        }
        if (other.hasConsistency()) {
          setConsistency(other.getConsistency());
        }
        if (cfTimeRangeBuilder_ == null) {
          if (!other.cfTimeRange_.isEmpty()) {
            if (cfTimeRange_.isEmpty()) {
              cfTimeRange_ = other.cfTimeRange_;
              bitField0_ = (bitField0_ & ~0x00001000);
            } else {
              ensureCfTimeRangeIsMutable();
              cfTimeRange_.addAll(other.cfTimeRange_);
            }
            onChanged();
          }
        } else {
          if (!other.cfTimeRange_.isEmpty()) {
            if (cfTimeRangeBuilder_.isEmpty()) {
              cfTimeRangeBuilder_.dispose();
              cfTimeRangeBuilder_ = null;
              cfTimeRange_ = other.cfTimeRange_;
              bitField0_ = (bitField0_ & ~0x00001000);
              cfTimeRangeBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getCfTimeRangeFieldBuilder() : null;
            } else {
              cfTimeRangeBuilder_.addAllMessages(other.cfTimeRange_);
            }
          }
        }
        if (other.hasLoadColumnFamiliesOnDemand()) {
          setLoadColumnFamiliesOnDemand(other.getLoadColumnFamiliesOnDemand());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRow()) {
          return false;
        }
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getCfTimeRangeCount(); i++) {
          if (!getCfTimeRange(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                row_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.PARSER,
                        extensionRegistry);
                if (columnBuilder_ == null) {
                  ensureColumnIsMutable();
                  column_.add(m);
                } else {
                  columnBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.PARSER,
                        extensionRegistry);
                if (attributeBuilder_ == null) {
                  ensureAttributeIsMutable();
                  attribute_.add(m);
                } else {
                  attributeBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 34: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                input.readMessage(
                    getTimeRangeFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 48: {
                maxVersions_ = input.readUInt32();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 56: {
                cacheBlocks_ = input.readBool();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              case 64: {
                storeLimit_ = input.readUInt32();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 72: {
                storeOffset_ = input.readUInt32();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              case 80: {
                existenceOnly_ = input.readBool();
                bitField0_ |= 0x00000200;
                break;
              } // case 80
              case 88: {
                closestRowBefore_ = input.readBool();
                bitField0_ |= 0x00000400;
                break;
              } // case 88
              case 96: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(12, tmpRaw);
                } else {
                  consistency_ = tmpRaw;
                  bitField0_ |= 0x00000800;
                }
                break;
              } // case 96
              case 106: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.PARSER,
                        extensionRegistry);
                if (cfTimeRangeBuilder_ == null) {
                  ensureCfTimeRangeIsMutable();
                  cfTimeRange_.add(m);
                } else {
                  cfTimeRangeBuilder_.addMessage(m);
                }
                break;
              } // case 106
              case 112: {
                loadColumnFamiliesOnDemand_ = input.readBool();
                bitField0_ |= 0x00002000;
                break;
              } // case 112
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       * @return Whether the row field is set.
       */
      @java.lang.Override
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return The row.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @param value The row to set.
       * @return This builder for chaining.
       */
      public Builder setRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        row_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;

      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder addColumn(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder addColumn(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Column column = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000008);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       * @return Whether the timeRange field is set.
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       * @return The timeRange.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            timeRange_ != null &&
            timeRange_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            getTimeRangeBuilder().mergeFrom(value);
          } else {
            timeRange_ = value;
          }
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        if (timeRange_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public Builder clearTimeRange() {
        bitField0_ = (bitField0_ & ~0x00000010);
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  getTimeRange(),
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      private int maxVersions_ = 1;
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       * @return Whether the maxVersions field is set.
       */
      @java.lang.Override
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       * @return The maxVersions.
       */
      @java.lang.Override
      public int getMaxVersions() {
        return maxVersions_;
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       * @param value The maxVersions to set.
       * @return This builder for chaining.
       */
      public Builder setMaxVersions(int value) {

        maxVersions_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000020);
        maxVersions_ = 1;
        onChanged();
        return this;
      }

      private boolean cacheBlocks_ = true;
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       * @return Whether the cacheBlocks field is set.
       */
      @java.lang.Override
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       * @return The cacheBlocks.
       */
      @java.lang.Override
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       * @param value The cacheBlocks to set.
       * @return This builder for chaining.
       */
      public Builder setCacheBlocks(boolean value) {

        cacheBlocks_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000040);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }

      private int storeLimit_ ;
      /**
       * <code>optional uint32 store_limit = 8;</code>
       * @return Whether the storeLimit field is set.
       */
      @java.lang.Override
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       * @return The storeLimit.
       */
      @java.lang.Override
      public int getStoreLimit() {
        return storeLimit_;
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       * @param value The storeLimit to set.
       * @return This builder for chaining.
       */
      public Builder setStoreLimit(int value) {

        storeLimit_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000080);
        storeLimit_ = 0;
        onChanged();
        return this;
      }

      private int storeOffset_ ;
      /**
       * <code>optional uint32 store_offset = 9;</code>
       * @return Whether the storeOffset field is set.
       */
      @java.lang.Override
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       * @return The storeOffset.
       */
      @java.lang.Override
      public int getStoreOffset() {
        return storeOffset_;
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       * @param value The storeOffset to set.
       * @return This builder for chaining.
       */
      public Builder setStoreOffset(int value) {

        storeOffset_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000100);
        storeOffset_ = 0;
        onChanged();
        return this;
      }

      private boolean existenceOnly_ ;
      /**
       * <pre>
       * The result isn't asked for, just check for
       * the existence.
       * </pre>
       *
       * <code>optional bool existence_only = 10 [default = false];</code>
       * @return Whether the existenceOnly field is set.
       */
      @java.lang.Override
      public boolean hasExistenceOnly() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <pre>
       * The result isn't asked for, just check for
       * the existence.
       * </pre>
       *
       * <code>optional bool existence_only = 10 [default = false];</code>
       * @return The existenceOnly.
       */
      @java.lang.Override
      public boolean getExistenceOnly() {
        return existenceOnly_;
      }
      /**
       * <pre>
       * The result isn't asked for, just check for
       * the existence.
       * </pre>
       *
       * <code>optional bool existence_only = 10 [default = false];</code>
       * @param value The existenceOnly to set.
       * @return This builder for chaining.
       */
      public Builder setExistenceOnly(boolean value) {

        existenceOnly_ = value;
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The result isn't asked for, just check for
       * the existence.
       * </pre>
       *
       * <code>optional bool existence_only = 10 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearExistenceOnly() {
        bitField0_ = (bitField0_ & ~0x00000200);
        existenceOnly_ = false;
        onChanged();
        return this;
      }

      private boolean closestRowBefore_ ;
      /**
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before. Deprecated. No longer used!
       * Since hbase-2.0.0 but left in place so can test
       * for Gets with this set and throw Exception.
       * </pre>
       *
       * <code>optional bool closest_row_before = 11 [default = false];</code>
       * @return Whether the closestRowBefore field is set.
       */
      @java.lang.Override
      public boolean hasClosestRowBefore() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before. Deprecated. No longer used!
       * Since hbase-2.0.0 but left in place so can test
       * for Gets with this set and throw Exception.
       * </pre>
       *
       * <code>optional bool closest_row_before = 11 [default = false];</code>
       * @return The closestRowBefore.
       */
      @java.lang.Override
      public boolean getClosestRowBefore() {
        return closestRowBefore_;
      }
      /**
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before. Deprecated. No longer used!
       * Since hbase-2.0.0 but left in place so can test
       * for Gets with this set and throw Exception.
       * </pre>
       *
       * <code>optional bool closest_row_before = 11 [default = false];</code>
       * @param value The closestRowBefore to set.
       * @return This builder for chaining.
       */
      public Builder setClosestRowBefore(boolean value) {

        closestRowBefore_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before. Deprecated. No longer used!
       * Since hbase-2.0.0 but left in place so can test
       * for Gets with this set and throw Exception.
       * </pre>
       *
       * <code>optional bool closest_row_before = 11 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearClosestRowBefore() {
        bitField0_ = (bitField0_ & ~0x00000400);
        closestRowBefore_ = false;
        onChanged();
        return this;
      }

      private int consistency_ = 0;
      /**
       * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
       * @return Whether the consistency field is set.
       */
      @java.lang.Override public boolean hasConsistency() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
       * @return The consistency.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(consistency_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.STRONG : result;
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
       * @param value The consistency to set.
       * @return This builder for chaining.
       */
      public Builder setConsistency(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000800;
        consistency_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 12 [default = STRONG];</code>
       * @return This builder for chaining.
       */
      public Builder clearConsistency() {
        bitField0_ = (bitField0_ & ~0x00000800);
        consistency_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> cfTimeRange_ =
        java.util.Collections.emptyList();
      private void ensureCfTimeRangeIsMutable() {
        if (!((bitField0_ & 0x00001000) != 0)) {
          cfTimeRange_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange>(cfTimeRange_);
          bitField0_ |= 0x00001000;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> cfTimeRangeBuilder_;

      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> getCfTimeRangeList() {
        if (cfTimeRangeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(cfTimeRange_);
        } else {
          return cfTimeRangeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public int getCfTimeRangeCount() {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.size();
        } else {
          return cfTimeRangeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index) {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.get(index);
        } else {
          return cfTimeRangeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder setCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.set(index, value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder setCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.set(index, builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder addCfTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder addCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(index, value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder addCfTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder addCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(index, builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder addAllCfTimeRange(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> values) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, cfTimeRange_);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder clearCfTimeRange() {
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRange_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00001000);
          onChanged();
        } else {
          cfTimeRangeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public Builder removeCfTimeRange(int index) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.remove(index);
          onChanged();
        } else {
          cfTimeRangeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder getCfTimeRangeBuilder(
          int index) {
        return getCfTimeRangeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
          int index) {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.get(index);  } else {
          return cfTimeRangeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
           getCfTimeRangeOrBuilderList() {
        if (cfTimeRangeBuilder_ != null) {
          return cfTimeRangeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(cfTimeRange_);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder addCfTimeRangeBuilder() {
        return getCfTimeRangeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder addCfTimeRangeBuilder(
          int index) {
        return getCfTimeRangeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 13;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder> 
           getCfTimeRangeBuilderList() {
        return getCfTimeRangeFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
          getCfTimeRangeFieldBuilder() {
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder>(
                  cfTimeRange_,
                  ((bitField0_ & 0x00001000) != 0),
                  getParentForChildren(),
                  isClean());
          cfTimeRange_ = null;
        }
        return cfTimeRangeBuilder_;
      }

      private boolean loadColumnFamiliesOnDemand_ ;
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 14;</code>
       * @return Whether the loadColumnFamiliesOnDemand field is set.
       */
      @java.lang.Override
      public boolean hasLoadColumnFamiliesOnDemand() {
        return ((bitField0_ & 0x00002000) != 0);
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 14;</code>
       * @return The loadColumnFamiliesOnDemand.
       */
      @java.lang.Override
      public boolean getLoadColumnFamiliesOnDemand() {
        return loadColumnFamiliesOnDemand_;
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 14;</code>
       * @param value The loadColumnFamiliesOnDemand to set.
       * @return This builder for chaining.
       */
      public Builder setLoadColumnFamiliesOnDemand(boolean value) {

        loadColumnFamiliesOnDemand_ = value;
        bitField0_ |= 0x00002000;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 14;</code>
       * @return This builder for chaining.
       */
      public Builder clearLoadColumnFamiliesOnDemand() {
        bitField0_ = (bitField0_ & ~0x00002000);
        loadColumnFamiliesOnDemand_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Get)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Get)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Get>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Get>() {
      @java.lang.Override
      public Get parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Get> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Get> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Result)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> 
        getCellList();
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell getCell(int index);
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    int getCellCount();
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder> 
        getCellOrBuilderList();
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
        int index);

    /**
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 2;</code>
     * @return Whether the associatedCellCount field is set.
     */
    boolean hasAssociatedCellCount();
    /**
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 2;</code>
     * @return The associatedCellCount.
     */
    int getAssociatedCellCount();

    /**
     * <pre>
     * used for Get to check existence only. Not set if existence_only was not set to true
     *  in the query.
     * </pre>
     *
     * <code>optional bool exists = 3;</code>
     * @return Whether the exists field is set.
     */
    boolean hasExists();
    /**
     * <pre>
     * used for Get to check existence only. Not set if existence_only was not set to true
     *  in the query.
     * </pre>
     *
     * <code>optional bool exists = 3;</code>
     * @return The exists.
     */
    boolean getExists();

    /**
     * <pre>
     * Whether or not the results are coming from possibly stale data
     * </pre>
     *
     * <code>optional bool stale = 4 [default = false];</code>
     * @return Whether the stale field is set.
     */
    boolean hasStale();
    /**
     * <pre>
     * Whether or not the results are coming from possibly stale data
     * </pre>
     *
     * <code>optional bool stale = 4 [default = false];</code>
     * @return The stale.
     */
    boolean getStale();

    /**
     * <pre>
     * Whether or not the entire result could be returned. Results will be split when
     * the RPC chunk size limit is reached. Partial results contain only a subset of the
     * cells for a row and must be combined with a result containing the remaining cells
     * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
     * mayHaveMoreCellsInRow.
     * </pre>
     *
     * <code>optional bool partial = 5 [default = false];</code>
     * @return Whether the partial field is set.
     */
    boolean hasPartial();
    /**
     * <pre>
     * Whether or not the entire result could be returned. Results will be split when
     * the RPC chunk size limit is reached. Partial results contain only a subset of the
     * cells for a row and must be combined with a result containing the remaining cells
     * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
     * mayHaveMoreCellsInRow.
     * </pre>
     *
     * <code>optional bool partial = 5 [default = false];</code>
     * @return The partial.
     */
    boolean getPartial();
  }
  /**
   * Protobuf type {@code hbase.pb.Result}
   */
  @javax.annotation.Generated("proto") public static final class Result extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Result)
      ResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Result.newBuilder() to construct.
    private Result(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Result() {
      cell_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Result();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Result_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Result_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder.class);
    }

    private int bitField0_;
    public static final int CELL_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> cell_;
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> getCellList() {
      return cell_;
    }
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder> 
        getCellOrBuilderList() {
      return cell_;
    }
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    @java.lang.Override
    public int getCellCount() {
      return cell_.size();
    }
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell getCell(int index) {
      return cell_.get(index);
    }
    /**
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     *
     * <code>repeated .hbase.pb.Cell cell = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
        int index) {
      return cell_.get(index);
    }

    public static final int ASSOCIATED_CELL_COUNT_FIELD_NUMBER = 2;
    private int associatedCellCount_ = 0;
    /**
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 2;</code>
     * @return Whether the associatedCellCount field is set.
     */
    @java.lang.Override
    public boolean hasAssociatedCellCount() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 2;</code>
     * @return The associatedCellCount.
     */
    @java.lang.Override
    public int getAssociatedCellCount() {
      return associatedCellCount_;
    }

    public static final int EXISTS_FIELD_NUMBER = 3;
    private boolean exists_ = false;
    /**
     * <pre>
     * used for Get to check existence only. Not set if existence_only was not set to true
     *  in the query.
     * </pre>
     *
     * <code>optional bool exists = 3;</code>
     * @return Whether the exists field is set.
     */
    @java.lang.Override
    public boolean hasExists() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * used for Get to check existence only. Not set if existence_only was not set to true
     *  in the query.
     * </pre>
     *
     * <code>optional bool exists = 3;</code>
     * @return The exists.
     */
    @java.lang.Override
    public boolean getExists() {
      return exists_;
    }

    public static final int STALE_FIELD_NUMBER = 4;
    private boolean stale_ = false;
    /**
     * <pre>
     * Whether or not the results are coming from possibly stale data
     * </pre>
     *
     * <code>optional bool stale = 4 [default = false];</code>
     * @return Whether the stale field is set.
     */
    @java.lang.Override
    public boolean hasStale() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * Whether or not the results are coming from possibly stale data
     * </pre>
     *
     * <code>optional bool stale = 4 [default = false];</code>
     * @return The stale.
     */
    @java.lang.Override
    public boolean getStale() {
      return stale_;
    }

    public static final int PARTIAL_FIELD_NUMBER = 5;
    private boolean partial_ = false;
    /**
     * <pre>
     * Whether or not the entire result could be returned. Results will be split when
     * the RPC chunk size limit is reached. Partial results contain only a subset of the
     * cells for a row and must be combined with a result containing the remaining cells
     * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
     * mayHaveMoreCellsInRow.
     * </pre>
     *
     * <code>optional bool partial = 5 [default = false];</code>
     * @return Whether the partial field is set.
     */
    @java.lang.Override
    public boolean hasPartial() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * Whether or not the entire result could be returned. Results will be split when
     * the RPC chunk size limit is reached. Partial results contain only a subset of the
     * cells for a row and must be combined with a result containing the remaining cells
     * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
     * mayHaveMoreCellsInRow.
     * </pre>
     *
     * <code>optional bool partial = 5 [default = false];</code>
     * @return The partial.
     */
    @java.lang.Override
    public boolean getPartial() {
      return partial_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < cell_.size(); i++) {
        output.writeMessage(1, cell_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(2, associatedCellCount_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(3, exists_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(4, stale_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(5, partial_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < cell_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, cell_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, associatedCellCount_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, exists_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, stale_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, partial_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result) obj;

      if (!getCellList()
          .equals(other.getCellList())) return false;
      if (hasAssociatedCellCount() != other.hasAssociatedCellCount()) return false;
      if (hasAssociatedCellCount()) {
        if (getAssociatedCellCount()
            != other.getAssociatedCellCount()) return false;
      }
      if (hasExists() != other.hasExists()) return false;
      if (hasExists()) {
        if (getExists()
            != other.getExists()) return false;
      }
      if (hasStale() != other.hasStale()) return false;
      if (hasStale()) {
        if (getStale()
            != other.getStale()) return false;
      }
      if (hasPartial() != other.hasPartial()) return false;
      if (hasPartial()) {
        if (getPartial()
            != other.getPartial()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getCellCount() > 0) {
        hash = (37 * hash) + CELL_FIELD_NUMBER;
        hash = (53 * hash) + getCellList().hashCode();
      }
      if (hasAssociatedCellCount()) {
        hash = (37 * hash) + ASSOCIATED_CELL_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getAssociatedCellCount();
      }
      if (hasExists()) {
        hash = (37 * hash) + EXISTS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getExists());
      }
      if (hasStale()) {
        hash = (37 * hash) + STALE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getStale());
      }
      if (hasPartial()) {
        hash = (37 * hash) + PARTIAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getPartial());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Result}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Result)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Result_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Result_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (cellBuilder_ == null) {
          cell_ = java.util.Collections.emptyList();
        } else {
          cell_ = null;
          cellBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        associatedCellCount_ = 0;
        exists_ = false;
        stale_ = false;
        partial_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Result_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result) {
        if (cellBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            cell_ = java.util.Collections.unmodifiableList(cell_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.cell_ = cell_;
        } else {
          result.cell_ = cellBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.associatedCellCount_ = associatedCellCount_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.exists_ = exists_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.stale_ = stale_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.partial_ = partial_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance()) return this;
        if (cellBuilder_ == null) {
          if (!other.cell_.isEmpty()) {
            if (cell_.isEmpty()) {
              cell_ = other.cell_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureCellIsMutable();
              cell_.addAll(other.cell_);
            }
            onChanged();
          }
        } else {
          if (!other.cell_.isEmpty()) {
            if (cellBuilder_.isEmpty()) {
              cellBuilder_.dispose();
              cellBuilder_ = null;
              cell_ = other.cell_;
              bitField0_ = (bitField0_ & ~0x00000001);
              cellBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getCellFieldBuilder() : null;
            } else {
              cellBuilder_.addAllMessages(other.cell_);
            }
          }
        }
        if (other.hasAssociatedCellCount()) {
          setAssociatedCellCount(other.getAssociatedCellCount());
        }
        if (other.hasExists()) {
          setExists(other.getExists());
        }
        if (other.hasStale()) {
          setStale(other.getStale());
        }
        if (other.hasPartial()) {
          setPartial(other.getPartial());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.PARSER,
                        extensionRegistry);
                if (cellBuilder_ == null) {
                  ensureCellIsMutable();
                  cell_.add(m);
                } else {
                  cellBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                associatedCellCount_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                exists_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 32: {
                stale_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 40: {
                partial_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> cell_ =
        java.util.Collections.emptyList();
      private void ensureCellIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          cell_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell>(cell_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder> cellBuilder_;

      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> getCellList() {
        if (cellBuilder_ == null) {
          return java.util.Collections.unmodifiableList(cell_);
        } else {
          return cellBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public int getCellCount() {
        if (cellBuilder_ == null) {
          return cell_.size();
        } else {
          return cellBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell getCell(int index) {
        if (cellBuilder_ == null) {
          return cell_.get(index);
        } else {
          return cellBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder setCell(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.set(index, value);
          onChanged();
        } else {
          cellBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder setCell(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.set(index, builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder addCell(org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.add(value);
          onChanged();
        } else {
          cellBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder addCell(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.add(index, value);
          onChanged();
        } else {
          cellBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder addCell(
          org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.add(builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder addCell(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.add(index, builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder addAllCell(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell> values) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, cell_);
          onChanged();
        } else {
          cellBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder clearCell() {
        if (cellBuilder_ == null) {
          cell_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          cellBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public Builder removeCell(int index) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.remove(index);
          onChanged();
        } else {
          cellBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder getCellBuilder(
          int index) {
        return getCellFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
          int index) {
        if (cellBuilder_ == null) {
          return cell_.get(index);  } else {
          return cellBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder> 
           getCellOrBuilderList() {
        if (cellBuilder_ != null) {
          return cellBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(cell_);
        }
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder addCellBuilder() {
        return getCellFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.getDefaultInstance());
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder addCellBuilder(
          int index) {
        return getCellFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.getDefaultInstance());
      }
      /**
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       *
       * <code>repeated .hbase.pb.Cell cell = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder> 
           getCellBuilderList() {
        return getCellFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder> 
          getCellFieldBuilder() {
        if (cellBuilder_ == null) {
          cellBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.CellOrBuilder>(
                  cell_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          cell_ = null;
        }
        return cellBuilder_;
      }

      private int associatedCellCount_ ;
      /**
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 2;</code>
       * @return Whether the associatedCellCount field is set.
       */
      @java.lang.Override
      public boolean hasAssociatedCellCount() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 2;</code>
       * @return The associatedCellCount.
       */
      @java.lang.Override
      public int getAssociatedCellCount() {
        return associatedCellCount_;
      }
      /**
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 2;</code>
       * @param value The associatedCellCount to set.
       * @return This builder for chaining.
       */
      public Builder setAssociatedCellCount(int value) {

        associatedCellCount_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssociatedCellCount() {
        bitField0_ = (bitField0_ & ~0x00000002);
        associatedCellCount_ = 0;
        onChanged();
        return this;
      }

      private boolean exists_ ;
      /**
       * <pre>
       * used for Get to check existence only. Not set if existence_only was not set to true
       *  in the query.
       * </pre>
       *
       * <code>optional bool exists = 3;</code>
       * @return Whether the exists field is set.
       */
      @java.lang.Override
      public boolean hasExists() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * used for Get to check existence only. Not set if existence_only was not set to true
       *  in the query.
       * </pre>
       *
       * <code>optional bool exists = 3;</code>
       * @return The exists.
       */
      @java.lang.Override
      public boolean getExists() {
        return exists_;
      }
      /**
       * <pre>
       * used for Get to check existence only. Not set if existence_only was not set to true
       *  in the query.
       * </pre>
       *
       * <code>optional bool exists = 3;</code>
       * @param value The exists to set.
       * @return This builder for chaining.
       */
      public Builder setExists(boolean value) {

        exists_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * used for Get to check existence only. Not set if existence_only was not set to true
       *  in the query.
       * </pre>
       *
       * <code>optional bool exists = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearExists() {
        bitField0_ = (bitField0_ & ~0x00000004);
        exists_ = false;
        onChanged();
        return this;
      }

      private boolean stale_ ;
      /**
       * <pre>
       * Whether or not the results are coming from possibly stale data
       * </pre>
       *
       * <code>optional bool stale = 4 [default = false];</code>
       * @return Whether the stale field is set.
       */
      @java.lang.Override
      public boolean hasStale() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * Whether or not the results are coming from possibly stale data
       * </pre>
       *
       * <code>optional bool stale = 4 [default = false];</code>
       * @return The stale.
       */
      @java.lang.Override
      public boolean getStale() {
        return stale_;
      }
      /**
       * <pre>
       * Whether or not the results are coming from possibly stale data
       * </pre>
       *
       * <code>optional bool stale = 4 [default = false];</code>
       * @param value The stale to set.
       * @return This builder for chaining.
       */
      public Builder setStale(boolean value) {

        stale_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Whether or not the results are coming from possibly stale data
       * </pre>
       *
       * <code>optional bool stale = 4 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearStale() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stale_ = false;
        onChanged();
        return this;
      }

      private boolean partial_ ;
      /**
       * <pre>
       * Whether or not the entire result could be returned. Results will be split when
       * the RPC chunk size limit is reached. Partial results contain only a subset of the
       * cells for a row and must be combined with a result containing the remaining cells
       * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
       * mayHaveMoreCellsInRow.
       * </pre>
       *
       * <code>optional bool partial = 5 [default = false];</code>
       * @return Whether the partial field is set.
       */
      @java.lang.Override
      public boolean hasPartial() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * Whether or not the entire result could be returned. Results will be split when
       * the RPC chunk size limit is reached. Partial results contain only a subset of the
       * cells for a row and must be combined with a result containing the remaining cells
       * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
       * mayHaveMoreCellsInRow.
       * </pre>
       *
       * <code>optional bool partial = 5 [default = false];</code>
       * @return The partial.
       */
      @java.lang.Override
      public boolean getPartial() {
        return partial_;
      }
      /**
       * <pre>
       * Whether or not the entire result could be returned. Results will be split when
       * the RPC chunk size limit is reached. Partial results contain only a subset of the
       * cells for a row and must be combined with a result containing the remaining cells
       * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
       * mayHaveMoreCellsInRow.
       * </pre>
       *
       * <code>optional bool partial = 5 [default = false];</code>
       * @param value The partial to set.
       * @return This builder for chaining.
       */
      public Builder setPartial(boolean value) {

        partial_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Whether or not the entire result could be returned. Results will be split when
       * the RPC chunk size limit is reached. Partial results contain only a subset of the
       * cells for a row and must be combined with a result containing the remaining cells
       * to form a complete result. The equivalent flag in o.a.h.h.client.Result is
       * mayHaveMoreCellsInRow.
       * </pre>
       *
       * <code>optional bool partial = 5 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearPartial() {
        bitField0_ = (bitField0_ & ~0x00000010);
        partial_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Result)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Result)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Result>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Result>() {
      @java.lang.Override
      public Result parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Result> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Result> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     * @return Whether the get field is set.
     */
    boolean hasGet();
    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     * @return The get.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet();
    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();
  }
  /**
   * <pre>
   **
   * The get request. Perform a single Get operation.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetRequest)
      GetRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetRequest.newBuilder() to construct.
    private GetRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int GET_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get get_;
    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     * @return Whether the get field is set.
     */
    @java.lang.Override
    public boolean hasGet() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     * @return The get.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet() {
      return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
    }
    /**
     * <code>required .hbase.pb.Get get = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasGet()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getGet().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getGet());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getGet());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasGet() != other.hasGet()) return false;
      if (hasGet()) {
        if (!getGet()
            .equals(other.getGet())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The get request. Perform a single Get operation.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getGetFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        get_ = null;
        if (getBuilder_ != null) {
          getBuilder_.dispose();
          getBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.get_ = getBuilder_ == null
              ? get_
              : getBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasGet()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getGet().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getGetFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get get_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       * @return Whether the get field is set.
       */
      public boolean hasGet() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       * @return The get.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public Builder setGet(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public Builder setGet(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public Builder mergeGet(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            get_ != null &&
            get_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            getGetBuilder().mergeFrom(value);
          } else {
            get_ = value;
          }
        } else {
          getBuilder_.mergeFrom(value);
        }
        if (get_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public Builder clearGet() {
        bitField0_ = (bitField0_ & ~0x00000002);
        get_ = null;
        if (getBuilder_ != null) {
          getBuilder_.dispose();
          getBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
        }
      }
      /**
       * <code>required .hbase.pb.Get get = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder>(
                  getGet(),
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetRequest>() {
      @java.lang.Override
      public GetRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return Whether the result field is set.
     */
    boolean hasResult();
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return The result.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult();
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GetResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetResponse)
      GetResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetResponse.newBuilder() to construct.
    private GetResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.Builder.class);
    }

    private int bitField0_;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return Whether the result field is set.
     */
    @java.lang.Override
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return The result.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getResult());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getResult());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse) obj;

      if (hasResult() != other.hasResult()) return false;
      if (hasResult()) {
        if (!getResult()
            .equals(other.getResult())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_GetResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.result_ = resultBuilder_ == null
              ? result_
              : resultBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       * @return Whether the result field is set.
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       * @return The result.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder setResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder setResult(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder mergeResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            result_ != null &&
            result_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            getResultBuilder().mergeFrom(value);
          } else {
            result_ = value;
          }
        } else {
          resultBuilder_.mergeFrom(value);
        }
        if (result_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder clearResult() {
        bitField0_ = (bitField0_ & ~0x00000001);
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  getResult(),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetResponse>() {
      @java.lang.Override
      public GetResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ConditionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Condition)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow();

    /**
     * <code>optional bytes family = 2;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>optional bytes family = 2;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

    /**
     * <code>optional bytes qualifier = 3;</code>
     * @return Whether the qualifier field is set.
     */
    boolean hasQualifier();
    /**
     * <code>optional bytes qualifier = 3;</code>
     * @return The qualifier.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier();

    /**
     * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
     * @return Whether the compareType field is set.
     */
    boolean hasCompareType();
    /**
     * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
     * @return The compareType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareType();

    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     * @return Whether the comparator field is set.
     */
    boolean hasComparator();
    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     * @return The comparator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator();
    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();

    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return Whether the timeRange field is set.
     */
    boolean hasTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return The timeRange.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();
  }
  /**
   * <pre>
   **
   * Condition to check if the value of a given cell (row, family, qualifier) matches a value via a
   * given comparator or the value of a given cell matches a given filter.
   *
   * Condition is used in check and mutate operations.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Condition}
   */
  @javax.annotation.Generated("proto") public static final class Condition extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Condition)
      ConditionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Condition.newBuilder() to construct.
    private Condition(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Condition() {
      row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      compareType_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Condition();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Condition_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Condition_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder.class);
    }

    private int bitField0_;
    public static final int ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    @java.lang.Override
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
      return row_;
    }

    public static final int FAMILY_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes family = 2;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes family = 2;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes qualifier = 3;</code>
     * @return Whether the qualifier field is set.
     */
    @java.lang.Override
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes qualifier = 3;</code>
     * @return The qualifier.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    public static final int COMPARE_TYPE_FIELD_NUMBER = 4;
    private int compareType_ = 0;
    /**
     * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
     * @return Whether the compareType field is set.
     */
    @java.lang.Override public boolean hasCompareType() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
     * @return The compareType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
    }

    public static final int COMPARATOR_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     * @return Whether the comparator field is set.
     */
    @java.lang.Override
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     * @return The comparator.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }
    /**
     * <code>optional .hbase.pb.Comparator comparator = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }

    public static final int TIME_RANGE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return Whether the timeRange field is set.
     */
    @java.lang.Override
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return The timeRange.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }

    public static final int FILTER_FIELD_NUMBER = 7;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 7;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasComparator()) {
        if (!getComparator().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(4, compareType_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(5, getComparator());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeMessage(6, getTimeRange());
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeMessage(7, getFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, compareType_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getComparator());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getTimeRange());
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition) obj;

      if (hasRow() != other.hasRow()) return false;
      if (hasRow()) {
        if (!getRow()
            .equals(other.getRow())) return false;
      }
      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (hasQualifier() != other.hasQualifier()) return false;
      if (hasQualifier()) {
        if (!getQualifier()
            .equals(other.getQualifier())) return false;
      }
      if (hasCompareType() != other.hasCompareType()) return false;
      if (hasCompareType()) {
        if (compareType_ != other.compareType_) return false;
      }
      if (hasComparator() != other.hasComparator()) return false;
      if (hasComparator()) {
        if (!getComparator()
            .equals(other.getComparator())) return false;
      }
      if (hasTimeRange() != other.hasTimeRange()) return false;
      if (hasTimeRange()) {
        if (!getTimeRange()
            .equals(other.getTimeRange())) return false;
      }
      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasCompareType()) {
        hash = (37 * hash) + COMPARE_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + compareType_;
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Condition to check if the value of a given cell (row, family, qualifier) matches a value via a
     * given comparator or the value of a given cell matches a given filter.
     *
     * Condition is used in check and mutate operations.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Condition}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Condition)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Condition_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Condition_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
          getTimeRangeFieldBuilder();
          getFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        compareType_ = 0;
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Condition_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.row_ = row_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.qualifier_ = qualifier_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.compareType_ = compareType_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.comparator_ = comparatorBuilder_ == null
              ? comparator_
              : comparatorBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.timeRange_ = timeRangeBuilder_ == null
              ? timeRange_
              : timeRangeBuilder_.build();
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasCompareType()) {
          setCompareType(other.getCompareType());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRow()) {
          return false;
        }
        if (hasComparator()) {
          if (!getComparator().isInitialized()) {
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                row_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                qualifier_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(4, tmpRaw);
                } else {
                  compareType_ = tmpRaw;
                  bitField0_ |= 0x00000008;
                }
                break;
              } // case 32
              case 42: {
                input.readMessage(
                    getComparatorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 50: {
                input.readMessage(
                    getTimeRangeFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000020;
                break;
              } // case 50
              case 58: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000040;
                break;
              } // case 58
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       * @return Whether the row field is set.
       */
      @java.lang.Override
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return The row.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @param value The row to set.
       * @return This builder for chaining.
       */
      public Builder setRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        row_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes family = 2;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes family = 2;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>optional bytes family = 2;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes family = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes qualifier = 3;</code>
       * @return Whether the qualifier field is set.
       */
      @java.lang.Override
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       * @return The qualifier.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       * @param value The qualifier to set.
       * @return This builder for chaining.
       */
      public Builder setQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        qualifier_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      private int compareType_ = 0;
      /**
       * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
       * @return Whether the compareType field is set.
       */
      @java.lang.Override public boolean hasCompareType() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
       * @return The compareType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
      }
      /**
       * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
       * @param value The compareType to set.
       * @return This builder for chaining.
       */
      public Builder setCompareType(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        compareType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.CompareType compare_type = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompareType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        compareType_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       * @return Whether the comparator field is set.
       */
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       * @return The comparator.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public Builder setComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public Builder setComparator(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public Builder mergeComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            comparator_ != null &&
            comparator_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            getComparatorBuilder().mergeFrom(value);
          } else {
            comparator_ = value;
          }
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        if (comparator_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public Builder clearComparator() {
        bitField0_ = (bitField0_ & ~0x00000010);
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        }
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  getComparator(),
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       * @return Whether the timeRange field is set.
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       * @return The timeRange.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
            timeRange_ != null &&
            timeRange_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            getTimeRangeBuilder().mergeFrom(value);
          } else {
            timeRange_ = value;
          }
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        if (timeRange_ != null) {
          bitField0_ |= 0x00000020;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder clearTimeRange() {
        bitField0_ = (bitField0_ & ~0x00000020);
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  getTimeRange(),
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000040) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000040;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000040);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 7;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Condition)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Condition)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Condition>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Condition>() {
      @java.lang.Override
      public Condition parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Condition> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Condition> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MutationProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MutationProto)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    boolean hasRow();
    /**
     * <code>optional bytes row = 1;</code>
     * @return The row.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow();

    /**
     * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
     * @return Whether the mutateType field is set.
     */
    boolean hasMutateType();
    /**
     * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
     * @return The mutateType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType();

    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> 
        getColumnValueList();
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index);
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    int getColumnValueCount();
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList();
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index);

    /**
     * <code>optional uint64 timestamp = 4;</code>
     * @return Whether the timestamp field is set.
     */
    boolean hasTimestamp();
    /**
     * <code>optional uint64 timestamp = 4;</code>
     * @return The timestamp.
     */
    long getTimestamp();

    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    /**
     * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     * @return Whether the durability field is set.
     */
    boolean hasDurability();
    /**
     * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     * @return The durability.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability getDurability();

    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     * @return Whether the timeRange field is set.
     */
    boolean hasTimeRange();
    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     * @return The timeRange.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    /**
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 8;</code>
     * @return Whether the associatedCellCount field is set.
     */
    boolean hasAssociatedCellCount();
    /**
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 8;</code>
     * @return The associatedCellCount.
     */
    int getAssociatedCellCount();

    /**
     * <code>optional uint64 nonce = 9;</code>
     * @return Whether the nonce field is set.
     */
    boolean hasNonce();
    /**
     * <code>optional uint64 nonce = 9;</code>
     * @return The nonce.
     */
    long getNonce();
  }
  /**
   * <pre>
   **
   * A specific mutation inside a mutate request.
   * It can be an append, increment, put or delete based
   * on the mutation type.  It can be fully filled in or
   * only metadata present because data is being carried
   * elsewhere outside of pb.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.MutationProto}
   */
  @javax.annotation.Generated("proto") public static final class MutationProto extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MutationProto)
      MutationProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MutationProto.newBuilder() to construct.
    private MutationProto(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MutationProto() {
      row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      mutateType_ = 0;
      columnValue_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      durability_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MutationProto();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.MutationProto.Durability}
     */
    public enum Durability
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>USE_DEFAULT = 0;</code>
       */
      USE_DEFAULT(0),
      /**
       * <code>SKIP_WAL = 1;</code>
       */
      SKIP_WAL(1),
      /**
       * <code>ASYNC_WAL = 2;</code>
       */
      ASYNC_WAL(2),
      /**
       * <code>SYNC_WAL = 3;</code>
       */
      SYNC_WAL(3),
      /**
       * <code>FSYNC_WAL = 4;</code>
       */
      FSYNC_WAL(4),
      ;

      /**
       * <code>USE_DEFAULT = 0;</code>
       */
      public static final int USE_DEFAULT_VALUE = 0;
      /**
       * <code>SKIP_WAL = 1;</code>
       */
      public static final int SKIP_WAL_VALUE = 1;
      /**
       * <code>ASYNC_WAL = 2;</code>
       */
      public static final int ASYNC_WAL_VALUE = 2;
      /**
       * <code>SYNC_WAL = 3;</code>
       */
      public static final int SYNC_WAL_VALUE = 3;
      /**
       * <code>FSYNC_WAL = 4;</code>
       */
      public static final int FSYNC_WAL_VALUE = 4;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Durability valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Durability forNumber(int value) {
        switch (value) {
          case 0: return USE_DEFAULT;
          case 1: return SKIP_WAL;
          case 2: return ASYNC_WAL;
          case 3: return SYNC_WAL;
          case 4: return FSYNC_WAL;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Durability>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          Durability> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Durability>() {
              public Durability findValueByNumber(int number) {
                return Durability.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(0);
      }

      private static final Durability[] VALUES = values();

      public static Durability valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Durability(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.MutationProto.Durability)
    }

    /**
     * Protobuf enum {@code hbase.pb.MutationProto.MutationType}
     */
    public enum MutationType
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>APPEND = 0;</code>
       */
      APPEND(0),
      /**
       * <code>INCREMENT = 1;</code>
       */
      INCREMENT(1),
      /**
       * <code>PUT = 2;</code>
       */
      PUT(2),
      /**
       * <code>DELETE = 3;</code>
       */
      DELETE(3),
      ;

      /**
       * <code>APPEND = 0;</code>
       */
      public static final int APPEND_VALUE = 0;
      /**
       * <code>INCREMENT = 1;</code>
       */
      public static final int INCREMENT_VALUE = 1;
      /**
       * <code>PUT = 2;</code>
       */
      public static final int PUT_VALUE = 2;
      /**
       * <code>DELETE = 3;</code>
       */
      public static final int DELETE_VALUE = 3;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static MutationType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static MutationType forNumber(int value) {
        switch (value) {
          case 0: return APPEND;
          case 1: return INCREMENT;
          case 2: return PUT;
          case 3: return DELETE;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MutationType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          MutationType> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<MutationType>() {
              public MutationType findValueByNumber(int number) {
                return MutationType.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(1);
      }

      private static final MutationType[] VALUES = values();

      public static MutationType valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private MutationType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.MutationProto.MutationType)
    }

    /**
     * Protobuf enum {@code hbase.pb.MutationProto.DeleteType}
     */
    public enum DeleteType
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>DELETE_ONE_VERSION = 0;</code>
       */
      DELETE_ONE_VERSION(0),
      /**
       * <code>DELETE_MULTIPLE_VERSIONS = 1;</code>
       */
      DELETE_MULTIPLE_VERSIONS(1),
      /**
       * <code>DELETE_FAMILY = 2;</code>
       */
      DELETE_FAMILY(2),
      /**
       * <code>DELETE_FAMILY_VERSION = 3;</code>
       */
      DELETE_FAMILY_VERSION(3),
      ;

      /**
       * <code>DELETE_ONE_VERSION = 0;</code>
       */
      public static final int DELETE_ONE_VERSION_VALUE = 0;
      /**
       * <code>DELETE_MULTIPLE_VERSIONS = 1;</code>
       */
      public static final int DELETE_MULTIPLE_VERSIONS_VALUE = 1;
      /**
       * <code>DELETE_FAMILY = 2;</code>
       */
      public static final int DELETE_FAMILY_VALUE = 2;
      /**
       * <code>DELETE_FAMILY_VERSION = 3;</code>
       */
      public static final int DELETE_FAMILY_VERSION_VALUE = 3;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static DeleteType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static DeleteType forNumber(int value) {
        switch (value) {
          case 0: return DELETE_ONE_VERSION;
          case 1: return DELETE_MULTIPLE_VERSIONS;
          case 2: return DELETE_FAMILY;
          case 3: return DELETE_FAMILY_VERSION;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          DeleteType> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<DeleteType>() {
              public DeleteType findValueByNumber(int number) {
                return DeleteType.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(2);
      }

      private static final DeleteType[] VALUES = values();

      public static DeleteType valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private DeleteType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.MutationProto.DeleteType)
    }

    public interface ColumnValueOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hbase.pb.MutationProto.ColumnValue)
        org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      boolean hasFamily();
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> 
          getQualifierValueList();
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index);
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      int getQualifierValueCount();
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList();
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code hbase.pb.MutationProto.ColumnValue}
     */
    @javax.annotation.Generated("proto") public static final class ColumnValue extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hbase.pb.MutationProto.ColumnValue)
        ColumnValueOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use ColumnValue.newBuilder() to construct.
      private ColumnValue(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private ColumnValue() {
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        qualifierValue_ = java.util.Collections.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new ColumnValue();
      }

      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder.class);
      }

      public interface QualifierValueOrBuilder extends
          // @@protoc_insertion_point(interface_extends:hbase.pb.MutationProto.ColumnValue.QualifierValue)
          org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

        /**
         * <code>optional bytes qualifier = 1;</code>
         * @return Whether the qualifier field is set.
         */
        boolean hasQualifier();
        /**
         * <code>optional bytes qualifier = 1;</code>
         * @return The qualifier.
         */
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier();

        /**
         * <code>optional bytes value = 2;</code>
         * @return Whether the value field is set.
         */
        boolean hasValue();
        /**
         * <code>optional bytes value = 2;</code>
         * @return The value.
         */
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue();

        /**
         * <code>optional uint64 timestamp = 3;</code>
         * @return Whether the timestamp field is set.
         */
        boolean hasTimestamp();
        /**
         * <code>optional uint64 timestamp = 3;</code>
         * @return The timestamp.
         */
        long getTimestamp();

        /**
         * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
         * @return Whether the deleteType field is set.
         */
        boolean hasDeleteType();
        /**
         * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
         * @return The deleteType.
         */
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType();

        /**
         * <code>optional bytes tags = 5;</code>
         * @return Whether the tags field is set.
         */
        boolean hasTags();
        /**
         * <code>optional bytes tags = 5;</code>
         * @return The tags.
         */
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTags();
      }
      /**
       * Protobuf type {@code hbase.pb.MutationProto.ColumnValue.QualifierValue}
       */
      @javax.annotation.Generated("proto") public static final class QualifierValue extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
          // @@protoc_insertion_point(message_implements:hbase.pb.MutationProto.ColumnValue.QualifierValue)
          QualifierValueOrBuilder {
      private static final long serialVersionUID = 0L;
        // Use QualifierValue.newBuilder() to construct.
        private QualifierValue(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
          super(builder);
        }
        private QualifierValue() {
          qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          deleteType_ = 0;
          tags_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        }

        @java.lang.Override
        @SuppressWarnings({"unused"})
        protected java.lang.Object newInstance(
            UnusedPrivateParameter unused) {
          return new QualifierValue();
        }

        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder.class);
        }

        private int bitField0_;
        public static final int QUALIFIER_FIELD_NUMBER = 1;
        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>optional bytes qualifier = 1;</code>
         * @return Whether the qualifier field is set.
         */
        @java.lang.Override
        public boolean hasQualifier() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>optional bytes qualifier = 1;</code>
         * @return The qualifier.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
          return qualifier_;
        }

        public static final int VALUE_FIELD_NUMBER = 2;
        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>optional bytes value = 2;</code>
         * @return Whether the value field is set.
         */
        @java.lang.Override
        public boolean hasValue() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional bytes value = 2;</code>
         * @return The value.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue() {
          return value_;
        }

        public static final int TIMESTAMP_FIELD_NUMBER = 3;
        private long timestamp_ = 0L;
        /**
         * <code>optional uint64 timestamp = 3;</code>
         * @return Whether the timestamp field is set.
         */
        @java.lang.Override
        public boolean hasTimestamp() {
          return ((bitField0_ & 0x00000004) != 0);
        }
        /**
         * <code>optional uint64 timestamp = 3;</code>
         * @return The timestamp.
         */
        @java.lang.Override
        public long getTimestamp() {
          return timestamp_;
        }

        public static final int DELETE_TYPE_FIELD_NUMBER = 4;
        private int deleteType_ = 0;
        /**
         * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
         * @return Whether the deleteType field is set.
         */
        @java.lang.Override public boolean hasDeleteType() {
          return ((bitField0_ & 0x00000008) != 0);
        }
        /**
         * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
         * @return The deleteType.
         */
        @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType.forNumber(deleteType_);
          return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION : result;
        }

        public static final int TAGS_FIELD_NUMBER = 5;
        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tags_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>optional bytes tags = 5;</code>
         * @return Whether the tags field is set.
         */
        @java.lang.Override
        public boolean hasTags() {
          return ((bitField0_ & 0x00000010) != 0);
        }
        /**
         * <code>optional bytes tags = 5;</code>
         * @return The tags.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTags() {
          return tags_;
        }

        private byte memoizedIsInitialized = -1;
        @java.lang.Override
        public final boolean isInitialized() {
          byte isInitialized = memoizedIsInitialized;
          if (isInitialized == 1) return true;
          if (isInitialized == 0) return false;

          memoizedIsInitialized = 1;
          return true;
        }

        @java.lang.Override
        public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                            throws java.io.IOException {
          if (((bitField0_ & 0x00000001) != 0)) {
            output.writeBytes(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) != 0)) {
            output.writeBytes(2, value_);
          }
          if (((bitField0_ & 0x00000004) != 0)) {
            output.writeUInt64(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) != 0)) {
            output.writeEnum(4, deleteType_);
          }
          if (((bitField0_ & 0x00000010) != 0)) {
            output.writeBytes(5, tags_);
          }
          getUnknownFields().writeTo(output);
        }

        @java.lang.Override
        public int getSerializedSize() {
          int size = memoizedSize;
          if (size != -1) return size;

          size = 0;
          if (((bitField0_ & 0x00000001) != 0)) {
            size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeBytesSize(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) != 0)) {
            size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeBytesSize(2, value_);
          }
          if (((bitField0_ & 0x00000004) != 0)) {
            size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeUInt64Size(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) != 0)) {
            size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeEnumSize(4, deleteType_);
          }
          if (((bitField0_ & 0x00000010) != 0)) {
            size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeBytesSize(5, tags_);
          }
          size += getUnknownFields().getSerializedSize();
          memoizedSize = size;
          return size;
        }

        @java.lang.Override
        public boolean equals(final java.lang.Object obj) {
          if (obj == this) {
           return true;
          }
          if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue)) {
            return super.equals(obj);
          }
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue) obj;

          if (hasQualifier() != other.hasQualifier()) return false;
          if (hasQualifier()) {
            if (!getQualifier()
                .equals(other.getQualifier())) return false;
          }
          if (hasValue() != other.hasValue()) return false;
          if (hasValue()) {
            if (!getValue()
                .equals(other.getValue())) return false;
          }
          if (hasTimestamp() != other.hasTimestamp()) return false;
          if (hasTimestamp()) {
            if (getTimestamp()
                != other.getTimestamp()) return false;
          }
          if (hasDeleteType() != other.hasDeleteType()) return false;
          if (hasDeleteType()) {
            if (deleteType_ != other.deleteType_) return false;
          }
          if (hasTags() != other.hasTags()) return false;
          if (hasTags()) {
            if (!getTags()
                .equals(other.getTags())) return false;
          }
          if (!getUnknownFields().equals(other.getUnknownFields())) return false;
          return true;
        }

        @java.lang.Override
        public int hashCode() {
          if (memoizedHashCode != 0) {
            return memoizedHashCode;
          }
          int hash = 41;
          hash = (19 * hash) + getDescriptor().hashCode();
          if (hasQualifier()) {
            hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
            hash = (53 * hash) + getQualifier().hashCode();
          }
          if (hasValue()) {
            hash = (37 * hash) + VALUE_FIELD_NUMBER;
            hash = (53 * hash) + getValue().hashCode();
          }
          if (hasTimestamp()) {
            hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
            hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
                getTimestamp());
          }
          if (hasDeleteType()) {
            hash = (37 * hash) + DELETE_TYPE_FIELD_NUMBER;
            hash = (53 * hash) + deleteType_;
          }
          if (hasTags()) {
            hash = (37 * hash) + TAGS_FIELD_NUMBER;
            hash = (53 * hash) + getTags().hashCode();
          }
          hash = (29 * hash) + getUnknownFields().hashCode();
          memoizedHashCode = hash;
          return hash;
        }

        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            java.nio.ByteBuffer data)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            java.nio.ByteBuffer data,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(byte[] data)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            byte[] data,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(java.io.InputStream input)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            java.io.InputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input, extensionRegistry);
        }

        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseDelimitedFrom(java.io.InputStream input)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseDelimitedWithIOException(PARSER, input);
        }

        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseDelimitedFrom(
            java.io.InputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input);
        }
        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input, extensionRegistry);
        }

        @java.lang.Override
        public Builder newBuilderForType() { return newBuilder(); }
        public static Builder newBuilder() {
          return DEFAULT_INSTANCE.toBuilder();
        }
        public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue prototype) {
          return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
        }
        @java.lang.Override
        public Builder toBuilder() {
          return this == DEFAULT_INSTANCE
              ? new Builder() : new Builder().mergeFrom(this);
        }

        @java.lang.Override
        protected Builder newBuilderForType(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          Builder builder = new Builder(parent);
          return builder;
        }
        /**
         * Protobuf type {@code hbase.pb.MutationProto.ColumnValue.QualifierValue}
         */
        @javax.annotation.Generated("proto") public static final class Builder extends
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
            // @@protoc_insertion_point(builder_implements:hbase.pb.MutationProto.ColumnValue.QualifierValue)
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder {
          public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
              getDescriptor() {
            return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor;
          }

          @java.lang.Override
          protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
              internalGetFieldAccessorTable() {
            return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable
                .ensureFieldAccessorsInitialized(
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder.class);
          }

          // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.newBuilder()
          private Builder() {

          }

          private Builder(
              org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
            super(parent);

          }
          @java.lang.Override
          public Builder clear() {
            super.clear();
            bitField0_ = 0;
            qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
            value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
            timestamp_ = 0L;
            deleteType_ = 0;
            tags_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
            return this;
          }

          @java.lang.Override
          public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
              getDescriptorForType() {
            return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor;
          }

          @java.lang.Override
          public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getDefaultInstanceForType() {
            return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance();
          }

          @java.lang.Override
          public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue build() {
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(result);
            }
            return result;
          }

          @java.lang.Override
          public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue buildPartial() {
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue(this);
            if (bitField0_ != 0) { buildPartial0(result); }
            onBuilt();
            return result;
          }

          private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue result) {
            int from_bitField0_ = bitField0_;
            int to_bitField0_ = 0;
            if (((from_bitField0_ & 0x00000001) != 0)) {
              result.qualifier_ = qualifier_;
              to_bitField0_ |= 0x00000001;
            }
            if (((from_bitField0_ & 0x00000002) != 0)) {
              result.value_ = value_;
              to_bitField0_ |= 0x00000002;
            }
            if (((from_bitField0_ & 0x00000004) != 0)) {
              result.timestamp_ = timestamp_;
              to_bitField0_ |= 0x00000004;
            }
            if (((from_bitField0_ & 0x00000008) != 0)) {
              result.deleteType_ = deleteType_;
              to_bitField0_ |= 0x00000008;
            }
            if (((from_bitField0_ & 0x00000010) != 0)) {
              result.tags_ = tags_;
              to_bitField0_ |= 0x00000010;
            }
            result.bitField0_ |= to_bitField0_;
          }

          @java.lang.Override
          public Builder clone() {
            return super.clone();
          }
          @java.lang.Override
          public Builder setField(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
              java.lang.Object value) {
            return super.setField(field, value);
          }
          @java.lang.Override
          public Builder clearField(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
            return super.clearField(field);
          }
          @java.lang.Override
          public Builder clearOneof(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
            return super.clearOneof(oneof);
          }
          @java.lang.Override
          public Builder setRepeatedField(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
              int index, java.lang.Object value) {
            return super.setRepeatedField(field, index, value);
          }
          @java.lang.Override
          public Builder addRepeatedField(
              org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
              java.lang.Object value) {
            return super.addRepeatedField(field, value);
          }
          @java.lang.Override
          public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
            if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue) {
              return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue)other);
            } else {
              super.mergeFrom(other);
              return this;
            }
          }

          public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue other) {
            if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance()) return this;
            if (other.hasQualifier()) {
              setQualifier(other.getQualifier());
            }
            if (other.hasValue()) {
              setValue(other.getValue());
            }
            if (other.hasTimestamp()) {
              setTimestamp(other.getTimestamp());
            }
            if (other.hasDeleteType()) {
              setDeleteType(other.getDeleteType());
            }
            if (other.hasTags()) {
              setTags(other.getTags());
            }
            this.mergeUnknownFields(other.getUnknownFields());
            onChanged();
            return this;
          }

          @java.lang.Override
          public final boolean isInitialized() {
            return true;
          }

          @java.lang.Override
          public Builder mergeFrom(
              org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
              org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
            if (extensionRegistry == null) {
              throw new java.lang.NullPointerException();
            }
            try {
              boolean done = false;
              while (!done) {
                int tag = input.readTag();
                switch (tag) {
                  case 0:
                    done = true;
                    break;
                  case 10: {
                    qualifier_ = input.readBytes();
                    bitField0_ |= 0x00000001;
                    break;
                  } // case 10
                  case 18: {
                    value_ = input.readBytes();
                    bitField0_ |= 0x00000002;
                    break;
                  } // case 18
                  case 24: {
                    timestamp_ = input.readUInt64();
                    bitField0_ |= 0x00000004;
                    break;
                  } // case 24
                  case 32: {
                    int tmpRaw = input.readEnum();
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType tmpValue =
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType.forNumber(tmpRaw);
                    if (tmpValue == null) {
                      mergeUnknownVarintField(4, tmpRaw);
                    } else {
                      deleteType_ = tmpRaw;
                      bitField0_ |= 0x00000008;
                    }
                    break;
                  } // case 32
                  case 42: {
                    tags_ = input.readBytes();
                    bitField0_ |= 0x00000010;
                    break;
                  } // case 42
                  default: {
                    if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                      done = true; // was an endgroup tag
                    }
                    break;
                  } // default:
                } // switch (tag)
              } // while (!done)
            } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.unwrapIOException();
            } finally {
              onChanged();
            } // finally
            return this;
          }
          private int bitField0_;

          private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          /**
           * <code>optional bytes qualifier = 1;</code>
           * @return Whether the qualifier field is set.
           */
          @java.lang.Override
          public boolean hasQualifier() {
            return ((bitField0_ & 0x00000001) != 0);
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           * @return The qualifier.
           */
          @java.lang.Override
          public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
            return qualifier_;
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           * @param value The qualifier to set.
           * @return This builder for chaining.
           */
          public Builder setQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
            if (value == null) { throw new NullPointerException(); }
            qualifier_ = value;
            bitField0_ |= 0x00000001;
            onChanged();
            return this;
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           * @return This builder for chaining.
           */
          public Builder clearQualifier() {
            bitField0_ = (bitField0_ & ~0x00000001);
            qualifier_ = getDefaultInstance().getQualifier();
            onChanged();
            return this;
          }

          private org.apache.hbase.thirdparty.com.google.protobuf.ByteString value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          /**
           * <code>optional bytes value = 2;</code>
           * @return Whether the value field is set.
           */
          @java.lang.Override
          public boolean hasValue() {
            return ((bitField0_ & 0x00000002) != 0);
          }
          /**
           * <code>optional bytes value = 2;</code>
           * @return The value.
           */
          @java.lang.Override
          public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue() {
            return value_;
          }
          /**
           * <code>optional bytes value = 2;</code>
           * @param value The value to set.
           * @return This builder for chaining.
           */
          public Builder setValue(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
            if (value == null) { throw new NullPointerException(); }
            value_ = value;
            bitField0_ |= 0x00000002;
            onChanged();
            return this;
          }
          /**
           * <code>optional bytes value = 2;</code>
           * @return This builder for chaining.
           */
          public Builder clearValue() {
            bitField0_ = (bitField0_ & ~0x00000002);
            value_ = getDefaultInstance().getValue();
            onChanged();
            return this;
          }

          private long timestamp_ ;
          /**
           * <code>optional uint64 timestamp = 3;</code>
           * @return Whether the timestamp field is set.
           */
          @java.lang.Override
          public boolean hasTimestamp() {
            return ((bitField0_ & 0x00000004) != 0);
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           * @return The timestamp.
           */
          @java.lang.Override
          public long getTimestamp() {
            return timestamp_;
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           * @param value The timestamp to set.
           * @return This builder for chaining.
           */
          public Builder setTimestamp(long value) {

            timestamp_ = value;
            bitField0_ |= 0x00000004;
            onChanged();
            return this;
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           * @return This builder for chaining.
           */
          public Builder clearTimestamp() {
            bitField0_ = (bitField0_ & ~0x00000004);
            timestamp_ = 0L;
            onChanged();
            return this;
          }

          private int deleteType_ = 0;
          /**
           * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
           * @return Whether the deleteType field is set.
           */
          @java.lang.Override public boolean hasDeleteType() {
            return ((bitField0_ & 0x00000008) != 0);
          }
          /**
           * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
           * @return The deleteType.
           */
          @java.lang.Override
          public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType() {
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType.forNumber(deleteType_);
            return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION : result;
          }
          /**
           * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
           * @param value The deleteType to set.
           * @return This builder for chaining.
           */
          public Builder setDeleteType(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.DeleteType value) {
            if (value == null) {
              throw new NullPointerException();
            }
            bitField0_ |= 0x00000008;
            deleteType_ = value.getNumber();
            onChanged();
            return this;
          }
          /**
           * <code>optional .hbase.pb.MutationProto.DeleteType delete_type = 4;</code>
           * @return This builder for chaining.
           */
          public Builder clearDeleteType() {
            bitField0_ = (bitField0_ & ~0x00000008);
            deleteType_ = 0;
            onChanged();
            return this;
          }

          private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tags_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          /**
           * <code>optional bytes tags = 5;</code>
           * @return Whether the tags field is set.
           */
          @java.lang.Override
          public boolean hasTags() {
            return ((bitField0_ & 0x00000010) != 0);
          }
          /**
           * <code>optional bytes tags = 5;</code>
           * @return The tags.
           */
          @java.lang.Override
          public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTags() {
            return tags_;
          }
          /**
           * <code>optional bytes tags = 5;</code>
           * @param value The tags to set.
           * @return This builder for chaining.
           */
          public Builder setTags(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
            if (value == null) { throw new NullPointerException(); }
            tags_ = value;
            bitField0_ |= 0x00000010;
            onChanged();
            return this;
          }
          /**
           * <code>optional bytes tags = 5;</code>
           * @return This builder for chaining.
           */
          public Builder clearTags() {
            bitField0_ = (bitField0_ & ~0x00000010);
            tags_ = getDefaultInstance().getTags();
            onChanged();
            return this;
          }
          @java.lang.Override
          public final Builder setUnknownFields(
              final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
            return super.setUnknownFields(unknownFields);
          }

          @java.lang.Override
          public final Builder mergeUnknownFields(
              final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
            return super.mergeUnknownFields(unknownFields);
          }


          // @@protoc_insertion_point(builder_scope:hbase.pb.MutationProto.ColumnValue.QualifierValue)
        }

        // @@protoc_insertion_point(class_scope:hbase.pb.MutationProto.ColumnValue.QualifierValue)
        private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue DEFAULT_INSTANCE;
        static {
          DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue();
        }

        public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getDefaultInstance() {
          return DEFAULT_INSTANCE;
        }

        @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierValue>
            PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<QualifierValue>() {
          @java.lang.Override
          public QualifierValue parsePartialFrom(
              org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
              org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

        public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierValue> parser() {
          return PARSER;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierValue> getParserForType() {
          return PARSER;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getDefaultInstanceForType() {
          return DEFAULT_INSTANCE;
        }

      }

      private int bitField0_;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }

      public static final int QUALIFIER_VALUE_FIELD_NUMBER = 2;
      @SuppressWarnings("serial")
      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> qualifierValue_;
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      @java.lang.Override
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> getQualifierValueList() {
        return qualifierValue_;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      @java.lang.Override
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList() {
        return qualifierValue_;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      @java.lang.Override
      public int getQualifierValueCount() {
        return qualifierValue_.size();
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index) {
        return qualifierValue_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index) {
        return qualifierValue_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeBytes(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          output.writeMessage(2, qualifierValue_.get(i));
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, qualifierValue_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue) obj;

        if (hasFamily() != other.hasFamily()) return false;
        if (hasFamily()) {
          if (!getFamily()
              .equals(other.getFamily())) return false;
        }
        if (!getQualifierValueList()
            .equals(other.getQualifierValueList())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (getQualifierValueCount() > 0) {
          hash = (37 * hash) + QUALIFIER_VALUE_FIELD_NUMBER;
          hash = (53 * hash) + getQualifierValueList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          java.nio.ByteBuffer data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          java.nio.ByteBuffer data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(byte[] data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          byte[] data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseDelimitedFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.MutationProto.ColumnValue}
       */
      @javax.annotation.Generated("proto") public static final class Builder extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hbase.pb.MutationProto.ColumnValue)
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder {
        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.newBuilder()
        private Builder() {

        }

        private Builder(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);

        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
          } else {
            qualifierValue_ = null;
            qualifierValueBuilder_.clear();
          }
          bitField0_ = (bitField0_ & ~0x00000002);
          return this;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_ColumnValue_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue build() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue buildPartial() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue(this);
          buildPartialRepeatedFields(result);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue result) {
          if (qualifierValueBuilder_ == null) {
            if (((bitField0_ & 0x00000002) != 0)) {
              qualifierValue_ = java.util.Collections.unmodifiableList(qualifierValue_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.qualifierValue_ = qualifierValue_;
          } else {
            result.qualifierValue_ = qualifierValueBuilder_.build();
          }
        }

        private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue result) {
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.family_ = family_;
            to_bitField0_ |= 0x00000001;
          }
          result.bitField0_ |= to_bitField0_;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue) {
            return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue other) {
          if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (qualifierValueBuilder_ == null) {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValue_.isEmpty()) {
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureQualifierValueIsMutable();
                qualifierValue_.addAll(other.qualifierValue_);
              }
              onChanged();
            }
          } else {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValueBuilder_.isEmpty()) {
                qualifierValueBuilder_.dispose();
                qualifierValueBuilder_ = null;
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
                qualifierValueBuilder_ = 
                  org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getQualifierValueFieldBuilder() : null;
              } else {
                qualifierValueBuilder_.addAllMessages(other.qualifierValue_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasFamily()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  family_ = input.readBytes();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 18: {
                  org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue m =
                      input.readMessage(
                          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.PARSER,
                          extensionRegistry);
                  if (qualifierValueBuilder_ == null) {
                    ensureQualifierValueIsMutable();
                    qualifierValue_.add(m);
                  } else {
                    qualifierValueBuilder_.addMessage(m);
                  }
                  break;
                } // case 18
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes family = 1;</code>
         * @return Whether the family field is set.
         */
        @java.lang.Override
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required bytes family = 1;</code>
         * @return The family.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        /**
         * <code>required bytes family = 1;</code>
         * @param value The family to set.
         * @return This builder for chaining.
         */
        public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          family_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes family = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }

        private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> qualifierValue_ =
          java.util.Collections.emptyList();
        private void ensureQualifierValueIsMutable() {
          if (!((bitField0_ & 0x00000002) != 0)) {
            qualifierValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue>(qualifierValue_);
            bitField0_ |= 0x00000002;
           }
        }

        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> qualifierValueBuilder_;

        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> getQualifierValueList() {
          if (qualifierValueBuilder_ == null) {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          } else {
            return qualifierValueBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public int getQualifierValueCount() {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.size();
          } else {
            return qualifierValueBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);
          } else {
            return qualifierValueBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addAllQualifierValue(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> values) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, qualifierValue_);
            onChanged();
          } else {
            qualifierValueBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder clearQualifierValue() {
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            qualifierValueBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder removeQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.remove(index);
            onChanged();
          } else {
            qualifierValueBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder getQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
            int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);  } else {
            return qualifierValueBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
             getQualifierValueOrBuilderList() {
          if (qualifierValueBuilder_ != null) {
            return qualifierValueBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          }
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder addQualifierValueBuilder() {
          return getQualifierValueFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder addQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder> 
             getQualifierValueBuilderList() {
          return getQualifierValueFieldBuilder().getBuilderList();
        }
        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
            getQualifierValueFieldBuilder() {
          if (qualifierValueBuilder_ == null) {
            qualifierValueBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder>(
                    qualifierValue_,
                    ((bitField0_ & 0x00000002) != 0),
                    getParentForChildren(),
                    isClean());
            qualifierValue_ = null;
          }
          return qualifierValueBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hbase.pb.MutationProto.ColumnValue)
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.MutationProto.ColumnValue)
      private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue();
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValue>
          PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnValue>() {
        @java.lang.Override
        public ColumnValue parsePartialFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValue> parser() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValue> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    @java.lang.Override
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes row = 1;</code>
     * @return The row.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
      return row_;
    }

    public static final int MUTATE_TYPE_FIELD_NUMBER = 2;
    private int mutateType_ = 0;
    /**
     * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
     * @return Whether the mutateType field is set.
     */
    @java.lang.Override public boolean hasMutateType() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
     * @return The mutateType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType.forNumber(mutateType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND : result;
    }

    public static final int COLUMN_VALUE_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> columnValue_;
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> getColumnValueList() {
      return columnValue_;
    }
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList() {
      return columnValue_;
    }
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    @java.lang.Override
    public int getColumnValueCount() {
      return columnValue_.size();
    }
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index) {
      return columnValue_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index) {
      return columnValue_.get(index);
    }

    public static final int TIMESTAMP_FIELD_NUMBER = 4;
    private long timestamp_ = 0L;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     * @return Whether the timestamp field is set.
     */
    @java.lang.Override
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional uint64 timestamp = 4;</code>
     * @return The timestamp.
     */
    @java.lang.Override
    public long getTimestamp() {
      return timestamp_;
    }

    public static final int ATTRIBUTE_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    @java.lang.Override
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    public static final int DURABILITY_FIELD_NUMBER = 6;
    private int durability_ = 0;
    /**
     * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     * @return Whether the durability field is set.
     */
    @java.lang.Override public boolean hasDurability() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     * @return The durability.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability getDurability() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability.forNumber(durability_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT : result;
    }

    public static final int TIME_RANGE_FIELD_NUMBER = 7;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     * @return Whether the timeRange field is set.
     */
    @java.lang.Override
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     * @return The timeRange.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }
    /**
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     *
     * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }

    public static final int ASSOCIATED_CELL_COUNT_FIELD_NUMBER = 8;
    private int associatedCellCount_ = 0;
    /**
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 8;</code>
     * @return Whether the associatedCellCount field is set.
     */
    @java.lang.Override
    public boolean hasAssociatedCellCount() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 8;</code>
     * @return The associatedCellCount.
     */
    @java.lang.Override
    public int getAssociatedCellCount() {
      return associatedCellCount_;
    }

    public static final int NONCE_FIELD_NUMBER = 9;
    private long nonce_ = 0L;
    /**
     * <code>optional uint64 nonce = 9;</code>
     * @return Whether the nonce field is set.
     */
    @java.lang.Override
    public boolean hasNonce() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional uint64 nonce = 9;</code>
     * @return The nonce.
     */
    @java.lang.Override
    public long getNonce() {
      return nonce_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getColumnValueCount(); i++) {
        if (!getColumnValue(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, mutateType_);
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        output.writeMessage(3, columnValue_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(4, timestamp_);
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(5, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(6, durability_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(7, getTimeRange());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeInt32(8, associatedCellCount_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeUInt64(9, nonce_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, mutateType_);
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnValue_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, timestamp_);
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, durability_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getTimeRange());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(8, associatedCellCount_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(9, nonce_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto) obj;

      if (hasRow() != other.hasRow()) return false;
      if (hasRow()) {
        if (!getRow()
            .equals(other.getRow())) return false;
      }
      if (hasMutateType() != other.hasMutateType()) return false;
      if (hasMutateType()) {
        if (mutateType_ != other.mutateType_) return false;
      }
      if (!getColumnValueList()
          .equals(other.getColumnValueList())) return false;
      if (hasTimestamp() != other.hasTimestamp()) return false;
      if (hasTimestamp()) {
        if (getTimestamp()
            != other.getTimestamp()) return false;
      }
      if (!getAttributeList()
          .equals(other.getAttributeList())) return false;
      if (hasDurability() != other.hasDurability()) return false;
      if (hasDurability()) {
        if (durability_ != other.durability_) return false;
      }
      if (hasTimeRange() != other.hasTimeRange()) return false;
      if (hasTimeRange()) {
        if (!getTimeRange()
            .equals(other.getTimeRange())) return false;
      }
      if (hasAssociatedCellCount() != other.hasAssociatedCellCount()) return false;
      if (hasAssociatedCellCount()) {
        if (getAssociatedCellCount()
            != other.getAssociatedCellCount()) return false;
      }
      if (hasNonce() != other.hasNonce()) return false;
      if (hasNonce()) {
        if (getNonce()
            != other.getNonce()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasMutateType()) {
        hash = (37 * hash) + MUTATE_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + mutateType_;
      }
      if (getColumnValueCount() > 0) {
        hash = (37 * hash) + COLUMN_VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getColumnValueList().hashCode();
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getTimestamp());
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasDurability()) {
        hash = (37 * hash) + DURABILITY_FIELD_NUMBER;
        hash = (53 * hash) + durability_;
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasAssociatedCellCount()) {
        hash = (37 * hash) + ASSOCIATED_CELL_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getAssociatedCellCount();
      }
      if (hasNonce()) {
        hash = (37 * hash) + NONCE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNonce());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * A specific mutation inside a mutate request.
     * It can be an append, increment, put or delete based
     * on the mutation type.  It can be fully filled in or
     * only metadata present because data is being carried
     * elsewhere outside of pb.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.MutationProto}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MutationProto)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getColumnValueFieldBuilder();
          getAttributeFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        mutateType_ = 0;
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
        } else {
          columnValue_ = null;
          columnValueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
        } else {
          attribute_ = null;
          attributeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        durability_ = 0;
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        associatedCellCount_ = 0;
        nonce_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutationProto_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto result) {
        if (columnValueBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            columnValue_ = java.util.Collections.unmodifiableList(columnValue_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.columnValue_ = columnValue_;
        } else {
          result.columnValue_ = columnValueBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.row_ = row_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.mutateType_ = mutateType_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.timestamp_ = timestamp_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.durability_ = durability_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.timeRange_ = timeRangeBuilder_ == null
              ? timeRange_
              : timeRangeBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.associatedCellCount_ = associatedCellCount_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.nonce_ = nonce_;
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasMutateType()) {
          setMutateType(other.getMutateType());
        }
        if (columnValueBuilder_ == null) {
          if (!other.columnValue_.isEmpty()) {
            if (columnValue_.isEmpty()) {
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureColumnValueIsMutable();
              columnValue_.addAll(other.columnValue_);
            }
            onChanged();
          }
        } else {
          if (!other.columnValue_.isEmpty()) {
            if (columnValueBuilder_.isEmpty()) {
              columnValueBuilder_.dispose();
              columnValueBuilder_ = null;
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
              columnValueBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getColumnValueFieldBuilder() : null;
            } else {
              columnValueBuilder_.addAllMessages(other.columnValue_);
            }
          }
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000010);
              attributeBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasDurability()) {
          setDurability(other.getDurability());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasAssociatedCellCount()) {
          setAssociatedCellCount(other.getAssociatedCellCount());
        }
        if (other.hasNonce()) {
          setNonce(other.getNonce());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getColumnValueCount(); i++) {
          if (!getColumnValue(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                row_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(2, tmpRaw);
                } else {
                  mutateType_ = tmpRaw;
                  bitField0_ |= 0x00000002;
                }
                break;
              } // case 16
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.PARSER,
                        extensionRegistry);
                if (columnValueBuilder_ == null) {
                  ensureColumnValueIsMutable();
                  columnValue_.add(m);
                } else {
                  columnValueBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 32: {
                timestamp_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.PARSER,
                        extensionRegistry);
                if (attributeBuilder_ == null) {
                  ensureAttributeIsMutable();
                  attribute_.add(m);
                } else {
                  attributeBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 48: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(6, tmpRaw);
                } else {
                  durability_ = tmpRaw;
                  bitField0_ |= 0x00000020;
                }
                break;
              } // case 48
              case 58: {
                input.readMessage(
                    getTimeRangeFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000040;
                break;
              } // case 58
              case 64: {
                associatedCellCount_ = input.readInt32();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 72: {
                nonce_ = input.readUInt64();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes row = 1;</code>
       * @return Whether the row field is set.
       */
      @java.lang.Override
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @return The row.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @param value The row to set.
       * @return This builder for chaining.
       */
      public Builder setRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        row_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      private int mutateType_ = 0;
      /**
       * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
       * @return Whether the mutateType field is set.
       */
      @java.lang.Override public boolean hasMutateType() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
       * @return The mutateType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType.forNumber(mutateType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND : result;
      }
      /**
       * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
       * @param value The mutateType to set.
       * @return This builder for chaining.
       */
      public Builder setMutateType(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.MutationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        mutateType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto.MutationType mutate_type = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearMutateType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mutateType_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> columnValue_ =
        java.util.Collections.emptyList();
      private void ensureColumnValueIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          columnValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue>(columnValue_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> columnValueBuilder_;

      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> getColumnValueList() {
        if (columnValueBuilder_ == null) {
          return java.util.Collections.unmodifiableList(columnValue_);
        } else {
          return columnValueBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public int getColumnValueCount() {
        if (columnValueBuilder_ == null) {
          return columnValue_.size();
        } else {
          return columnValueBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);
        } else {
          return columnValueBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.set(index, value);
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(index, value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addAllColumnValue(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue> values) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, columnValue_);
          onChanged();
        } else {
          columnValueBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder clearColumnValue() {
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          columnValueBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder removeColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.remove(index);
          onChanged();
        } else {
          columnValueBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder getColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
          int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);  } else {
          return columnValueBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
           getColumnValueOrBuilderList() {
        if (columnValueBuilder_ != null) {
          return columnValueBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(columnValue_);
        }
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder addColumnValueBuilder() {
        return getColumnValueFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder addColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder> 
           getColumnValueBuilderList() {
        return getColumnValueFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
          getColumnValueFieldBuilder() {
        if (columnValueBuilder_ == null) {
          columnValueBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder>(
                  columnValue_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          columnValue_ = null;
        }
        return columnValueBuilder_;
      }

      private long timestamp_ ;
      /**
       * <code>optional uint64 timestamp = 4;</code>
       * @return Whether the timestamp field is set.
       */
      @java.lang.Override
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       * @return The timestamp.
       */
      @java.lang.Override
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       * @param value The timestamp to set.
       * @return This builder for chaining.
       */
      public Builder setTimestamp(long value) {

        timestamp_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000008);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      private int durability_ = 0;
      /**
       * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       * @return Whether the durability field is set.
       */
      @java.lang.Override public boolean hasDurability() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       * @return The durability.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability getDurability() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability.forNumber(durability_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT : result;
      }
      /**
       * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       * @param value The durability to set.
       * @return This builder for chaining.
       */
      public Builder setDurability(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Durability value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        durability_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       * @return This builder for chaining.
       */
      public Builder clearDurability() {
        bitField0_ = (bitField0_ & ~0x00000020);
        durability_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       * @return Whether the timeRange field is set.
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       * @return The timeRange.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000040) != 0) &&
            timeRange_ != null &&
            timeRange_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            getTimeRangeBuilder().mergeFrom(value);
          } else {
            timeRange_ = value;
          }
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        if (timeRange_ != null) {
          bitField0_ |= 0x00000040;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public Builder clearTimeRange() {
        bitField0_ = (bitField0_ & ~0x00000040);
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        }
      }
      /**
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       *
       * <code>optional .hbase.pb.TimeRange time_range = 7;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  getTimeRange(),
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      private int associatedCellCount_ ;
      /**
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 8;</code>
       * @return Whether the associatedCellCount field is set.
       */
      @java.lang.Override
      public boolean hasAssociatedCellCount() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 8;</code>
       * @return The associatedCellCount.
       */
      @java.lang.Override
      public int getAssociatedCellCount() {
        return associatedCellCount_;
      }
      /**
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 8;</code>
       * @param value The associatedCellCount to set.
       * @return This builder for chaining.
       */
      public Builder setAssociatedCellCount(int value) {

        associatedCellCount_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssociatedCellCount() {
        bitField0_ = (bitField0_ & ~0x00000080);
        associatedCellCount_ = 0;
        onChanged();
        return this;
      }

      private long nonce_ ;
      /**
       * <code>optional uint64 nonce = 9;</code>
       * @return Whether the nonce field is set.
       */
      @java.lang.Override
      public boolean hasNonce() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional uint64 nonce = 9;</code>
       * @return The nonce.
       */
      @java.lang.Override
      public long getNonce() {
        return nonce_;
      }
      /**
       * <code>optional uint64 nonce = 9;</code>
       * @param value The nonce to set.
       * @return This builder for chaining.
       */
      public Builder setNonce(long value) {

        nonce_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 nonce = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearNonce() {
        bitField0_ = (bitField0_ & ~0x00000100);
        nonce_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MutationProto)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MutationProto)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutationProto>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MutationProto>() {
      @java.lang.Override
      public MutationProto parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutationProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutationProto> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MutateRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MutateRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     * @return Whether the mutation field is set.
     */
    boolean hasMutation();
    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     * @return The mutation.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation();
    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder();

    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     * @return Whether the condition field is set.
     */
    boolean hasCondition();
    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     * @return The condition.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition();
    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder();

    /**
     * <code>optional uint64 nonce_group = 4;</code>
     * @return Whether the nonceGroup field is set.
     */
    boolean hasNonceGroup();
    /**
     * <code>optional uint64 nonce_group = 4;</code>
     * @return The nonceGroup.
     */
    long getNonceGroup();
  }
  /**
   * <pre>
   **
   * The mutate request. Perform a single Mutate operation.
   *
   * Optionally, you can specify a condition. The mutate
   * will take place only if the condition is met.  Otherwise,
   * the mutate will be ignored.  In the response result,
   * parameter processed is used to indicate if the mutate
   * actually happened.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.MutateRequest}
   */
  @javax.annotation.Generated("proto") public static final class MutateRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MutateRequest)
      MutateRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MutateRequest.newBuilder() to construct.
    private MutateRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MutateRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MutateRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int MUTATION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto mutation_;
    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     * @return Whether the mutation field is set.
     */
    @java.lang.Override
    public boolean hasMutation() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     * @return The mutation.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation() {
      return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
    }
    /**
     * <code>required .hbase.pb.MutationProto mutation = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
      return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
    }

    public static final int CONDITION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     * @return Whether the condition field is set.
     */
    @java.lang.Override
    public boolean hasCondition() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     * @return The condition.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }
    /**
     * <code>optional .hbase.pb.Condition condition = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }

    public static final int NONCE_GROUP_FIELD_NUMBER = 4;
    private long nonceGroup_ = 0L;
    /**
     * <code>optional uint64 nonce_group = 4;</code>
     * @return Whether the nonceGroup field is set.
     */
    @java.lang.Override
    public boolean hasNonceGroup() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional uint64 nonce_group = 4;</code>
     * @return The nonceGroup.
     */
    @java.lang.Override
    public long getNonceGroup() {
      return nonceGroup_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMutation()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getMutation().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasCondition()) {
        if (!getCondition().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getMutation());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getCondition());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt64(4, nonceGroup_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getMutation());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCondition());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, nonceGroup_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasMutation() != other.hasMutation()) return false;
      if (hasMutation()) {
        if (!getMutation()
            .equals(other.getMutation())) return false;
      }
      if (hasCondition() != other.hasCondition()) return false;
      if (hasCondition()) {
        if (!getCondition()
            .equals(other.getCondition())) return false;
      }
      if (hasNonceGroup() != other.hasNonceGroup()) return false;
      if (hasNonceGroup()) {
        if (getNonceGroup()
            != other.getNonceGroup()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasMutation()) {
        hash = (37 * hash) + MUTATION_FIELD_NUMBER;
        hash = (53 * hash) + getMutation().hashCode();
      }
      if (hasCondition()) {
        hash = (37 * hash) + CONDITION_FIELD_NUMBER;
        hash = (53 * hash) + getCondition().hashCode();
      }
      if (hasNonceGroup()) {
        hash = (37 * hash) + NONCE_GROUP_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNonceGroup());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The mutate request. Perform a single Mutate operation.
     *
     * Optionally, you can specify a condition. The mutate
     * will take place only if the condition is met.  Otherwise,
     * the mutate will be ignored.  In the response result,
     * parameter processed is used to indicate if the mutate
     * actually happened.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.MutateRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MutateRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getMutationFieldBuilder();
          getConditionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        mutation_ = null;
        if (mutationBuilder_ != null) {
          mutationBuilder_.dispose();
          mutationBuilder_ = null;
        }
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        nonceGroup_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.mutation_ = mutationBuilder_ == null
              ? mutation_
              : mutationBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.condition_ = conditionBuilder_ == null
              ? condition_
              : conditionBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.nonceGroup_ = nonceGroup_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasMutation()) {
          mergeMutation(other.getMutation());
        }
        if (other.hasCondition()) {
          mergeCondition(other.getCondition());
        }
        if (other.hasNonceGroup()) {
          setNonceGroup(other.getNonceGroup());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasMutation()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getMutation().isInitialized()) {
          return false;
        }
        if (hasCondition()) {
          if (!getCondition().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getMutationFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getConditionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                nonceGroup_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto mutation_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder> mutationBuilder_;
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       * @return Whether the mutation field is set.
       */
      public boolean hasMutation() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       * @return The mutation.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation() {
        if (mutationBuilder_ == null) {
          return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
        } else {
          return mutationBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder setMutation(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutation_ = value;
        } else {
          mutationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder setMutation(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder builderForValue) {
        if (mutationBuilder_ == null) {
          mutation_ = builderForValue.build();
        } else {
          mutationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder mergeMutation(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            mutation_ != null &&
            mutation_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) {
            getMutationBuilder().mergeFrom(value);
          } else {
            mutation_ = value;
          }
        } else {
          mutationBuilder_.mergeFrom(value);
        }
        if (mutation_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder clearMutation() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mutation_ = null;
        if (mutationBuilder_ != null) {
          mutationBuilder_.dispose();
          mutationBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder getMutationBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMutationFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
        if (mutationBuilder_ != null) {
          return mutationBuilder_.getMessageOrBuilder();
        } else {
          return mutation_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
        }
      }
      /**
       * <code>required .hbase.pb.MutationProto mutation = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder> 
          getMutationFieldBuilder() {
        if (mutationBuilder_ == null) {
          mutationBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder>(
                  getMutation(),
                  getParentForChildren(),
                  isClean());
          mutation_ = null;
        }
        return mutationBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> conditionBuilder_;
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       * @return Whether the condition field is set.
       */
      public boolean hasCondition() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       * @return The condition.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
        if (conditionBuilder_ == null) {
          return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        } else {
          return conditionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public Builder setCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          condition_ = value;
        } else {
          conditionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public Builder setCondition(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder builderForValue) {
        if (conditionBuilder_ == null) {
          condition_ = builderForValue.build();
        } else {
          conditionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public Builder mergeCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            condition_ != null &&
            condition_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) {
            getConditionBuilder().mergeFrom(value);
          } else {
            condition_ = value;
          }
        } else {
          conditionBuilder_.mergeFrom(value);
        }
        if (condition_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public Builder clearCondition() {
        bitField0_ = (bitField0_ & ~0x00000004);
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder getConditionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getConditionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
        if (conditionBuilder_ != null) {
          return conditionBuilder_.getMessageOrBuilder();
        } else {
          return condition_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        }
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> 
          getConditionFieldBuilder() {
        if (conditionBuilder_ == null) {
          conditionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder>(
                  getCondition(),
                  getParentForChildren(),
                  isClean());
          condition_ = null;
        }
        return conditionBuilder_;
      }

      private long nonceGroup_ ;
      /**
       * <code>optional uint64 nonce_group = 4;</code>
       * @return Whether the nonceGroup field is set.
       */
      @java.lang.Override
      public boolean hasNonceGroup() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint64 nonce_group = 4;</code>
       * @return The nonceGroup.
       */
      @java.lang.Override
      public long getNonceGroup() {
        return nonceGroup_;
      }
      /**
       * <code>optional uint64 nonce_group = 4;</code>
       * @param value The nonceGroup to set.
       * @return This builder for chaining.
       */
      public Builder setNonceGroup(long value) {

        nonceGroup_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 nonce_group = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearNonceGroup() {
        bitField0_ = (bitField0_ & ~0x00000008);
        nonceGroup_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MutateRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MutateRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MutateRequest>() {
      @java.lang.Override
      public MutateRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MutateResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MutateResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return Whether the result field is set.
     */
    boolean hasResult();
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return The result.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult();
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();

    /**
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     *
     * <code>optional bool processed = 2;</code>
     * @return Whether the processed field is set.
     */
    boolean hasProcessed();
    /**
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     *
     * <code>optional bool processed = 2;</code>
     * @return The processed.
     */
    boolean getProcessed();
  }
  /**
   * Protobuf type {@code hbase.pb.MutateResponse}
   */
  @javax.annotation.Generated("proto") public static final class MutateResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MutateResponse)
      MutateResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MutateResponse.newBuilder() to construct.
    private MutateResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MutateResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MutateResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.Builder.class);
    }

    private int bitField0_;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return Whether the result field is set.
     */
    @java.lang.Override
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     * @return The result.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }
    /**
     * <code>optional .hbase.pb.Result result = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }

    public static final int PROCESSED_FIELD_NUMBER = 2;
    private boolean processed_ = false;
    /**
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     *
     * <code>optional bool processed = 2;</code>
     * @return Whether the processed field is set.
     */
    @java.lang.Override
    public boolean hasProcessed() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     *
     * <code>optional bool processed = 2;</code>
     * @return The processed.
     */
    @java.lang.Override
    public boolean getProcessed() {
      return processed_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getResult());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, processed_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getResult());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, processed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse) obj;

      if (hasResult() != other.hasResult()) return false;
      if (hasResult()) {
        if (!getResult()
            .equals(other.getResult())) return false;
      }
      if (hasProcessed() != other.hasProcessed()) return false;
      if (hasProcessed()) {
        if (getProcessed()
            != other.getProcessed()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasProcessed()) {
        hash = (37 * hash) + PROCESSED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getProcessed());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MutateResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MutateResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        processed_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MutateResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.result_ = resultBuilder_ == null
              ? result_
              : resultBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.processed_ = processed_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasProcessed()) {
          setProcessed(other.getProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                processed_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       * @return Whether the result field is set.
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       * @return The result.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder setResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder setResult(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder mergeResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            result_ != null &&
            result_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            getResultBuilder().mergeFrom(value);
          } else {
            result_ = value;
          }
        } else {
          resultBuilder_.mergeFrom(value);
        }
        if (result_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public Builder clearResult() {
        bitField0_ = (bitField0_ & ~0x00000001);
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  getResult(),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      private boolean processed_ ;
      /**
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       *
       * <code>optional bool processed = 2;</code>
       * @return Whether the processed field is set.
       */
      @java.lang.Override
      public boolean hasProcessed() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       *
       * <code>optional bool processed = 2;</code>
       * @return The processed.
       */
      @java.lang.Override
      public boolean getProcessed() {
        return processed_;
      }
      /**
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       *
       * <code>optional bool processed = 2;</code>
       * @param value The processed to set.
       * @return This builder for chaining.
       */
      public Builder setProcessed(boolean value) {

        processed_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       *
       * <code>optional bool processed = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearProcessed() {
        bitField0_ = (bitField0_ & ~0x00000002);
        processed_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MutateResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MutateResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MutateResponse>() {
      @java.lang.Override
      public MutateResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MutateResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ScanOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Scan)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index);
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    int getColumnCount();
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    /**
     * <code>optional bytes start_row = 3;</code>
     * @return Whether the startRow field is set.
     */
    boolean hasStartRow();
    /**
     * <code>optional bytes start_row = 3;</code>
     * @return The startRow.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow();

    /**
     * <code>optional bytes stop_row = 4;</code>
     * @return Whether the stopRow field is set.
     */
    boolean hasStopRow();
    /**
     * <code>optional bytes stop_row = 4;</code>
     * @return The stopRow.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow();

    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();

    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return Whether the timeRange field is set.
     */
    boolean hasTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return The timeRange.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     * @return Whether the maxVersions field is set.
     */
    boolean hasMaxVersions();
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     * @return The maxVersions.
     */
    int getMaxVersions();

    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     * @return Whether the cacheBlocks field is set.
     */
    boolean hasCacheBlocks();
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     * @return The cacheBlocks.
     */
    boolean getCacheBlocks();

    /**
     * <code>optional uint32 batch_size = 9;</code>
     * @return Whether the batchSize field is set.
     */
    boolean hasBatchSize();
    /**
     * <code>optional uint32 batch_size = 9;</code>
     * @return The batchSize.
     */
    int getBatchSize();

    /**
     * <code>optional uint64 max_result_size = 10;</code>
     * @return Whether the maxResultSize field is set.
     */
    boolean hasMaxResultSize();
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     * @return The maxResultSize.
     */
    long getMaxResultSize();

    /**
     * <code>optional uint32 store_limit = 11;</code>
     * @return Whether the storeLimit field is set.
     */
    boolean hasStoreLimit();
    /**
     * <code>optional uint32 store_limit = 11;</code>
     * @return The storeLimit.
     */
    int getStoreLimit();

    /**
     * <code>optional uint32 store_offset = 12;</code>
     * @return Whether the storeOffset field is set.
     */
    boolean hasStoreOffset();
    /**
     * <code>optional uint32 store_offset = 12;</code>
     * @return The storeOffset.
     */
    int getStoreOffset();

    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 13;</code>
     * @return Whether the loadColumnFamiliesOnDemand field is set.
     */
    boolean hasLoadColumnFamiliesOnDemand();
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 13;</code>
     * @return The loadColumnFamiliesOnDemand.
     */
    boolean getLoadColumnFamiliesOnDemand();

    /**
     * <code>optional bool small = 14 [deprecated = true];</code>
     * @deprecated hbase.pb.Scan.small is deprecated.
     *     See Client.proto;l=260
     * @return Whether the small field is set.
     */
    @java.lang.Deprecated boolean hasSmall();
    /**
     * <code>optional bool small = 14 [deprecated = true];</code>
     * @deprecated hbase.pb.Scan.small is deprecated.
     *     See Client.proto;l=260
     * @return The small.
     */
    @java.lang.Deprecated boolean getSmall();

    /**
     * <code>optional bool reversed = 15 [default = false];</code>
     * @return Whether the reversed field is set.
     */
    boolean hasReversed();
    /**
     * <code>optional bool reversed = 15 [default = false];</code>
     * @return The reversed.
     */
    boolean getReversed();

    /**
     * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
     * @return Whether the consistency field is set.
     */
    boolean hasConsistency();
    /**
     * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
     * @return The consistency.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency();

    /**
     * <code>optional uint32 caching = 17;</code>
     * @return Whether the caching field is set.
     */
    boolean hasCaching();
    /**
     * <code>optional uint32 caching = 17;</code>
     * @return The caching.
     */
    int getCaching();

    /**
     * <code>optional bool allow_partial_results = 18;</code>
     * @return Whether the allowPartialResults field is set.
     */
    boolean hasAllowPartialResults();
    /**
     * <code>optional bool allow_partial_results = 18;</code>
     * @return The allowPartialResults.
     */
    boolean getAllowPartialResults();

    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> 
        getCfTimeRangeList();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index);
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    int getCfTimeRangeCount();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
        getCfTimeRangeOrBuilderList();
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
        int index);

    /**
     * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
     * @return Whether the mvccReadPoint field is set.
     */
    boolean hasMvccReadPoint();
    /**
     * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
     * @return The mvccReadPoint.
     */
    long getMvccReadPoint();

    /**
     * <code>optional bool include_start_row = 21 [default = true];</code>
     * @return Whether the includeStartRow field is set.
     */
    boolean hasIncludeStartRow();
    /**
     * <code>optional bool include_start_row = 21 [default = true];</code>
     * @return The includeStartRow.
     */
    boolean getIncludeStartRow();

    /**
     * <code>optional bool include_stop_row = 22 [default = false];</code>
     * @return Whether the includeStopRow field is set.
     */
    boolean hasIncludeStopRow();
    /**
     * <code>optional bool include_stop_row = 22 [default = false];</code>
     * @return The includeStopRow.
     */
    boolean getIncludeStopRow();

    /**
     * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
     * @return Whether the readType field is set.
     */
    boolean hasReadType();
    /**
     * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
     * @return The readType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType getReadType();

    /**
     * <code>optional bool need_cursor_result = 24 [default = false];</code>
     * @return Whether the needCursorResult field is set.
     */
    boolean hasNeedCursorResult();
    /**
     * <code>optional bool need_cursor_result = 24 [default = false];</code>
     * @return The needCursorResult.
     */
    boolean getNeedCursorResult();
  }
  /**
   * <pre>
   **
   * Instead of get from a table, you can scan it with optional filters.
   * You can specify the row key range, time range, the columns/families
   * to scan and so on.
   *
   * This scan is used the first time in a scan request. The response of
   * the initial scan will return a scanner id, which should be used to
   * fetch result batches later on before it is closed.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Scan}
   */
  @javax.annotation.Generated("proto") public static final class Scan extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Scan)
      ScanOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Scan.newBuilder() to construct.
    private Scan(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Scan() {
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      maxVersions_ = 1;
      cacheBlocks_ = true;
      consistency_ = 0;
      cfTimeRange_ = java.util.Collections.emptyList();
      includeStartRow_ = true;
      readType_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Scan();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Scan_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Scan_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.Scan.ReadType}
     */
    public enum ReadType
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>DEFAULT = 0;</code>
       */
      DEFAULT(0),
      /**
       * <code>STREAM = 1;</code>
       */
      STREAM(1),
      /**
       * <code>PREAD = 2;</code>
       */
      PREAD(2),
      ;

      /**
       * <code>DEFAULT = 0;</code>
       */
      public static final int DEFAULT_VALUE = 0;
      /**
       * <code>STREAM = 1;</code>
       */
      public static final int STREAM_VALUE = 1;
      /**
       * <code>PREAD = 2;</code>
       */
      public static final int PREAD_VALUE = 2;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static ReadType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static ReadType forNumber(int value) {
        switch (value) {
          case 0: return DEFAULT;
          case 1: return STREAM;
          case 2: return PREAD;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReadType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          ReadType> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ReadType>() {
              public ReadType findValueByNumber(int number) {
                return ReadType.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDescriptor().getEnumTypes().get(0);
      }

      private static final ReadType[] VALUES = values();

      public static ReadType valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private ReadType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.Scan.ReadType)
    }

    private int bitField0_;
    public static final int COLUMN_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> column_;
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    @java.lang.Override
    public int getColumnCount() {
      return column_.size();
    }
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Column column = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }

    public static final int ATTRIBUTE_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    @java.lang.Override
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    public static final int START_ROW_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes start_row = 3;</code>
     * @return Whether the startRow field is set.
     */
    @java.lang.Override
    public boolean hasStartRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes start_row = 3;</code>
     * @return The startRow.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow() {
      return startRow_;
    }

    public static final int STOP_ROW_FIELD_NUMBER = 4;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes stop_row = 4;</code>
     * @return Whether the stopRow field is set.
     */
    @java.lang.Override
    public boolean hasStopRow() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes stop_row = 4;</code>
     * @return The stopRow.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow() {
      return stopRow_;
    }

    public static final int FILTER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>optional .hbase.pb.Filter filter = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    public static final int TIME_RANGE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return Whether the timeRange field is set.
     */
    @java.lang.Override
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     * @return The timeRange.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }
    /**
     * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
    }

    public static final int MAX_VERSIONS_FIELD_NUMBER = 7;
    private int maxVersions_ = 1;
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     * @return Whether the maxVersions field is set.
     */
    @java.lang.Override
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     * @return The maxVersions.
     */
    @java.lang.Override
    public int getMaxVersions() {
      return maxVersions_;
    }

    public static final int CACHE_BLOCKS_FIELD_NUMBER = 8;
    private boolean cacheBlocks_ = true;
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     * @return Whether the cacheBlocks field is set.
     */
    @java.lang.Override
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     * @return The cacheBlocks.
     */
    @java.lang.Override
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }

    public static final int BATCH_SIZE_FIELD_NUMBER = 9;
    private int batchSize_ = 0;
    /**
     * <code>optional uint32 batch_size = 9;</code>
     * @return Whether the batchSize field is set.
     */
    @java.lang.Override
    public boolean hasBatchSize() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional uint32 batch_size = 9;</code>
     * @return The batchSize.
     */
    @java.lang.Override
    public int getBatchSize() {
      return batchSize_;
    }

    public static final int MAX_RESULT_SIZE_FIELD_NUMBER = 10;
    private long maxResultSize_ = 0L;
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     * @return Whether the maxResultSize field is set.
     */
    @java.lang.Override
    public boolean hasMaxResultSize() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     * @return The maxResultSize.
     */
    @java.lang.Override
    public long getMaxResultSize() {
      return maxResultSize_;
    }

    public static final int STORE_LIMIT_FIELD_NUMBER = 11;
    private int storeLimit_ = 0;
    /**
     * <code>optional uint32 store_limit = 11;</code>
     * @return Whether the storeLimit field is set.
     */
    @java.lang.Override
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <code>optional uint32 store_limit = 11;</code>
     * @return The storeLimit.
     */
    @java.lang.Override
    public int getStoreLimit() {
      return storeLimit_;
    }

    public static final int STORE_OFFSET_FIELD_NUMBER = 12;
    private int storeOffset_ = 0;
    /**
     * <code>optional uint32 store_offset = 12;</code>
     * @return Whether the storeOffset field is set.
     */
    @java.lang.Override
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000200) != 0);
    }
    /**
     * <code>optional uint32 store_offset = 12;</code>
     * @return The storeOffset.
     */
    @java.lang.Override
    public int getStoreOffset() {
      return storeOffset_;
    }

    public static final int LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER = 13;
    private boolean loadColumnFamiliesOnDemand_ = false;
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 13;</code>
     * @return Whether the loadColumnFamiliesOnDemand field is set.
     */
    @java.lang.Override
    public boolean hasLoadColumnFamiliesOnDemand() {
      return ((bitField0_ & 0x00000400) != 0);
    }
    /**
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     *
     * <code>optional bool load_column_families_on_demand = 13;</code>
     * @return The loadColumnFamiliesOnDemand.
     */
    @java.lang.Override
    public boolean getLoadColumnFamiliesOnDemand() {
      return loadColumnFamiliesOnDemand_;
    }

    public static final int SMALL_FIELD_NUMBER = 14;
    private boolean small_ = false;
    /**
     * <code>optional bool small = 14 [deprecated = true];</code>
     * @deprecated hbase.pb.Scan.small is deprecated.
     *     See Client.proto;l=260
     * @return Whether the small field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasSmall() {
      return ((bitField0_ & 0x00000800) != 0);
    }
    /**
     * <code>optional bool small = 14 [deprecated = true];</code>
     * @deprecated hbase.pb.Scan.small is deprecated.
     *     See Client.proto;l=260
     * @return The small.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean getSmall() {
      return small_;
    }

    public static final int REVERSED_FIELD_NUMBER = 15;
    private boolean reversed_ = false;
    /**
     * <code>optional bool reversed = 15 [default = false];</code>
     * @return Whether the reversed field is set.
     */
    @java.lang.Override
    public boolean hasReversed() {
      return ((bitField0_ & 0x00001000) != 0);
    }
    /**
     * <code>optional bool reversed = 15 [default = false];</code>
     * @return The reversed.
     */
    @java.lang.Override
    public boolean getReversed() {
      return reversed_;
    }

    public static final int CONSISTENCY_FIELD_NUMBER = 16;
    private int consistency_ = 0;
    /**
     * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
     * @return Whether the consistency field is set.
     */
    @java.lang.Override public boolean hasConsistency() {
      return ((bitField0_ & 0x00002000) != 0);
    }
    /**
     * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
     * @return The consistency.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(consistency_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.STRONG : result;
    }

    public static final int CACHING_FIELD_NUMBER = 17;
    private int caching_ = 0;
    /**
     * <code>optional uint32 caching = 17;</code>
     * @return Whether the caching field is set.
     */
    @java.lang.Override
    public boolean hasCaching() {
      return ((bitField0_ & 0x00004000) != 0);
    }
    /**
     * <code>optional uint32 caching = 17;</code>
     * @return The caching.
     */
    @java.lang.Override
    public int getCaching() {
      return caching_;
    }

    public static final int ALLOW_PARTIAL_RESULTS_FIELD_NUMBER = 18;
    private boolean allowPartialResults_ = false;
    /**
     * <code>optional bool allow_partial_results = 18;</code>
     * @return Whether the allowPartialResults field is set.
     */
    @java.lang.Override
    public boolean hasAllowPartialResults() {
      return ((bitField0_ & 0x00008000) != 0);
    }
    /**
     * <code>optional bool allow_partial_results = 18;</code>
     * @return The allowPartialResults.
     */
    @java.lang.Override
    public boolean getAllowPartialResults() {
      return allowPartialResults_;
    }

    public static final int CF_TIME_RANGE_FIELD_NUMBER = 19;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> cfTimeRange_;
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> getCfTimeRangeList() {
      return cfTimeRange_;
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
        getCfTimeRangeOrBuilderList() {
      return cfTimeRange_;
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    @java.lang.Override
    public int getCfTimeRangeCount() {
      return cfTimeRange_.size();
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index) {
      return cfTimeRange_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
        int index) {
      return cfTimeRange_.get(index);
    }

    public static final int MVCC_READ_POINT_FIELD_NUMBER = 20;
    private long mvccReadPoint_ = 0L;
    /**
     * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
     * @return Whether the mvccReadPoint field is set.
     */
    @java.lang.Override
    public boolean hasMvccReadPoint() {
      return ((bitField0_ & 0x00010000) != 0);
    }
    /**
     * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
     * @return The mvccReadPoint.
     */
    @java.lang.Override
    public long getMvccReadPoint() {
      return mvccReadPoint_;
    }

    public static final int INCLUDE_START_ROW_FIELD_NUMBER = 21;
    private boolean includeStartRow_ = true;
    /**
     * <code>optional bool include_start_row = 21 [default = true];</code>
     * @return Whether the includeStartRow field is set.
     */
    @java.lang.Override
    public boolean hasIncludeStartRow() {
      return ((bitField0_ & 0x00020000) != 0);
    }
    /**
     * <code>optional bool include_start_row = 21 [default = true];</code>
     * @return The includeStartRow.
     */
    @java.lang.Override
    public boolean getIncludeStartRow() {
      return includeStartRow_;
    }

    public static final int INCLUDE_STOP_ROW_FIELD_NUMBER = 22;
    private boolean includeStopRow_ = false;
    /**
     * <code>optional bool include_stop_row = 22 [default = false];</code>
     * @return Whether the includeStopRow field is set.
     */
    @java.lang.Override
    public boolean hasIncludeStopRow() {
      return ((bitField0_ & 0x00040000) != 0);
    }
    /**
     * <code>optional bool include_stop_row = 22 [default = false];</code>
     * @return The includeStopRow.
     */
    @java.lang.Override
    public boolean getIncludeStopRow() {
      return includeStopRow_;
    }

    public static final int READTYPE_FIELD_NUMBER = 23;
    private int readType_ = 0;
    /**
     * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
     * @return Whether the readType field is set.
     */
    @java.lang.Override public boolean hasReadType() {
      return ((bitField0_ & 0x00080000) != 0);
    }
    /**
     * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
     * @return The readType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType getReadType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType.forNumber(readType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType.DEFAULT : result;
    }

    public static final int NEED_CURSOR_RESULT_FIELD_NUMBER = 24;
    private boolean needCursorResult_ = false;
    /**
     * <code>optional bool need_cursor_result = 24 [default = false];</code>
     * @return Whether the needCursorResult field is set.
     */
    @java.lang.Override
    public boolean hasNeedCursorResult() {
      return ((bitField0_ & 0x00100000) != 0);
    }
    /**
     * <code>optional bool need_cursor_result = 24 [default = false];</code>
     * @return The needCursorResult.
     */
    @java.lang.Override
    public boolean getNeedCursorResult() {
      return needCursorResult_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getCfTimeRangeCount(); i++) {
        if (!getCfTimeRange(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(5, getFilter());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(6, getTimeRange());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeUInt32(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeUInt32(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeUInt64(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeUInt32(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        output.writeUInt32(12, storeOffset_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        output.writeBool(13, loadColumnFamiliesOnDemand_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        output.writeBool(14, small_);
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        output.writeBool(15, reversed_);
      }
      if (((bitField0_ & 0x00002000) != 0)) {
        output.writeEnum(16, consistency_);
      }
      if (((bitField0_ & 0x00004000) != 0)) {
        output.writeUInt32(17, caching_);
      }
      if (((bitField0_ & 0x00008000) != 0)) {
        output.writeBool(18, allowPartialResults_);
      }
      for (int i = 0; i < cfTimeRange_.size(); i++) {
        output.writeMessage(19, cfTimeRange_.get(i));
      }
      if (((bitField0_ & 0x00010000) != 0)) {
        output.writeUInt64(20, mvccReadPoint_);
      }
      if (((bitField0_ & 0x00020000) != 0)) {
        output.writeBool(21, includeStartRow_);
      }
      if (((bitField0_ & 0x00040000) != 0)) {
        output.writeBool(22, includeStopRow_);
      }
      if (((bitField0_ & 0x00080000) != 0)) {
        output.writeEnum(23, readType_);
      }
      if (((bitField0_ & 0x00100000) != 0)) {
        output.writeBool(24, needCursorResult_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < column_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getFilter());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getTimeRange());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, storeOffset_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(13, loadColumnFamiliesOnDemand_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(14, small_);
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(15, reversed_);
      }
      if (((bitField0_ & 0x00002000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(16, consistency_);
      }
      if (((bitField0_ & 0x00004000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(17, caching_);
      }
      if (((bitField0_ & 0x00008000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(18, allowPartialResults_);
      }
      for (int i = 0; i < cfTimeRange_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, cfTimeRange_.get(i));
      }
      if (((bitField0_ & 0x00010000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(20, mvccReadPoint_);
      }
      if (((bitField0_ & 0x00020000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(21, includeStartRow_);
      }
      if (((bitField0_ & 0x00040000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(22, includeStopRow_);
      }
      if (((bitField0_ & 0x00080000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(23, readType_);
      }
      if (((bitField0_ & 0x00100000) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(24, needCursorResult_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan) obj;

      if (!getColumnList()
          .equals(other.getColumnList())) return false;
      if (!getAttributeList()
          .equals(other.getAttributeList())) return false;
      if (hasStartRow() != other.hasStartRow()) return false;
      if (hasStartRow()) {
        if (!getStartRow()
            .equals(other.getStartRow())) return false;
      }
      if (hasStopRow() != other.hasStopRow()) return false;
      if (hasStopRow()) {
        if (!getStopRow()
            .equals(other.getStopRow())) return false;
      }
      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (hasTimeRange() != other.hasTimeRange()) return false;
      if (hasTimeRange()) {
        if (!getTimeRange()
            .equals(other.getTimeRange())) return false;
      }
      if (hasMaxVersions() != other.hasMaxVersions()) return false;
      if (hasMaxVersions()) {
        if (getMaxVersions()
            != other.getMaxVersions()) return false;
      }
      if (hasCacheBlocks() != other.hasCacheBlocks()) return false;
      if (hasCacheBlocks()) {
        if (getCacheBlocks()
            != other.getCacheBlocks()) return false;
      }
      if (hasBatchSize() != other.hasBatchSize()) return false;
      if (hasBatchSize()) {
        if (getBatchSize()
            != other.getBatchSize()) return false;
      }
      if (hasMaxResultSize() != other.hasMaxResultSize()) return false;
      if (hasMaxResultSize()) {
        if (getMaxResultSize()
            != other.getMaxResultSize()) return false;
      }
      if (hasStoreLimit() != other.hasStoreLimit()) return false;
      if (hasStoreLimit()) {
        if (getStoreLimit()
            != other.getStoreLimit()) return false;
      }
      if (hasStoreOffset() != other.hasStoreOffset()) return false;
      if (hasStoreOffset()) {
        if (getStoreOffset()
            != other.getStoreOffset()) return false;
      }
      if (hasLoadColumnFamiliesOnDemand() != other.hasLoadColumnFamiliesOnDemand()) return false;
      if (hasLoadColumnFamiliesOnDemand()) {
        if (getLoadColumnFamiliesOnDemand()
            != other.getLoadColumnFamiliesOnDemand()) return false;
      }
      if (hasSmall() != other.hasSmall()) return false;
      if (hasSmall()) {
        if (getSmall()
            != other.getSmall()) return false;
      }
      if (hasReversed() != other.hasReversed()) return false;
      if (hasReversed()) {
        if (getReversed()
            != other.getReversed()) return false;
      }
      if (hasConsistency() != other.hasConsistency()) return false;
      if (hasConsistency()) {
        if (consistency_ != other.consistency_) return false;
      }
      if (hasCaching() != other.hasCaching()) return false;
      if (hasCaching()) {
        if (getCaching()
            != other.getCaching()) return false;
      }
      if (hasAllowPartialResults() != other.hasAllowPartialResults()) return false;
      if (hasAllowPartialResults()) {
        if (getAllowPartialResults()
            != other.getAllowPartialResults()) return false;
      }
      if (!getCfTimeRangeList()
          .equals(other.getCfTimeRangeList())) return false;
      if (hasMvccReadPoint() != other.hasMvccReadPoint()) return false;
      if (hasMvccReadPoint()) {
        if (getMvccReadPoint()
            != other.getMvccReadPoint()) return false;
      }
      if (hasIncludeStartRow() != other.hasIncludeStartRow()) return false;
      if (hasIncludeStartRow()) {
        if (getIncludeStartRow()
            != other.getIncludeStartRow()) return false;
      }
      if (hasIncludeStopRow() != other.hasIncludeStopRow()) return false;
      if (hasIncludeStopRow()) {
        if (getIncludeStopRow()
            != other.getIncludeStopRow()) return false;
      }
      if (hasReadType() != other.hasReadType()) return false;
      if (hasReadType()) {
        if (readType_ != other.readType_) return false;
      }
      if (hasNeedCursorResult() != other.hasNeedCursorResult()) return false;
      if (hasNeedCursorResult()) {
        if (getNeedCursorResult()
            != other.getNeedCursorResult()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasStartRow()) {
        hash = (37 * hash) + START_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStartRow().hashCode();
      }
      if (hasStopRow()) {
        hash = (37 * hash) + STOP_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStopRow().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAX_VERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHE_BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCacheBlocks());
      }
      if (hasBatchSize()) {
        hash = (37 * hash) + BATCH_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getBatchSize();
      }
      if (hasMaxResultSize()) {
        hash = (37 * hash) + MAX_RESULT_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getMaxResultSize());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STORE_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      if (hasLoadColumnFamiliesOnDemand()) {
        hash = (37 * hash) + LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getLoadColumnFamiliesOnDemand());
      }
      if (hasSmall()) {
        hash = (37 * hash) + SMALL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSmall());
      }
      if (hasReversed()) {
        hash = (37 * hash) + REVERSED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getReversed());
      }
      if (hasConsistency()) {
        hash = (37 * hash) + CONSISTENCY_FIELD_NUMBER;
        hash = (53 * hash) + consistency_;
      }
      if (hasCaching()) {
        hash = (37 * hash) + CACHING_FIELD_NUMBER;
        hash = (53 * hash) + getCaching();
      }
      if (hasAllowPartialResults()) {
        hash = (37 * hash) + ALLOW_PARTIAL_RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getAllowPartialResults());
      }
      if (getCfTimeRangeCount() > 0) {
        hash = (37 * hash) + CF_TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getCfTimeRangeList().hashCode();
      }
      if (hasMvccReadPoint()) {
        hash = (37 * hash) + MVCC_READ_POINT_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getMvccReadPoint());
      }
      if (hasIncludeStartRow()) {
        hash = (37 * hash) + INCLUDE_START_ROW_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getIncludeStartRow());
      }
      if (hasIncludeStopRow()) {
        hash = (37 * hash) + INCLUDE_STOP_ROW_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getIncludeStopRow());
      }
      if (hasReadType()) {
        hash = (37 * hash) + READTYPE_FIELD_NUMBER;
        hash = (53 * hash) + readType_;
      }
      if (hasNeedCursorResult()) {
        hash = (37 * hash) + NEED_CURSOR_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getNeedCursorResult());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Instead of get from a table, you can scan it with optional filters.
     * You can specify the row key range, time range, the columns/families
     * to scan and so on.
     *
     * This scan is used the first time in a scan request. The response of
     * the initial scan will return a scanner id, which should be used to
     * fetch result batches later on before it is closed.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Scan}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Scan)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Scan_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Scan_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
          getCfTimeRangeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
        } else {
          column_ = null;
          columnBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
        } else {
          attribute_ = null;
          attributeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        maxVersions_ = 1;
        cacheBlocks_ = true;
        batchSize_ = 0;
        maxResultSize_ = 0L;
        storeLimit_ = 0;
        storeOffset_ = 0;
        loadColumnFamiliesOnDemand_ = false;
        small_ = false;
        reversed_ = false;
        consistency_ = 0;
        caching_ = 0;
        allowPartialResults_ = false;
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRange_ = java.util.Collections.emptyList();
        } else {
          cfTimeRange_ = null;
          cfTimeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        mvccReadPoint_ = 0L;
        includeStartRow_ = true;
        includeStopRow_ = false;
        readType_ = 0;
        needCursorResult_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Scan_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan result) {
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (cfTimeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00040000) != 0)) {
            cfTimeRange_ = java.util.Collections.unmodifiableList(cfTimeRange_);
            bitField0_ = (bitField0_ & ~0x00040000);
          }
          result.cfTimeRange_ = cfTimeRange_;
        } else {
          result.cfTimeRange_ = cfTimeRangeBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.startRow_ = startRow_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.stopRow_ = stopRow_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.timeRange_ = timeRangeBuilder_ == null
              ? timeRange_
              : timeRangeBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.maxVersions_ = maxVersions_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.cacheBlocks_ = cacheBlocks_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.batchSize_ = batchSize_;
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.maxResultSize_ = maxResultSize_;
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.storeLimit_ = storeLimit_;
          to_bitField0_ |= 0x00000100;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          result.storeOffset_ = storeOffset_;
          to_bitField0_ |= 0x00000200;
        }
        if (((from_bitField0_ & 0x00001000) != 0)) {
          result.loadColumnFamiliesOnDemand_ = loadColumnFamiliesOnDemand_;
          to_bitField0_ |= 0x00000400;
        }
        if (((from_bitField0_ & 0x00002000) != 0)) {
          result.small_ = small_;
          to_bitField0_ |= 0x00000800;
        }
        if (((from_bitField0_ & 0x00004000) != 0)) {
          result.reversed_ = reversed_;
          to_bitField0_ |= 0x00001000;
        }
        if (((from_bitField0_ & 0x00008000) != 0)) {
          result.consistency_ = consistency_;
          to_bitField0_ |= 0x00002000;
        }
        if (((from_bitField0_ & 0x00010000) != 0)) {
          result.caching_ = caching_;
          to_bitField0_ |= 0x00004000;
        }
        if (((from_bitField0_ & 0x00020000) != 0)) {
          result.allowPartialResults_ = allowPartialResults_;
          to_bitField0_ |= 0x00008000;
        }
        if (((from_bitField0_ & 0x00080000) != 0)) {
          result.mvccReadPoint_ = mvccReadPoint_;
          to_bitField0_ |= 0x00010000;
        }
        if (((from_bitField0_ & 0x00100000) != 0)) {
          result.includeStartRow_ = includeStartRow_;
          to_bitField0_ |= 0x00020000;
        }
        if (((from_bitField0_ & 0x00200000) != 0)) {
          result.includeStopRow_ = includeStopRow_;
          to_bitField0_ |= 0x00040000;
        }
        if (((from_bitField0_ & 0x00400000) != 0)) {
          result.readType_ = readType_;
          to_bitField0_ |= 0x00080000;
        }
        if (((from_bitField0_ & 0x00800000) != 0)) {
          result.needCursorResult_ = needCursorResult_;
          to_bitField0_ |= 0x00100000;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) return this;
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
              columnBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
              attributeBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasStartRow()) {
          setStartRow(other.getStartRow());
        }
        if (other.hasStopRow()) {
          setStopRow(other.getStopRow());
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasBatchSize()) {
          setBatchSize(other.getBatchSize());
        }
        if (other.hasMaxResultSize()) {
          setMaxResultSize(other.getMaxResultSize());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        if (other.hasLoadColumnFamiliesOnDemand()) {
          setLoadColumnFamiliesOnDemand(other.getLoadColumnFamiliesOnDemand());
        }
        if (other.hasSmall()) {
          setSmall(other.getSmall());
        }
        if (other.hasReversed()) {
          setReversed(other.getReversed());
        }
        if (other.hasConsistency()) {
          setConsistency(other.getConsistency());
        }
        if (other.hasCaching()) {
          setCaching(other.getCaching());
        }
        if (other.hasAllowPartialResults()) {
          setAllowPartialResults(other.getAllowPartialResults());
        }
        if (cfTimeRangeBuilder_ == null) {
          if (!other.cfTimeRange_.isEmpty()) {
            if (cfTimeRange_.isEmpty()) {
              cfTimeRange_ = other.cfTimeRange_;
              bitField0_ = (bitField0_ & ~0x00040000);
            } else {
              ensureCfTimeRangeIsMutable();
              cfTimeRange_.addAll(other.cfTimeRange_);
            }
            onChanged();
          }
        } else {
          if (!other.cfTimeRange_.isEmpty()) {
            if (cfTimeRangeBuilder_.isEmpty()) {
              cfTimeRangeBuilder_.dispose();
              cfTimeRangeBuilder_ = null;
              cfTimeRange_ = other.cfTimeRange_;
              bitField0_ = (bitField0_ & ~0x00040000);
              cfTimeRangeBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getCfTimeRangeFieldBuilder() : null;
            } else {
              cfTimeRangeBuilder_.addAllMessages(other.cfTimeRange_);
            }
          }
        }
        if (other.hasMvccReadPoint()) {
          setMvccReadPoint(other.getMvccReadPoint());
        }
        if (other.hasIncludeStartRow()) {
          setIncludeStartRow(other.getIncludeStartRow());
        }
        if (other.hasIncludeStopRow()) {
          setIncludeStopRow(other.getIncludeStopRow());
        }
        if (other.hasReadType()) {
          setReadType(other.getReadType());
        }
        if (other.hasNeedCursorResult()) {
          setNeedCursorResult(other.getNeedCursorResult());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getCfTimeRangeCount(); i++) {
          if (!getCfTimeRange(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.PARSER,
                        extensionRegistry);
                if (columnBuilder_ == null) {
                  ensureColumnIsMutable();
                  column_.add(m);
                } else {
                  columnBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.PARSER,
                        extensionRegistry);
                if (attributeBuilder_ == null) {
                  ensureAttributeIsMutable();
                  attribute_.add(m);
                } else {
                  attributeBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 26: {
                startRow_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                stopRow_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 50: {
                input.readMessage(
                    getTimeRangeFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000020;
                break;
              } // case 50
              case 56: {
                maxVersions_ = input.readUInt32();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              case 64: {
                cacheBlocks_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 72: {
                batchSize_ = input.readUInt32();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              case 80: {
                maxResultSize_ = input.readUInt64();
                bitField0_ |= 0x00000200;
                break;
              } // case 80
              case 88: {
                storeLimit_ = input.readUInt32();
                bitField0_ |= 0x00000400;
                break;
              } // case 88
              case 96: {
                storeOffset_ = input.readUInt32();
                bitField0_ |= 0x00000800;
                break;
              } // case 96
              case 104: {
                loadColumnFamiliesOnDemand_ = input.readBool();
                bitField0_ |= 0x00001000;
                break;
              } // case 104
              case 112: {
                small_ = input.readBool();
                bitField0_ |= 0x00002000;
                break;
              } // case 112
              case 120: {
                reversed_ = input.readBool();
                bitField0_ |= 0x00004000;
                break;
              } // case 120
              case 128: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(16, tmpRaw);
                } else {
                  consistency_ = tmpRaw;
                  bitField0_ |= 0x00008000;
                }
                break;
              } // case 128
              case 136: {
                caching_ = input.readUInt32();
                bitField0_ |= 0x00010000;
                break;
              } // case 136
              case 144: {
                allowPartialResults_ = input.readBool();
                bitField0_ |= 0x00020000;
                break;
              } // case 144
              case 154: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.PARSER,
                        extensionRegistry);
                if (cfTimeRangeBuilder_ == null) {
                  ensureCfTimeRangeIsMutable();
                  cfTimeRange_.add(m);
                } else {
                  cfTimeRangeBuilder_.addMessage(m);
                }
                break;
              } // case 154
              case 160: {
                mvccReadPoint_ = input.readUInt64();
                bitField0_ |= 0x00080000;
                break;
              } // case 160
              case 168: {
                includeStartRow_ = input.readBool();
                bitField0_ |= 0x00100000;
                break;
              } // case 168
              case 176: {
                includeStopRow_ = input.readBool();
                bitField0_ |= 0x00200000;
                break;
              } // case 176
              case 184: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(23, tmpRaw);
                } else {
                  readType_ = tmpRaw;
                  bitField0_ |= 0x00400000;
                }
                break;
              } // case 184
              case 192: {
                needCursorResult_ = input.readBool();
                bitField0_ |= 0x00800000;
                break;
              } // case 192
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;

      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder addColumn(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder addColumn(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Column column = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.NameBytesPair attribute = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes start_row = 3;</code>
       * @return Whether the startRow field is set.
       */
      @java.lang.Override
      public boolean hasStartRow() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       * @return The startRow.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow() {
        return startRow_;
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       * @param value The startRow to set.
       * @return This builder for chaining.
       */
      public Builder setStartRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        startRow_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearStartRow() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startRow_ = getDefaultInstance().getStartRow();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes stop_row = 4;</code>
       * @return Whether the stopRow field is set.
       */
      @java.lang.Override
      public boolean hasStopRow() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       * @return The stopRow.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow() {
        return stopRow_;
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       * @param value The stopRow to set.
       * @return This builder for chaining.
       */
      public Builder setStopRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        stopRow_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearStopRow() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stopRow_ = getDefaultInstance().getStopRow();
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000010);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>optional .hbase.pb.Filter filter = 5;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange timeRange_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       * @return Whether the timeRange field is set.
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       * @return The timeRange.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
            timeRange_ != null &&
            timeRange_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            getTimeRangeBuilder().mergeFrom(value);
          } else {
            timeRange_ = value;
          }
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        if (timeRange_ != null) {
          bitField0_ |= 0x00000020;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public Builder clearTimeRange() {
        bitField0_ = (bitField0_ & ~0x00000020);
        timeRange_ = null;
        if (timeRangeBuilder_ != null) {
          timeRangeBuilder_.dispose();
          timeRangeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance() : timeRange_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimeRange time_range = 6;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  getTimeRange(),
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      private int maxVersions_ = 1;
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       * @return Whether the maxVersions field is set.
       */
      @java.lang.Override
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       * @return The maxVersions.
       */
      @java.lang.Override
      public int getMaxVersions() {
        return maxVersions_;
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       * @param value The maxVersions to set.
       * @return This builder for chaining.
       */
      public Builder setMaxVersions(int value) {

        maxVersions_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000040);
        maxVersions_ = 1;
        onChanged();
        return this;
      }

      private boolean cacheBlocks_ = true;
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       * @return Whether the cacheBlocks field is set.
       */
      @java.lang.Override
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       * @return The cacheBlocks.
       */
      @java.lang.Override
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       * @param value The cacheBlocks to set.
       * @return This builder for chaining.
       */
      public Builder setCacheBlocks(boolean value) {

        cacheBlocks_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000080);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }

      private int batchSize_ ;
      /**
       * <code>optional uint32 batch_size = 9;</code>
       * @return Whether the batchSize field is set.
       */
      @java.lang.Override
      public boolean hasBatchSize() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       * @return The batchSize.
       */
      @java.lang.Override
      public int getBatchSize() {
        return batchSize_;
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       * @param value The batchSize to set.
       * @return This builder for chaining.
       */
      public Builder setBatchSize(int value) {

        batchSize_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearBatchSize() {
        bitField0_ = (bitField0_ & ~0x00000100);
        batchSize_ = 0;
        onChanged();
        return this;
      }

      private long maxResultSize_ ;
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       * @return Whether the maxResultSize field is set.
       */
      @java.lang.Override
      public boolean hasMaxResultSize() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       * @return The maxResultSize.
       */
      @java.lang.Override
      public long getMaxResultSize() {
        return maxResultSize_;
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       * @param value The maxResultSize to set.
       * @return This builder for chaining.
       */
      public Builder setMaxResultSize(long value) {

        maxResultSize_ = value;
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxResultSize() {
        bitField0_ = (bitField0_ & ~0x00000200);
        maxResultSize_ = 0L;
        onChanged();
        return this;
      }

      private int storeLimit_ ;
      /**
       * <code>optional uint32 store_limit = 11;</code>
       * @return Whether the storeLimit field is set.
       */
      @java.lang.Override
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       * @return The storeLimit.
       */
      @java.lang.Override
      public int getStoreLimit() {
        return storeLimit_;
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       * @param value The storeLimit to set.
       * @return This builder for chaining.
       */
      public Builder setStoreLimit(int value) {

        storeLimit_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000400);
        storeLimit_ = 0;
        onChanged();
        return this;
      }

      private int storeOffset_ ;
      /**
       * <code>optional uint32 store_offset = 12;</code>
       * @return Whether the storeOffset field is set.
       */
      @java.lang.Override
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       * @return The storeOffset.
       */
      @java.lang.Override
      public int getStoreOffset() {
        return storeOffset_;
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       * @param value The storeOffset to set.
       * @return This builder for chaining.
       */
      public Builder setStoreOffset(int value) {

        storeOffset_ = value;
        bitField0_ |= 0x00000800;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000800);
        storeOffset_ = 0;
        onChanged();
        return this;
      }

      private boolean loadColumnFamiliesOnDemand_ ;
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 13;</code>
       * @return Whether the loadColumnFamiliesOnDemand field is set.
       */
      @java.lang.Override
      public boolean hasLoadColumnFamiliesOnDemand() {
        return ((bitField0_ & 0x00001000) != 0);
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 13;</code>
       * @return The loadColumnFamiliesOnDemand.
       */
      @java.lang.Override
      public boolean getLoadColumnFamiliesOnDemand() {
        return loadColumnFamiliesOnDemand_;
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 13;</code>
       * @param value The loadColumnFamiliesOnDemand to set.
       * @return This builder for chaining.
       */
      public Builder setLoadColumnFamiliesOnDemand(boolean value) {

        loadColumnFamiliesOnDemand_ = value;
        bitField0_ |= 0x00001000;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       *
       * <code>optional bool load_column_families_on_demand = 13;</code>
       * @return This builder for chaining.
       */
      public Builder clearLoadColumnFamiliesOnDemand() {
        bitField0_ = (bitField0_ & ~0x00001000);
        loadColumnFamiliesOnDemand_ = false;
        onChanged();
        return this;
      }

      private boolean small_ ;
      /**
       * <code>optional bool small = 14 [deprecated = true];</code>
       * @deprecated hbase.pb.Scan.small is deprecated.
       *     See Client.proto;l=260
       * @return Whether the small field is set.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean hasSmall() {
        return ((bitField0_ & 0x00002000) != 0);
      }
      /**
       * <code>optional bool small = 14 [deprecated = true];</code>
       * @deprecated hbase.pb.Scan.small is deprecated.
       *     See Client.proto;l=260
       * @return The small.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean getSmall() {
        return small_;
      }
      /**
       * <code>optional bool small = 14 [deprecated = true];</code>
       * @deprecated hbase.pb.Scan.small is deprecated.
       *     See Client.proto;l=260
       * @param value The small to set.
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder setSmall(boolean value) {

        small_ = value;
        bitField0_ |= 0x00002000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool small = 14 [deprecated = true];</code>
       * @deprecated hbase.pb.Scan.small is deprecated.
       *     See Client.proto;l=260
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder clearSmall() {
        bitField0_ = (bitField0_ & ~0x00002000);
        small_ = false;
        onChanged();
        return this;
      }

      private boolean reversed_ ;
      /**
       * <code>optional bool reversed = 15 [default = false];</code>
       * @return Whether the reversed field is set.
       */
      @java.lang.Override
      public boolean hasReversed() {
        return ((bitField0_ & 0x00004000) != 0);
      }
      /**
       * <code>optional bool reversed = 15 [default = false];</code>
       * @return The reversed.
       */
      @java.lang.Override
      public boolean getReversed() {
        return reversed_;
      }
      /**
       * <code>optional bool reversed = 15 [default = false];</code>
       * @param value The reversed to set.
       * @return This builder for chaining.
       */
      public Builder setReversed(boolean value) {

        reversed_ = value;
        bitField0_ |= 0x00004000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool reversed = 15 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearReversed() {
        bitField0_ = (bitField0_ & ~0x00004000);
        reversed_ = false;
        onChanged();
        return this;
      }

      private int consistency_ = 0;
      /**
       * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
       * @return Whether the consistency field is set.
       */
      @java.lang.Override public boolean hasConsistency() {
        return ((bitField0_ & 0x00008000) != 0);
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
       * @return The consistency.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency getConsistency() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.forNumber(consistency_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency.STRONG : result;
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
       * @param value The consistency to set.
       * @return This builder for chaining.
       */
      public Builder setConsistency(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Consistency value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00008000;
        consistency_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Consistency consistency = 16 [default = STRONG];</code>
       * @return This builder for chaining.
       */
      public Builder clearConsistency() {
        bitField0_ = (bitField0_ & ~0x00008000);
        consistency_ = 0;
        onChanged();
        return this;
      }

      private int caching_ ;
      /**
       * <code>optional uint32 caching = 17;</code>
       * @return Whether the caching field is set.
       */
      @java.lang.Override
      public boolean hasCaching() {
        return ((bitField0_ & 0x00010000) != 0);
      }
      /**
       * <code>optional uint32 caching = 17;</code>
       * @return The caching.
       */
      @java.lang.Override
      public int getCaching() {
        return caching_;
      }
      /**
       * <code>optional uint32 caching = 17;</code>
       * @param value The caching to set.
       * @return This builder for chaining.
       */
      public Builder setCaching(int value) {

        caching_ = value;
        bitField0_ |= 0x00010000;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 caching = 17;</code>
       * @return This builder for chaining.
       */
      public Builder clearCaching() {
        bitField0_ = (bitField0_ & ~0x00010000);
        caching_ = 0;
        onChanged();
        return this;
      }

      private boolean allowPartialResults_ ;
      /**
       * <code>optional bool allow_partial_results = 18;</code>
       * @return Whether the allowPartialResults field is set.
       */
      @java.lang.Override
      public boolean hasAllowPartialResults() {
        return ((bitField0_ & 0x00020000) != 0);
      }
      /**
       * <code>optional bool allow_partial_results = 18;</code>
       * @return The allowPartialResults.
       */
      @java.lang.Override
      public boolean getAllowPartialResults() {
        return allowPartialResults_;
      }
      /**
       * <code>optional bool allow_partial_results = 18;</code>
       * @param value The allowPartialResults to set.
       * @return This builder for chaining.
       */
      public Builder setAllowPartialResults(boolean value) {

        allowPartialResults_ = value;
        bitField0_ |= 0x00020000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool allow_partial_results = 18;</code>
       * @return This builder for chaining.
       */
      public Builder clearAllowPartialResults() {
        bitField0_ = (bitField0_ & ~0x00020000);
        allowPartialResults_ = false;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> cfTimeRange_ =
        java.util.Collections.emptyList();
      private void ensureCfTimeRangeIsMutable() {
        if (!((bitField0_ & 0x00040000) != 0)) {
          cfTimeRange_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange>(cfTimeRange_);
          bitField0_ |= 0x00040000;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> cfTimeRangeBuilder_;

      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> getCfTimeRangeList() {
        if (cfTimeRangeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(cfTimeRange_);
        } else {
          return cfTimeRangeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public int getCfTimeRangeCount() {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.size();
        } else {
          return cfTimeRangeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange getCfTimeRange(int index) {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.get(index);
        } else {
          return cfTimeRangeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder setCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.set(index, value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder setCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.set(index, builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder addCfTimeRange(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder addCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange value) {
        if (cfTimeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(index, value);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder addCfTimeRange(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder addCfTimeRange(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder builderForValue) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.add(index, builderForValue.build());
          onChanged();
        } else {
          cfTimeRangeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder addAllCfTimeRange(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange> values) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, cfTimeRange_);
          onChanged();
        } else {
          cfTimeRangeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder clearCfTimeRange() {
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRange_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00040000);
          onChanged();
        } else {
          cfTimeRangeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public Builder removeCfTimeRange(int index) {
        if (cfTimeRangeBuilder_ == null) {
          ensureCfTimeRangeIsMutable();
          cfTimeRange_.remove(index);
          onChanged();
        } else {
          cfTimeRangeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder getCfTimeRangeBuilder(
          int index) {
        return getCfTimeRangeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder getCfTimeRangeOrBuilder(
          int index) {
        if (cfTimeRangeBuilder_ == null) {
          return cfTimeRange_.get(index);  } else {
          return cfTimeRangeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
           getCfTimeRangeOrBuilderList() {
        if (cfTimeRangeBuilder_ != null) {
          return cfTimeRangeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(cfTimeRange_);
        }
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder addCfTimeRangeBuilder() {
        return getCfTimeRangeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder addCfTimeRangeBuilder(
          int index) {
        return getCfTimeRangeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ColumnFamilyTimeRange cf_time_range = 19;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder> 
           getCfTimeRangeBuilderList() {
        return getCfTimeRangeFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder> 
          getCfTimeRangeFieldBuilder() {
        if (cfTimeRangeBuilder_ == null) {
          cfTimeRangeBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ColumnFamilyTimeRangeOrBuilder>(
                  cfTimeRange_,
                  ((bitField0_ & 0x00040000) != 0),
                  getParentForChildren(),
                  isClean());
          cfTimeRange_ = null;
        }
        return cfTimeRangeBuilder_;
      }

      private long mvccReadPoint_ ;
      /**
       * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
       * @return Whether the mvccReadPoint field is set.
       */
      @java.lang.Override
      public boolean hasMvccReadPoint() {
        return ((bitField0_ & 0x00080000) != 0);
      }
      /**
       * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
       * @return The mvccReadPoint.
       */
      @java.lang.Override
      public long getMvccReadPoint() {
        return mvccReadPoint_;
      }
      /**
       * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
       * @param value The mvccReadPoint to set.
       * @return This builder for chaining.
       */
      public Builder setMvccReadPoint(long value) {

        mvccReadPoint_ = value;
        bitField0_ |= 0x00080000;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 mvcc_read_point = 20 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearMvccReadPoint() {
        bitField0_ = (bitField0_ & ~0x00080000);
        mvccReadPoint_ = 0L;
        onChanged();
        return this;
      }

      private boolean includeStartRow_ = true;
      /**
       * <code>optional bool include_start_row = 21 [default = true];</code>
       * @return Whether the includeStartRow field is set.
       */
      @java.lang.Override
      public boolean hasIncludeStartRow() {
        return ((bitField0_ & 0x00100000) != 0);
      }
      /**
       * <code>optional bool include_start_row = 21 [default = true];</code>
       * @return The includeStartRow.
       */
      @java.lang.Override
      public boolean getIncludeStartRow() {
        return includeStartRow_;
      }
      /**
       * <code>optional bool include_start_row = 21 [default = true];</code>
       * @param value The includeStartRow to set.
       * @return This builder for chaining.
       */
      public Builder setIncludeStartRow(boolean value) {

        includeStartRow_ = value;
        bitField0_ |= 0x00100000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool include_start_row = 21 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearIncludeStartRow() {
        bitField0_ = (bitField0_ & ~0x00100000);
        includeStartRow_ = true;
        onChanged();
        return this;
      }

      private boolean includeStopRow_ ;
      /**
       * <code>optional bool include_stop_row = 22 [default = false];</code>
       * @return Whether the includeStopRow field is set.
       */
      @java.lang.Override
      public boolean hasIncludeStopRow() {
        return ((bitField0_ & 0x00200000) != 0);
      }
      /**
       * <code>optional bool include_stop_row = 22 [default = false];</code>
       * @return The includeStopRow.
       */
      @java.lang.Override
      public boolean getIncludeStopRow() {
        return includeStopRow_;
      }
      /**
       * <code>optional bool include_stop_row = 22 [default = false];</code>
       * @param value The includeStopRow to set.
       * @return This builder for chaining.
       */
      public Builder setIncludeStopRow(boolean value) {

        includeStopRow_ = value;
        bitField0_ |= 0x00200000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool include_stop_row = 22 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearIncludeStopRow() {
        bitField0_ = (bitField0_ & ~0x00200000);
        includeStopRow_ = false;
        onChanged();
        return this;
      }

      private int readType_ = 0;
      /**
       * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
       * @return Whether the readType field is set.
       */
      @java.lang.Override public boolean hasReadType() {
        return ((bitField0_ & 0x00400000) != 0);
      }
      /**
       * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
       * @return The readType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType getReadType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType result = org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType.forNumber(readType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType.DEFAULT : result;
      }
      /**
       * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
       * @param value The readType to set.
       * @return This builder for chaining.
       */
      public Builder setReadType(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.ReadType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00400000;
        readType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Scan.ReadType readType = 23 [default = DEFAULT];</code>
       * @return This builder for chaining.
       */
      public Builder clearReadType() {
        bitField0_ = (bitField0_ & ~0x00400000);
        readType_ = 0;
        onChanged();
        return this;
      }

      private boolean needCursorResult_ ;
      /**
       * <code>optional bool need_cursor_result = 24 [default = false];</code>
       * @return Whether the needCursorResult field is set.
       */
      @java.lang.Override
      public boolean hasNeedCursorResult() {
        return ((bitField0_ & 0x00800000) != 0);
      }
      /**
       * <code>optional bool need_cursor_result = 24 [default = false];</code>
       * @return The needCursorResult.
       */
      @java.lang.Override
      public boolean getNeedCursorResult() {
        return needCursorResult_;
      }
      /**
       * <code>optional bool need_cursor_result = 24 [default = false];</code>
       * @param value The needCursorResult to set.
       * @return This builder for chaining.
       */
      public Builder setNeedCursorResult(boolean value) {

        needCursorResult_ = value;
        bitField0_ |= 0x00800000;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool need_cursor_result = 24 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearNeedCursorResult() {
        bitField0_ = (bitField0_ & ~0x00800000);
        needCursorResult_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Scan)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Scan)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Scan>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Scan>() {
      @java.lang.Override
      public Scan parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Scan> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Scan> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ScanRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ScanRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     * @return Whether the scan field is set.
     */
    boolean hasScan();
    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     * @return The scan.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getScan();
    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder();

    /**
     * <code>optional uint64 scanner_id = 3;</code>
     * @return Whether the scannerId field is set.
     */
    boolean hasScannerId();
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     * @return The scannerId.
     */
    long getScannerId();

    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     * @return Whether the numberOfRows field is set.
     */
    boolean hasNumberOfRows();
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     * @return The numberOfRows.
     */
    int getNumberOfRows();

    /**
     * <code>optional bool close_scanner = 5;</code>
     * @return Whether the closeScanner field is set.
     */
    boolean hasCloseScanner();
    /**
     * <code>optional bool close_scanner = 5;</code>
     * @return The closeScanner.
     */
    boolean getCloseScanner();

    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     * @return Whether the nextCallSeq field is set.
     */
    boolean hasNextCallSeq();
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     * @return The nextCallSeq.
     */
    long getNextCallSeq();

    /**
     * <code>optional bool client_handles_partials = 7;</code>
     * @return Whether the clientHandlesPartials field is set.
     */
    boolean hasClientHandlesPartials();
    /**
     * <code>optional bool client_handles_partials = 7;</code>
     * @return The clientHandlesPartials.
     */
    boolean getClientHandlesPartials();

    /**
     * <code>optional bool client_handles_heartbeats = 8;</code>
     * @return Whether the clientHandlesHeartbeats field is set.
     */
    boolean hasClientHandlesHeartbeats();
    /**
     * <code>optional bool client_handles_heartbeats = 8;</code>
     * @return The clientHandlesHeartbeats.
     */
    boolean getClientHandlesHeartbeats();

    /**
     * <code>optional bool track_scan_metrics = 9;</code>
     * @return Whether the trackScanMetrics field is set.
     */
    boolean hasTrackScanMetrics();
    /**
     * <code>optional bool track_scan_metrics = 9;</code>
     * @return The trackScanMetrics.
     */
    boolean getTrackScanMetrics();

    /**
     * <code>optional bool renew = 10 [default = false];</code>
     * @return Whether the renew field is set.
     */
    boolean hasRenew();
    /**
     * <code>optional bool renew = 10 [default = false];</code>
     * @return The renew.
     */
    boolean getRenew();

    /**
     * <pre>
     * if we have returned limit_of_rows rows to client, then close the scanner.
     * </pre>
     *
     * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
     * @return Whether the limitOfRows field is set.
     */
    boolean hasLimitOfRows();
    /**
     * <pre>
     * if we have returned limit_of_rows rows to client, then close the scanner.
     * </pre>
     *
     * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
     * @return The limitOfRows.
     */
    int getLimitOfRows();
  }
  /**
   * <pre>
   **
   * A scan request. Initially, it should specify a scan. Later on, you
   * can use the scanner id returned to fetch result batches with a different
   * scan request.
   *
   * The scanner will remain open if there are more results, and it's not
   * asked to be closed explicitly.
   *
   * You can fetch the results and ask the scanner to be closed to save
   * a trip if you are not interested in remaining results.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.ScanRequest}
   */
  @javax.annotation.Generated("proto") public static final class ScanRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ScanRequest)
      ScanRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ScanRequest.newBuilder() to construct.
    private ScanRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ScanRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ScanRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int SCAN_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan scan_;
    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     * @return Whether the scan field is set.
     */
    @java.lang.Override
    public boolean hasScan() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     * @return The scan.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getScan() {
      return scan_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance() : scan_;
    }
    /**
     * <code>optional .hbase.pb.Scan scan = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
      return scan_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance() : scan_;
    }

    public static final int SCANNER_ID_FIELD_NUMBER = 3;
    private long scannerId_ = 0L;
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     * @return Whether the scannerId field is set.
     */
    @java.lang.Override
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     * @return The scannerId.
     */
    @java.lang.Override
    public long getScannerId() {
      return scannerId_;
    }

    public static final int NUMBER_OF_ROWS_FIELD_NUMBER = 4;
    private int numberOfRows_ = 0;
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     * @return Whether the numberOfRows field is set.
     */
    @java.lang.Override
    public boolean hasNumberOfRows() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     * @return The numberOfRows.
     */
    @java.lang.Override
    public int getNumberOfRows() {
      return numberOfRows_;
    }

    public static final int CLOSE_SCANNER_FIELD_NUMBER = 5;
    private boolean closeScanner_ = false;
    /**
     * <code>optional bool close_scanner = 5;</code>
     * @return Whether the closeScanner field is set.
     */
    @java.lang.Override
    public boolean hasCloseScanner() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional bool close_scanner = 5;</code>
     * @return The closeScanner.
     */
    @java.lang.Override
    public boolean getCloseScanner() {
      return closeScanner_;
    }

    public static final int NEXT_CALL_SEQ_FIELD_NUMBER = 6;
    private long nextCallSeq_ = 0L;
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     * @return Whether the nextCallSeq field is set.
     */
    @java.lang.Override
    public boolean hasNextCallSeq() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     * @return The nextCallSeq.
     */
    @java.lang.Override
    public long getNextCallSeq() {
      return nextCallSeq_;
    }

    public static final int CLIENT_HANDLES_PARTIALS_FIELD_NUMBER = 7;
    private boolean clientHandlesPartials_ = false;
    /**
     * <code>optional bool client_handles_partials = 7;</code>
     * @return Whether the clientHandlesPartials field is set.
     */
    @java.lang.Override
    public boolean hasClientHandlesPartials() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional bool client_handles_partials = 7;</code>
     * @return The clientHandlesPartials.
     */
    @java.lang.Override
    public boolean getClientHandlesPartials() {
      return clientHandlesPartials_;
    }

    public static final int CLIENT_HANDLES_HEARTBEATS_FIELD_NUMBER = 8;
    private boolean clientHandlesHeartbeats_ = false;
    /**
     * <code>optional bool client_handles_heartbeats = 8;</code>
     * @return Whether the clientHandlesHeartbeats field is set.
     */
    @java.lang.Override
    public boolean hasClientHandlesHeartbeats() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <code>optional bool client_handles_heartbeats = 8;</code>
     * @return The clientHandlesHeartbeats.
     */
    @java.lang.Override
    public boolean getClientHandlesHeartbeats() {
      return clientHandlesHeartbeats_;
    }

    public static final int TRACK_SCAN_METRICS_FIELD_NUMBER = 9;
    private boolean trackScanMetrics_ = false;
    /**
     * <code>optional bool track_scan_metrics = 9;</code>
     * @return Whether the trackScanMetrics field is set.
     */
    @java.lang.Override
    public boolean hasTrackScanMetrics() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <code>optional bool track_scan_metrics = 9;</code>
     * @return The trackScanMetrics.
     */
    @java.lang.Override
    public boolean getTrackScanMetrics() {
      return trackScanMetrics_;
    }

    public static final int RENEW_FIELD_NUMBER = 10;
    private boolean renew_ = false;
    /**
     * <code>optional bool renew = 10 [default = false];</code>
     * @return Whether the renew field is set.
     */
    @java.lang.Override
    public boolean hasRenew() {
      return ((bitField0_ & 0x00000200) != 0);
    }
    /**
     * <code>optional bool renew = 10 [default = false];</code>
     * @return The renew.
     */
    @java.lang.Override
    public boolean getRenew() {
      return renew_;
    }

    public static final int LIMIT_OF_ROWS_FIELD_NUMBER = 11;
    private int limitOfRows_ = 0;
    /**
     * <pre>
     * if we have returned limit_of_rows rows to client, then close the scanner.
     * </pre>
     *
     * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
     * @return Whether the limitOfRows field is set.
     */
    @java.lang.Override
    public boolean hasLimitOfRows() {
      return ((bitField0_ & 0x00000400) != 0);
    }
    /**
     * <pre>
     * if we have returned limit_of_rows rows to client, then close the scanner.
     * </pre>
     *
     * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
     * @return The limitOfRows.
     */
    @java.lang.Override
    public int getLimitOfRows() {
      return limitOfRows_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasRegion()) {
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasScan()) {
        if (!getScan().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getScan());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt32(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(5, closeScanner_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeUInt64(6, nextCallSeq_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeBool(7, clientHandlesPartials_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeBool(8, clientHandlesHeartbeats_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeBool(9, trackScanMetrics_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        output.writeBool(10, renew_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        output.writeUInt32(11, limitOfRows_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getScan());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, closeScanner_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(6, nextCallSeq_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, clientHandlesPartials_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, clientHandlesHeartbeats_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, trackScanMetrics_);
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(10, renew_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(11, limitOfRows_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasScan() != other.hasScan()) return false;
      if (hasScan()) {
        if (!getScan()
            .equals(other.getScan())) return false;
      }
      if (hasScannerId() != other.hasScannerId()) return false;
      if (hasScannerId()) {
        if (getScannerId()
            != other.getScannerId()) return false;
      }
      if (hasNumberOfRows() != other.hasNumberOfRows()) return false;
      if (hasNumberOfRows()) {
        if (getNumberOfRows()
            != other.getNumberOfRows()) return false;
      }
      if (hasCloseScanner() != other.hasCloseScanner()) return false;
      if (hasCloseScanner()) {
        if (getCloseScanner()
            != other.getCloseScanner()) return false;
      }
      if (hasNextCallSeq() != other.hasNextCallSeq()) return false;
      if (hasNextCallSeq()) {
        if (getNextCallSeq()
            != other.getNextCallSeq()) return false;
      }
      if (hasClientHandlesPartials() != other.hasClientHandlesPartials()) return false;
      if (hasClientHandlesPartials()) {
        if (getClientHandlesPartials()
            != other.getClientHandlesPartials()) return false;
      }
      if (hasClientHandlesHeartbeats() != other.hasClientHandlesHeartbeats()) return false;
      if (hasClientHandlesHeartbeats()) {
        if (getClientHandlesHeartbeats()
            != other.getClientHandlesHeartbeats()) return false;
      }
      if (hasTrackScanMetrics() != other.hasTrackScanMetrics()) return false;
      if (hasTrackScanMetrics()) {
        if (getTrackScanMetrics()
            != other.getTrackScanMetrics()) return false;
      }
      if (hasRenew() != other.hasRenew()) return false;
      if (hasRenew()) {
        if (getRenew()
            != other.getRenew()) return false;
      }
      if (hasLimitOfRows() != other.hasLimitOfRows()) return false;
      if (hasLimitOfRows()) {
        if (getLimitOfRows()
            != other.getLimitOfRows()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasScan()) {
        hash = (37 * hash) + SCAN_FIELD_NUMBER;
        hash = (53 * hash) + getScan().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNER_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getScannerId());
      }
      if (hasNumberOfRows()) {
        hash = (37 * hash) + NUMBER_OF_ROWS_FIELD_NUMBER;
        hash = (53 * hash) + getNumberOfRows();
      }
      if (hasCloseScanner()) {
        hash = (37 * hash) + CLOSE_SCANNER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCloseScanner());
      }
      if (hasNextCallSeq()) {
        hash = (37 * hash) + NEXT_CALL_SEQ_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNextCallSeq());
      }
      if (hasClientHandlesPartials()) {
        hash = (37 * hash) + CLIENT_HANDLES_PARTIALS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getClientHandlesPartials());
      }
      if (hasClientHandlesHeartbeats()) {
        hash = (37 * hash) + CLIENT_HANDLES_HEARTBEATS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getClientHandlesHeartbeats());
      }
      if (hasTrackScanMetrics()) {
        hash = (37 * hash) + TRACK_SCAN_METRICS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getTrackScanMetrics());
      }
      if (hasRenew()) {
        hash = (37 * hash) + RENEW_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getRenew());
      }
      if (hasLimitOfRows()) {
        hash = (37 * hash) + LIMIT_OF_ROWS_FIELD_NUMBER;
        hash = (53 * hash) + getLimitOfRows();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * A scan request. Initially, it should specify a scan. Later on, you
     * can use the scanner id returned to fetch result batches with a different
     * scan request.
     *
     * The scanner will remain open if there are more results, and it's not
     * asked to be closed explicitly.
     *
     * You can fetch the results and ask the scanner to be closed to save
     * a trip if you are not interested in remaining results.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.ScanRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ScanRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getScanFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        scan_ = null;
        if (scanBuilder_ != null) {
          scanBuilder_.dispose();
          scanBuilder_ = null;
        }
        scannerId_ = 0L;
        numberOfRows_ = 0;
        closeScanner_ = false;
        nextCallSeq_ = 0L;
        clientHandlesPartials_ = false;
        clientHandlesHeartbeats_ = false;
        trackScanMetrics_ = false;
        renew_ = false;
        limitOfRows_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.scan_ = scanBuilder_ == null
              ? scan_
              : scanBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.scannerId_ = scannerId_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.numberOfRows_ = numberOfRows_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.closeScanner_ = closeScanner_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.nextCallSeq_ = nextCallSeq_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.clientHandlesPartials_ = clientHandlesPartials_;
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.clientHandlesHeartbeats_ = clientHandlesHeartbeats_;
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.trackScanMetrics_ = trackScanMetrics_;
          to_bitField0_ |= 0x00000100;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.renew_ = renew_;
          to_bitField0_ |= 0x00000200;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.limitOfRows_ = limitOfRows_;
          to_bitField0_ |= 0x00000400;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasScan()) {
          mergeScan(other.getScan());
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasNumberOfRows()) {
          setNumberOfRows(other.getNumberOfRows());
        }
        if (other.hasCloseScanner()) {
          setCloseScanner(other.getCloseScanner());
        }
        if (other.hasNextCallSeq()) {
          setNextCallSeq(other.getNextCallSeq());
        }
        if (other.hasClientHandlesPartials()) {
          setClientHandlesPartials(other.getClientHandlesPartials());
        }
        if (other.hasClientHandlesHeartbeats()) {
          setClientHandlesHeartbeats(other.getClientHandlesHeartbeats());
        }
        if (other.hasTrackScanMetrics()) {
          setTrackScanMetrics(other.getTrackScanMetrics());
        }
        if (other.hasRenew()) {
          setRenew(other.getRenew());
        }
        if (other.hasLimitOfRows()) {
          setLimitOfRows(other.getLimitOfRows());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasRegion()) {
          if (!getRegion().isInitialized()) {
            return false;
          }
        }
        if (hasScan()) {
          if (!getScan().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getScanFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                scannerId_ = input.readUInt64();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 32: {
                numberOfRows_ = input.readUInt32();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 40: {
                closeScanner_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 48: {
                nextCallSeq_ = input.readUInt64();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 56: {
                clientHandlesPartials_ = input.readBool();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              case 64: {
                clientHandlesHeartbeats_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 72: {
                trackScanMetrics_ = input.readBool();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              case 80: {
                renew_ = input.readBool();
                bitField0_ |= 0x00000200;
                break;
              } // case 80
              case 88: {
                limitOfRows_ = input.readUInt32();
                bitField0_ |= 0x00000400;
                break;
              } // case 88
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan scan_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder> scanBuilder_;
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       * @return Whether the scan field is set.
       */
      public boolean hasScan() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       * @return The scan.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan getScan() {
        if (scanBuilder_ == null) {
          return scan_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance() : scan_;
        } else {
          return scanBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public Builder setScan(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scan_ = value;
        } else {
          scanBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public Builder setScan(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder builderForValue) {
        if (scanBuilder_ == null) {
          scan_ = builderForValue.build();
        } else {
          scanBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public Builder mergeScan(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            scan_ != null &&
            scan_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) {
            getScanBuilder().mergeFrom(value);
          } else {
            scan_ = value;
          }
        } else {
          scanBuilder_.mergeFrom(value);
        }
        if (scan_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public Builder clearScan() {
        bitField0_ = (bitField0_ & ~0x00000002);
        scan_ = null;
        if (scanBuilder_ != null) {
          scanBuilder_.dispose();
          scanBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder getScanBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getScanFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
        if (scanBuilder_ != null) {
          return scanBuilder_.getMessageOrBuilder();
        } else {
          return scan_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.getDefaultInstance() : scan_;
        }
      }
      /**
       * <code>optional .hbase.pb.Scan scan = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder> 
          getScanFieldBuilder() {
        if (scanBuilder_ == null) {
          scanBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanOrBuilder>(
                  getScan(),
                  getParentForChildren(),
                  isClean());
          scan_ = null;
        }
        return scanBuilder_;
      }

      private long scannerId_ ;
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       * @return Whether the scannerId field is set.
       */
      @java.lang.Override
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       * @return The scannerId.
       */
      @java.lang.Override
      public long getScannerId() {
        return scannerId_;
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       * @param value The scannerId to set.
       * @return This builder for chaining.
       */
      public Builder setScannerId(long value) {

        scannerId_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        scannerId_ = 0L;
        onChanged();
        return this;
      }

      private int numberOfRows_ ;
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       * @return Whether the numberOfRows field is set.
       */
      @java.lang.Override
      public boolean hasNumberOfRows() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       * @return The numberOfRows.
       */
      @java.lang.Override
      public int getNumberOfRows() {
        return numberOfRows_;
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       * @param value The numberOfRows to set.
       * @return This builder for chaining.
       */
      public Builder setNumberOfRows(int value) {

        numberOfRows_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearNumberOfRows() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numberOfRows_ = 0;
        onChanged();
        return this;
      }

      private boolean closeScanner_ ;
      /**
       * <code>optional bool close_scanner = 5;</code>
       * @return Whether the closeScanner field is set.
       */
      @java.lang.Override
      public boolean hasCloseScanner() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       * @return The closeScanner.
       */
      @java.lang.Override
      public boolean getCloseScanner() {
        return closeScanner_;
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       * @param value The closeScanner to set.
       * @return This builder for chaining.
       */
      public Builder setCloseScanner(boolean value) {

        closeScanner_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearCloseScanner() {
        bitField0_ = (bitField0_ & ~0x00000010);
        closeScanner_ = false;
        onChanged();
        return this;
      }

      private long nextCallSeq_ ;
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       * @return Whether the nextCallSeq field is set.
       */
      @java.lang.Override
      public boolean hasNextCallSeq() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       * @return The nextCallSeq.
       */
      @java.lang.Override
      public long getNextCallSeq() {
        return nextCallSeq_;
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       * @param value The nextCallSeq to set.
       * @return This builder for chaining.
       */
      public Builder setNextCallSeq(long value) {

        nextCallSeq_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearNextCallSeq() {
        bitField0_ = (bitField0_ & ~0x00000020);
        nextCallSeq_ = 0L;
        onChanged();
        return this;
      }

      private boolean clientHandlesPartials_ ;
      /**
       * <code>optional bool client_handles_partials = 7;</code>
       * @return Whether the clientHandlesPartials field is set.
       */
      @java.lang.Override
      public boolean hasClientHandlesPartials() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional bool client_handles_partials = 7;</code>
       * @return The clientHandlesPartials.
       */
      @java.lang.Override
      public boolean getClientHandlesPartials() {
        return clientHandlesPartials_;
      }
      /**
       * <code>optional bool client_handles_partials = 7;</code>
       * @param value The clientHandlesPartials to set.
       * @return This builder for chaining.
       */
      public Builder setClientHandlesPartials(boolean value) {

        clientHandlesPartials_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool client_handles_partials = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearClientHandlesPartials() {
        bitField0_ = (bitField0_ & ~0x00000040);
        clientHandlesPartials_ = false;
        onChanged();
        return this;
      }

      private boolean clientHandlesHeartbeats_ ;
      /**
       * <code>optional bool client_handles_heartbeats = 8;</code>
       * @return Whether the clientHandlesHeartbeats field is set.
       */
      @java.lang.Override
      public boolean hasClientHandlesHeartbeats() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional bool client_handles_heartbeats = 8;</code>
       * @return The clientHandlesHeartbeats.
       */
      @java.lang.Override
      public boolean getClientHandlesHeartbeats() {
        return clientHandlesHeartbeats_;
      }
      /**
       * <code>optional bool client_handles_heartbeats = 8;</code>
       * @param value The clientHandlesHeartbeats to set.
       * @return This builder for chaining.
       */
      public Builder setClientHandlesHeartbeats(boolean value) {

        clientHandlesHeartbeats_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool client_handles_heartbeats = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearClientHandlesHeartbeats() {
        bitField0_ = (bitField0_ & ~0x00000080);
        clientHandlesHeartbeats_ = false;
        onChanged();
        return this;
      }

      private boolean trackScanMetrics_ ;
      /**
       * <code>optional bool track_scan_metrics = 9;</code>
       * @return Whether the trackScanMetrics field is set.
       */
      @java.lang.Override
      public boolean hasTrackScanMetrics() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional bool track_scan_metrics = 9;</code>
       * @return The trackScanMetrics.
       */
      @java.lang.Override
      public boolean getTrackScanMetrics() {
        return trackScanMetrics_;
      }
      /**
       * <code>optional bool track_scan_metrics = 9;</code>
       * @param value The trackScanMetrics to set.
       * @return This builder for chaining.
       */
      public Builder setTrackScanMetrics(boolean value) {

        trackScanMetrics_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool track_scan_metrics = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearTrackScanMetrics() {
        bitField0_ = (bitField0_ & ~0x00000100);
        trackScanMetrics_ = false;
        onChanged();
        return this;
      }

      private boolean renew_ ;
      /**
       * <code>optional bool renew = 10 [default = false];</code>
       * @return Whether the renew field is set.
       */
      @java.lang.Override
      public boolean hasRenew() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <code>optional bool renew = 10 [default = false];</code>
       * @return The renew.
       */
      @java.lang.Override
      public boolean getRenew() {
        return renew_;
      }
      /**
       * <code>optional bool renew = 10 [default = false];</code>
       * @param value The renew to set.
       * @return This builder for chaining.
       */
      public Builder setRenew(boolean value) {

        renew_ = value;
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool renew = 10 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearRenew() {
        bitField0_ = (bitField0_ & ~0x00000200);
        renew_ = false;
        onChanged();
        return this;
      }

      private int limitOfRows_ ;
      /**
       * <pre>
       * if we have returned limit_of_rows rows to client, then close the scanner.
       * </pre>
       *
       * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
       * @return Whether the limitOfRows field is set.
       */
      @java.lang.Override
      public boolean hasLimitOfRows() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <pre>
       * if we have returned limit_of_rows rows to client, then close the scanner.
       * </pre>
       *
       * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
       * @return The limitOfRows.
       */
      @java.lang.Override
      public int getLimitOfRows() {
        return limitOfRows_;
      }
      /**
       * <pre>
       * if we have returned limit_of_rows rows to client, then close the scanner.
       * </pre>
       *
       * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
       * @param value The limitOfRows to set.
       * @return This builder for chaining.
       */
      public Builder setLimitOfRows(int value) {

        limitOfRows_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * if we have returned limit_of_rows rows to client, then close the scanner.
       * </pre>
       *
       * <code>optional uint32 limit_of_rows = 11 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearLimitOfRows() {
        bitField0_ = (bitField0_ & ~0x00000400);
        limitOfRows_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ScanRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ScanRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ScanRequest>() {
      @java.lang.Override
      public ScanRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CursorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Cursor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    boolean hasRow();
    /**
     * <code>optional bytes row = 1;</code>
     * @return The row.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow();
  }
  /**
   * <pre>
   **
   * Scan cursor to tell client where we are scanning.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Cursor}
   */
  @javax.annotation.Generated("proto") public static final class Cursor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Cursor)
      CursorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Cursor.newBuilder() to construct.
    private Cursor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Cursor() {
      row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Cursor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Cursor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Cursor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder.class);
    }

    private int bitField0_;
    public static final int ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    @java.lang.Override
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes row = 1;</code>
     * @return The row.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
      return row_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, row_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor) obj;

      if (hasRow() != other.hasRow()) return false;
      if (hasRow()) {
        if (!getRow()
            .equals(other.getRow())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Scan cursor to tell client where we are scanning.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Cursor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Cursor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Cursor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Cursor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Cursor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.row_ = row_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                row_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes row = 1;</code>
       * @return Whether the row field is set.
       */
      @java.lang.Override
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @return The row.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @param value The row to set.
       * @return This builder for chaining.
       */
      public Builder setRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        row_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Cursor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Cursor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Cursor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Cursor>() {
      @java.lang.Override
      public Cursor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Cursor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Cursor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ScanResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ScanResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @return A list containing the cellsPerResult.
     */
    java.util.List<java.lang.Integer> getCellsPerResultList();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @return The count of cellsPerResult.
     */
    int getCellsPerResultCount();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @param index The index of the element to return.
     * @return The cellsPerResult at the given index.
     */
    int getCellsPerResult(int index);

    /**
     * <code>optional uint64 scanner_id = 2;</code>
     * @return Whether the scannerId field is set.
     */
    boolean hasScannerId();
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     * @return The scannerId.
     */
    long getScannerId();

    /**
     * <code>optional bool more_results = 3;</code>
     * @return Whether the moreResults field is set.
     */
    boolean hasMoreResults();
    /**
     * <code>optional bool more_results = 3;</code>
     * @return The moreResults.
     */
    boolean getMoreResults();

    /**
     * <code>optional uint32 ttl = 4;</code>
     * @return Whether the ttl field is set.
     */
    boolean hasTtl();
    /**
     * <code>optional uint32 ttl = 4;</code>
     * @return The ttl.
     */
    int getTtl();

    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> 
        getResultsList();
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResults(int index);
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    int getResultsCount();
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultsOrBuilderList();
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
        int index);

    /**
     * <code>optional bool stale = 6;</code>
     * @return Whether the stale field is set.
     */
    boolean hasStale();
    /**
     * <code>optional bool stale = 6;</code>
     * @return The stale.
     */
    boolean getStale();

    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @return A list containing the partialFlagPerResult.
     */
    java.util.List<java.lang.Boolean> getPartialFlagPerResultList();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @return The count of partialFlagPerResult.
     */
    int getPartialFlagPerResultCount();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @param index The index of the element to return.
     * @return The partialFlagPerResult at the given index.
     */
    boolean getPartialFlagPerResult(int index);

    /**
     * <pre>
     * A server may choose to limit the number of results returned to the client for
     * reasons such as the size in bytes or quantity of results accumulated. This field
     * will true when more results exist in the current region.
     * </pre>
     *
     * <code>optional bool more_results_in_region = 8;</code>
     * @return Whether the moreResultsInRegion field is set.
     */
    boolean hasMoreResultsInRegion();
    /**
     * <pre>
     * A server may choose to limit the number of results returned to the client for
     * reasons such as the size in bytes or quantity of results accumulated. This field
     * will true when more results exist in the current region.
     * </pre>
     *
     * <code>optional bool more_results_in_region = 8;</code>
     * @return The moreResultsInRegion.
     */
    boolean getMoreResultsInRegion();

    /**
     * <pre>
     * This field is filled in if the server is sending back a heartbeat message.
     * Heartbeat messages are sent back to the client to prevent the scanner from
     * timing out. Seeing a heartbeat message communicates to the Client that the
     * server would have continued to scan had the time limit not been reached.
     * </pre>
     *
     * <code>optional bool heartbeat_message = 9;</code>
     * @return Whether the heartbeatMessage field is set.
     */
    boolean hasHeartbeatMessage();
    /**
     * <pre>
     * This field is filled in if the server is sending back a heartbeat message.
     * Heartbeat messages are sent back to the client to prevent the scanner from
     * timing out. Seeing a heartbeat message communicates to the Client that the
     * server would have continued to scan had the time limit not been reached.
     * </pre>
     *
     * <code>optional bool heartbeat_message = 9;</code>
     * @return The heartbeatMessage.
     */
    boolean getHeartbeatMessage();

    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     * @return Whether the scanMetrics field is set.
     */
    boolean hasScanMetrics();
    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     * @return The scanMetrics.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics getScanMetrics();
    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder getScanMetricsOrBuilder();

    /**
     * <pre>
     * The mvcc read point which is used to open the scanner at server side. Client can
     * make use of this mvcc_read_point when restarting a scanner to get a consistent view
     * of a row.
     * </pre>
     *
     * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
     * @return Whether the mvccReadPoint field is set.
     */
    boolean hasMvccReadPoint();
    /**
     * <pre>
     * The mvcc read point which is used to open the scanner at server side. Client can
     * make use of this mvcc_read_point when restarting a scanner to get a consistent view
     * of a row.
     * </pre>
     *
     * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
     * @return The mvccReadPoint.
     */
    long getMvccReadPoint();

    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     * @return Whether the cursor field is set.
     */
    boolean hasCursor();
    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     * @return The cursor.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getCursor();
    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder getCursorOrBuilder();
  }
  /**
   * <pre>
   **
   * The scan response. If there are no more results, more_results will
   * be false.  If it is not specified, it means there are more.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.ScanResponse}
   */
  @javax.annotation.Generated("proto") public static final class ScanResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ScanResponse)
      ScanResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ScanResponse.newBuilder() to construct.
    private ScanResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ScanResponse() {
      cellsPerResult_ = emptyIntList();
      results_ = java.util.Collections.emptyList();
      partialFlagPerResult_ = emptyBooleanList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ScanResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.Builder.class);
    }

    private int bitField0_;
    public static final int CELLS_PER_RESULT_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.IntList cellsPerResult_ =
        emptyIntList();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @return A list containing the cellsPerResult.
     */
    @java.lang.Override
    public java.util.List<java.lang.Integer>
        getCellsPerResultList() {
      return cellsPerResult_;
    }
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @return The count of cellsPerResult.
     */
    public int getCellsPerResultCount() {
      return cellsPerResult_.size();
    }
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     *
     * <code>repeated uint32 cells_per_result = 1;</code>
     * @param index The index of the element to return.
     * @return The cellsPerResult at the given index.
     */
    public int getCellsPerResult(int index) {
      return cellsPerResult_.getInt(index);
    }

    public static final int SCANNER_ID_FIELD_NUMBER = 2;
    private long scannerId_ = 0L;
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     * @return Whether the scannerId field is set.
     */
    @java.lang.Override
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     * @return The scannerId.
     */
    @java.lang.Override
    public long getScannerId() {
      return scannerId_;
    }

    public static final int MORE_RESULTS_FIELD_NUMBER = 3;
    private boolean moreResults_ = false;
    /**
     * <code>optional bool more_results = 3;</code>
     * @return Whether the moreResults field is set.
     */
    @java.lang.Override
    public boolean hasMoreResults() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool more_results = 3;</code>
     * @return The moreResults.
     */
    @java.lang.Override
    public boolean getMoreResults() {
      return moreResults_;
    }

    public static final int TTL_FIELD_NUMBER = 4;
    private int ttl_ = 0;
    /**
     * <code>optional uint32 ttl = 4;</code>
     * @return Whether the ttl field is set.
     */
    @java.lang.Override
    public boolean hasTtl() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional uint32 ttl = 4;</code>
     * @return The ttl.
     */
    @java.lang.Override
    public int getTtl() {
      return ttl_;
    }

    public static final int RESULTS_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> results_;
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> getResultsList() {
      return results_;
    }
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    @java.lang.Override
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResults(int index) {
      return results_.get(index);
    }
    /**
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     *
     * <code>repeated .hbase.pb.Result results = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    public static final int STALE_FIELD_NUMBER = 6;
    private boolean stale_ = false;
    /**
     * <code>optional bool stale = 6;</code>
     * @return Whether the stale field is set.
     */
    @java.lang.Override
    public boolean hasStale() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool stale = 6;</code>
     * @return The stale.
     */
    @java.lang.Override
    public boolean getStale() {
      return stale_;
    }

    public static final int PARTIAL_FLAG_PER_RESULT_FIELD_NUMBER = 7;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.BooleanList partialFlagPerResult_ =
        emptyBooleanList();
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @return A list containing the partialFlagPerResult.
     */
    @java.lang.Override
    public java.util.List<java.lang.Boolean>
        getPartialFlagPerResultList() {
      return partialFlagPerResult_;
    }
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @return The count of partialFlagPerResult.
     */
    public int getPartialFlagPerResultCount() {
      return partialFlagPerResult_.size();
    }
    /**
     * <pre>
     * This field is filled in if we are doing cellblocks. In the event that a row
     * could not fit all of its cells into a single RPC chunk, the results will be
     * returned as partials, and reconstructed into a complete result on the client
     * side. This field is a list of flags indicating whether or not the result
     * that the cells belong to is a partial result. For example, if this field
     * has false, false, true in it, then we know that on the client side, we need to
     * make another RPC request since the last result was only a partial.
     * </pre>
     *
     * <code>repeated bool partial_flag_per_result = 7;</code>
     * @param index The index of the element to return.
     * @return The partialFlagPerResult at the given index.
     */
    public boolean getPartialFlagPerResult(int index) {
      return partialFlagPerResult_.getBoolean(index);
    }

    public static final int MORE_RESULTS_IN_REGION_FIELD_NUMBER = 8;
    private boolean moreResultsInRegion_ = false;
    /**
     * <pre>
     * A server may choose to limit the number of results returned to the client for
     * reasons such as the size in bytes or quantity of results accumulated. This field
     * will true when more results exist in the current region.
     * </pre>
     *
     * <code>optional bool more_results_in_region = 8;</code>
     * @return Whether the moreResultsInRegion field is set.
     */
    @java.lang.Override
    public boolean hasMoreResultsInRegion() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * A server may choose to limit the number of results returned to the client for
     * reasons such as the size in bytes or quantity of results accumulated. This field
     * will true when more results exist in the current region.
     * </pre>
     *
     * <code>optional bool more_results_in_region = 8;</code>
     * @return The moreResultsInRegion.
     */
    @java.lang.Override
    public boolean getMoreResultsInRegion() {
      return moreResultsInRegion_;
    }

    public static final int HEARTBEAT_MESSAGE_FIELD_NUMBER = 9;
    private boolean heartbeatMessage_ = false;
    /**
     * <pre>
     * This field is filled in if the server is sending back a heartbeat message.
     * Heartbeat messages are sent back to the client to prevent the scanner from
     * timing out. Seeing a heartbeat message communicates to the Client that the
     * server would have continued to scan had the time limit not been reached.
     * </pre>
     *
     * <code>optional bool heartbeat_message = 9;</code>
     * @return Whether the heartbeatMessage field is set.
     */
    @java.lang.Override
    public boolean hasHeartbeatMessage() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <pre>
     * This field is filled in if the server is sending back a heartbeat message.
     * Heartbeat messages are sent back to the client to prevent the scanner from
     * timing out. Seeing a heartbeat message communicates to the Client that the
     * server would have continued to scan had the time limit not been reached.
     * </pre>
     *
     * <code>optional bool heartbeat_message = 9;</code>
     * @return The heartbeatMessage.
     */
    @java.lang.Override
    public boolean getHeartbeatMessage() {
      return heartbeatMessage_;
    }

    public static final int SCAN_METRICS_FIELD_NUMBER = 10;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics scanMetrics_;
    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     * @return Whether the scanMetrics field is set.
     */
    @java.lang.Override
    public boolean hasScanMetrics() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     * @return The scanMetrics.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics getScanMetrics() {
      return scanMetrics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.getDefaultInstance() : scanMetrics_;
    }
    /**
     * <pre>
     * This field is filled in if the client has requested that scan metrics be tracked.
     * The metrics tracked here are sent back to the client to be tracked together with
     * the existing client side metrics.
     * </pre>
     *
     * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder getScanMetricsOrBuilder() {
      return scanMetrics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.getDefaultInstance() : scanMetrics_;
    }

    public static final int MVCC_READ_POINT_FIELD_NUMBER = 11;
    private long mvccReadPoint_ = 0L;
    /**
     * <pre>
     * The mvcc read point which is used to open the scanner at server side. Client can
     * make use of this mvcc_read_point when restarting a scanner to get a consistent view
     * of a row.
     * </pre>
     *
     * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
     * @return Whether the mvccReadPoint field is set.
     */
    @java.lang.Override
    public boolean hasMvccReadPoint() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <pre>
     * The mvcc read point which is used to open the scanner at server side. Client can
     * make use of this mvcc_read_point when restarting a scanner to get a consistent view
     * of a row.
     * </pre>
     *
     * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
     * @return The mvccReadPoint.
     */
    @java.lang.Override
    public long getMvccReadPoint() {
      return mvccReadPoint_;
    }

    public static final int CURSOR_FIELD_NUMBER = 12;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor cursor_;
    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     * @return Whether the cursor field is set.
     */
    @java.lang.Override
    public boolean hasCursor() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     * @return The cursor.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getCursor() {
      return cursor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance() : cursor_;
    }
    /**
     * <pre>
     * If the Scan need cursor, return the row key we are scanning in heartbeat message.
     * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
     * </pre>
     *
     * <code>optional .hbase.pb.Cursor cursor = 12;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder getCursorOrBuilder() {
      return cursor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance() : cursor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < cellsPerResult_.size(); i++) {
        output.writeUInt32(1, cellsPerResult_.getInt(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt32(4, ttl_);
      }
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(5, results_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(6, stale_);
      }
      for (int i = 0; i < partialFlagPerResult_.size(); i++) {
        output.writeBool(7, partialFlagPerResult_.getBoolean(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(8, moreResultsInRegion_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(9, heartbeatMessage_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeMessage(10, getScanMetrics());
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeUInt64(11, mvccReadPoint_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeMessage(12, getCursor());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < cellsPerResult_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeUInt32SizeNoTag(cellsPerResult_.getInt(i));
        }
        size += dataSize;
        size += 1 * getCellsPerResultList().size();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, ttl_);
      }
      for (int i = 0; i < results_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, results_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, stale_);
      }
      {
        int dataSize = 0;
        dataSize = 1 * getPartialFlagPerResultList().size();
        size += dataSize;
        size += 1 * getPartialFlagPerResultList().size();
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, moreResultsInRegion_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, heartbeatMessage_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getScanMetrics());
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(11, mvccReadPoint_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getCursor());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse) obj;

      if (!getCellsPerResultList()
          .equals(other.getCellsPerResultList())) return false;
      if (hasScannerId() != other.hasScannerId()) return false;
      if (hasScannerId()) {
        if (getScannerId()
            != other.getScannerId()) return false;
      }
      if (hasMoreResults() != other.hasMoreResults()) return false;
      if (hasMoreResults()) {
        if (getMoreResults()
            != other.getMoreResults()) return false;
      }
      if (hasTtl() != other.hasTtl()) return false;
      if (hasTtl()) {
        if (getTtl()
            != other.getTtl()) return false;
      }
      if (!getResultsList()
          .equals(other.getResultsList())) return false;
      if (hasStale() != other.hasStale()) return false;
      if (hasStale()) {
        if (getStale()
            != other.getStale()) return false;
      }
      if (!getPartialFlagPerResultList()
          .equals(other.getPartialFlagPerResultList())) return false;
      if (hasMoreResultsInRegion() != other.hasMoreResultsInRegion()) return false;
      if (hasMoreResultsInRegion()) {
        if (getMoreResultsInRegion()
            != other.getMoreResultsInRegion()) return false;
      }
      if (hasHeartbeatMessage() != other.hasHeartbeatMessage()) return false;
      if (hasHeartbeatMessage()) {
        if (getHeartbeatMessage()
            != other.getHeartbeatMessage()) return false;
      }
      if (hasScanMetrics() != other.hasScanMetrics()) return false;
      if (hasScanMetrics()) {
        if (!getScanMetrics()
            .equals(other.getScanMetrics())) return false;
      }
      if (hasMvccReadPoint() != other.hasMvccReadPoint()) return false;
      if (hasMvccReadPoint()) {
        if (getMvccReadPoint()
            != other.getMvccReadPoint()) return false;
      }
      if (hasCursor() != other.hasCursor()) return false;
      if (hasCursor()) {
        if (!getCursor()
            .equals(other.getCursor())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getCellsPerResultCount() > 0) {
        hash = (37 * hash) + CELLS_PER_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getCellsPerResultList().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNER_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getScannerId());
      }
      if (hasMoreResults()) {
        hash = (37 * hash) + MORE_RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMoreResults());
      }
      if (hasTtl()) {
        hash = (37 * hash) + TTL_FIELD_NUMBER;
        hash = (53 * hash) + getTtl();
      }
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      if (hasStale()) {
        hash = (37 * hash) + STALE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getStale());
      }
      if (getPartialFlagPerResultCount() > 0) {
        hash = (37 * hash) + PARTIAL_FLAG_PER_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getPartialFlagPerResultList().hashCode();
      }
      if (hasMoreResultsInRegion()) {
        hash = (37 * hash) + MORE_RESULTS_IN_REGION_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMoreResultsInRegion());
      }
      if (hasHeartbeatMessage()) {
        hash = (37 * hash) + HEARTBEAT_MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getHeartbeatMessage());
      }
      if (hasScanMetrics()) {
        hash = (37 * hash) + SCAN_METRICS_FIELD_NUMBER;
        hash = (53 * hash) + getScanMetrics().hashCode();
      }
      if (hasMvccReadPoint()) {
        hash = (37 * hash) + MVCC_READ_POINT_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getMvccReadPoint());
      }
      if (hasCursor()) {
        hash = (37 * hash) + CURSOR_FIELD_NUMBER;
        hash = (53 * hash) + getCursor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The scan response. If there are no more results, more_results will
     * be false.  If it is not specified, it means there are more.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.ScanResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ScanResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultsFieldBuilder();
          getScanMetricsFieldBuilder();
          getCursorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        cellsPerResult_ = emptyIntList();
        scannerId_ = 0L;
        moreResults_ = false;
        ttl_ = 0;
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
        } else {
          results_ = null;
          resultsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        stale_ = false;
        partialFlagPerResult_ = emptyBooleanList();
        moreResultsInRegion_ = false;
        heartbeatMessage_ = false;
        scanMetrics_ = null;
        if (scanMetricsBuilder_ != null) {
          scanMetricsBuilder_.dispose();
          scanMetricsBuilder_ = null;
        }
        mvccReadPoint_ = 0L;
        cursor_ = null;
        if (cursorBuilder_ != null) {
          cursorBuilder_.dispose();
          cursorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ScanResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse result) {
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          cellsPerResult_.makeImmutable();
          result.cellsPerResult_ = cellsPerResult_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.scannerId_ = scannerId_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.moreResults_ = moreResults_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.ttl_ = ttl_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.stale_ = stale_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          partialFlagPerResult_.makeImmutable();
          result.partialFlagPerResult_ = partialFlagPerResult_;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.moreResultsInRegion_ = moreResultsInRegion_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.heartbeatMessage_ = heartbeatMessage_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.scanMetrics_ = scanMetricsBuilder_ == null
              ? scanMetrics_
              : scanMetricsBuilder_.build();
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.mvccReadPoint_ = mvccReadPoint_;
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          result.cursor_ = cursorBuilder_ == null
              ? cursor_
              : cursorBuilder_.build();
          to_bitField0_ |= 0x00000100;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()) return this;
        if (!other.cellsPerResult_.isEmpty()) {
          if (cellsPerResult_.isEmpty()) {
            cellsPerResult_ = other.cellsPerResult_;
            cellsPerResult_.makeImmutable();
            bitField0_ |= 0x00000001;
          } else {
            ensureCellsPerResultIsMutable();
            cellsPerResult_.addAll(other.cellsPerResult_);
          }
          onChanged();
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasMoreResults()) {
          setMoreResults(other.getMoreResults());
        }
        if (other.hasTtl()) {
          setTtl(other.getTtl());
        }
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000010);
              resultsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        if (other.hasStale()) {
          setStale(other.getStale());
        }
        if (!other.partialFlagPerResult_.isEmpty()) {
          if (partialFlagPerResult_.isEmpty()) {
            partialFlagPerResult_ = other.partialFlagPerResult_;
            partialFlagPerResult_.makeImmutable();
            bitField0_ |= 0x00000040;
          } else {
            ensurePartialFlagPerResultIsMutable();
            partialFlagPerResult_.addAll(other.partialFlagPerResult_);
          }
          onChanged();
        }
        if (other.hasMoreResultsInRegion()) {
          setMoreResultsInRegion(other.getMoreResultsInRegion());
        }
        if (other.hasHeartbeatMessage()) {
          setHeartbeatMessage(other.getHeartbeatMessage());
        }
        if (other.hasScanMetrics()) {
          mergeScanMetrics(other.getScanMetrics());
        }
        if (other.hasMvccReadPoint()) {
          setMvccReadPoint(other.getMvccReadPoint());
        }
        if (other.hasCursor()) {
          mergeCursor(other.getCursor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int v = input.readUInt32();
                ensureCellsPerResultIsMutable();
                cellsPerResult_.addInt(v);
                break;
              } // case 8
              case 10: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                ensureCellsPerResultIsMutable();
                while (input.getBytesUntilLimit() > 0) {
                  cellsPerResult_.addInt(input.readUInt32());
                }
                input.popLimit(limit);
                break;
              } // case 10
              case 16: {
                scannerId_ = input.readUInt64();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                moreResults_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 32: {
                ttl_ = input.readUInt32();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.PARSER,
                        extensionRegistry);
                if (resultsBuilder_ == null) {
                  ensureResultsIsMutable();
                  results_.add(m);
                } else {
                  resultsBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 48: {
                stale_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 56: {
                boolean v = input.readBool();
                ensurePartialFlagPerResultIsMutable();
                partialFlagPerResult_.addBoolean(v);
                break;
              } // case 56
              case 58: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                int alloc = length > 4096 ? 4096 : length;
                ensurePartialFlagPerResultIsMutable(alloc / 1);
                while (input.getBytesUntilLimit() > 0) {
                  partialFlagPerResult_.addBoolean(input.readBool());
                }
                input.popLimit(limit);
                break;
              } // case 58
              case 64: {
                moreResultsInRegion_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 72: {
                heartbeatMessage_ = input.readBool();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              case 82: {
                input.readMessage(
                    getScanMetricsFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000200;
                break;
              } // case 82
              case 88: {
                mvccReadPoint_ = input.readUInt64();
                bitField0_ |= 0x00000400;
                break;
              } // case 88
              case 98: {
                input.readMessage(
                    getCursorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000800;
                break;
              } // case 98
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.IntList cellsPerResult_ = emptyIntList();
      private void ensureCellsPerResultIsMutable() {
        if (!cellsPerResult_.isModifiable()) {
          cellsPerResult_ = makeMutableCopy(cellsPerResult_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @return A list containing the cellsPerResult.
       */
      public java.util.List<java.lang.Integer>
          getCellsPerResultList() {
        cellsPerResult_.makeImmutable();
        return cellsPerResult_;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @return The count of cellsPerResult.
       */
      public int getCellsPerResultCount() {
        return cellsPerResult_.size();
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @param index The index of the element to return.
       * @return The cellsPerResult at the given index.
       */
      public int getCellsPerResult(int index) {
        return cellsPerResult_.getInt(index);
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @param index The index to set the value at.
       * @param value The cellsPerResult to set.
       * @return This builder for chaining.
       */
      public Builder setCellsPerResult(
          int index, int value) {

        ensureCellsPerResultIsMutable();
        cellsPerResult_.setInt(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @param value The cellsPerResult to add.
       * @return This builder for chaining.
       */
      public Builder addCellsPerResult(int value) {

        ensureCellsPerResultIsMutable();
        cellsPerResult_.addInt(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @param values The cellsPerResult to add.
       * @return This builder for chaining.
       */
      public Builder addAllCellsPerResult(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureCellsPerResultIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, cellsPerResult_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       *
       * <code>repeated uint32 cells_per_result = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearCellsPerResult() {
        cellsPerResult_ = emptyIntList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      private long scannerId_ ;
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       * @return Whether the scannerId field is set.
       */
      @java.lang.Override
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       * @return The scannerId.
       */
      @java.lang.Override
      public long getScannerId() {
        return scannerId_;
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       * @param value The scannerId to set.
       * @return This builder for chaining.
       */
      public Builder setScannerId(long value) {

        scannerId_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        scannerId_ = 0L;
        onChanged();
        return this;
      }

      private boolean moreResults_ ;
      /**
       * <code>optional bool more_results = 3;</code>
       * @return Whether the moreResults field is set.
       */
      @java.lang.Override
      public boolean hasMoreResults() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool more_results = 3;</code>
       * @return The moreResults.
       */
      @java.lang.Override
      public boolean getMoreResults() {
        return moreResults_;
      }
      /**
       * <code>optional bool more_results = 3;</code>
       * @param value The moreResults to set.
       * @return This builder for chaining.
       */
      public Builder setMoreResults(boolean value) {

        moreResults_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool more_results = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearMoreResults() {
        bitField0_ = (bitField0_ & ~0x00000004);
        moreResults_ = false;
        onChanged();
        return this;
      }

      private int ttl_ ;
      /**
       * <code>optional uint32 ttl = 4;</code>
       * @return Whether the ttl field is set.
       */
      @java.lang.Override
      public boolean hasTtl() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       * @return The ttl.
       */
      @java.lang.Override
      public int getTtl() {
        return ttl_;
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       * @param value The ttl to set.
       * @return This builder for chaining.
       */
      public Builder setTtl(int value) {

        ttl_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearTtl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        ttl_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          results_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result>(results_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> resultsBuilder_;

      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder setResults(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder setResults(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder addResults(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder addResults(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder addResults(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder addResults(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder addAllResults(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       *
       * <code>repeated .hbase.pb.Result results = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder> 
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }

      private boolean stale_ ;
      /**
       * <code>optional bool stale = 6;</code>
       * @return Whether the stale field is set.
       */
      @java.lang.Override
      public boolean hasStale() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool stale = 6;</code>
       * @return The stale.
       */
      @java.lang.Override
      public boolean getStale() {
        return stale_;
      }
      /**
       * <code>optional bool stale = 6;</code>
       * @param value The stale to set.
       * @return This builder for chaining.
       */
      public Builder setStale(boolean value) {

        stale_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool stale = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearStale() {
        bitField0_ = (bitField0_ & ~0x00000020);
        stale_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.BooleanList partialFlagPerResult_ = emptyBooleanList();
      private void ensurePartialFlagPerResultIsMutable() {
        if (!partialFlagPerResult_.isModifiable()) {
          partialFlagPerResult_ = makeMutableCopy(partialFlagPerResult_);
        }
        bitField0_ |= 0x00000040;
      }
      private void ensurePartialFlagPerResultIsMutable(int capacity) {
        if (!partialFlagPerResult_.isModifiable()) {
          partialFlagPerResult_ = makeMutableCopy(partialFlagPerResult_, capacity);
        }
        bitField0_ |= 0x00000040;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @return A list containing the partialFlagPerResult.
       */
      public java.util.List<java.lang.Boolean>
          getPartialFlagPerResultList() {
        partialFlagPerResult_.makeImmutable();
        return partialFlagPerResult_;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @return The count of partialFlagPerResult.
       */
      public int getPartialFlagPerResultCount() {
        return partialFlagPerResult_.size();
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @param index The index of the element to return.
       * @return The partialFlagPerResult at the given index.
       */
      public boolean getPartialFlagPerResult(int index) {
        return partialFlagPerResult_.getBoolean(index);
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @param index The index to set the value at.
       * @param value The partialFlagPerResult to set.
       * @return This builder for chaining.
       */
      public Builder setPartialFlagPerResult(
          int index, boolean value) {

        ensurePartialFlagPerResultIsMutable();
        partialFlagPerResult_.setBoolean(index, value);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @param value The partialFlagPerResult to add.
       * @return This builder for chaining.
       */
      public Builder addPartialFlagPerResult(boolean value) {

        ensurePartialFlagPerResultIsMutable();
        partialFlagPerResult_.addBoolean(value);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @param values The partialFlagPerResult to add.
       * @return This builder for chaining.
       */
      public Builder addAllPartialFlagPerResult(
          java.lang.Iterable<? extends java.lang.Boolean> values) {
        ensurePartialFlagPerResultIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, partialFlagPerResult_);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if we are doing cellblocks. In the event that a row
       * could not fit all of its cells into a single RPC chunk, the results will be
       * returned as partials, and reconstructed into a complete result on the client
       * side. This field is a list of flags indicating whether or not the result
       * that the cells belong to is a partial result. For example, if this field
       * has false, false, true in it, then we know that on the client side, we need to
       * make another RPC request since the last result was only a partial.
       * </pre>
       *
       * <code>repeated bool partial_flag_per_result = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearPartialFlagPerResult() {
        partialFlagPerResult_ = emptyBooleanList();
        bitField0_ = (bitField0_ & ~0x00000040);
        onChanged();
        return this;
      }

      private boolean moreResultsInRegion_ ;
      /**
       * <pre>
       * A server may choose to limit the number of results returned to the client for
       * reasons such as the size in bytes or quantity of results accumulated. This field
       * will true when more results exist in the current region.
       * </pre>
       *
       * <code>optional bool more_results_in_region = 8;</code>
       * @return Whether the moreResultsInRegion field is set.
       */
      @java.lang.Override
      public boolean hasMoreResultsInRegion() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <pre>
       * A server may choose to limit the number of results returned to the client for
       * reasons such as the size in bytes or quantity of results accumulated. This field
       * will true when more results exist in the current region.
       * </pre>
       *
       * <code>optional bool more_results_in_region = 8;</code>
       * @return The moreResultsInRegion.
       */
      @java.lang.Override
      public boolean getMoreResultsInRegion() {
        return moreResultsInRegion_;
      }
      /**
       * <pre>
       * A server may choose to limit the number of results returned to the client for
       * reasons such as the size in bytes or quantity of results accumulated. This field
       * will true when more results exist in the current region.
       * </pre>
       *
       * <code>optional bool more_results_in_region = 8;</code>
       * @param value The moreResultsInRegion to set.
       * @return This builder for chaining.
       */
      public Builder setMoreResultsInRegion(boolean value) {

        moreResultsInRegion_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A server may choose to limit the number of results returned to the client for
       * reasons such as the size in bytes or quantity of results accumulated. This field
       * will true when more results exist in the current region.
       * </pre>
       *
       * <code>optional bool more_results_in_region = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearMoreResultsInRegion() {
        bitField0_ = (bitField0_ & ~0x00000080);
        moreResultsInRegion_ = false;
        onChanged();
        return this;
      }

      private boolean heartbeatMessage_ ;
      /**
       * <pre>
       * This field is filled in if the server is sending back a heartbeat message.
       * Heartbeat messages are sent back to the client to prevent the scanner from
       * timing out. Seeing a heartbeat message communicates to the Client that the
       * server would have continued to scan had the time limit not been reached.
       * </pre>
       *
       * <code>optional bool heartbeat_message = 9;</code>
       * @return Whether the heartbeatMessage field is set.
       */
      @java.lang.Override
      public boolean hasHeartbeatMessage() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <pre>
       * This field is filled in if the server is sending back a heartbeat message.
       * Heartbeat messages are sent back to the client to prevent the scanner from
       * timing out. Seeing a heartbeat message communicates to the Client that the
       * server would have continued to scan had the time limit not been reached.
       * </pre>
       *
       * <code>optional bool heartbeat_message = 9;</code>
       * @return The heartbeatMessage.
       */
      @java.lang.Override
      public boolean getHeartbeatMessage() {
        return heartbeatMessage_;
      }
      /**
       * <pre>
       * This field is filled in if the server is sending back a heartbeat message.
       * Heartbeat messages are sent back to the client to prevent the scanner from
       * timing out. Seeing a heartbeat message communicates to the Client that the
       * server would have continued to scan had the time limit not been reached.
       * </pre>
       *
       * <code>optional bool heartbeat_message = 9;</code>
       * @param value The heartbeatMessage to set.
       * @return This builder for chaining.
       */
      public Builder setHeartbeatMessage(boolean value) {

        heartbeatMessage_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if the server is sending back a heartbeat message.
       * Heartbeat messages are sent back to the client to prevent the scanner from
       * timing out. Seeing a heartbeat message communicates to the Client that the
       * server would have continued to scan had the time limit not been reached.
       * </pre>
       *
       * <code>optional bool heartbeat_message = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearHeartbeatMessage() {
        bitField0_ = (bitField0_ & ~0x00000100);
        heartbeatMessage_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics scanMetrics_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder> scanMetricsBuilder_;
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       * @return Whether the scanMetrics field is set.
       */
      public boolean hasScanMetrics() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       * @return The scanMetrics.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics getScanMetrics() {
        if (scanMetricsBuilder_ == null) {
          return scanMetrics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.getDefaultInstance() : scanMetrics_;
        } else {
          return scanMetricsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public Builder setScanMetrics(org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics value) {
        if (scanMetricsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scanMetrics_ = value;
        } else {
          scanMetricsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public Builder setScanMetrics(
          org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.Builder builderForValue) {
        if (scanMetricsBuilder_ == null) {
          scanMetrics_ = builderForValue.build();
        } else {
          scanMetricsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public Builder mergeScanMetrics(org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics value) {
        if (scanMetricsBuilder_ == null) {
          if (((bitField0_ & 0x00000200) != 0) &&
            scanMetrics_ != null &&
            scanMetrics_ != org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.getDefaultInstance()) {
            getScanMetricsBuilder().mergeFrom(value);
          } else {
            scanMetrics_ = value;
          }
        } else {
          scanMetricsBuilder_.mergeFrom(value);
        }
        if (scanMetrics_ != null) {
          bitField0_ |= 0x00000200;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public Builder clearScanMetrics() {
        bitField0_ = (bitField0_ & ~0x00000200);
        scanMetrics_ = null;
        if (scanMetricsBuilder_ != null) {
          scanMetricsBuilder_.dispose();
          scanMetricsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.Builder getScanMetricsBuilder() {
        bitField0_ |= 0x00000200;
        onChanged();
        return getScanMetricsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder getScanMetricsOrBuilder() {
        if (scanMetricsBuilder_ != null) {
          return scanMetricsBuilder_.getMessageOrBuilder();
        } else {
          return scanMetrics_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.getDefaultInstance() : scanMetrics_;
        }
      }
      /**
       * <pre>
       * This field is filled in if the client has requested that scan metrics be tracked.
       * The metrics tracked here are sent back to the client to be tracked together with
       * the existing client side metrics.
       * </pre>
       *
       * <code>optional .hbase.pb.ScanMetrics scan_metrics = 10;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder> 
          getScanMetricsFieldBuilder() {
        if (scanMetricsBuilder_ == null) {
          scanMetricsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetrics.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.ScanMetricsOrBuilder>(
                  getScanMetrics(),
                  getParentForChildren(),
                  isClean());
          scanMetrics_ = null;
        }
        return scanMetricsBuilder_;
      }

      private long mvccReadPoint_ ;
      /**
       * <pre>
       * The mvcc read point which is used to open the scanner at server side. Client can
       * make use of this mvcc_read_point when restarting a scanner to get a consistent view
       * of a row.
       * </pre>
       *
       * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
       * @return Whether the mvccReadPoint field is set.
       */
      @java.lang.Override
      public boolean hasMvccReadPoint() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <pre>
       * The mvcc read point which is used to open the scanner at server side. Client can
       * make use of this mvcc_read_point when restarting a scanner to get a consistent view
       * of a row.
       * </pre>
       *
       * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
       * @return The mvccReadPoint.
       */
      @java.lang.Override
      public long getMvccReadPoint() {
        return mvccReadPoint_;
      }
      /**
       * <pre>
       * The mvcc read point which is used to open the scanner at server side. Client can
       * make use of this mvcc_read_point when restarting a scanner to get a consistent view
       * of a row.
       * </pre>
       *
       * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
       * @param value The mvccReadPoint to set.
       * @return This builder for chaining.
       */
      public Builder setMvccReadPoint(long value) {

        mvccReadPoint_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The mvcc read point which is used to open the scanner at server side. Client can
       * make use of this mvcc_read_point when restarting a scanner to get a consistent view
       * of a row.
       * </pre>
       *
       * <code>optional uint64 mvcc_read_point = 11 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearMvccReadPoint() {
        bitField0_ = (bitField0_ & ~0x00000400);
        mvccReadPoint_ = 0L;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor cursor_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder> cursorBuilder_;
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       * @return Whether the cursor field is set.
       */
      public boolean hasCursor() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       * @return The cursor.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor getCursor() {
        if (cursorBuilder_ == null) {
          return cursor_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance() : cursor_;
        } else {
          return cursorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public Builder setCursor(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor value) {
        if (cursorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          cursor_ = value;
        } else {
          cursorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000800;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public Builder setCursor(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder builderForValue) {
        if (cursorBuilder_ == null) {
          cursor_ = builderForValue.build();
        } else {
          cursorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000800;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public Builder mergeCursor(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor value) {
        if (cursorBuilder_ == null) {
          if (((bitField0_ & 0x00000800) != 0) &&
            cursor_ != null &&
            cursor_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance()) {
            getCursorBuilder().mergeFrom(value);
          } else {
            cursor_ = value;
          }
        } else {
          cursorBuilder_.mergeFrom(value);
        }
        if (cursor_ != null) {
          bitField0_ |= 0x00000800;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public Builder clearCursor() {
        bitField0_ = (bitField0_ & ~0x00000800);
        cursor_ = null;
        if (cursorBuilder_ != null) {
          cursorBuilder_.dispose();
          cursorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder getCursorBuilder() {
        bitField0_ |= 0x00000800;
        onChanged();
        return getCursorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder getCursorOrBuilder() {
        if (cursorBuilder_ != null) {
          return cursorBuilder_.getMessageOrBuilder();
        } else {
          return cursor_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.getDefaultInstance() : cursor_;
        }
      }
      /**
       * <pre>
       * If the Scan need cursor, return the row key we are scanning in heartbeat message.
       * If the Scan doesn't need a cursor, don't set this field to reduce network IO.
       * </pre>
       *
       * <code>optional .hbase.pb.Cursor cursor = 12;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder> 
          getCursorFieldBuilder() {
        if (cursorBuilder_ == null) {
          cursorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Cursor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CursorOrBuilder>(
                  getCursor(),
                  getParentForChildren(),
                  isClean());
          cursor_ = null;
        }
        return cursorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ScanResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ScanResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ScanResponse>() {
      @java.lang.Override
      public ScanResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ScanResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BulkLoadHFileRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BulkLoadHFileRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> 
        getFamilyPathList();
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index);
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    int getFamilyPathCount();
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList();
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index);

    /**
     * <code>optional bool assign_seq_num = 3;</code>
     * @return Whether the assignSeqNum field is set.
     */
    boolean hasAssignSeqNum();
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     * @return The assignSeqNum.
     */
    boolean getAssignSeqNum();

    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     * @return Whether the fsToken field is set.
     */
    boolean hasFsToken();
    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     * @return The fsToken.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getFsToken();
    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder getFsTokenOrBuilder();

    /**
     * <code>optional string bulk_token = 5;</code>
     * @return Whether the bulkToken field is set.
     */
    boolean hasBulkToken();
    /**
     * <code>optional string bulk_token = 5;</code>
     * @return The bulkToken.
     */
    java.lang.String getBulkToken();
    /**
     * <code>optional string bulk_token = 5;</code>
     * @return The bytes for bulkToken.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes();

    /**
     * <code>optional bool copy_file = 6 [default = false];</code>
     * @return Whether the copyFile field is set.
     */
    boolean hasCopyFile();
    /**
     * <code>optional bool copy_file = 6 [default = false];</code>
     * @return The copyFile.
     */
    boolean getCopyFile();

    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @return A list containing the clusterIds.
     */
    java.util.List<java.lang.String>
        getClusterIdsList();
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @return The count of clusterIds.
     */
    int getClusterIdsCount();
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @param index The index of the element to return.
     * @return The clusterIds at the given index.
     */
    java.lang.String getClusterIds(int index);
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @param index The index of the value to return.
     * @return The bytes of the clusterIds at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdsBytes(int index);

    /**
     * <code>optional bool replicate = 8 [default = true];</code>
     * @return Whether the replicate field is set.
     */
    boolean hasReplicate();
    /**
     * <code>optional bool replicate = 8 [default = true];</code>
     * @return The replicate.
     */
    boolean getReplicate();
  }
  /**
   * <pre>
   **
   * Atomically bulk load multiple HFiles (say from different column families)
   * into an open region.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.BulkLoadHFileRequest}
   */
  @javax.annotation.Generated("proto") public static final class BulkLoadHFileRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BulkLoadHFileRequest)
      BulkLoadHFileRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BulkLoadHFileRequest.newBuilder() to construct.
    private BulkLoadHFileRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BulkLoadHFileRequest() {
      familyPath_ = java.util.Collections.emptyList();
      bulkToken_ = "";
      clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      replicate_ = true;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BulkLoadHFileRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.Builder.class);
    }

    public interface FamilyPathOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hbase.pb.BulkLoadHFileRequest.FamilyPath)
        org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      boolean hasFamily();
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

      /**
       * <code>required string path = 2;</code>
       * @return Whether the path field is set.
       */
      boolean hasPath();
      /**
       * <code>required string path = 2;</code>
       * @return The path.
       */
      java.lang.String getPath();
      /**
       * <code>required string path = 2;</code>
       * @return The bytes for path.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPathBytes();
    }
    /**
     * Protobuf type {@code hbase.pb.BulkLoadHFileRequest.FamilyPath}
     */
    @javax.annotation.Generated("proto") public static final class FamilyPath extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hbase.pb.BulkLoadHFileRequest.FamilyPath)
        FamilyPathOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use FamilyPath.newBuilder() to construct.
      private FamilyPath(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private FamilyPath() {
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        path_ = "";
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new FamilyPath();
      }

      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder.class);
      }

      private int bitField0_;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }

      public static final int PATH_FIELD_NUMBER = 2;
      @SuppressWarnings("serial")
      private volatile java.lang.Object path_ = "";
      /**
       * <code>required string path = 2;</code>
       * @return Whether the path field is set.
       */
      @java.lang.Override
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string path = 2;</code>
       * @return The path.
       */
      @java.lang.Override
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        }
      }
      /**
       * <code>required string path = 2;</code>
       * @return The bytes for path.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!hasPath()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeBytes(1, family_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, path_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, path_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) obj;

        if (hasFamily() != other.hasFamily()) return false;
        if (hasFamily()) {
          if (!getFamily()
              .equals(other.getFamily())) return false;
        }
        if (hasPath() != other.hasPath()) return false;
        if (hasPath()) {
          if (!getPath()
              .equals(other.getPath())) return false;
        }
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (hasPath()) {
          hash = (37 * hash) + PATH_FIELD_NUMBER;
          hash = (53 * hash) + getPath().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          java.nio.ByteBuffer data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          java.nio.ByteBuffer data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(byte[] data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          byte[] data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.BulkLoadHFileRequest.FamilyPath}
       */
      @javax.annotation.Generated("proto") public static final class Builder extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hbase.pb.BulkLoadHFileRequest.FamilyPath)
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder {
        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.newBuilder()
        private Builder() {

        }

        private Builder(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);

        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          path_ = "";
          return this;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath build() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath buildPartial() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath(this);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result) {
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.family_ = family_;
            to_bitField0_ |= 0x00000001;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.path_ = path_;
            to_bitField0_ |= 0x00000002;
          }
          result.bitField0_ |= to_bitField0_;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) {
            return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other) {
          if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (other.hasPath()) {
            path_ = other.path_;
            bitField0_ |= 0x00000002;
            onChanged();
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasFamily()) {
            return false;
          }
          if (!hasPath()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  family_ = input.readBytes();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 18: {
                  path_ = input.readBytes();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 18
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes family = 1;</code>
         * @return Whether the family field is set.
         */
        @java.lang.Override
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required bytes family = 1;</code>
         * @return The family.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        /**
         * <code>required bytes family = 1;</code>
         * @param value The family to set.
         * @return This builder for chaining.
         */
        public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          family_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes family = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }

        private java.lang.Object path_ = "";
        /**
         * <code>required string path = 2;</code>
         * @return Whether the path field is set.
         */
        public boolean hasPath() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>required string path = 2;</code>
         * @return The path.
         */
        public java.lang.String getPath() {
          java.lang.Object ref = path_;
          if (!(ref instanceof java.lang.String)) {
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
                (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            if (bs.isValidUtf8()) {
              path_ = s;
            }
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <code>required string path = 2;</code>
         * @return The bytes for path.
         */
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
            getPathBytes() {
          java.lang.Object ref = path_;
          if (ref instanceof String) {
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            path_ = b;
            return b;
          } else {
            return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <code>required string path = 2;</code>
         * @param value The path to set.
         * @return This builder for chaining.
         */
        public Builder setPath(
            java.lang.String value) {
          if (value == null) { throw new NullPointerException(); }
          path_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         * <code>required string path = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearPath() {
          path_ = getDefaultInstance().getPath();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }
        /**
         * <code>required string path = 2;</code>
         * @param value The bytes for path to set.
         * @return This builder for chaining.
         */
        public Builder setPathBytes(
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          path_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hbase.pb.BulkLoadHFileRequest.FamilyPath)
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.BulkLoadHFileRequest.FamilyPath)
      private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath();
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyPath>
          PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FamilyPath>() {
        @java.lang.Override
        public FamilyPath parsePartialFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyPath> parser() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyPath> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int FAMILY_PATH_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_;
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
      return familyPath_;
    }
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList() {
      return familyPath_;
    }
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    @java.lang.Override
    public int getFamilyPathCount() {
      return familyPath_.size();
    }
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
      return familyPath_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index) {
      return familyPath_.get(index);
    }

    public static final int ASSIGN_SEQ_NUM_FIELD_NUMBER = 3;
    private boolean assignSeqNum_ = false;
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     * @return Whether the assignSeqNum field is set.
     */
    @java.lang.Override
    public boolean hasAssignSeqNum() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     * @return The assignSeqNum.
     */
    @java.lang.Override
    public boolean getAssignSeqNum() {
      return assignSeqNum_;
    }

    public static final int FS_TOKEN_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken fsToken_;
    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     * @return Whether the fsToken field is set.
     */
    @java.lang.Override
    public boolean hasFsToken() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     * @return The fsToken.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getFsToken() {
      return fsToken_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance() : fsToken_;
    }
    /**
     * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder getFsTokenOrBuilder() {
      return fsToken_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance() : fsToken_;
    }

    public static final int BULK_TOKEN_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private volatile java.lang.Object bulkToken_ = "";
    /**
     * <code>optional string bulk_token = 5;</code>
     * @return Whether the bulkToken field is set.
     */
    @java.lang.Override
    public boolean hasBulkToken() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional string bulk_token = 5;</code>
     * @return The bulkToken.
     */
    @java.lang.Override
    public java.lang.String getBulkToken() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          bulkToken_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string bulk_token = 5;</code>
     * @return The bytes for bulkToken.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        bulkToken_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int COPY_FILE_FIELD_NUMBER = 6;
    private boolean copyFile_ = false;
    /**
     * <code>optional bool copy_file = 6 [default = false];</code>
     * @return Whether the copyFile field is set.
     */
    @java.lang.Override
    public boolean hasCopyFile() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional bool copy_file = 6 [default = false];</code>
     * @return The copyFile.
     */
    @java.lang.Override
    public boolean getCopyFile() {
      return copyFile_;
    }

    public static final int CLUSTER_IDS_FIELD_NUMBER = 7;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList clusterIds_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @return A list containing the clusterIds.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getClusterIdsList() {
      return clusterIds_;
    }
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @return The count of clusterIds.
     */
    public int getClusterIdsCount() {
      return clusterIds_.size();
    }
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @param index The index of the element to return.
     * @return The clusterIds at the given index.
     */
    public java.lang.String getClusterIds(int index) {
      return clusterIds_.get(index);
    }
    /**
     * <code>repeated string cluster_ids = 7;</code>
     * @param index The index of the value to return.
     * @return The bytes of the clusterIds at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdsBytes(int index) {
      return clusterIds_.getByteString(index);
    }

    public static final int REPLICATE_FIELD_NUMBER = 8;
    private boolean replicate_ = true;
    /**
     * <code>optional bool replicate = 8 [default = true];</code>
     * @return Whether the replicate field is set.
     */
    @java.lang.Override
    public boolean hasReplicate() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool replicate = 8 [default = true];</code>
     * @return The replicate.
     */
    @java.lang.Override
    public boolean getReplicate() {
      return replicate_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getFamilyPathCount(); i++) {
        if (!getFamilyPath(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        output.writeMessage(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(3, assignSeqNum_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(4, getFsToken());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 5, bulkToken_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(6, copyFile_);
      }
      for (int i = 0; i < clusterIds_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 7, clusterIds_.getRaw(i));
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(8, replicate_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, assignSeqNum_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getFsToken());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(5, bulkToken_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, copyFile_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < clusterIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(clusterIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getClusterIdsList().size();
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, replicate_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (!getFamilyPathList()
          .equals(other.getFamilyPathList())) return false;
      if (hasAssignSeqNum() != other.hasAssignSeqNum()) return false;
      if (hasAssignSeqNum()) {
        if (getAssignSeqNum()
            != other.getAssignSeqNum()) return false;
      }
      if (hasFsToken() != other.hasFsToken()) return false;
      if (hasFsToken()) {
        if (!getFsToken()
            .equals(other.getFsToken())) return false;
      }
      if (hasBulkToken() != other.hasBulkToken()) return false;
      if (hasBulkToken()) {
        if (!getBulkToken()
            .equals(other.getBulkToken())) return false;
      }
      if (hasCopyFile() != other.hasCopyFile()) return false;
      if (hasCopyFile()) {
        if (getCopyFile()
            != other.getCopyFile()) return false;
      }
      if (!getClusterIdsList()
          .equals(other.getClusterIdsList())) return false;
      if (hasReplicate() != other.hasReplicate()) return false;
      if (hasReplicate()) {
        if (getReplicate()
            != other.getReplicate()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getFamilyPathCount() > 0) {
        hash = (37 * hash) + FAMILY_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyPathList().hashCode();
      }
      if (hasAssignSeqNum()) {
        hash = (37 * hash) + ASSIGN_SEQ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getAssignSeqNum());
      }
      if (hasFsToken()) {
        hash = (37 * hash) + FS_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getFsToken().hashCode();
      }
      if (hasBulkToken()) {
        hash = (37 * hash) + BULK_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getBulkToken().hashCode();
      }
      if (hasCopyFile()) {
        hash = (37 * hash) + COPY_FILE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCopyFile());
      }
      if (getClusterIdsCount() > 0) {
        hash = (37 * hash) + CLUSTER_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getClusterIdsList().hashCode();
      }
      if (hasReplicate()) {
        hash = (37 * hash) + REPLICATE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getReplicate());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Atomically bulk load multiple HFiles (say from different column families)
     * into an open region.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.BulkLoadHFileRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BulkLoadHFileRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getFamilyPathFieldBuilder();
          getFsTokenFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
        } else {
          familyPath_ = null;
          familyPathBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        assignSeqNum_ = false;
        fsToken_ = null;
        if (fsTokenBuilder_ != null) {
          fsTokenBuilder_.dispose();
          fsTokenBuilder_ = null;
        }
        bulkToken_ = "";
        copyFile_ = false;
        clusterIds_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        replicate_ = true;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest result) {
        if (familyPathBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            familyPath_ = java.util.Collections.unmodifiableList(familyPath_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.familyPath_ = familyPath_;
        } else {
          result.familyPath_ = familyPathBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.assignSeqNum_ = assignSeqNum_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.fsToken_ = fsTokenBuilder_ == null
              ? fsToken_
              : fsTokenBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.bulkToken_ = bulkToken_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.copyFile_ = copyFile_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          clusterIds_.makeImmutable();
          result.clusterIds_ = clusterIds_;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.replicate_ = replicate_;
          to_bitField0_ |= 0x00000020;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (familyPathBuilder_ == null) {
          if (!other.familyPath_.isEmpty()) {
            if (familyPath_.isEmpty()) {
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFamilyPathIsMutable();
              familyPath_.addAll(other.familyPath_);
            }
            onChanged();
          }
        } else {
          if (!other.familyPath_.isEmpty()) {
            if (familyPathBuilder_.isEmpty()) {
              familyPathBuilder_.dispose();
              familyPathBuilder_ = null;
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
              familyPathBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFamilyPathFieldBuilder() : null;
            } else {
              familyPathBuilder_.addAllMessages(other.familyPath_);
            }
          }
        }
        if (other.hasAssignSeqNum()) {
          setAssignSeqNum(other.getAssignSeqNum());
        }
        if (other.hasFsToken()) {
          mergeFsToken(other.getFsToken());
        }
        if (other.hasBulkToken()) {
          bulkToken_ = other.bulkToken_;
          bitField0_ |= 0x00000010;
          onChanged();
        }
        if (other.hasCopyFile()) {
          setCopyFile(other.getCopyFile());
        }
        if (!other.clusterIds_.isEmpty()) {
          if (clusterIds_.isEmpty()) {
            clusterIds_ = other.clusterIds_;
            bitField0_ |= 0x00000040;
          } else {
            ensureClusterIdsIsMutable();
            clusterIds_.addAll(other.clusterIds_);
          }
          onChanged();
        }
        if (other.hasReplicate()) {
          setReplicate(other.getReplicate());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getFamilyPathCount(); i++) {
          if (!getFamilyPath(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.PARSER,
                        extensionRegistry);
                if (familyPathBuilder_ == null) {
                  ensureFamilyPathIsMutable();
                  familyPath_.add(m);
                } else {
                  familyPathBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 24: {
                assignSeqNum_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getFsTokenFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                bulkToken_ = input.readBytes();
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 48: {
                copyFile_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 58: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureClusterIdsIsMutable();
                clusterIds_.add(bs);
                break;
              } // case 58
              case 64: {
                replicate_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_ =
        java.util.Collections.emptyList();
      private void ensureFamilyPathIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          familyPath_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath>(familyPath_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> familyPathBuilder_;

      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
        if (familyPathBuilder_ == null) {
          return java.util.Collections.unmodifiableList(familyPath_);
        } else {
          return familyPathBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public int getFamilyPathCount() {
        if (familyPathBuilder_ == null) {
          return familyPath_.size();
        } else {
          return familyPathBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);
        } else {
          return familyPathBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.set(index, value);
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.set(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(index, value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addAllFamilyPath(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> values) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, familyPath_);
          onChanged();
        } else {
          familyPathBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder clearFamilyPath() {
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          familyPathBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder removeFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.remove(index);
          onChanged();
        } else {
          familyPathBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder getFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
          int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);  } else {
          return familyPathBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
           getFamilyPathOrBuilderList() {
        if (familyPathBuilder_ != null) {
          return familyPathBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(familyPath_);
        }
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder() {
        return getFamilyPathFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder> 
           getFamilyPathBuilderList() {
        return getFamilyPathFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
          getFamilyPathFieldBuilder() {
        if (familyPathBuilder_ == null) {
          familyPathBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder>(
                  familyPath_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          familyPath_ = null;
        }
        return familyPathBuilder_;
      }

      private boolean assignSeqNum_ ;
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       * @return Whether the assignSeqNum field is set.
       */
      @java.lang.Override
      public boolean hasAssignSeqNum() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       * @return The assignSeqNum.
       */
      @java.lang.Override
      public boolean getAssignSeqNum() {
        return assignSeqNum_;
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       * @param value The assignSeqNum to set.
       * @return This builder for chaining.
       */
      public Builder setAssignSeqNum(boolean value) {

        assignSeqNum_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssignSeqNum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        assignSeqNum_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken fsToken_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder> fsTokenBuilder_;
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       * @return Whether the fsToken field is set.
       */
      public boolean hasFsToken() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       * @return The fsToken.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getFsToken() {
        if (fsTokenBuilder_ == null) {
          return fsToken_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance() : fsToken_;
        } else {
          return fsTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public Builder setFsToken(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken value) {
        if (fsTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fsToken_ = value;
        } else {
          fsTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public Builder setFsToken(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder builderForValue) {
        if (fsTokenBuilder_ == null) {
          fsToken_ = builderForValue.build();
        } else {
          fsTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public Builder mergeFsToken(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken value) {
        if (fsTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            fsToken_ != null &&
            fsToken_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance()) {
            getFsTokenBuilder().mergeFrom(value);
          } else {
            fsToken_ = value;
          }
        } else {
          fsTokenBuilder_.mergeFrom(value);
        }
        if (fsToken_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public Builder clearFsToken() {
        bitField0_ = (bitField0_ & ~0x00000008);
        fsToken_ = null;
        if (fsTokenBuilder_ != null) {
          fsTokenBuilder_.dispose();
          fsTokenBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder getFsTokenBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getFsTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder getFsTokenOrBuilder() {
        if (fsTokenBuilder_ != null) {
          return fsTokenBuilder_.getMessageOrBuilder();
        } else {
          return fsToken_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance() : fsToken_;
        }
      }
      /**
       * <code>optional .hbase.pb.DelegationToken fs_token = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder> 
          getFsTokenFieldBuilder() {
        if (fsTokenBuilder_ == null) {
          fsTokenBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder>(
                  getFsToken(),
                  getParentForChildren(),
                  isClean());
          fsToken_ = null;
        }
        return fsTokenBuilder_;
      }

      private java.lang.Object bulkToken_ = "";
      /**
       * <code>optional string bulk_token = 5;</code>
       * @return Whether the bulkToken field is set.
       */
      public boolean hasBulkToken() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional string bulk_token = 5;</code>
       * @return The bulkToken.
       */
      public java.lang.String getBulkToken() {
        java.lang.Object ref = bulkToken_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            bulkToken_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string bulk_token = 5;</code>
       * @return The bytes for bulkToken.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getBulkTokenBytes() {
        java.lang.Object ref = bulkToken_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          bulkToken_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string bulk_token = 5;</code>
       * @param value The bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkToken(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional string bulk_token = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearBulkToken() {
        bulkToken_ = getDefaultInstance().getBulkToken();
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <code>optional string bulk_token = 5;</code>
       * @param value The bytes for bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkTokenBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }

      private boolean copyFile_ ;
      /**
       * <code>optional bool copy_file = 6 [default = false];</code>
       * @return Whether the copyFile field is set.
       */
      @java.lang.Override
      public boolean hasCopyFile() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool copy_file = 6 [default = false];</code>
       * @return The copyFile.
       */
      @java.lang.Override
      public boolean getCopyFile() {
        return copyFile_;
      }
      /**
       * <code>optional bool copy_file = 6 [default = false];</code>
       * @param value The copyFile to set.
       * @return This builder for chaining.
       */
      public Builder setCopyFile(boolean value) {

        copyFile_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool copy_file = 6 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearCopyFile() {
        bitField0_ = (bitField0_ & ~0x00000020);
        copyFile_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureClusterIdsIsMutable() {
        if (!clusterIds_.isModifiable()) {
          clusterIds_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(clusterIds_);
        }
        bitField0_ |= 0x00000040;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @return A list containing the clusterIds.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getClusterIdsList() {
        clusterIds_.makeImmutable();
        return clusterIds_;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @return The count of clusterIds.
       */
      public int getClusterIdsCount() {
        return clusterIds_.size();
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param index The index of the element to return.
       * @return The clusterIds at the given index.
       */
      public java.lang.String getClusterIds(int index) {
        return clusterIds_.get(index);
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param index The index of the value to return.
       * @return The bytes of the clusterIds at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getClusterIdsBytes(int index) {
        return clusterIds_.getByteString(index);
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param index The index to set the value at.
       * @param value The clusterIds to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIds(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.set(index, value);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param value The clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addClusterIds(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.add(value);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param values The clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addAllClusterIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureClusterIdsIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, clusterIds_);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterIds() {
        clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000040);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 7;</code>
       * @param value The bytes of the clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addClusterIdsBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.add(value);
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }

      private boolean replicate_ = true;
      /**
       * <code>optional bool replicate = 8 [default = true];</code>
       * @return Whether the replicate field is set.
       */
      @java.lang.Override
      public boolean hasReplicate() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional bool replicate = 8 [default = true];</code>
       * @return The replicate.
       */
      @java.lang.Override
      public boolean getReplicate() {
        return replicate_;
      }
      /**
       * <code>optional bool replicate = 8 [default = true];</code>
       * @param value The replicate to set.
       * @return This builder for chaining.
       */
      public Builder setReplicate(boolean value) {

        replicate_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool replicate = 8 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearReplicate() {
        bitField0_ = (bitField0_ & ~0x00000080);
        replicate_ = true;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BulkLoadHFileRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BulkLoadHFileRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<BulkLoadHFileRequest>() {
      @java.lang.Override
      public BulkLoadHFileRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BulkLoadHFileResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BulkLoadHFileResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool loaded = 1;</code>
     * @return Whether the loaded field is set.
     */
    boolean hasLoaded();
    /**
     * <code>required bool loaded = 1;</code>
     * @return The loaded.
     */
    boolean getLoaded();
  }
  /**
   * Protobuf type {@code hbase.pb.BulkLoadHFileResponse}
   */
  @javax.annotation.Generated("proto") public static final class BulkLoadHFileResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BulkLoadHFileResponse)
      BulkLoadHFileResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BulkLoadHFileResponse.newBuilder() to construct.
    private BulkLoadHFileResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BulkLoadHFileResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BulkLoadHFileResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.Builder.class);
    }

    private int bitField0_;
    public static final int LOADED_FIELD_NUMBER = 1;
    private boolean loaded_ = false;
    /**
     * <code>required bool loaded = 1;</code>
     * @return Whether the loaded field is set.
     */
    @java.lang.Override
    public boolean hasLoaded() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool loaded = 1;</code>
     * @return The loaded.
     */
    @java.lang.Override
    public boolean getLoaded() {
      return loaded_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasLoaded()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, loaded_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, loaded_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse) obj;

      if (hasLoaded() != other.hasLoaded()) return false;
      if (hasLoaded()) {
        if (getLoaded()
            != other.getLoaded()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLoaded()) {
        hash = (37 * hash) + LOADED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getLoaded());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.BulkLoadHFileResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BulkLoadHFileResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        loaded_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_BulkLoadHFileResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.loaded_ = loaded_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()) return this;
        if (other.hasLoaded()) {
          setLoaded(other.getLoaded());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasLoaded()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                loaded_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean loaded_ ;
      /**
       * <code>required bool loaded = 1;</code>
       * @return Whether the loaded field is set.
       */
      @java.lang.Override
      public boolean hasLoaded() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool loaded = 1;</code>
       * @return The loaded.
       */
      @java.lang.Override
      public boolean getLoaded() {
        return loaded_;
      }
      /**
       * <code>required bool loaded = 1;</code>
       * @param value The loaded to set.
       * @return This builder for chaining.
       */
      public Builder setLoaded(boolean value) {

        loaded_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool loaded = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLoaded() {
        bitField0_ = (bitField0_ & ~0x00000001);
        loaded_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BulkLoadHFileResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BulkLoadHFileResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<BulkLoadHFileResponse>() {
      @java.lang.Override
      public BulkLoadHFileResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadHFileResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DelegationTokenOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DelegationToken)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes identifier = 1;</code>
     * @return Whether the identifier field is set.
     */
    boolean hasIdentifier();
    /**
     * <code>optional bytes identifier = 1;</code>
     * @return The identifier.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getIdentifier();

    /**
     * <code>optional bytes password = 2;</code>
     * @return Whether the password field is set.
     */
    boolean hasPassword();
    /**
     * <code>optional bytes password = 2;</code>
     * @return The password.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPassword();

    /**
     * <code>optional string kind = 3;</code>
     * @return Whether the kind field is set.
     */
    boolean hasKind();
    /**
     * <code>optional string kind = 3;</code>
     * @return The kind.
     */
    java.lang.String getKind();
    /**
     * <code>optional string kind = 3;</code>
     * @return The bytes for kind.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getKindBytes();

    /**
     * <code>optional string service = 4;</code>
     * @return Whether the service field is set.
     */
    boolean hasService();
    /**
     * <code>optional string service = 4;</code>
     * @return The service.
     */
    java.lang.String getService();
    /**
     * <code>optional string service = 4;</code>
     * @return The bytes for service.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getServiceBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.DelegationToken}
   */
  @javax.annotation.Generated("proto") public static final class DelegationToken extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DelegationToken)
      DelegationTokenOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DelegationToken.newBuilder() to construct.
    private DelegationToken(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DelegationToken() {
      identifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      password_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      kind_ = "";
      service_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DelegationToken();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_DelegationToken_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_DelegationToken_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder.class);
    }

    private int bitField0_;
    public static final int IDENTIFIER_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString identifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes identifier = 1;</code>
     * @return Whether the identifier field is set.
     */
    @java.lang.Override
    public boolean hasIdentifier() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes identifier = 1;</code>
     * @return The identifier.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getIdentifier() {
      return identifier_;
    }

    public static final int PASSWORD_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString password_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes password = 2;</code>
     * @return Whether the password field is set.
     */
    @java.lang.Override
    public boolean hasPassword() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes password = 2;</code>
     * @return The password.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPassword() {
      return password_;
    }

    public static final int KIND_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object kind_ = "";
    /**
     * <code>optional string kind = 3;</code>
     * @return Whether the kind field is set.
     */
    @java.lang.Override
    public boolean hasKind() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional string kind = 3;</code>
     * @return The kind.
     */
    @java.lang.Override
    public java.lang.String getKind() {
      java.lang.Object ref = kind_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          kind_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string kind = 3;</code>
     * @return The bytes for kind.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getKindBytes() {
      java.lang.Object ref = kind_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        kind_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SERVICE_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object service_ = "";
    /**
     * <code>optional string service = 4;</code>
     * @return Whether the service field is set.
     */
    @java.lang.Override
    public boolean hasService() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional string service = 4;</code>
     * @return The service.
     */
    @java.lang.Override
    public java.lang.String getService() {
      java.lang.Object ref = service_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          service_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string service = 4;</code>
     * @return The bytes for service.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getServiceBytes() {
      java.lang.Object ref = service_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        service_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, identifier_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, password_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, kind_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 4, service_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, identifier_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, password_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, kind_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(4, service_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken) obj;

      if (hasIdentifier() != other.hasIdentifier()) return false;
      if (hasIdentifier()) {
        if (!getIdentifier()
            .equals(other.getIdentifier())) return false;
      }
      if (hasPassword() != other.hasPassword()) return false;
      if (hasPassword()) {
        if (!getPassword()
            .equals(other.getPassword())) return false;
      }
      if (hasKind() != other.hasKind()) return false;
      if (hasKind()) {
        if (!getKind()
            .equals(other.getKind())) return false;
      }
      if (hasService() != other.hasService()) return false;
      if (hasService()) {
        if (!getService()
            .equals(other.getService())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasIdentifier()) {
        hash = (37 * hash) + IDENTIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getIdentifier().hashCode();
      }
      if (hasPassword()) {
        hash = (37 * hash) + PASSWORD_FIELD_NUMBER;
        hash = (53 * hash) + getPassword().hashCode();
      }
      if (hasKind()) {
        hash = (37 * hash) + KIND_FIELD_NUMBER;
        hash = (53 * hash) + getKind().hashCode();
      }
      if (hasService()) {
        hash = (37 * hash) + SERVICE_FIELD_NUMBER;
        hash = (53 * hash) + getService().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DelegationToken}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DelegationToken)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationTokenOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_DelegationToken_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_DelegationToken_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        identifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        password_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        kind_ = "";
        service_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_DelegationToken_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.identifier_ = identifier_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.password_ = password_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.kind_ = kind_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.service_ = service_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken.getDefaultInstance()) return this;
        if (other.hasIdentifier()) {
          setIdentifier(other.getIdentifier());
        }
        if (other.hasPassword()) {
          setPassword(other.getPassword());
        }
        if (other.hasKind()) {
          kind_ = other.kind_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.hasService()) {
          service_ = other.service_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                identifier_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                password_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                kind_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                service_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString identifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes identifier = 1;</code>
       * @return Whether the identifier field is set.
       */
      @java.lang.Override
      public boolean hasIdentifier() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes identifier = 1;</code>
       * @return The identifier.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getIdentifier() {
        return identifier_;
      }
      /**
       * <code>optional bytes identifier = 1;</code>
       * @param value The identifier to set.
       * @return This builder for chaining.
       */
      public Builder setIdentifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        identifier_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes identifier = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIdentifier() {
        bitField0_ = (bitField0_ & ~0x00000001);
        identifier_ = getDefaultInstance().getIdentifier();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString password_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes password = 2;</code>
       * @return Whether the password field is set.
       */
      @java.lang.Override
      public boolean hasPassword() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes password = 2;</code>
       * @return The password.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPassword() {
        return password_;
      }
      /**
       * <code>optional bytes password = 2;</code>
       * @param value The password to set.
       * @return This builder for chaining.
       */
      public Builder setPassword(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        password_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes password = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearPassword() {
        bitField0_ = (bitField0_ & ~0x00000002);
        password_ = getDefaultInstance().getPassword();
        onChanged();
        return this;
      }

      private java.lang.Object kind_ = "";
      /**
       * <code>optional string kind = 3;</code>
       * @return Whether the kind field is set.
       */
      public boolean hasKind() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional string kind = 3;</code>
       * @return The kind.
       */
      public java.lang.String getKind() {
        java.lang.Object ref = kind_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            kind_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string kind = 3;</code>
       * @return The bytes for kind.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getKindBytes() {
        java.lang.Object ref = kind_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          kind_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string kind = 3;</code>
       * @param value The kind to set.
       * @return This builder for chaining.
       */
      public Builder setKind(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        kind_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional string kind = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearKind() {
        kind_ = getDefaultInstance().getKind();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>optional string kind = 3;</code>
       * @param value The bytes for kind to set.
       * @return This builder for chaining.
       */
      public Builder setKindBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        kind_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private java.lang.Object service_ = "";
      /**
       * <code>optional string service = 4;</code>
       * @return Whether the service field is set.
       */
      public boolean hasService() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional string service = 4;</code>
       * @return The service.
       */
      public java.lang.String getService() {
        java.lang.Object ref = service_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            service_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string service = 4;</code>
       * @return The bytes for service.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getServiceBytes() {
        java.lang.Object ref = service_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          service_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string service = 4;</code>
       * @param value The service to set.
       * @return This builder for chaining.
       */
      public Builder setService(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        service_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional string service = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearService() {
        service_ = getDefaultInstance().getService();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <code>optional string service = 4;</code>
       * @param value The bytes for service to set.
       * @return This builder for chaining.
       */
      public Builder setServiceBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        service_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DelegationToken)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DelegationToken)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DelegationToken>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DelegationToken>() {
      @java.lang.Override
      public DelegationToken parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DelegationToken> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DelegationToken> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.DelegationToken getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PrepareBulkLoadRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PrepareBulkLoadRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.PrepareBulkLoadRequest}
   */
  @javax.annotation.Generated("proto") public static final class PrepareBulkLoadRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PrepareBulkLoadRequest)
      PrepareBulkLoadRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PrepareBulkLoadRequest.newBuilder() to construct.
    private PrepareBulkLoadRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PrepareBulkLoadRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PrepareBulkLoadRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasRegion()) {
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getRegion());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegion());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PrepareBulkLoadRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PrepareBulkLoadRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        if (hasRegion()) {
          if (!getRegion().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000002);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PrepareBulkLoadRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PrepareBulkLoadRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PrepareBulkLoadRequest>() {
      @java.lang.Override
      public PrepareBulkLoadRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PrepareBulkLoadResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PrepareBulkLoadResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string bulk_token = 1;</code>
     * @return Whether the bulkToken field is set.
     */
    boolean hasBulkToken();
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bulkToken.
     */
    java.lang.String getBulkToken();
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bytes for bulkToken.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.PrepareBulkLoadResponse}
   */
  @javax.annotation.Generated("proto") public static final class PrepareBulkLoadResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PrepareBulkLoadResponse)
      PrepareBulkLoadResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PrepareBulkLoadResponse.newBuilder() to construct.
    private PrepareBulkLoadResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PrepareBulkLoadResponse() {
      bulkToken_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PrepareBulkLoadResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.Builder.class);
    }

    private int bitField0_;
    public static final int BULK_TOKEN_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object bulkToken_ = "";
    /**
     * <code>required string bulk_token = 1;</code>
     * @return Whether the bulkToken field is set.
     */
    @java.lang.Override
    public boolean hasBulkToken() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bulkToken.
     */
    @java.lang.Override
    public java.lang.String getBulkToken() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          bulkToken_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bytes for bulkToken.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        bulkToken_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasBulkToken()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, bulkToken_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, bulkToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse) obj;

      if (hasBulkToken() != other.hasBulkToken()) return false;
      if (hasBulkToken()) {
        if (!getBulkToken()
            .equals(other.getBulkToken())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBulkToken()) {
        hash = (37 * hash) + BULK_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getBulkToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PrepareBulkLoadResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PrepareBulkLoadResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        bulkToken_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bulkToken_ = bulkToken_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance()) return this;
        if (other.hasBulkToken()) {
          bulkToken_ = other.bulkToken_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasBulkToken()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                bulkToken_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object bulkToken_ = "";
      /**
       * <code>required string bulk_token = 1;</code>
       * @return Whether the bulkToken field is set.
       */
      public boolean hasBulkToken() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return The bulkToken.
       */
      public java.lang.String getBulkToken() {
        java.lang.Object ref = bulkToken_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            bulkToken_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return The bytes for bulkToken.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getBulkTokenBytes() {
        java.lang.Object ref = bulkToken_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          bulkToken_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @param value The bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkToken(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBulkToken() {
        bulkToken_ = getDefaultInstance().getBulkToken();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @param value The bytes for bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkTokenBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PrepareBulkLoadResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PrepareBulkLoadResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PrepareBulkLoadResponse>() {
      @java.lang.Override
      public PrepareBulkLoadResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrepareBulkLoadResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CleanupBulkLoadRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CleanupBulkLoadRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string bulk_token = 1;</code>
     * @return Whether the bulkToken field is set.
     */
    boolean hasBulkToken();
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bulkToken.
     */
    java.lang.String getBulkToken();
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bytes for bulkToken.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes();

    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CleanupBulkLoadRequest}
   */
  @javax.annotation.Generated("proto") public static final class CleanupBulkLoadRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CleanupBulkLoadRequest)
      CleanupBulkLoadRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CleanupBulkLoadRequest.newBuilder() to construct.
    private CleanupBulkLoadRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CleanupBulkLoadRequest() {
      bulkToken_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CleanupBulkLoadRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.Builder.class);
    }

    private int bitField0_;
    public static final int BULK_TOKEN_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object bulkToken_ = "";
    /**
     * <code>required string bulk_token = 1;</code>
     * @return Whether the bulkToken field is set.
     */
    @java.lang.Override
    public boolean hasBulkToken() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bulkToken.
     */
    @java.lang.Override
    public java.lang.String getBulkToken() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          bulkToken_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string bulk_token = 1;</code>
     * @return The bytes for bulkToken.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getBulkTokenBytes() {
      java.lang.Object ref = bulkToken_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        bulkToken_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int REGION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasBulkToken()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasRegion()) {
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, bulkToken_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getRegion());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, bulkToken_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getRegion());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest) obj;

      if (hasBulkToken() != other.hasBulkToken()) return false;
      if (hasBulkToken()) {
        if (!getBulkToken()
            .equals(other.getBulkToken())) return false;
      }
      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBulkToken()) {
        hash = (37 * hash) + BULK_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getBulkToken().hashCode();
      }
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CleanupBulkLoadRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CleanupBulkLoadRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        bulkToken_ = "";
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bulkToken_ = bulkToken_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.getDefaultInstance()) return this;
        if (other.hasBulkToken()) {
          bulkToken_ = other.bulkToken_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasBulkToken()) {
          return false;
        }
        if (hasRegion()) {
          if (!getRegion().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                bulkToken_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object bulkToken_ = "";
      /**
       * <code>required string bulk_token = 1;</code>
       * @return Whether the bulkToken field is set.
       */
      public boolean hasBulkToken() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return The bulkToken.
       */
      public java.lang.String getBulkToken() {
        java.lang.Object ref = bulkToken_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            bulkToken_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return The bytes for bulkToken.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getBulkTokenBytes() {
        java.lang.Object ref = bulkToken_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          bulkToken_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @param value The bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkToken(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBulkToken() {
        bulkToken_ = getDefaultInstance().getBulkToken();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string bulk_token = 1;</code>
       * @param value The bytes for bulkToken to set.
       * @return This builder for chaining.
       */
      public Builder setBulkTokenBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        bulkToken_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000002);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>optional .hbase.pb.RegionSpecifier region = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CleanupBulkLoadRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CleanupBulkLoadRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CleanupBulkLoadRequest>() {
      @java.lang.Override
      public CleanupBulkLoadRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CleanupBulkLoadResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CleanupBulkLoadResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.CleanupBulkLoadResponse}
   */
  @javax.annotation.Generated("proto") public static final class CleanupBulkLoadResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CleanupBulkLoadResponse)
      CleanupBulkLoadResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CleanupBulkLoadResponse.newBuilder() to construct.
    private CleanupBulkLoadResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CleanupBulkLoadResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CleanupBulkLoadResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CleanupBulkLoadResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CleanupBulkLoadResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CleanupBulkLoadResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CleanupBulkLoadResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CleanupBulkLoadResponse>() {
      @java.lang.Override
      public CleanupBulkLoadResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CleanupBulkLoadResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CoprocessorServiceCallOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CoprocessorServiceCall)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow();

    /**
     * <code>required string service_name = 2;</code>
     * @return Whether the serviceName field is set.
     */
    boolean hasServiceName();
    /**
     * <code>required string service_name = 2;</code>
     * @return The serviceName.
     */
    java.lang.String getServiceName();
    /**
     * <code>required string service_name = 2;</code>
     * @return The bytes for serviceName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getServiceNameBytes();

    /**
     * <code>required string method_name = 3;</code>
     * @return Whether the methodName field is set.
     */
    boolean hasMethodName();
    /**
     * <code>required string method_name = 3;</code>
     * @return The methodName.
     */
    java.lang.String getMethodName();
    /**
     * <code>required string method_name = 3;</code>
     * @return The bytes for methodName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getMethodNameBytes();

    /**
     * <code>required bytes request = 4;</code>
     * @return Whether the request field is set.
     */
    boolean hasRequest();
    /**
     * <code>required bytes request = 4;</code>
     * @return The request.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRequest();
  }
  /**
   * Protobuf type {@code hbase.pb.CoprocessorServiceCall}
   */
  @javax.annotation.Generated("proto") public static final class CoprocessorServiceCall extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CoprocessorServiceCall)
      CoprocessorServiceCallOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CoprocessorServiceCall.newBuilder() to construct.
    private CoprocessorServiceCall(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CoprocessorServiceCall() {
      row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      serviceName_ = "";
      methodName_ = "";
      request_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CoprocessorServiceCall();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceCall_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceCall_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder.class);
    }

    private int bitField0_;
    public static final int ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes row = 1;</code>
     * @return Whether the row field is set.
     */
    @java.lang.Override
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes row = 1;</code>
     * @return The row.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
      return row_;
    }

    public static final int SERVICE_NAME_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object serviceName_ = "";
    /**
     * <code>required string service_name = 2;</code>
     * @return Whether the serviceName field is set.
     */
    @java.lang.Override
    public boolean hasServiceName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string service_name = 2;</code>
     * @return The serviceName.
     */
    @java.lang.Override
    public java.lang.String getServiceName() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          serviceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string service_name = 2;</code>
     * @return The bytes for serviceName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getServiceNameBytes() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        serviceName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int METHOD_NAME_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object methodName_ = "";
    /**
     * <code>required string method_name = 3;</code>
     * @return Whether the methodName field is set.
     */
    @java.lang.Override
    public boolean hasMethodName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required string method_name = 3;</code>
     * @return The methodName.
     */
    @java.lang.Override
    public java.lang.String getMethodName() {
      java.lang.Object ref = methodName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          methodName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string method_name = 3;</code>
     * @return The bytes for methodName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getMethodNameBytes() {
      java.lang.Object ref = methodName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        methodName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int REQUEST_FIELD_NUMBER = 4;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString request_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes request = 4;</code>
     * @return Whether the request field is set.
     */
    @java.lang.Override
    public boolean hasRequest() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required bytes request = 4;</code>
     * @return The request.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRequest() {
      return request_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasServiceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMethodName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRequest()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, serviceName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, methodName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBytes(4, request_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, serviceName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, methodName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, request_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall) obj;

      if (hasRow() != other.hasRow()) return false;
      if (hasRow()) {
        if (!getRow()
            .equals(other.getRow())) return false;
      }
      if (hasServiceName() != other.hasServiceName()) return false;
      if (hasServiceName()) {
        if (!getServiceName()
            .equals(other.getServiceName())) return false;
      }
      if (hasMethodName() != other.hasMethodName()) return false;
      if (hasMethodName()) {
        if (!getMethodName()
            .equals(other.getMethodName())) return false;
      }
      if (hasRequest() != other.hasRequest()) return false;
      if (hasRequest()) {
        if (!getRequest()
            .equals(other.getRequest())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasServiceName()) {
        hash = (37 * hash) + SERVICE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServiceName().hashCode();
      }
      if (hasMethodName()) {
        hash = (37 * hash) + METHOD_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getMethodName().hashCode();
      }
      if (hasRequest()) {
        hash = (37 * hash) + REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getRequest().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CoprocessorServiceCall}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CoprocessorServiceCall)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceCall_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceCall_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        serviceName_ = "";
        methodName_ = "";
        request_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceCall_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.row_ = row_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.serviceName_ = serviceName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.methodName_ = methodName_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.request_ = request_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasServiceName()) {
          serviceName_ = other.serviceName_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasMethodName()) {
          methodName_ = other.methodName_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.hasRequest()) {
          setRequest(other.getRequest());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRow()) {
          return false;
        }
        if (!hasServiceName()) {
          return false;
        }
        if (!hasMethodName()) {
          return false;
        }
        if (!hasRequest()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                row_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                serviceName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                methodName_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                request_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString row_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       * @return Whether the row field is set.
       */
      @java.lang.Override
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return The row.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @param value The row to set.
       * @return This builder for chaining.
       */
      public Builder setRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        row_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      private java.lang.Object serviceName_ = "";
      /**
       * <code>required string service_name = 2;</code>
       * @return Whether the serviceName field is set.
       */
      public boolean hasServiceName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string service_name = 2;</code>
       * @return The serviceName.
       */
      public java.lang.String getServiceName() {
        java.lang.Object ref = serviceName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            serviceName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string service_name = 2;</code>
       * @return The bytes for serviceName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getServiceNameBytes() {
        java.lang.Object ref = serviceName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          serviceName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string service_name = 2;</code>
       * @param value The serviceName to set.
       * @return This builder for chaining.
       */
      public Builder setServiceName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        serviceName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string service_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearServiceName() {
        serviceName_ = getDefaultInstance().getServiceName();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string service_name = 2;</code>
       * @param value The bytes for serviceName to set.
       * @return This builder for chaining.
       */
      public Builder setServiceNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        serviceName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object methodName_ = "";
      /**
       * <code>required string method_name = 3;</code>
       * @return Whether the methodName field is set.
       */
      public boolean hasMethodName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required string method_name = 3;</code>
       * @return The methodName.
       */
      public java.lang.String getMethodName() {
        java.lang.Object ref = methodName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            methodName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string method_name = 3;</code>
       * @return The bytes for methodName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getMethodNameBytes() {
        java.lang.Object ref = methodName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          methodName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string method_name = 3;</code>
       * @param value The methodName to set.
       * @return This builder for chaining.
       */
      public Builder setMethodName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        methodName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required string method_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearMethodName() {
        methodName_ = getDefaultInstance().getMethodName();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>required string method_name = 3;</code>
       * @param value The bytes for methodName to set.
       * @return This builder for chaining.
       */
      public Builder setMethodNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        methodName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString request_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes request = 4;</code>
       * @return Whether the request field is set.
       */
      @java.lang.Override
      public boolean hasRequest() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required bytes request = 4;</code>
       * @return The request.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRequest() {
        return request_;
      }
      /**
       * <code>required bytes request = 4;</code>
       * @param value The request to set.
       * @return This builder for chaining.
       */
      public Builder setRequest(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        request_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes request = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearRequest() {
        bitField0_ = (bitField0_ & ~0x00000008);
        request_ = getDefaultInstance().getRequest();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CoprocessorServiceCall)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CoprocessorServiceCall)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceCall>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CoprocessorServiceCall>() {
      @java.lang.Override
      public CoprocessorServiceCall parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceCall> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceCall> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CoprocessorServiceResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CoprocessorServiceResult)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     * @return Whether the value field is set.
     */
    boolean hasValue();
    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     * @return The value.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CoprocessorServiceResult}
   */
  @javax.annotation.Generated("proto") public static final class CoprocessorServiceResult extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CoprocessorServiceResult)
      CoprocessorServiceResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CoprocessorServiceResult.newBuilder() to construct.
    private CoprocessorServiceResult(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CoprocessorServiceResult() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CoprocessorServiceResult();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResult_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder.class);
    }

    private int bitField0_;
    public static final int VALUE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value_;
    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     * @return Whether the value field is set.
     */
    @java.lang.Override
    public boolean hasValue() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     * @return The value.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
    }
    /**
     * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasValue()) {
        if (!getValue().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getValue());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getValue());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult) obj;

      if (hasValue() != other.hasValue()) return false;
      if (hasValue()) {
        if (!getValue()
            .equals(other.getValue())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CoprocessorServiceResult}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CoprocessorServiceResult)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResult_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getValueFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        value_ = null;
        if (valueBuilder_ != null) {
          valueBuilder_.dispose();
          valueBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResult_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.value_ = valueBuilder_ == null
              ? value_
              : valueBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance()) return this;
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasValue()) {
          if (!getValue().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getValueFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       * @return Whether the value field is set.
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       * @return The value.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public Builder setValue(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public Builder setValue(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public Builder mergeValue(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            value_ != null &&
            value_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            getValueBuilder().mergeFrom(value);
          } else {
            value_ = value;
          }
        } else {
          valueBuilder_.mergeFrom(value);
        }
        if (value_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = null;
        if (valueBuilder_ != null) {
          valueBuilder_.dispose();
          valueBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
        }
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair value = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  getValue(),
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CoprocessorServiceResult)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CoprocessorServiceResult)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResult>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CoprocessorServiceResult>() {
      @java.lang.Override
      public CoprocessorServiceResult parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResult> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CoprocessorServiceRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CoprocessorServiceRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     * @return Whether the call field is set.
     */
    boolean hasCall();
    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     * @return The call.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall();
    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CoprocessorServiceRequest}
   */
  @javax.annotation.Generated("proto") public static final class CoprocessorServiceRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CoprocessorServiceRequest)
      CoprocessorServiceRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CoprocessorServiceRequest.newBuilder() to construct.
    private CoprocessorServiceRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CoprocessorServiceRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CoprocessorServiceRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int CALL_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall call_;
    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     * @return Whether the call field is set.
     */
    @java.lang.Override
    public boolean hasCall() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     * @return The call.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
      return call_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : call_;
    }
    /**
     * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
      return call_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : call_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCall()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCall().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getCall());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCall());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasCall() != other.hasCall()) return false;
      if (hasCall()) {
        if (!getCall()
            .equals(other.getCall())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasCall()) {
        hash = (37 * hash) + CALL_FIELD_NUMBER;
        hash = (53 * hash) + getCall().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CoprocessorServiceRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CoprocessorServiceRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getCallFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        call_ = null;
        if (callBuilder_ != null) {
          callBuilder_.dispose();
          callBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.call_ = callBuilder_ == null
              ? call_
              : callBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasCall()) {
          mergeCall(other.getCall());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasCall()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getCall().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getCallFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall call_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> callBuilder_;
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       * @return Whether the call field is set.
       */
      public boolean hasCall() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       * @return The call.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
        if (callBuilder_ == null) {
          return call_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : call_;
        } else {
          return callBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public Builder setCall(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          call_ = value;
        } else {
          callBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public Builder setCall(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder builderForValue) {
        if (callBuilder_ == null) {
          call_ = builderForValue.build();
        } else {
          callBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public Builder mergeCall(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            call_ != null &&
            call_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) {
            getCallBuilder().mergeFrom(value);
          } else {
            call_ = value;
          }
        } else {
          callBuilder_.mergeFrom(value);
        }
        if (call_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public Builder clearCall() {
        bitField0_ = (bitField0_ & ~0x00000002);
        call_ = null;
        if (callBuilder_ != null) {
          callBuilder_.dispose();
          callBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder getCallBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCallFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
        if (callBuilder_ != null) {
          return callBuilder_.getMessageOrBuilder();
        } else {
          return call_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : call_;
        }
      }
      /**
       * <code>required .hbase.pb.CoprocessorServiceCall call = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> 
          getCallFieldBuilder() {
        if (callBuilder_ == null) {
          callBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder>(
                  getCall(),
                  getParentForChildren(),
                  isClean());
          call_ = null;
        }
        return callBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CoprocessorServiceRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CoprocessorServiceRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CoprocessorServiceRequest>() {
      @java.lang.Override
      public CoprocessorServiceRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CoprocessorServiceResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CoprocessorServiceResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     * @return Whether the value field is set.
     */
    boolean hasValue();
    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     * @return The value.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CoprocessorServiceResponse}
   */
  @javax.annotation.Generated("proto") public static final class CoprocessorServiceResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CoprocessorServiceResponse)
      CoprocessorServiceResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CoprocessorServiceResponse.newBuilder() to construct.
    private CoprocessorServiceResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CoprocessorServiceResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CoprocessorServiceResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value_;
    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     * @return Whether the value field is set.
     */
    @java.lang.Override
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     * @return The value.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
    }
    /**
     * <code>required .hbase.pb.NameBytesPair value = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getValue().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getValue());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getValue());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasValue() != other.hasValue()) return false;
      if (hasValue()) {
        if (!getValue()
            .equals(other.getValue())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CoprocessorServiceResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CoprocessorServiceResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getValueFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        value_ = null;
        if (valueBuilder_ != null) {
          valueBuilder_.dispose();
          valueBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_CoprocessorServiceResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.value_ = valueBuilder_ == null
              ? value_
              : valueBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!hasValue()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (!getValue().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getValueFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       * @return Whether the value field is set.
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       * @return The value.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            value_ != null &&
            value_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            getValueBuilder().mergeFrom(value);
          } else {
            value_ = value;
          }
        } else {
          valueBuilder_.mergeFrom(value);
        }
        if (value_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = null;
        if (valueBuilder_ != null) {
          valueBuilder_.dispose();
          valueBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : value_;
        }
      }
      /**
       * <code>required .hbase.pb.NameBytesPair value = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  getValue(),
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CoprocessorServiceResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CoprocessorServiceResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CoprocessorServiceResponse>() {
      @java.lang.Override
      public CoprocessorServiceResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CoprocessorServiceResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ActionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Action)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * If part of a multi action, useful aligning
     * result with what was originally submitted.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return Whether the index field is set.
     */
    boolean hasIndex();
    /**
     * <pre>
     * If part of a multi action, useful aligning
     * result with what was originally submitted.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return The index.
     */
    int getIndex();

    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     * @return Whether the mutation field is set.
     */
    boolean hasMutation();
    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     * @return The mutation.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation();
    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder();

    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     * @return Whether the get field is set.
     */
    boolean hasGet();
    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     * @return The get.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet();
    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();

    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     * @return Whether the serviceCall field is set.
     */
    boolean hasServiceCall();
    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     * @return The serviceCall.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getServiceCall();
    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getServiceCallOrBuilder();
  }
  /**
   * <pre>
   * Either a Get or a Mutation
   * </pre>
   *
   * Protobuf type {@code hbase.pb.Action}
   */
  @javax.annotation.Generated("proto") public static final class Action extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Action)
      ActionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Action.newBuilder() to construct.
    private Action(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Action() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Action();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Action_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Action_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder.class);
    }

    private int bitField0_;
    public static final int INDEX_FIELD_NUMBER = 1;
    private int index_ = 0;
    /**
     * <pre>
     * If part of a multi action, useful aligning
     * result with what was originally submitted.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return Whether the index field is set.
     */
    @java.lang.Override
    public boolean hasIndex() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * If part of a multi action, useful aligning
     * result with what was originally submitted.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return The index.
     */
    @java.lang.Override
    public int getIndex() {
      return index_;
    }

    public static final int MUTATION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto mutation_;
    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     * @return Whether the mutation field is set.
     */
    @java.lang.Override
    public boolean hasMutation() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     * @return The mutation.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation() {
      return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
    }
    /**
     * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
      return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
    }

    public static final int GET_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get get_;
    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     * @return Whether the get field is set.
     */
    @java.lang.Override
    public boolean hasGet() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     * @return The get.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet() {
      return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
    }
    /**
     * <code>optional .hbase.pb.Get get = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
    }

    public static final int SERVICE_CALL_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall serviceCall_;
    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     * @return Whether the serviceCall field is set.
     */
    @java.lang.Override
    public boolean hasServiceCall() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     * @return The serviceCall.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getServiceCall() {
      return serviceCall_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : serviceCall_;
    }
    /**
     * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getServiceCallOrBuilder() {
      return serviceCall_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : serviceCall_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasMutation()) {
        if (!getMutation().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasGet()) {
        if (!getGet().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasServiceCall()) {
        if (!getServiceCall().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt32(1, index_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getMutation());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getGet());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getServiceCall());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, index_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getMutation());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getGet());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getServiceCall());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action) obj;

      if (hasIndex() != other.hasIndex()) return false;
      if (hasIndex()) {
        if (getIndex()
            != other.getIndex()) return false;
      }
      if (hasMutation() != other.hasMutation()) return false;
      if (hasMutation()) {
        if (!getMutation()
            .equals(other.getMutation())) return false;
      }
      if (hasGet() != other.hasGet()) return false;
      if (hasGet()) {
        if (!getGet()
            .equals(other.getGet())) return false;
      }
      if (hasServiceCall() != other.hasServiceCall()) return false;
      if (hasServiceCall()) {
        if (!getServiceCall()
            .equals(other.getServiceCall())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasIndex()) {
        hash = (37 * hash) + INDEX_FIELD_NUMBER;
        hash = (53 * hash) + getIndex();
      }
      if (hasMutation()) {
        hash = (37 * hash) + MUTATION_FIELD_NUMBER;
        hash = (53 * hash) + getMutation().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      if (hasServiceCall()) {
        hash = (37 * hash) + SERVICE_CALL_FIELD_NUMBER;
        hash = (53 * hash) + getServiceCall().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Either a Get or a Mutation
     * </pre>
     *
     * Protobuf type {@code hbase.pb.Action}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Action)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Action_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Action_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getMutationFieldBuilder();
          getGetFieldBuilder();
          getServiceCallFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        index_ = 0;
        mutation_ = null;
        if (mutationBuilder_ != null) {
          mutationBuilder_.dispose();
          mutationBuilder_ = null;
        }
        get_ = null;
        if (getBuilder_ != null) {
          getBuilder_.dispose();
          getBuilder_ = null;
        }
        serviceCall_ = null;
        if (serviceCallBuilder_ != null) {
          serviceCallBuilder_.dispose();
          serviceCallBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_Action_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.index_ = index_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.mutation_ = mutationBuilder_ == null
              ? mutation_
              : mutationBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.get_ = getBuilder_ == null
              ? get_
              : getBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.serviceCall_ = serviceCallBuilder_ == null
              ? serviceCall_
              : serviceCallBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.getDefaultInstance()) return this;
        if (other.hasIndex()) {
          setIndex(other.getIndex());
        }
        if (other.hasMutation()) {
          mergeMutation(other.getMutation());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        if (other.hasServiceCall()) {
          mergeServiceCall(other.getServiceCall());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasMutation()) {
          if (!getMutation().isInitialized()) {
            return false;
          }
        }
        if (hasGet()) {
          if (!getGet().isInitialized()) {
            return false;
          }
        }
        if (hasServiceCall()) {
          if (!getServiceCall().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                index_ = input.readUInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getMutationFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getGetFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                input.readMessage(
                    getServiceCallFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int index_ ;
      /**
       * <pre>
       * If part of a multi action, useful aligning
       * result with what was originally submitted.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return Whether the index field is set.
       */
      @java.lang.Override
      public boolean hasIndex() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * If part of a multi action, useful aligning
       * result with what was originally submitted.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return The index.
       */
      @java.lang.Override
      public int getIndex() {
        return index_;
      }
      /**
       * <pre>
       * If part of a multi action, useful aligning
       * result with what was originally submitted.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @param value The index to set.
       * @return This builder for chaining.
       */
      public Builder setIndex(int value) {

        index_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If part of a multi action, useful aligning
       * result with what was originally submitted.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIndex() {
        bitField0_ = (bitField0_ & ~0x00000001);
        index_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto mutation_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder> mutationBuilder_;
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       * @return Whether the mutation field is set.
       */
      public boolean hasMutation() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       * @return The mutation.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto getMutation() {
        if (mutationBuilder_ == null) {
          return mutation_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
        } else {
          return mutationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder setMutation(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutation_ = value;
        } else {
          mutationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder setMutation(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder builderForValue) {
        if (mutationBuilder_ == null) {
          mutation_ = builderForValue.build();
        } else {
          mutationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder mergeMutation(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            mutation_ != null &&
            mutation_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) {
            getMutationBuilder().mergeFrom(value);
          } else {
            mutation_ = value;
          }
        } else {
          mutationBuilder_.mergeFrom(value);
        }
        if (mutation_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public Builder clearMutation() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mutation_ = null;
        if (mutationBuilder_ != null) {
          mutationBuilder_.dispose();
          mutationBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder getMutationBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMutationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
        if (mutationBuilder_ != null) {
          return mutationBuilder_.getMessageOrBuilder();
        } else {
          return mutation_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance() : mutation_;
        }
      }
      /**
       * <code>optional .hbase.pb.MutationProto mutation = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder> 
          getMutationFieldBuilder() {
        if (mutationBuilder_ == null) {
          mutationBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutationProtoOrBuilder>(
                  getMutation(),
                  getParentForChildren(),
                  isClean());
          mutation_ = null;
        }
        return mutationBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get get_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       * @return Whether the get field is set.
       */
      public boolean hasGet() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       * @return The get.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public Builder setGet(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public Builder setGet(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public Builder mergeGet(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            get_ != null &&
            get_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            getGetBuilder().mergeFrom(value);
          } else {
            get_ = value;
          }
        } else {
          getBuilder_.mergeFrom(value);
        }
        if (get_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public Builder clearGet() {
        bitField0_ = (bitField0_ & ~0x00000004);
        get_ = null;
        if (getBuilder_ != null) {
          getBuilder_.dispose();
          getBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.getDefaultInstance() : get_;
        }
      }
      /**
       * <code>optional .hbase.pb.Get get = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetOrBuilder>(
                  getGet(),
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall serviceCall_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> serviceCallBuilder_;
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       * @return Whether the serviceCall field is set.
       */
      public boolean hasServiceCall() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       * @return The serviceCall.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall getServiceCall() {
        if (serviceCallBuilder_ == null) {
          return serviceCall_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : serviceCall_;
        } else {
          return serviceCallBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public Builder setServiceCall(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (serviceCallBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serviceCall_ = value;
        } else {
          serviceCallBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public Builder setServiceCall(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder builderForValue) {
        if (serviceCallBuilder_ == null) {
          serviceCall_ = builderForValue.build();
        } else {
          serviceCallBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public Builder mergeServiceCall(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (serviceCallBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            serviceCall_ != null &&
            serviceCall_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) {
            getServiceCallBuilder().mergeFrom(value);
          } else {
            serviceCall_ = value;
          }
        } else {
          serviceCallBuilder_.mergeFrom(value);
        }
        if (serviceCall_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public Builder clearServiceCall() {
        bitField0_ = (bitField0_ & ~0x00000008);
        serviceCall_ = null;
        if (serviceCallBuilder_ != null) {
          serviceCallBuilder_.dispose();
          serviceCallBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder getServiceCallBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getServiceCallFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getServiceCallOrBuilder() {
        if (serviceCallBuilder_ != null) {
          return serviceCallBuilder_.getMessageOrBuilder();
        } else {
          return serviceCall_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance() : serviceCall_;
        }
      }
      /**
       * <code>optional .hbase.pb.CoprocessorServiceCall service_call = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> 
          getServiceCallFieldBuilder() {
        if (serviceCallBuilder_ == null) {
          serviceCallBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder>(
                  getServiceCall(),
                  getParentForChildren(),
                  isClean());
          serviceCall_ = null;
        }
        return serviceCallBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Action)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Action)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Action>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Action>() {
      @java.lang.Override
      public Action parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Action> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Action> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionActionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionAction)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <pre>
     * When set, run mutations as atomic unit.
     * </pre>
     *
     * <code>optional bool atomic = 2;</code>
     * @return Whether the atomic field is set.
     */
    boolean hasAtomic();
    /**
     * <pre>
     * When set, run mutations as atomic unit.
     * </pre>
     *
     * <code>optional bool atomic = 2;</code>
     * @return The atomic.
     */
    boolean getAtomic();

    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> 
        getActionList();
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getAction(int index);
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    int getActionCount();
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder> 
        getActionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder getActionOrBuilder(
        int index);

    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     * @return Whether the condition field is set.
     */
    boolean hasCondition();
    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     * @return The condition.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition();
    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder();
  }
  /**
   * <pre>
   **
   * Actions to run against a Region.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.RegionAction}
   */
  @javax.annotation.Generated("proto") public static final class RegionAction extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionAction)
      RegionActionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionAction.newBuilder() to construct.
    private RegionAction(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionAction() {
      action_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionAction();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionAction_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionAction_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int ATOMIC_FIELD_NUMBER = 2;
    private boolean atomic_ = false;
    /**
     * <pre>
     * When set, run mutations as atomic unit.
     * </pre>
     *
     * <code>optional bool atomic = 2;</code>
     * @return Whether the atomic field is set.
     */
    @java.lang.Override
    public boolean hasAtomic() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * When set, run mutations as atomic unit.
     * </pre>
     *
     * <code>optional bool atomic = 2;</code>
     * @return The atomic.
     */
    @java.lang.Override
    public boolean getAtomic() {
      return atomic_;
    }

    public static final int ACTION_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> action_;
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> getActionList() {
      return action_;
    }
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder> 
        getActionOrBuilderList() {
      return action_;
    }
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    @java.lang.Override
    public int getActionCount() {
      return action_.size();
    }
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getAction(int index) {
      return action_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Action action = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder getActionOrBuilder(
        int index) {
      return action_.get(index);
    }

    public static final int CONDITION_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     * @return Whether the condition field is set.
     */
    @java.lang.Override
    public boolean hasCondition() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     * @return The condition.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }
    /**
     * <code>optional .hbase.pb.Condition condition = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getActionCount(); i++) {
        if (!getAction(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasCondition()) {
        if (!getCondition().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, atomic_);
      }
      for (int i = 0; i < action_.size(); i++) {
        output.writeMessage(3, action_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(4, getCondition());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, atomic_);
      }
      for (int i = 0; i < action_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, action_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getCondition());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasAtomic() != other.hasAtomic()) return false;
      if (hasAtomic()) {
        if (getAtomic()
            != other.getAtomic()) return false;
      }
      if (!getActionList()
          .equals(other.getActionList())) return false;
      if (hasCondition() != other.hasCondition()) return false;
      if (hasCondition()) {
        if (!getCondition()
            .equals(other.getCondition())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasAtomic()) {
        hash = (37 * hash) + ATOMIC_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getAtomic());
      }
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + getActionList().hashCode();
      }
      if (hasCondition()) {
        hash = (37 * hash) + CONDITION_FIELD_NUMBER;
        hash = (53 * hash) + getCondition().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Actions to run against a Region.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.RegionAction}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionAction)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionAction_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionAction_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getActionFieldBuilder();
          getConditionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        atomic_ = false;
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
        } else {
          action_ = null;
          actionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionAction_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction result) {
        if (actionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            action_ = java.util.Collections.unmodifiableList(action_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.action_ = action_;
        } else {
          result.action_ = actionBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.atomic_ = atomic_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.condition_ = conditionBuilder_ == null
              ? condition_
              : conditionBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasAtomic()) {
          setAtomic(other.getAtomic());
        }
        if (actionBuilder_ == null) {
          if (!other.action_.isEmpty()) {
            if (action_.isEmpty()) {
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureActionIsMutable();
              action_.addAll(other.action_);
            }
            onChanged();
          }
        } else {
          if (!other.action_.isEmpty()) {
            if (actionBuilder_.isEmpty()) {
              actionBuilder_.dispose();
              actionBuilder_ = null;
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000004);
              actionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getActionFieldBuilder() : null;
            } else {
              actionBuilder_.addAllMessages(other.action_);
            }
          }
        }
        if (other.hasCondition()) {
          mergeCondition(other.getCondition());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getActionCount(); i++) {
          if (!getAction(i).isInitialized()) {
            return false;
          }
        }
        if (hasCondition()) {
          if (!getCondition().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                atomic_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.PARSER,
                        extensionRegistry);
                if (actionBuilder_ == null) {
                  ensureActionIsMutable();
                  action_.add(m);
                } else {
                  actionBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 34: {
                input.readMessage(
                    getConditionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private boolean atomic_ ;
      /**
       * <pre>
       * When set, run mutations as atomic unit.
       * </pre>
       *
       * <code>optional bool atomic = 2;</code>
       * @return Whether the atomic field is set.
       */
      @java.lang.Override
      public boolean hasAtomic() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * When set, run mutations as atomic unit.
       * </pre>
       *
       * <code>optional bool atomic = 2;</code>
       * @return The atomic.
       */
      @java.lang.Override
      public boolean getAtomic() {
        return atomic_;
      }
      /**
       * <pre>
       * When set, run mutations as atomic unit.
       * </pre>
       *
       * <code>optional bool atomic = 2;</code>
       * @param value The atomic to set.
       * @return This builder for chaining.
       */
      public Builder setAtomic(boolean value) {

        atomic_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * When set, run mutations as atomic unit.
       * </pre>
       *
       * <code>optional bool atomic = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAtomic() {
        bitField0_ = (bitField0_ & ~0x00000002);
        atomic_ = false;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action>(action_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder> actionBuilder_;

      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> getActionList() {
        if (actionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(action_);
        } else {
          return actionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public int getActionCount() {
        if (actionBuilder_ == null) {
          return action_.size();
        } else {
          return actionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action getAction(int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);
        } else {
          return actionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.set(index, value);
          onChanged();
        } else {
          actionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.set(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder addAction(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(value);
          onChanged();
        } else {
          actionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder addAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(index, value);
          onChanged();
        } else {
          actionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder addAction(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder addAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action> values) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, action_);
          onChanged();
        } else {
          actionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder clearAction() {
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          actionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public Builder removeAction(int index) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.remove(index);
          onChanged();
        } else {
          actionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder getActionBuilder(
          int index) {
        return getActionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder getActionOrBuilder(
          int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);  } else {
          return actionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder> 
           getActionOrBuilderList() {
        if (actionBuilder_ != null) {
          return actionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(action_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder addActionBuilder() {
        return getActionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder addActionBuilder(
          int index) {
        return getActionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Action action = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder> 
           getActionBuilderList() {
        return getActionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder> 
          getActionFieldBuilder() {
        if (actionBuilder_ == null) {
          actionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Action.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ActionOrBuilder>(
                  action_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          action_ = null;
        }
        return actionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> conditionBuilder_;
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       * @return Whether the condition field is set.
       */
      public boolean hasCondition() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       * @return The condition.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
        if (conditionBuilder_ == null) {
          return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        } else {
          return conditionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public Builder setCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          condition_ = value;
        } else {
          conditionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public Builder setCondition(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder builderForValue) {
        if (conditionBuilder_ == null) {
          condition_ = builderForValue.build();
        } else {
          conditionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public Builder mergeCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            condition_ != null &&
            condition_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) {
            getConditionBuilder().mergeFrom(value);
          } else {
            condition_ = value;
          }
        } else {
          conditionBuilder_.mergeFrom(value);
        }
        if (condition_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public Builder clearCondition() {
        bitField0_ = (bitField0_ & ~0x00000008);
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder getConditionBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getConditionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
        if (conditionBuilder_ != null) {
          return conditionBuilder_.getMessageOrBuilder();
        } else {
          return condition_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        }
      }
      /**
       * <code>optional .hbase.pb.Condition condition = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> 
          getConditionFieldBuilder() {
        if (conditionBuilder_ == null) {
          conditionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder>(
                  getCondition(),
                  getParentForChildren(),
                  isClean());
          condition_ = null;
        }
        return conditionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionAction)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionAction)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionAction>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionAction>() {
      @java.lang.Override
      public RegionAction parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionAction> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionAction> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionLoadStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionLoadStats)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
     * @return Whether the memStoreLoad field is set.
     */
    boolean hasMemStoreLoad();
    /**
     * <pre>
     * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
     * @return The memStoreLoad.
     */
    int getMemStoreLoad();

    /**
     * <pre>
     * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
     * We can move this to "ServerLoadStats" should we develop them.
     * </pre>
     *
     * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
     * @return Whether the heapOccupancy field is set.
     */
    boolean hasHeapOccupancy();
    /**
     * <pre>
     * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
     * We can move this to "ServerLoadStats" should we develop them.
     * </pre>
     *
     * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
     * @return The heapOccupancy.
     */
    int getHeapOccupancy();

    /**
     * <pre>
     * Compaction pressure. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 compactionPressure = 3 [default = 0];</code>
     * @return Whether the compactionPressure field is set.
     */
    boolean hasCompactionPressure();
    /**
     * <pre>
     * Compaction pressure. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 compactionPressure = 3 [default = 0];</code>
     * @return The compactionPressure.
     */
    int getCompactionPressure();
  }
  /**
   * <pre>
   *
   * Statistics about the current load on the region
   * </pre>
   *
   * Protobuf type {@code hbase.pb.RegionLoadStats}
   */
  @javax.annotation.Generated("proto") public static final class RegionLoadStats extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionLoadStats)
      RegionLoadStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionLoadStats.newBuilder() to construct.
    private RegionLoadStats(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionLoadStats() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionLoadStats();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionLoadStats_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionLoadStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder.class);
    }

    private int bitField0_;
    public static final int MEMSTORELOAD_FIELD_NUMBER = 1;
    private int memStoreLoad_ = 0;
    /**
     * <pre>
     * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
     * @return Whether the memStoreLoad field is set.
     */
    @java.lang.Override
    public boolean hasMemStoreLoad() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
     * @return The memStoreLoad.
     */
    @java.lang.Override
    public int getMemStoreLoad() {
      return memStoreLoad_;
    }

    public static final int HEAPOCCUPANCY_FIELD_NUMBER = 2;
    private int heapOccupancy_ = 0;
    /**
     * <pre>
     * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
     * We can move this to "ServerLoadStats" should we develop them.
     * </pre>
     *
     * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
     * @return Whether the heapOccupancy field is set.
     */
    @java.lang.Override
    public boolean hasHeapOccupancy() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
     * We can move this to "ServerLoadStats" should we develop them.
     * </pre>
     *
     * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
     * @return The heapOccupancy.
     */
    @java.lang.Override
    public int getHeapOccupancy() {
      return heapOccupancy_;
    }

    public static final int COMPACTIONPRESSURE_FIELD_NUMBER = 3;
    private int compactionPressure_ = 0;
    /**
     * <pre>
     * Compaction pressure. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 compactionPressure = 3 [default = 0];</code>
     * @return Whether the compactionPressure field is set.
     */
    @java.lang.Override
    public boolean hasCompactionPressure() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * Compaction pressure. Guaranteed to be positive, between 0 and 100.
     * </pre>
     *
     * <code>optional int32 compactionPressure = 3 [default = 0];</code>
     * @return The compactionPressure.
     */
    @java.lang.Override
    public int getCompactionPressure() {
      return compactionPressure_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, memStoreLoad_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(2, heapOccupancy_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeInt32(3, compactionPressure_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, memStoreLoad_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, heapOccupancy_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, compactionPressure_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats) obj;

      if (hasMemStoreLoad() != other.hasMemStoreLoad()) return false;
      if (hasMemStoreLoad()) {
        if (getMemStoreLoad()
            != other.getMemStoreLoad()) return false;
      }
      if (hasHeapOccupancy() != other.hasHeapOccupancy()) return false;
      if (hasHeapOccupancy()) {
        if (getHeapOccupancy()
            != other.getHeapOccupancy()) return false;
      }
      if (hasCompactionPressure() != other.hasCompactionPressure()) return false;
      if (hasCompactionPressure()) {
        if (getCompactionPressure()
            != other.getCompactionPressure()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMemStoreLoad()) {
        hash = (37 * hash) + MEMSTORELOAD_FIELD_NUMBER;
        hash = (53 * hash) + getMemStoreLoad();
      }
      if (hasHeapOccupancy()) {
        hash = (37 * hash) + HEAPOCCUPANCY_FIELD_NUMBER;
        hash = (53 * hash) + getHeapOccupancy();
      }
      if (hasCompactionPressure()) {
        hash = (37 * hash) + COMPACTIONPRESSURE_FIELD_NUMBER;
        hash = (53 * hash) + getCompactionPressure();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *
     * Statistics about the current load on the region
     * </pre>
     *
     * Protobuf type {@code hbase.pb.RegionLoadStats}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionLoadStats)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionLoadStats_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionLoadStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        memStoreLoad_ = 0;
        heapOccupancy_ = 0;
        compactionPressure_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionLoadStats_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.memStoreLoad_ = memStoreLoad_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.heapOccupancy_ = heapOccupancy_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.compactionPressure_ = compactionPressure_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance()) return this;
        if (other.hasMemStoreLoad()) {
          setMemStoreLoad(other.getMemStoreLoad());
        }
        if (other.hasHeapOccupancy()) {
          setHeapOccupancy(other.getHeapOccupancy());
        }
        if (other.hasCompactionPressure()) {
          setCompactionPressure(other.getCompactionPressure());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                memStoreLoad_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                heapOccupancy_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                compactionPressure_ = input.readInt32();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int memStoreLoad_ ;
      /**
       * <pre>
       * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
       * @return Whether the memStoreLoad field is set.
       */
      @java.lang.Override
      public boolean hasMemStoreLoad() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
       * @return The memStoreLoad.
       */
      @java.lang.Override
      public int getMemStoreLoad() {
        return memStoreLoad_;
      }
      /**
       * <pre>
       * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
       * @param value The memStoreLoad to set.
       * @return This builder for chaining.
       */
      public Builder setMemStoreLoad(int value) {

        memStoreLoad_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Percent load on the memstore. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 memStoreLoad = 1 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearMemStoreLoad() {
        bitField0_ = (bitField0_ & ~0x00000001);
        memStoreLoad_ = 0;
        onChanged();
        return this;
      }

      private int heapOccupancy_ ;
      /**
       * <pre>
       * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
       * We can move this to "ServerLoadStats" should we develop them.
       * </pre>
       *
       * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
       * @return Whether the heapOccupancy field is set.
       */
      @java.lang.Override
      public boolean hasHeapOccupancy() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
       * We can move this to "ServerLoadStats" should we develop them.
       * </pre>
       *
       * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
       * @return The heapOccupancy.
       */
      @java.lang.Override
      public int getHeapOccupancy() {
        return heapOccupancy_;
      }
      /**
       * <pre>
       * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
       * We can move this to "ServerLoadStats" should we develop them.
       * </pre>
       *
       * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
       * @param value The heapOccupancy to set.
       * @return This builder for chaining.
       */
      public Builder setHeapOccupancy(int value) {

        heapOccupancy_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Percent JVM heap occupancy. Guaranteed to be positive, between 0 and 100.
       * We can move this to "ServerLoadStats" should we develop them.
       * </pre>
       *
       * <code>optional int32 heapOccupancy = 2 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearHeapOccupancy() {
        bitField0_ = (bitField0_ & ~0x00000002);
        heapOccupancy_ = 0;
        onChanged();
        return this;
      }

      private int compactionPressure_ ;
      /**
       * <pre>
       * Compaction pressure. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 compactionPressure = 3 [default = 0];</code>
       * @return Whether the compactionPressure field is set.
       */
      @java.lang.Override
      public boolean hasCompactionPressure() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * Compaction pressure. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 compactionPressure = 3 [default = 0];</code>
       * @return The compactionPressure.
       */
      @java.lang.Override
      public int getCompactionPressure() {
        return compactionPressure_;
      }
      /**
       * <pre>
       * Compaction pressure. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 compactionPressure = 3 [default = 0];</code>
       * @param value The compactionPressure to set.
       * @return This builder for chaining.
       */
      public Builder setCompactionPressure(int value) {

        compactionPressure_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Compaction pressure. Guaranteed to be positive, between 0 and 100.
       * </pre>
       *
       * <code>optional int32 compactionPressure = 3 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearCompactionPressure() {
        bitField0_ = (bitField0_ & ~0x00000004);
        compactionPressure_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionLoadStats)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionLoadStats)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionLoadStats>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionLoadStats>() {
      @java.lang.Override
      public RegionLoadStats parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionLoadStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionLoadStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MultiRegionLoadStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MultiRegionLoadStats)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> 
        getRegionList();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index);
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    int getRegionCount();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
        getRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> 
        getStatList();
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getStat(int index);
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    int getStatCount();
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> 
        getStatOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getStatOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.MultiRegionLoadStats}
   */
  @javax.annotation.Generated("proto") public static final class MultiRegionLoadStats extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MultiRegionLoadStats)
      MultiRegionLoadStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MultiRegionLoadStats.newBuilder() to construct.
    private MultiRegionLoadStats(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MultiRegionLoadStats() {
      region_ = java.util.Collections.emptyList();
      stat_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MultiRegionLoadStats();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRegionLoadStats_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRegionLoadStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder.class);
    }

    public static final int REGION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> region_;
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> getRegionList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
        getRegionOrBuilderList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public int getRegionCount() {
      return region_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index) {
      return region_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
        int index) {
      return region_.get(index);
    }

    public static final int STAT_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> stat_;
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> getStatList() {
      return stat_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> 
        getStatOrBuilderList() {
      return stat_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    @java.lang.Override
    public int getStatCount() {
      return stat_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getStat(int index) {
      return stat_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getStatOrBuilder(
        int index) {
      return stat_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionCount(); i++) {
        if (!getRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < region_.size(); i++) {
        output.writeMessage(1, region_.get(i));
      }
      for (int i = 0; i < stat_.size(); i++) {
        output.writeMessage(2, stat_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < region_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_.get(i));
      }
      for (int i = 0; i < stat_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, stat_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats) obj;

      if (!getRegionList()
          .equals(other.getRegionList())) return false;
      if (!getStatList()
          .equals(other.getStatList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionCount() > 0) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionList().hashCode();
      }
      if (getStatCount() > 0) {
        hash = (37 * hash) + STAT_FIELD_NUMBER;
        hash = (53 * hash) + getStatList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MultiRegionLoadStats}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MultiRegionLoadStats)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRegionLoadStats_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRegionLoadStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
        } else {
          region_ = null;
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (statBuilder_ == null) {
          stat_ = java.util.Collections.emptyList();
        } else {
          stat_ = null;
          statBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRegionLoadStats_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats result) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            region_ = java.util.Collections.unmodifiableList(region_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (statBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            stat_ = java.util.Collections.unmodifiableList(stat_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.stat_ = stat_;
        } else {
          result.stat_ = statBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance()) return this;
        if (regionBuilder_ == null) {
          if (!other.region_.isEmpty()) {
            if (region_.isEmpty()) {
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionIsMutable();
              region_.addAll(other.region_);
            }
            onChanged();
          }
        } else {
          if (!other.region_.isEmpty()) {
            if (regionBuilder_.isEmpty()) {
              regionBuilder_.dispose();
              regionBuilder_ = null;
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionFieldBuilder() : null;
            } else {
              regionBuilder_.addAllMessages(other.region_);
            }
          }
        }
        if (statBuilder_ == null) {
          if (!other.stat_.isEmpty()) {
            if (stat_.isEmpty()) {
              stat_ = other.stat_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureStatIsMutable();
              stat_.addAll(other.stat_);
            }
            onChanged();
          }
        } else {
          if (!other.stat_.isEmpty()) {
            if (statBuilder_.isEmpty()) {
              statBuilder_.dispose();
              statBuilder_ = null;
              stat_ = other.stat_;
              bitField0_ = (bitField0_ & ~0x00000002);
              statBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStatFieldBuilder() : null;
            } else {
              statBuilder_.addAllMessages(other.stat_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionCount(); i++) {
          if (!getRegion(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER,
                        extensionRegistry);
                if (regionBuilder_ == null) {
                  ensureRegionIsMutable();
                  region_.add(m);
                } else {
                  regionBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.PARSER,
                        extensionRegistry);
                if (statBuilder_ == null) {
                  ensureStatIsMutable();
                  stat_.add(m);
                } else {
                  statBuilder_.addMessage(m);
                }
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> region_ =
        java.util.Collections.emptyList();
      private void ensureRegionIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          region_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier>(region_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> getRegionList() {
        if (regionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(region_);
        } else {
          return regionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public int getRegionCount() {
        if (regionBuilder_ == null) {
          return region_.size();
        } else {
          return regionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);
        } else {
          return regionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.set(index, value);
          onChanged();
        } else {
          regionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(value);
          onChanged();
        } else {
          regionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(index, value);
          onChanged();
        } else {
          regionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addAllRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> values) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, region_);
          onChanged();
        } else {
          regionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder removeRegion(int index) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.remove(index);
          onChanged();
        } else {
          regionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder(
          int index) {
        return getRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
          int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);  } else {
          return regionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
           getRegionOrBuilderList() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(region_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder addRegionBuilder() {
        return getRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder addRegionBuilder(
          int index) {
        return getRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder> 
           getRegionBuilderList() {
        return getRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> stat_ =
        java.util.Collections.emptyList();
      private void ensureStatIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          stat_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats>(stat_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> statBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> getStatList() {
        if (statBuilder_ == null) {
          return java.util.Collections.unmodifiableList(stat_);
        } else {
          return statBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public int getStatCount() {
        if (statBuilder_ == null) {
          return stat_.size();
        } else {
          return statBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getStat(int index) {
        if (statBuilder_ == null) {
          return stat_.get(index);
        } else {
          return statBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder setStat(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats value) {
        if (statBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatIsMutable();
          stat_.set(index, value);
          onChanged();
        } else {
          statBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder setStat(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder builderForValue) {
        if (statBuilder_ == null) {
          ensureStatIsMutable();
          stat_.set(index, builderForValue.build());
          onChanged();
        } else {
          statBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder addStat(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats value) {
        if (statBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatIsMutable();
          stat_.add(value);
          onChanged();
        } else {
          statBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder addStat(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats value) {
        if (statBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStatIsMutable();
          stat_.add(index, value);
          onChanged();
        } else {
          statBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder addStat(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder builderForValue) {
        if (statBuilder_ == null) {
          ensureStatIsMutable();
          stat_.add(builderForValue.build());
          onChanged();
        } else {
          statBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder addStat(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder builderForValue) {
        if (statBuilder_ == null) {
          ensureStatIsMutable();
          stat_.add(index, builderForValue.build());
          onChanged();
        } else {
          statBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder addAllStat(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats> values) {
        if (statBuilder_ == null) {
          ensureStatIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, stat_);
          onChanged();
        } else {
          statBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder clearStat() {
        if (statBuilder_ == null) {
          stat_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          statBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public Builder removeStat(int index) {
        if (statBuilder_ == null) {
          ensureStatIsMutable();
          stat_.remove(index);
          onChanged();
        } else {
          statBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder getStatBuilder(
          int index) {
        return getStatFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getStatOrBuilder(
          int index) {
        if (statBuilder_ == null) {
          return stat_.get(index);  } else {
          return statBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> 
           getStatOrBuilderList() {
        if (statBuilder_ != null) {
          return statBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(stat_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder addStatBuilder() {
        return getStatFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder addStatBuilder(
          int index) {
        return getStatFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLoadStats stat = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder> 
           getStatBuilderList() {
        return getStatFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> 
          getStatFieldBuilder() {
        if (statBuilder_ == null) {
          statBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder>(
                  stat_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          stat_ = null;
        }
        return statBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MultiRegionLoadStats)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MultiRegionLoadStats)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRegionLoadStats>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MultiRegionLoadStats>() {
      @java.lang.Override
      public MultiRegionLoadStats parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRegionLoadStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRegionLoadStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResultOrExceptionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ResultOrException)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * If part of a multi call, save original index of the list of all
     * passed so can align this response w/ original request.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return Whether the index field is set.
     */
    boolean hasIndex();
    /**
     * <pre>
     * If part of a multi call, save original index of the list of all
     * passed so can align this response w/ original request.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return The index.
     */
    int getIndex();

    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     * @return Whether the result field is set.
     */
    boolean hasResult();
    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     * @return The result.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult();
    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();

    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     * @return Whether the exception field is set.
     */
    boolean hasException();
    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     * @return The exception.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException();
    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder();

    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     * @return Whether the serviceResult field is set.
     */
    boolean hasServiceResult();
    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     * @return The serviceResult.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getServiceResult();
    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder getServiceResultOrBuilder();

    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
     *     See Client.proto;l=492
     * @return Whether the loadStats field is set.
     */
    @java.lang.Deprecated boolean hasLoadStats();
    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
     *     See Client.proto;l=492
     * @return The loadStats.
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getLoadStats();
    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getLoadStatsOrBuilder();
  }
  /**
   * <pre>
   **
   * Either a Result or an Exception NameBytesPair (keyed by
   * exception name whose value is the exception stringified)
   * or maybe empty if no result and no exception.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.ResultOrException}
   */
  @javax.annotation.Generated("proto") public static final class ResultOrException extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ResultOrException)
      ResultOrExceptionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ResultOrException.newBuilder() to construct.
    private ResultOrException(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResultOrException() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ResultOrException();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ResultOrException_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ResultOrException_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder.class);
    }

    private int bitField0_;
    public static final int INDEX_FIELD_NUMBER = 1;
    private int index_ = 0;
    /**
     * <pre>
     * If part of a multi call, save original index of the list of all
     * passed so can align this response w/ original request.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return Whether the index field is set.
     */
    @java.lang.Override
    public boolean hasIndex() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * If part of a multi call, save original index of the list of all
     * passed so can align this response w/ original request.
     * </pre>
     *
     * <code>optional uint32 index = 1;</code>
     * @return The index.
     */
    @java.lang.Override
    public int getIndex() {
      return index_;
    }

    public static final int RESULT_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     * @return Whether the result field is set.
     */
    @java.lang.Override
    public boolean hasResult() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     * @return The result.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }
    /**
     * <code>optional .hbase.pb.Result result = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
    }

    public static final int EXCEPTION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair exception_;
    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     * @return Whether the exception field is set.
     */
    @java.lang.Override
    public boolean hasException() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     * @return The exception.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException() {
      return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
    }
    /**
     * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
      return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
    }

    public static final int SERVICE_RESULT_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult serviceResult_;
    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     * @return Whether the serviceResult field is set.
     */
    @java.lang.Override
    public boolean hasServiceResult() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     * @return The serviceResult.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getServiceResult() {
      return serviceResult_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance() : serviceResult_;
    }
    /**
     * <pre>
     * result if this was a coprocessor service call
     * </pre>
     *
     * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder getServiceResultOrBuilder() {
      return serviceResult_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance() : serviceResult_;
    }

    public static final int LOADSTATS_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats loadStats_;
    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
     *     See Client.proto;l=492
     * @return Whether the loadStats field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasLoadStats() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
     *     See Client.proto;l=492
     * @return The loadStats.
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getLoadStats() {
      return loadStats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance() : loadStats_;
    }
    /**
     * <pre>
     * current load on the region
     * </pre>
     *
     * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getLoadStatsOrBuilder() {
      return loadStats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance() : loadStats_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasException()) {
        if (!getException().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasServiceResult()) {
        if (!getServiceResult().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt32(1, index_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getResult());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getException());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getServiceResult());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(5, getLoadStats());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, index_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getResult());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getException());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getServiceResult());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLoadStats());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException) obj;

      if (hasIndex() != other.hasIndex()) return false;
      if (hasIndex()) {
        if (getIndex()
            != other.getIndex()) return false;
      }
      if (hasResult() != other.hasResult()) return false;
      if (hasResult()) {
        if (!getResult()
            .equals(other.getResult())) return false;
      }
      if (hasException() != other.hasException()) return false;
      if (hasException()) {
        if (!getException()
            .equals(other.getException())) return false;
      }
      if (hasServiceResult() != other.hasServiceResult()) return false;
      if (hasServiceResult()) {
        if (!getServiceResult()
            .equals(other.getServiceResult())) return false;
      }
      if (hasLoadStats() != other.hasLoadStats()) return false;
      if (hasLoadStats()) {
        if (!getLoadStats()
            .equals(other.getLoadStats())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasIndex()) {
        hash = (37 * hash) + INDEX_FIELD_NUMBER;
        hash = (53 * hash) + getIndex();
      }
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasException()) {
        hash = (37 * hash) + EXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getException().hashCode();
      }
      if (hasServiceResult()) {
        hash = (37 * hash) + SERVICE_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getServiceResult().hashCode();
      }
      if (hasLoadStats()) {
        hash = (37 * hash) + LOADSTATS_FIELD_NUMBER;
        hash = (53 * hash) + getLoadStats().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Either a Result or an Exception NameBytesPair (keyed by
     * exception name whose value is the exception stringified)
     * or maybe empty if no result and no exception.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.ResultOrException}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ResultOrException)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ResultOrException_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ResultOrException_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultFieldBuilder();
          getExceptionFieldBuilder();
          getServiceResultFieldBuilder();
          getLoadStatsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        index_ = 0;
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        exception_ = null;
        if (exceptionBuilder_ != null) {
          exceptionBuilder_.dispose();
          exceptionBuilder_ = null;
        }
        serviceResult_ = null;
        if (serviceResultBuilder_ != null) {
          serviceResultBuilder_.dispose();
          serviceResultBuilder_ = null;
        }
        loadStats_ = null;
        if (loadStatsBuilder_ != null) {
          loadStatsBuilder_.dispose();
          loadStatsBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_ResultOrException_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.index_ = index_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.result_ = resultBuilder_ == null
              ? result_
              : resultBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.exception_ = exceptionBuilder_ == null
              ? exception_
              : exceptionBuilder_.build();
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.serviceResult_ = serviceResultBuilder_ == null
              ? serviceResult_
              : serviceResultBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.loadStats_ = loadStatsBuilder_ == null
              ? loadStats_
              : loadStatsBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.getDefaultInstance()) return this;
        if (other.hasIndex()) {
          setIndex(other.getIndex());
        }
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasException()) {
          mergeException(other.getException());
        }
        if (other.hasServiceResult()) {
          mergeServiceResult(other.getServiceResult());
        }
        if (other.hasLoadStats()) {
          mergeLoadStats(other.getLoadStats());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasException()) {
          if (!getException().isInitialized()) {
            return false;
          }
        }
        if (hasServiceResult()) {
          if (!getServiceResult().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                index_ = input.readUInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                input.readMessage(
                    getExceptionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                input.readMessage(
                    getServiceResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                input.readMessage(
                    getLoadStatsFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int index_ ;
      /**
       * <pre>
       * If part of a multi call, save original index of the list of all
       * passed so can align this response w/ original request.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return Whether the index field is set.
       */
      @java.lang.Override
      public boolean hasIndex() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * If part of a multi call, save original index of the list of all
       * passed so can align this response w/ original request.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return The index.
       */
      @java.lang.Override
      public int getIndex() {
        return index_;
      }
      /**
       * <pre>
       * If part of a multi call, save original index of the list of all
       * passed so can align this response w/ original request.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @param value The index to set.
       * @return This builder for chaining.
       */
      public Builder setIndex(int value) {

        index_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If part of a multi call, save original index of the list of all
       * passed so can align this response w/ original request.
       * </pre>
       *
       * <code>optional uint32 index = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIndex() {
        bitField0_ = (bitField0_ & ~0x00000001);
        index_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result result_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       * @return Whether the result field is set.
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       * @return The result.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public Builder setResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public Builder setResult(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public Builder mergeResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            result_ != null &&
            result_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            getResultBuilder().mergeFrom(value);
          } else {
            result_ = value;
          }
        } else {
          resultBuilder_.mergeFrom(value);
        }
        if (result_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public Builder clearResult() {
        bitField0_ = (bitField0_ & ~0x00000002);
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.getDefaultInstance() : result_;
        }
      }
      /**
       * <code>optional .hbase.pb.Result result = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  getResult(),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair exception_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> exceptionBuilder_;
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       * @return Whether the exception field is set.
       */
      public boolean hasException() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       * @return The exception.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException() {
        if (exceptionBuilder_ == null) {
          return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
        } else {
          return exceptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public Builder setException(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exception_ = value;
        } else {
          exceptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public Builder setException(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (exceptionBuilder_ == null) {
          exception_ = builderForValue.build();
        } else {
          exceptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public Builder mergeException(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            exception_ != null &&
            exception_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            getExceptionBuilder().mergeFrom(value);
          } else {
            exception_ = value;
          }
        } else {
          exceptionBuilder_.mergeFrom(value);
        }
        if (exception_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public Builder clearException() {
        bitField0_ = (bitField0_ & ~0x00000004);
        exception_ = null;
        if (exceptionBuilder_ != null) {
          exceptionBuilder_.dispose();
          exceptionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getExceptionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getExceptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
        if (exceptionBuilder_ != null) {
          return exceptionBuilder_.getMessageOrBuilder();
        } else {
          return exception_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
        }
      }
      /**
       * <code>optional .hbase.pb.NameBytesPair exception = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getExceptionFieldBuilder() {
        if (exceptionBuilder_ == null) {
          exceptionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  getException(),
                  getParentForChildren(),
                  isClean());
          exception_ = null;
        }
        return exceptionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult serviceResult_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder> serviceResultBuilder_;
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       * @return Whether the serviceResult field is set.
       */
      public boolean hasServiceResult() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       * @return The serviceResult.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult getServiceResult() {
        if (serviceResultBuilder_ == null) {
          return serviceResult_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance() : serviceResult_;
        } else {
          return serviceResultBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public Builder setServiceResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult value) {
        if (serviceResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serviceResult_ = value;
        } else {
          serviceResultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public Builder setServiceResult(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder builderForValue) {
        if (serviceResultBuilder_ == null) {
          serviceResult_ = builderForValue.build();
        } else {
          serviceResultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public Builder mergeServiceResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult value) {
        if (serviceResultBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            serviceResult_ != null &&
            serviceResult_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance()) {
            getServiceResultBuilder().mergeFrom(value);
          } else {
            serviceResult_ = value;
          }
        } else {
          serviceResultBuilder_.mergeFrom(value);
        }
        if (serviceResult_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public Builder clearServiceResult() {
        bitField0_ = (bitField0_ & ~0x00000008);
        serviceResult_ = null;
        if (serviceResultBuilder_ != null) {
          serviceResultBuilder_.dispose();
          serviceResultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder getServiceResultBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getServiceResultFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder getServiceResultOrBuilder() {
        if (serviceResultBuilder_ != null) {
          return serviceResultBuilder_.getMessageOrBuilder();
        } else {
          return serviceResult_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.getDefaultInstance() : serviceResult_;
        }
      }
      /**
       * <pre>
       * result if this was a coprocessor service call
       * </pre>
       *
       * <code>optional .hbase.pb.CoprocessorServiceResult service_result = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder> 
          getServiceResultFieldBuilder() {
        if (serviceResultBuilder_ == null) {
          serviceResultBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResultOrBuilder>(
                  getServiceResult(),
                  getParentForChildren(),
                  isClean());
          serviceResult_ = null;
        }
        return serviceResultBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats loadStats_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> loadStatsBuilder_;
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
       *     See Client.proto;l=492
       * @return Whether the loadStats field is set.
       */
      @java.lang.Deprecated public boolean hasLoadStats() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       * @deprecated hbase.pb.ResultOrException.loadStats is deprecated.
       *     See Client.proto;l=492
       * @return The loadStats.
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats getLoadStats() {
        if (loadStatsBuilder_ == null) {
          return loadStats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance() : loadStats_;
        } else {
          return loadStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setLoadStats(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats value) {
        if (loadStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          loadStats_ = value;
        } else {
          loadStatsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setLoadStats(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder builderForValue) {
        if (loadStatsBuilder_ == null) {
          loadStats_ = builderForValue.build();
        } else {
          loadStatsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder mergeLoadStats(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats value) {
        if (loadStatsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            loadStats_ != null &&
            loadStats_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance()) {
            getLoadStatsBuilder().mergeFrom(value);
          } else {
            loadStats_ = value;
          }
        } else {
          loadStatsBuilder_.mergeFrom(value);
        }
        if (loadStats_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder clearLoadStats() {
        bitField0_ = (bitField0_ & ~0x00000010);
        loadStats_ = null;
        if (loadStatsBuilder_ != null) {
          loadStatsBuilder_.dispose();
          loadStatsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder getLoadStatsBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getLoadStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder getLoadStatsOrBuilder() {
        if (loadStatsBuilder_ != null) {
          return loadStatsBuilder_.getMessageOrBuilder();
        } else {
          return loadStats_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.getDefaultInstance() : loadStats_;
        }
      }
      /**
       * <pre>
       * current load on the region
       * </pre>
       *
       * <code>optional .hbase.pb.RegionLoadStats loadStats = 5 [deprecated = true];</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder> 
          getLoadStatsFieldBuilder() {
        if (loadStatsBuilder_ == null) {
          loadStatsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionLoadStatsOrBuilder>(
                  getLoadStats(),
                  getParentForChildren(),
                  isClean());
          loadStats_ = null;
        }
        return loadStatsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ResultOrException)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ResultOrException)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ResultOrException>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ResultOrException>() {
      @java.lang.Override
      public ResultOrException parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ResultOrException> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ResultOrException> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionActionResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionActionResult)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> 
        getResultOrExceptionList();
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getResultOrException(int index);
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    int getResultOrExceptionCount();
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder> 
        getResultOrExceptionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder getResultOrExceptionOrBuilder(
        int index);

    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     * @return Whether the exception field is set.
     */
    boolean hasException();
    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     * @return The exception.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException();
    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder();

    /**
     * <code>optional bool processed = 3;</code>
     * @return Whether the processed field is set.
     */
    boolean hasProcessed();
    /**
     * <code>optional bool processed = 3;</code>
     * @return The processed.
     */
    boolean getProcessed();
  }
  /**
   * <pre>
   **
   * The result of a RegionAction.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.RegionActionResult}
   */
  @javax.annotation.Generated("proto") public static final class RegionActionResult extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionActionResult)
      RegionActionResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionActionResult.newBuilder() to construct.
    private RegionActionResult(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionActionResult() {
      resultOrException_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionActionResult();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionActionResult_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionActionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder.class);
    }

    private int bitField0_;
    public static final int RESULTOREXCEPTION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> resultOrException_;
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> getResultOrExceptionList() {
      return resultOrException_;
    }
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder> 
        getResultOrExceptionOrBuilderList() {
      return resultOrException_;
    }
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    @java.lang.Override
    public int getResultOrExceptionCount() {
      return resultOrException_.size();
    }
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getResultOrException(int index) {
      return resultOrException_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder getResultOrExceptionOrBuilder(
        int index) {
      return resultOrException_.get(index);
    }

    public static final int EXCEPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair exception_;
    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     * @return Whether the exception field is set.
     */
    @java.lang.Override
    public boolean hasException() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     * @return The exception.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException() {
      return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
    }
    /**
     * <pre>
     * If the operation failed globally for this region, this exception is set
     * </pre>
     *
     * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
      return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
    }

    public static final int PROCESSED_FIELD_NUMBER = 3;
    private boolean processed_ = false;
    /**
     * <code>optional bool processed = 3;</code>
     * @return Whether the processed field is set.
     */
    @java.lang.Override
    public boolean hasProcessed() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool processed = 3;</code>
     * @return The processed.
     */
    @java.lang.Override
    public boolean getProcessed() {
      return processed_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getResultOrExceptionCount(); i++) {
        if (!getResultOrException(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasException()) {
        if (!getException().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < resultOrException_.size(); i++) {
        output.writeMessage(1, resultOrException_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(2, getException());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(3, processed_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < resultOrException_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resultOrException_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getException());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, processed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult) obj;

      if (!getResultOrExceptionList()
          .equals(other.getResultOrExceptionList())) return false;
      if (hasException() != other.hasException()) return false;
      if (hasException()) {
        if (!getException()
            .equals(other.getException())) return false;
      }
      if (hasProcessed() != other.hasProcessed()) return false;
      if (hasProcessed()) {
        if (getProcessed()
            != other.getProcessed()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getResultOrExceptionCount() > 0) {
        hash = (37 * hash) + RESULTOREXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getResultOrExceptionList().hashCode();
      }
      if (hasException()) {
        hash = (37 * hash) + EXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getException().hashCode();
      }
      if (hasProcessed()) {
        hash = (37 * hash) + PROCESSED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getProcessed());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * The result of a RegionAction.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.RegionActionResult}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionActionResult)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionActionResult_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionActionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultOrExceptionFieldBuilder();
          getExceptionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (resultOrExceptionBuilder_ == null) {
          resultOrException_ = java.util.Collections.emptyList();
        } else {
          resultOrException_ = null;
          resultOrExceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        exception_ = null;
        if (exceptionBuilder_ != null) {
          exceptionBuilder_.dispose();
          exceptionBuilder_ = null;
        }
        processed_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_RegionActionResult_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult result) {
        if (resultOrExceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            resultOrException_ = java.util.Collections.unmodifiableList(resultOrException_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.resultOrException_ = resultOrException_;
        } else {
          result.resultOrException_ = resultOrExceptionBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.exception_ = exceptionBuilder_ == null
              ? exception_
              : exceptionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.processed_ = processed_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.getDefaultInstance()) return this;
        if (resultOrExceptionBuilder_ == null) {
          if (!other.resultOrException_.isEmpty()) {
            if (resultOrException_.isEmpty()) {
              resultOrException_ = other.resultOrException_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultOrExceptionIsMutable();
              resultOrException_.addAll(other.resultOrException_);
            }
            onChanged();
          }
        } else {
          if (!other.resultOrException_.isEmpty()) {
            if (resultOrExceptionBuilder_.isEmpty()) {
              resultOrExceptionBuilder_.dispose();
              resultOrExceptionBuilder_ = null;
              resultOrException_ = other.resultOrException_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultOrExceptionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultOrExceptionFieldBuilder() : null;
            } else {
              resultOrExceptionBuilder_.addAllMessages(other.resultOrException_);
            }
          }
        }
        if (other.hasException()) {
          mergeException(other.getException());
        }
        if (other.hasProcessed()) {
          setProcessed(other.getProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getResultOrExceptionCount(); i++) {
          if (!getResultOrException(i).isInitialized()) {
            return false;
          }
        }
        if (hasException()) {
          if (!getException().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.PARSER,
                        extensionRegistry);
                if (resultOrExceptionBuilder_ == null) {
                  ensureResultOrExceptionIsMutable();
                  resultOrException_.add(m);
                } else {
                  resultOrExceptionBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getExceptionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                processed_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> resultOrException_ =
        java.util.Collections.emptyList();
      private void ensureResultOrExceptionIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          resultOrException_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException>(resultOrException_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder> resultOrExceptionBuilder_;

      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> getResultOrExceptionList() {
        if (resultOrExceptionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(resultOrException_);
        } else {
          return resultOrExceptionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public int getResultOrExceptionCount() {
        if (resultOrExceptionBuilder_ == null) {
          return resultOrException_.size();
        } else {
          return resultOrExceptionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException getResultOrException(int index) {
        if (resultOrExceptionBuilder_ == null) {
          return resultOrException_.get(index);
        } else {
          return resultOrExceptionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder setResultOrException(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException value) {
        if (resultOrExceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultOrExceptionIsMutable();
          resultOrException_.set(index, value);
          onChanged();
        } else {
          resultOrExceptionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder setResultOrException(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder builderForValue) {
        if (resultOrExceptionBuilder_ == null) {
          ensureResultOrExceptionIsMutable();
          resultOrException_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultOrExceptionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder addResultOrException(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException value) {
        if (resultOrExceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultOrExceptionIsMutable();
          resultOrException_.add(value);
          onChanged();
        } else {
          resultOrExceptionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder addResultOrException(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException value) {
        if (resultOrExceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultOrExceptionIsMutable();
          resultOrException_.add(index, value);
          onChanged();
        } else {
          resultOrExceptionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder addResultOrException(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder builderForValue) {
        if (resultOrExceptionBuilder_ == null) {
          ensureResultOrExceptionIsMutable();
          resultOrException_.add(builderForValue.build());
          onChanged();
        } else {
          resultOrExceptionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder addResultOrException(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder builderForValue) {
        if (resultOrExceptionBuilder_ == null) {
          ensureResultOrExceptionIsMutable();
          resultOrException_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultOrExceptionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder addAllResultOrException(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException> values) {
        if (resultOrExceptionBuilder_ == null) {
          ensureResultOrExceptionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, resultOrException_);
          onChanged();
        } else {
          resultOrExceptionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder clearResultOrException() {
        if (resultOrExceptionBuilder_ == null) {
          resultOrException_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultOrExceptionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public Builder removeResultOrException(int index) {
        if (resultOrExceptionBuilder_ == null) {
          ensureResultOrExceptionIsMutable();
          resultOrException_.remove(index);
          onChanged();
        } else {
          resultOrExceptionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder getResultOrExceptionBuilder(
          int index) {
        return getResultOrExceptionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder getResultOrExceptionOrBuilder(
          int index) {
        if (resultOrExceptionBuilder_ == null) {
          return resultOrException_.get(index);  } else {
          return resultOrExceptionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder> 
           getResultOrExceptionOrBuilderList() {
        if (resultOrExceptionBuilder_ != null) {
          return resultOrExceptionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(resultOrException_);
        }
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder addResultOrExceptionBuilder() {
        return getResultOrExceptionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder addResultOrExceptionBuilder(
          int index) {
        return getResultOrExceptionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.ResultOrException resultOrException = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder> 
           getResultOrExceptionBuilderList() {
        return getResultOrExceptionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder> 
          getResultOrExceptionFieldBuilder() {
        if (resultOrExceptionBuilder_ == null) {
          resultOrExceptionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrException.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ResultOrExceptionOrBuilder>(
                  resultOrException_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          resultOrException_ = null;
        }
        return resultOrExceptionBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair exception_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> exceptionBuilder_;
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       * @return Whether the exception field is set.
       */
      public boolean hasException() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       * @return The exception.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair getException() {
        if (exceptionBuilder_ == null) {
          return exception_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
        } else {
          return exceptionBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public Builder setException(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exception_ = value;
        } else {
          exceptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public Builder setException(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (exceptionBuilder_ == null) {
          exception_ = builderForValue.build();
        } else {
          exceptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public Builder mergeException(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            exception_ != null &&
            exception_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            getExceptionBuilder().mergeFrom(value);
          } else {
            exception_ = value;
          }
        } else {
          exceptionBuilder_.mergeFrom(value);
        }
        if (exception_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public Builder clearException() {
        bitField0_ = (bitField0_ & ~0x00000002);
        exception_ = null;
        if (exceptionBuilder_ != null) {
          exceptionBuilder_.dispose();
          exceptionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder getExceptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getExceptionFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
        if (exceptionBuilder_ != null) {
          return exceptionBuilder_.getMessageOrBuilder();
        } else {
          return exception_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance() : exception_;
        }
      }
      /**
       * <pre>
       * If the operation failed globally for this region, this exception is set
       * </pre>
       *
       * <code>optional .hbase.pb.NameBytesPair exception = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getExceptionFieldBuilder() {
        if (exceptionBuilder_ == null) {
          exceptionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  getException(),
                  getParentForChildren(),
                  isClean());
          exception_ = null;
        }
        return exceptionBuilder_;
      }

      private boolean processed_ ;
      /**
       * <code>optional bool processed = 3;</code>
       * @return Whether the processed field is set.
       */
      @java.lang.Override
      public boolean hasProcessed() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool processed = 3;</code>
       * @return The processed.
       */
      @java.lang.Override
      public boolean getProcessed() {
        return processed_;
      }
      /**
       * <code>optional bool processed = 3;</code>
       * @param value The processed to set.
       * @return This builder for chaining.
       */
      public Builder setProcessed(boolean value) {

        processed_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool processed = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearProcessed() {
        bitField0_ = (bitField0_ & ~0x00000004);
        processed_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionActionResult)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionActionResult)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionActionResult>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionActionResult>() {
      @java.lang.Override
      public RegionActionResult parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionActionResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionActionResult> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MultiRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MultiRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> 
        getRegionActionList();
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getRegionAction(int index);
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    int getRegionActionCount();
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder> 
        getRegionActionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder getRegionActionOrBuilder(
        int index);

    /**
     * <code>optional uint64 nonceGroup = 2;</code>
     * @return Whether the nonceGroup field is set.
     */
    boolean hasNonceGroup();
    /**
     * <code>optional uint64 nonceGroup = 2;</code>
     * @return The nonceGroup.
     */
    long getNonceGroup();

    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiRequest.condition is deprecated.
     *     See Client.proto;l=517
     * @return Whether the condition field is set.
     */
    @java.lang.Deprecated boolean hasCondition();
    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiRequest.condition is deprecated.
     *     See Client.proto;l=517
     * @return The condition.
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition();
    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder();
  }
  /**
   * <pre>
   **
   * Execute a list of actions on a given region in order.
   * Nothing prevents a request to contains a set of RegionAction on the same region.
   * For this reason, the matching between the MultiRequest and the MultiResponse is not
   *  done by the region specifier but by keeping the order of the RegionActionResult vs.
   *  the order of the RegionAction.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.MultiRequest}
   */
  @javax.annotation.Generated("proto") public static final class MultiRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MultiRequest)
      MultiRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MultiRequest.newBuilder() to construct.
    private MultiRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MultiRequest() {
      regionAction_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MultiRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGIONACTION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> regionAction_;
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> getRegionActionList() {
      return regionAction_;
    }
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder> 
        getRegionActionOrBuilderList() {
      return regionAction_;
    }
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    @java.lang.Override
    public int getRegionActionCount() {
      return regionAction_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getRegionAction(int index) {
      return regionAction_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder getRegionActionOrBuilder(
        int index) {
      return regionAction_.get(index);
    }

    public static final int NONCEGROUP_FIELD_NUMBER = 2;
    private long nonceGroup_ = 0L;
    /**
     * <code>optional uint64 nonceGroup = 2;</code>
     * @return Whether the nonceGroup field is set.
     */
    @java.lang.Override
    public boolean hasNonceGroup() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional uint64 nonceGroup = 2;</code>
     * @return The nonceGroup.
     */
    @java.lang.Override
    public long getNonceGroup() {
      return nonceGroup_;
    }

    public static final int CONDITION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiRequest.condition is deprecated.
     *     See Client.proto;l=517
     * @return Whether the condition field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasCondition() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiRequest.condition is deprecated.
     *     See Client.proto;l=517
     * @return The condition.
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }
    /**
     * <pre>
     * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
     * it in the future.
     * </pre>
     *
     * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
      return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionActionCount(); i++) {
        if (!getRegionAction(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasCondition()) {
        if (!getCondition().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < regionAction_.size(); i++) {
        output.writeMessage(1, regionAction_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(2, nonceGroup_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(3, getCondition());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < regionAction_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionAction_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, nonceGroup_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCondition());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest) obj;

      if (!getRegionActionList()
          .equals(other.getRegionActionList())) return false;
      if (hasNonceGroup() != other.hasNonceGroup()) return false;
      if (hasNonceGroup()) {
        if (getNonceGroup()
            != other.getNonceGroup()) return false;
      }
      if (hasCondition() != other.hasCondition()) return false;
      if (hasCondition()) {
        if (!getCondition()
            .equals(other.getCondition())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionActionCount() > 0) {
        hash = (37 * hash) + REGIONACTION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionActionList().hashCode();
      }
      if (hasNonceGroup()) {
        hash = (37 * hash) + NONCEGROUP_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNonceGroup());
      }
      if (hasCondition()) {
        hash = (37 * hash) + CONDITION_FIELD_NUMBER;
        hash = (53 * hash) + getCondition().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Execute a list of actions on a given region in order.
     * Nothing prevents a request to contains a set of RegionAction on the same region.
     * For this reason, the matching between the MultiRequest and the MultiResponse is not
     *  done by the region specifier but by keeping the order of the RegionActionResult vs.
     *  the order of the RegionAction.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.MultiRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MultiRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionActionFieldBuilder();
          getConditionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionActionBuilder_ == null) {
          regionAction_ = java.util.Collections.emptyList();
        } else {
          regionAction_ = null;
          regionActionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        nonceGroup_ = 0L;
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest result) {
        if (regionActionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            regionAction_ = java.util.Collections.unmodifiableList(regionAction_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.regionAction_ = regionAction_;
        } else {
          result.regionAction_ = regionActionBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.nonceGroup_ = nonceGroup_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.condition_ = conditionBuilder_ == null
              ? condition_
              : conditionBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance()) return this;
        if (regionActionBuilder_ == null) {
          if (!other.regionAction_.isEmpty()) {
            if (regionAction_.isEmpty()) {
              regionAction_ = other.regionAction_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionActionIsMutable();
              regionAction_.addAll(other.regionAction_);
            }
            onChanged();
          }
        } else {
          if (!other.regionAction_.isEmpty()) {
            if (regionActionBuilder_.isEmpty()) {
              regionActionBuilder_.dispose();
              regionActionBuilder_ = null;
              regionAction_ = other.regionAction_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionActionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionActionFieldBuilder() : null;
            } else {
              regionActionBuilder_.addAllMessages(other.regionAction_);
            }
          }
        }
        if (other.hasNonceGroup()) {
          setNonceGroup(other.getNonceGroup());
        }
        if (other.hasCondition()) {
          mergeCondition(other.getCondition());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionActionCount(); i++) {
          if (!getRegionAction(i).isInitialized()) {
            return false;
          }
        }
        if (hasCondition()) {
          if (!getCondition().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.PARSER,
                        extensionRegistry);
                if (regionActionBuilder_ == null) {
                  ensureRegionActionIsMutable();
                  regionAction_.add(m);
                } else {
                  regionActionBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                nonceGroup_ = input.readUInt64();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                input.readMessage(
                    getConditionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> regionAction_ =
        java.util.Collections.emptyList();
      private void ensureRegionActionIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          regionAction_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction>(regionAction_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder> regionActionBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> getRegionActionList() {
        if (regionActionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionAction_);
        } else {
          return regionActionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public int getRegionActionCount() {
        if (regionActionBuilder_ == null) {
          return regionAction_.size();
        } else {
          return regionActionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction getRegionAction(int index) {
        if (regionActionBuilder_ == null) {
          return regionAction_.get(index);
        } else {
          return regionActionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder setRegionAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction value) {
        if (regionActionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionIsMutable();
          regionAction_.set(index, value);
          onChanged();
        } else {
          regionActionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder setRegionAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder builderForValue) {
        if (regionActionBuilder_ == null) {
          ensureRegionActionIsMutable();
          regionAction_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionActionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder addRegionAction(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction value) {
        if (regionActionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionIsMutable();
          regionAction_.add(value);
          onChanged();
        } else {
          regionActionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder addRegionAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction value) {
        if (regionActionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionIsMutable();
          regionAction_.add(index, value);
          onChanged();
        } else {
          regionActionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder addRegionAction(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder builderForValue) {
        if (regionActionBuilder_ == null) {
          ensureRegionActionIsMutable();
          regionAction_.add(builderForValue.build());
          onChanged();
        } else {
          regionActionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder addRegionAction(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder builderForValue) {
        if (regionActionBuilder_ == null) {
          ensureRegionActionIsMutable();
          regionAction_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionActionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder addAllRegionAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction> values) {
        if (regionActionBuilder_ == null) {
          ensureRegionActionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionAction_);
          onChanged();
        } else {
          regionActionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder clearRegionAction() {
        if (regionActionBuilder_ == null) {
          regionAction_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionActionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public Builder removeRegionAction(int index) {
        if (regionActionBuilder_ == null) {
          ensureRegionActionIsMutable();
          regionAction_.remove(index);
          onChanged();
        } else {
          regionActionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder getRegionActionBuilder(
          int index) {
        return getRegionActionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder getRegionActionOrBuilder(
          int index) {
        if (regionActionBuilder_ == null) {
          return regionAction_.get(index);  } else {
          return regionActionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder> 
           getRegionActionOrBuilderList() {
        if (regionActionBuilder_ != null) {
          return regionActionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionAction_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder addRegionActionBuilder() {
        return getRegionActionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder addRegionActionBuilder(
          int index) {
        return getRegionActionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionAction regionAction = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder> 
           getRegionActionBuilderList() {
        return getRegionActionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder> 
          getRegionActionFieldBuilder() {
        if (regionActionBuilder_ == null) {
          regionActionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionAction.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionOrBuilder>(
                  regionAction_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          regionAction_ = null;
        }
        return regionActionBuilder_;
      }

      private long nonceGroup_ ;
      /**
       * <code>optional uint64 nonceGroup = 2;</code>
       * @return Whether the nonceGroup field is set.
       */
      @java.lang.Override
      public boolean hasNonceGroup() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint64 nonceGroup = 2;</code>
       * @return The nonceGroup.
       */
      @java.lang.Override
      public long getNonceGroup() {
        return nonceGroup_;
      }
      /**
       * <code>optional uint64 nonceGroup = 2;</code>
       * @param value The nonceGroup to set.
       * @return This builder for chaining.
       */
      public Builder setNonceGroup(long value) {

        nonceGroup_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 nonceGroup = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearNonceGroup() {
        bitField0_ = (bitField0_ & ~0x00000002);
        nonceGroup_ = 0L;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition condition_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> conditionBuilder_;
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiRequest.condition is deprecated.
       *     See Client.proto;l=517
       * @return Whether the condition field is set.
       */
      @java.lang.Deprecated public boolean hasCondition() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiRequest.condition is deprecated.
       *     See Client.proto;l=517
       * @return The condition.
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition getCondition() {
        if (conditionBuilder_ == null) {
          return condition_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        } else {
          return conditionBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          condition_ = value;
        } else {
          conditionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setCondition(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder builderForValue) {
        if (conditionBuilder_ == null) {
          condition_ = builderForValue.build();
        } else {
          conditionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder mergeCondition(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            condition_ != null &&
            condition_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) {
            getConditionBuilder().mergeFrom(value);
          } else {
            condition_ = value;
          }
        } else {
          conditionBuilder_.mergeFrom(value);
        }
        if (condition_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder clearCondition() {
        bitField0_ = (bitField0_ & ~0x00000004);
        condition_ = null;
        if (conditionBuilder_ != null) {
          conditionBuilder_.dispose();
          conditionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder getConditionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getConditionFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
        if (conditionBuilder_ != null) {
          return conditionBuilder_.getMessageOrBuilder();
        } else {
          return condition_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.getDefaultInstance() : condition_;
        }
      }
      /**
       * <pre>
       * Moved this to RegionAction in HBASE-8458. Keep it for backward compatibility. Need to remove
       * it in the future.
       * </pre>
       *
       * <code>optional .hbase.pb.Condition condition = 3 [deprecated = true];</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder> 
          getConditionFieldBuilder() {
        if (conditionBuilder_ == null) {
          conditionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ConditionOrBuilder>(
                  getCondition(),
                  getParentForChildren(),
                  isClean());
          condition_ = null;
        }
        return conditionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MultiRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MultiRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MultiRequest>() {
      @java.lang.Override
      public MultiRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MultiResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MultiResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> 
        getRegionActionResultList();
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getRegionActionResult(int index);
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    int getRegionActionResultCount();
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder> 
        getRegionActionResultOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder getRegionActionResultOrBuilder(
        int index);

    /**
     * <pre>
     * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
     * remove it in the future.
     * </pre>
     *
     * <code>optional bool processed = 2 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiResponse.processed is deprecated.
     *     See Client.proto;l=524
     * @return Whether the processed field is set.
     */
    @java.lang.Deprecated boolean hasProcessed();
    /**
     * <pre>
     * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
     * remove it in the future.
     * </pre>
     *
     * <code>optional bool processed = 2 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiResponse.processed is deprecated.
     *     See Client.proto;l=524
     * @return The processed.
     */
    @java.lang.Deprecated boolean getProcessed();

    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     * @return Whether the regionStatistics field is set.
     */
    boolean hasRegionStatistics();
    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     * @return The regionStatistics.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getRegionStatistics();
    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder getRegionStatisticsOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.MultiResponse}
   */
  @javax.annotation.Generated("proto") public static final class MultiResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MultiResponse)
      MultiResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MultiResponse.newBuilder() to construct.
    private MultiResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MultiResponse() {
      regionActionResult_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MultiResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.Builder.class);
    }

    private int bitField0_;
    public static final int REGIONACTIONRESULT_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> regionActionResult_;
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> getRegionActionResultList() {
      return regionActionResult_;
    }
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder> 
        getRegionActionResultOrBuilderList() {
      return regionActionResult_;
    }
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    @java.lang.Override
    public int getRegionActionResultCount() {
      return regionActionResult_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getRegionActionResult(int index) {
      return regionActionResult_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder getRegionActionResultOrBuilder(
        int index) {
      return regionActionResult_.get(index);
    }

    public static final int PROCESSED_FIELD_NUMBER = 2;
    private boolean processed_ = false;
    /**
     * <pre>
     * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
     * remove it in the future.
     * </pre>
     *
     * <code>optional bool processed = 2 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiResponse.processed is deprecated.
     *     See Client.proto;l=524
     * @return Whether the processed field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasProcessed() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
     * remove it in the future.
     * </pre>
     *
     * <code>optional bool processed = 2 [deprecated = true];</code>
     * @deprecated hbase.pb.MultiResponse.processed is deprecated.
     *     See Client.proto;l=524
     * @return The processed.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean getProcessed() {
      return processed_;
    }

    public static final int REGIONSTATISTICS_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats regionStatistics_;
    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     * @return Whether the regionStatistics field is set.
     */
    @java.lang.Override
    public boolean hasRegionStatistics() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     * @return The regionStatistics.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getRegionStatistics() {
      return regionStatistics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance() : regionStatistics_;
    }
    /**
     * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder getRegionStatisticsOrBuilder() {
      return regionStatistics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance() : regionStatistics_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionActionResultCount(); i++) {
        if (!getRegionActionResult(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasRegionStatistics()) {
        if (!getRegionStatistics().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < regionActionResult_.size(); i++) {
        output.writeMessage(1, regionActionResult_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(2, processed_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(3, getRegionStatistics());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < regionActionResult_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionActionResult_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, processed_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getRegionStatistics());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse) obj;

      if (!getRegionActionResultList()
          .equals(other.getRegionActionResultList())) return false;
      if (hasProcessed() != other.hasProcessed()) return false;
      if (hasProcessed()) {
        if (getProcessed()
            != other.getProcessed()) return false;
      }
      if (hasRegionStatistics() != other.hasRegionStatistics()) return false;
      if (hasRegionStatistics()) {
        if (!getRegionStatistics()
            .equals(other.getRegionStatistics())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionActionResultCount() > 0) {
        hash = (37 * hash) + REGIONACTIONRESULT_FIELD_NUMBER;
        hash = (53 * hash) + getRegionActionResultList().hashCode();
      }
      if (hasProcessed()) {
        hash = (37 * hash) + PROCESSED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getProcessed());
      }
      if (hasRegionStatistics()) {
        hash = (37 * hash) + REGIONSTATISTICS_FIELD_NUMBER;
        hash = (53 * hash) + getRegionStatistics().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MultiResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MultiResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionActionResultFieldBuilder();
          getRegionStatisticsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionActionResultBuilder_ == null) {
          regionActionResult_ = java.util.Collections.emptyList();
        } else {
          regionActionResult_ = null;
          regionActionResultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        processed_ = false;
        regionStatistics_ = null;
        if (regionStatisticsBuilder_ != null) {
          regionStatisticsBuilder_.dispose();
          regionStatisticsBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.internal_static_hbase_pb_MultiResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse result) {
        if (regionActionResultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            regionActionResult_ = java.util.Collections.unmodifiableList(regionActionResult_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.regionActionResult_ = regionActionResult_;
        } else {
          result.regionActionResult_ = regionActionResultBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.processed_ = processed_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.regionStatistics_ = regionStatisticsBuilder_ == null
              ? regionStatistics_
              : regionStatisticsBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()) return this;
        if (regionActionResultBuilder_ == null) {
          if (!other.regionActionResult_.isEmpty()) {
            if (regionActionResult_.isEmpty()) {
              regionActionResult_ = other.regionActionResult_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionActionResultIsMutable();
              regionActionResult_.addAll(other.regionActionResult_);
            }
            onChanged();
          }
        } else {
          if (!other.regionActionResult_.isEmpty()) {
            if (regionActionResultBuilder_.isEmpty()) {
              regionActionResultBuilder_.dispose();
              regionActionResultBuilder_ = null;
              regionActionResult_ = other.regionActionResult_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionActionResultBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionActionResultFieldBuilder() : null;
            } else {
              regionActionResultBuilder_.addAllMessages(other.regionActionResult_);
            }
          }
        }
        if (other.hasProcessed()) {
          setProcessed(other.getProcessed());
        }
        if (other.hasRegionStatistics()) {
          mergeRegionStatistics(other.getRegionStatistics());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionActionResultCount(); i++) {
          if (!getRegionActionResult(i).isInitialized()) {
            return false;
          }
        }
        if (hasRegionStatistics()) {
          if (!getRegionStatistics().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.PARSER,
                        extensionRegistry);
                if (regionActionResultBuilder_ == null) {
                  ensureRegionActionResultIsMutable();
                  regionActionResult_.add(m);
                } else {
                  regionActionResultBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                processed_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                input.readMessage(
                    getRegionStatisticsFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> regionActionResult_ =
        java.util.Collections.emptyList();
      private void ensureRegionActionResultIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          regionActionResult_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult>(regionActionResult_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder> regionActionResultBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> getRegionActionResultList() {
        if (regionActionResultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionActionResult_);
        } else {
          return regionActionResultBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public int getRegionActionResultCount() {
        if (regionActionResultBuilder_ == null) {
          return regionActionResult_.size();
        } else {
          return regionActionResultBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult getRegionActionResult(int index) {
        if (regionActionResultBuilder_ == null) {
          return regionActionResult_.get(index);
        } else {
          return regionActionResultBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder setRegionActionResult(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult value) {
        if (regionActionResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionResultIsMutable();
          regionActionResult_.set(index, value);
          onChanged();
        } else {
          regionActionResultBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder setRegionActionResult(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder builderForValue) {
        if (regionActionResultBuilder_ == null) {
          ensureRegionActionResultIsMutable();
          regionActionResult_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionActionResultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder addRegionActionResult(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult value) {
        if (regionActionResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionResultIsMutable();
          regionActionResult_.add(value);
          onChanged();
        } else {
          regionActionResultBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder addRegionActionResult(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult value) {
        if (regionActionResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionActionResultIsMutable();
          regionActionResult_.add(index, value);
          onChanged();
        } else {
          regionActionResultBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder addRegionActionResult(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder builderForValue) {
        if (regionActionResultBuilder_ == null) {
          ensureRegionActionResultIsMutable();
          regionActionResult_.add(builderForValue.build());
          onChanged();
        } else {
          regionActionResultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder addRegionActionResult(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder builderForValue) {
        if (regionActionResultBuilder_ == null) {
          ensureRegionActionResultIsMutable();
          regionActionResult_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionActionResultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder addAllRegionActionResult(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult> values) {
        if (regionActionResultBuilder_ == null) {
          ensureRegionActionResultIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionActionResult_);
          onChanged();
        } else {
          regionActionResultBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder clearRegionActionResult() {
        if (regionActionResultBuilder_ == null) {
          regionActionResult_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionActionResultBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public Builder removeRegionActionResult(int index) {
        if (regionActionResultBuilder_ == null) {
          ensureRegionActionResultIsMutable();
          regionActionResult_.remove(index);
          onChanged();
        } else {
          regionActionResultBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder getRegionActionResultBuilder(
          int index) {
        return getRegionActionResultFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder getRegionActionResultOrBuilder(
          int index) {
        if (regionActionResultBuilder_ == null) {
          return regionActionResult_.get(index);  } else {
          return regionActionResultBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder> 
           getRegionActionResultOrBuilderList() {
        if (regionActionResultBuilder_ != null) {
          return regionActionResultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionActionResult_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder addRegionActionResultBuilder() {
        return getRegionActionResultFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder addRegionActionResultBuilder(
          int index) {
        return getRegionActionResultFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionActionResult regionActionResult = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder> 
           getRegionActionResultBuilderList() {
        return getRegionActionResultFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder> 
          getRegionActionResultFieldBuilder() {
        if (regionActionResultBuilder_ == null) {
          regionActionResultBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResult.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.RegionActionResultOrBuilder>(
                  regionActionResult_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          regionActionResult_ = null;
        }
        return regionActionResultBuilder_;
      }

      private boolean processed_ ;
      /**
       * <pre>
       * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
       * remove it in the future.
       * </pre>
       *
       * <code>optional bool processed = 2 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiResponse.processed is deprecated.
       *     See Client.proto;l=524
       * @return Whether the processed field is set.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean hasProcessed() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
       * remove it in the future.
       * </pre>
       *
       * <code>optional bool processed = 2 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiResponse.processed is deprecated.
       *     See Client.proto;l=524
       * @return The processed.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean getProcessed() {
        return processed_;
      }
      /**
       * <pre>
       * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
       * remove it in the future.
       * </pre>
       *
       * <code>optional bool processed = 2 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiResponse.processed is deprecated.
       *     See Client.proto;l=524
       * @param value The processed to set.
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder setProcessed(boolean value) {

        processed_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Moved this to RegionActionResult in HBASE-8458. Keep it for backward compatibility. Need to
       * remove it in the future.
       * </pre>
       *
       * <code>optional bool processed = 2 [deprecated = true];</code>
       * @deprecated hbase.pb.MultiResponse.processed is deprecated.
       *     See Client.proto;l=524
       * @return This builder for chaining.
       */
      @java.lang.Deprecated public Builder clearProcessed() {
        bitField0_ = (bitField0_ & ~0x00000002);
        processed_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats regionStatistics_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder> regionStatisticsBuilder_;
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       * @return Whether the regionStatistics field is set.
       */
      public boolean hasRegionStatistics() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       * @return The regionStatistics.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats getRegionStatistics() {
        if (regionStatisticsBuilder_ == null) {
          return regionStatistics_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance() : regionStatistics_;
        } else {
          return regionStatisticsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public Builder setRegionStatistics(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats value) {
        if (regionStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionStatistics_ = value;
        } else {
          regionStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public Builder setRegionStatistics(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder builderForValue) {
        if (regionStatisticsBuilder_ == null) {
          regionStatistics_ = builderForValue.build();
        } else {
          regionStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public Builder mergeRegionStatistics(org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats value) {
        if (regionStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
            regionStatistics_ != null &&
            regionStatistics_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance()) {
            getRegionStatisticsBuilder().mergeFrom(value);
          } else {
            regionStatistics_ = value;
          }
        } else {
          regionStatisticsBuilder_.mergeFrom(value);
        }
        if (regionStatistics_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public Builder clearRegionStatistics() {
        bitField0_ = (bitField0_ & ~0x00000004);
        regionStatistics_ = null;
        if (regionStatisticsBuilder_ != null) {
          regionStatisticsBuilder_.dispose();
          regionStatisticsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder getRegionStatisticsBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getRegionStatisticsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder getRegionStatisticsOrBuilder() {
        if (regionStatisticsBuilder_ != null) {
          return regionStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return regionStatistics_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.getDefaultInstance() : regionStatistics_;
        }
      }
      /**
       * <code>optional .hbase.pb.MultiRegionLoadStats regionStatistics = 3;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder> 
          getRegionStatisticsFieldBuilder() {
        if (regionStatisticsBuilder_ == null) {
          regionStatisticsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRegionLoadStatsOrBuilder>(
                  getRegionStatistics(),
                  getParentForChildren(),
                  isClean());
          regionStatistics_ = null;
        }
        return regionStatisticsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MultiResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MultiResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MultiResponse>() {
      @java.lang.Override
      public MultiResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  /**
   * Protobuf service {@code hbase.pb.ClientService}
   */
  public static abstract class ClientService
      implements org.apache.hbase.thirdparty.com.google.protobuf.Service {
    protected ClientService() {}

    public interface Interface {
      /**
       * <code>rpc Get(.hbase.pb.GetRequest) returns (.hbase.pb.GetResponse);</code>
       */
      public abstract void get(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse> done);

      /**
       * <code>rpc Mutate(.hbase.pb.MutateRequest) returns (.hbase.pb.MutateResponse);</code>
       */
      public abstract void mutate(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse> done);

      /**
       * <code>rpc Scan(.hbase.pb.ScanRequest) returns (.hbase.pb.ScanResponse);</code>
       */
      public abstract void scan(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse> done);

      /**
       * <code>rpc BulkLoadHFile(.hbase.pb.BulkLoadHFileRequest) returns (.hbase.pb.BulkLoadHFileResponse);</code>
       */
      public abstract void bulkLoadHFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);

      /**
       * <code>rpc PrepareBulkLoad(.hbase.pb.PrepareBulkLoadRequest) returns (.hbase.pb.PrepareBulkLoadResponse);</code>
       */
      public abstract void prepareBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse> done);

      /**
       * <code>rpc CleanupBulkLoad(.hbase.pb.CleanupBulkLoadRequest) returns (.hbase.pb.CleanupBulkLoadResponse);</code>
       */
      public abstract void cleanupBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse> done);

      /**
       * <code>rpc ExecService(.hbase.pb.CoprocessorServiceRequest) returns (.hbase.pb.CoprocessorServiceResponse);</code>
       */
      public abstract void execService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

      /**
       * <code>rpc ExecRegionServerService(.hbase.pb.CoprocessorServiceRequest) returns (.hbase.pb.CoprocessorServiceResponse);</code>
       */
      public abstract void execRegionServerService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

      /**
       * <code>rpc Multi(.hbase.pb.MultiRequest) returns (.hbase.pb.MultiResponse);</code>
       */
      public abstract void multi(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse> done);

    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new ClientService() {
        @java.lang.Override
        public  void get(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse> done) {
          impl.get(controller, request, done);
        }

        @java.lang.Override
        public  void mutate(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse> done) {
          impl.mutate(controller, request, done);
        }

        @java.lang.Override
        public  void scan(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse> done) {
          impl.scan(controller, request, done);
        }

        @java.lang.Override
        public  void bulkLoadHFile(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
          impl.bulkLoadHFile(controller, request, done);
        }

        @java.lang.Override
        public  void prepareBulkLoad(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse> done) {
          impl.prepareBulkLoad(controller, request, done);
        }

        @java.lang.Override
        public  void cleanupBulkLoad(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse> done) {
          impl.cleanupBulkLoad(controller, request, done);
        }

        @java.lang.Override
        public  void execService(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
          impl.execService(controller, request, done);
        }

        @java.lang.Override
        public  void execRegionServerService(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
          impl.execRegionServerService(controller, request, done);
        }

        @java.lang.Override
        public  void multi(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse> done) {
          impl.multi(controller, request, done);
        }

      };
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new org.apache.hbase.thirdparty.com.google.protobuf.BlockingService() {
        public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message callBlockingMethod(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hbase.thirdparty.com.google.protobuf.Message request)
            throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.get(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest)request);
            case 1:
              return impl.mutate(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest)request);
            case 2:
              return impl.scan(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest)request);
            case 3:
              return impl.bulkLoadHFile(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request);
            case 4:
              return impl.prepareBulkLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest)request);
            case 5:
              return impl.cleanupBulkLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest)request);
            case 6:
              return impl.execService(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request);
            case 7:
              return impl.execRegionServerService(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request);
            case 8:
              return impl.multi(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getRequestPrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getResponsePrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

      };
    }

    /**
     * <code>rpc Get(.hbase.pb.GetRequest) returns (.hbase.pb.GetResponse);</code>
     */
    public abstract void get(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse> done);

    /**
     * <code>rpc Mutate(.hbase.pb.MutateRequest) returns (.hbase.pb.MutateResponse);</code>
     */
    public abstract void mutate(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse> done);

    /**
     * <code>rpc Scan(.hbase.pb.ScanRequest) returns (.hbase.pb.ScanResponse);</code>
     */
    public abstract void scan(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse> done);

    /**
     * <code>rpc BulkLoadHFile(.hbase.pb.BulkLoadHFileRequest) returns (.hbase.pb.BulkLoadHFileResponse);</code>
     */
    public abstract void bulkLoadHFile(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);

    /**
     * <code>rpc PrepareBulkLoad(.hbase.pb.PrepareBulkLoadRequest) returns (.hbase.pb.PrepareBulkLoadResponse);</code>
     */
    public abstract void prepareBulkLoad(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse> done);

    /**
     * <code>rpc CleanupBulkLoad(.hbase.pb.CleanupBulkLoadRequest) returns (.hbase.pb.CleanupBulkLoadResponse);</code>
     */
    public abstract void cleanupBulkLoad(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse> done);

    /**
     * <code>rpc ExecService(.hbase.pb.CoprocessorServiceRequest) returns (.hbase.pb.CoprocessorServiceResponse);</code>
     */
    public abstract void execService(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

    /**
     * <code>rpc ExecRegionServerService(.hbase.pb.CoprocessorServiceRequest) returns (.hbase.pb.CoprocessorServiceResponse);</code>
     */
    public abstract void execRegionServerService(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

    /**
     * <code>rpc Multi(.hbase.pb.MultiRequest) returns (.hbase.pb.MultiResponse);</code>
     */
    public abstract void multi(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse> done);

    public static final
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.getDescriptor().getServices().get(0);
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }

    public final void callMethod(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hbase.thirdparty.com.google.protobuf.Message request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<
          org.apache.hbase.thirdparty.com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.get(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse>specializeCallback(
              done));
          return;
        case 1:
          this.mutate(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse>specializeCallback(
              done));
          return;
        case 2:
          this.scan(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse>specializeCallback(
              done));
          return;
        case 3:
          this.bulkLoadHFile(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse>specializeCallback(
              done));
          return;
        case 4:
          this.prepareBulkLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse>specializeCallback(
              done));
          return;
        case 5:
          this.cleanupBulkLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse>specializeCallback(
              done));
          return;
        case 6:
          this.execService(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse>specializeCallback(
              done));
          return;
        case 7:
          this.execRegionServerService(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse>specializeCallback(
              done));
          return;
        case 8:
          this.multi(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getRequestPrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getResponsePrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public static Stub newStub(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }

    @javax.annotation.Generated("proto") public static final class Stub extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ClientService implements Interface {
      private Stub(org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel;

      public org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }

      public  void get(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()));
      }

      public  void mutate(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()));
      }

      public  void scan(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()));
      }

      public  void bulkLoadHFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()));
      }

      public  void prepareBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance()));
      }

      public  void cleanupBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance()));
      }

      public  void execService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()));
      }

      public  void execRegionServerService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()));
      }

      public  void multi(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()));
      }
    }

    public static BlockingInterface newBlockingStub(
        org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }

    public interface BlockingInterface {
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse get(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse mutate(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse scan(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse prepareBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse cleanupBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse execRegionServerService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse multi(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
    }

    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse get(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse mutate(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse scan(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse prepareBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.PrepareBulkLoadResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse cleanupBulkLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CleanupBulkLoadResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse execRegionServerService(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse multi(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance());
      }

    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClientService)
  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Authorizations_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Authorizations_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CellVisibility_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CellVisibility_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Column_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Column_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Get_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Get_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Result_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Result_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Condition_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Condition_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MutationProto_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MutationProto_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MutationProto_ColumnValue_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MutationProto_ColumnValue_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MutateRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MutateRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MutateResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MutateResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Scan_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Scan_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ScanRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ScanRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Cursor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Cursor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ScanResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ScanResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BulkLoadHFileRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BulkLoadHFileRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BulkLoadHFileResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BulkLoadHFileResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DelegationToken_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DelegationToken_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PrepareBulkLoadRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PrepareBulkLoadResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CleanupBulkLoadRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CleanupBulkLoadResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CoprocessorServiceCall_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CoprocessorServiceCall_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CoprocessorServiceResult_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CoprocessorServiceResult_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CoprocessorServiceRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CoprocessorServiceRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CoprocessorServiceResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CoprocessorServiceResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Action_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Action_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionAction_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionAction_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionLoadStats_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionLoadStats_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MultiRegionLoadStats_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MultiRegionLoadStats_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ResultOrException_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ResultOrException_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionActionResult_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionActionResult_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MultiRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MultiRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MultiResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MultiResponse_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\014Client.proto\022\010hbase.pb\032\013HBase.proto\032\014F" +
      "ilter.proto\032\nCell.proto\032\020Comparator.prot" +
      "o\032\017MapReduce.proto\"\037\n\016Authorizations\022\r\n\005" +
      "label\030\001 \003(\t\"$\n\016CellVisibility\022\022\n\nexpress" +
      "ion\030\001 \002(\t\"+\n\006Column\022\016\n\006family\030\001 \002(\014\022\021\n\tq" +
      "ualifier\030\002 \003(\014\"\341\003\n\003Get\022\013\n\003row\030\001 \002(\014\022 \n\006c" +
      "olumn\030\002 \003(\0132\020.hbase.pb.Column\022*\n\tattribu" +
      "te\030\003 \003(\0132\027.hbase.pb.NameBytesPair\022 \n\006fil" +
      "ter\030\004 \001(\0132\020.hbase.pb.Filter\022\'\n\ntime_rang" +
      "e\030\005 \001(\0132\023.hbase.pb.TimeRange\022\027\n\014max_vers" +
      "ions\030\006 \001(\r:\0011\022\032\n\014cache_blocks\030\007 \001(\010:\004tru" +
      "e\022\023\n\013store_limit\030\010 \001(\r\022\024\n\014store_offset\030\t" +
      " \001(\r\022\035\n\016existence_only\030\n \001(\010:\005false\022!\n\022c" +
      "losest_row_before\030\013 \001(\010:\005false\0222\n\013consis" +
      "tency\030\014 \001(\0162\025.hbase.pb.Consistency:\006STRO" +
      "NG\0226\n\rcf_time_range\030\r \003(\0132\037.hbase.pb.Col" +
      "umnFamilyTimeRange\022&\n\036load_column_famili" +
      "es_on_demand\030\016 \001(\010\"\203\001\n\006Result\022\034\n\004cell\030\001 " +
      "\003(\0132\016.hbase.pb.Cell\022\035\n\025associated_cell_c" +
      "ount\030\002 \001(\005\022\016\n\006exists\030\003 \001(\010\022\024\n\005stale\030\004 \001(" +
      "\010:\005false\022\026\n\007partial\030\005 \001(\010:\005false\"S\n\nGetR" +
      "equest\022)\n\006region\030\001 \002(\0132\031.hbase.pb.Region" +
      "Specifier\022\032\n\003get\030\002 \002(\0132\r.hbase.pb.Get\"/\n" +
      "\013GetResponse\022 \n\006result\030\001 \001(\0132\020.hbase.pb." +
      "Result\"\335\001\n\tCondition\022\013\n\003row\030\001 \002(\014\022\016\n\006fam" +
      "ily\030\002 \001(\014\022\021\n\tqualifier\030\003 \001(\014\022+\n\014compare_" +
      "type\030\004 \001(\0162\025.hbase.pb.CompareType\022(\n\ncom" +
      "parator\030\005 \001(\0132\024.hbase.pb.Comparator\022\'\n\nt" +
      "ime_range\030\006 \001(\0132\023.hbase.pb.TimeRange\022 \n\006" +
      "filter\030\007 \001(\0132\020.hbase.pb.Filter\"\364\006\n\rMutat" +
      "ionProto\022\013\n\003row\030\001 \001(\014\0229\n\013mutate_type\030\002 \001" +
      "(\0162$.hbase.pb.MutationProto.MutationType" +
      "\0229\n\014column_value\030\003 \003(\0132#.hbase.pb.Mutati" +
      "onProto.ColumnValue\022\021\n\ttimestamp\030\004 \001(\004\022*" +
      "\n\tattribute\030\005 \003(\0132\027.hbase.pb.NameBytesPa" +
      "ir\022C\n\ndurability\030\006 \001(\0162\".hbase.pb.Mutati" +
      "onProto.Durability:\013USE_DEFAULT\022\'\n\ntime_" +
      "range\030\007 \001(\0132\023.hbase.pb.TimeRange\022\035\n\025asso" +
      "ciated_cell_count\030\010 \001(\005\022\r\n\005nonce\030\t \001(\004\032\371" +
      "\001\n\013ColumnValue\022\016\n\006family\030\001 \002(\014\022K\n\017qualif" +
      "ier_value\030\002 \003(\01322.hbase.pb.MutationProto" +
      ".ColumnValue.QualifierValue\032\214\001\n\016Qualifie" +
      "rValue\022\021\n\tqualifier\030\001 \001(\014\022\r\n\005value\030\002 \001(\014" +
      "\022\021\n\ttimestamp\030\003 \001(\004\0227\n\013delete_type\030\004 \001(\016" +
      "2\".hbase.pb.MutationProto.DeleteType\022\014\n\004" +
      "tags\030\005 \001(\014\"W\n\nDurability\022\017\n\013USE_DEFAULT\020" +
      "\000\022\014\n\010SKIP_WAL\020\001\022\r\n\tASYNC_WAL\020\002\022\014\n\010SYNC_W" +
      "AL\020\003\022\r\n\tFSYNC_WAL\020\004\">\n\014MutationType\022\n\n\006A" +
      "PPEND\020\000\022\r\n\tINCREMENT\020\001\022\007\n\003PUT\020\002\022\n\n\006DELET" +
      "E\020\003\"p\n\nDeleteType\022\026\n\022DELETE_ONE_VERSION\020" +
      "\000\022\034\n\030DELETE_MULTIPLE_VERSIONS\020\001\022\021\n\rDELET" +
      "E_FAMILY\020\002\022\031\n\025DELETE_FAMILY_VERSION\020\003\"\242\001" +
      "\n\rMutateRequest\022)\n\006region\030\001 \002(\0132\031.hbase." +
      "pb.RegionSpecifier\022)\n\010mutation\030\002 \002(\0132\027.h" +
      "base.pb.MutationProto\022&\n\tcondition\030\003 \001(\013" +
      "2\023.hbase.pb.Condition\022\023\n\013nonce_group\030\004 \001" +
      "(\004\"E\n\016MutateResponse\022 \n\006result\030\001 \001(\0132\020.h" +
      "base.pb.Result\022\021\n\tprocessed\030\002 \001(\010\"\246\006\n\004Sc" +
      "an\022 \n\006column\030\001 \003(\0132\020.hbase.pb.Column\022*\n\t" +
      "attribute\030\002 \003(\0132\027.hbase.pb.NameBytesPair" +
      "\022\021\n\tstart_row\030\003 \001(\014\022\020\n\010stop_row\030\004 \001(\014\022 \n" +
      "\006filter\030\005 \001(\0132\020.hbase.pb.Filter\022\'\n\ntime_" +
      "range\030\006 \001(\0132\023.hbase.pb.TimeRange\022\027\n\014max_" +
      "versions\030\007 \001(\r:\0011\022\032\n\014cache_blocks\030\010 \001(\010:" +
      "\004true\022\022\n\nbatch_size\030\t \001(\r\022\027\n\017max_result_" +
      "size\030\n \001(\004\022\023\n\013store_limit\030\013 \001(\r\022\024\n\014store" +
      "_offset\030\014 \001(\r\022&\n\036load_column_families_on" +
      "_demand\030\r \001(\010\022\021\n\005small\030\016 \001(\010B\002\030\001\022\027\n\010reve" +
      "rsed\030\017 \001(\010:\005false\0222\n\013consistency\030\020 \001(\0162\025" +
      ".hbase.pb.Consistency:\006STRONG\022\017\n\007caching" +
      "\030\021 \001(\r\022\035\n\025allow_partial_results\030\022 \001(\010\0226\n" +
      "\rcf_time_range\030\023 \003(\0132\037.hbase.pb.ColumnFa" +
      "milyTimeRange\022\032\n\017mvcc_read_point\030\024 \001(\004:\001" +
      "0\022\037\n\021include_start_row\030\025 \001(\010:\004true\022\037\n\020in" +
      "clude_stop_row\030\026 \001(\010:\005false\0222\n\010readType\030" +
      "\027 \001(\0162\027.hbase.pb.Scan.ReadType:\007DEFAULT\022" +
      "!\n\022need_cursor_result\030\030 \001(\010:\005false\".\n\010Re" +
      "adType\022\013\n\007DEFAULT\020\000\022\n\n\006STREAM\020\001\022\t\n\005PREAD" +
      "\020\002\"\300\002\n\013ScanRequest\022)\n\006region\030\001 \001(\0132\031.hba" +
      "se.pb.RegionSpecifier\022\034\n\004scan\030\002 \001(\0132\016.hb" +
      "ase.pb.Scan\022\022\n\nscanner_id\030\003 \001(\004\022\026\n\016numbe" +
      "r_of_rows\030\004 \001(\r\022\025\n\rclose_scanner\030\005 \001(\010\022\025" +
      "\n\rnext_call_seq\030\006 \001(\004\022\037\n\027client_handles_" +
      "partials\030\007 \001(\010\022!\n\031client_handles_heartbe" +
      "ats\030\010 \001(\010\022\032\n\022track_scan_metrics\030\t \001(\010\022\024\n" +
      "\005renew\030\n \001(\010:\005false\022\030\n\rlimit_of_rows\030\013 \001" +
      "(\r:\0010\"\025\n\006Cursor\022\013\n\003row\030\001 \001(\014\"\330\002\n\014ScanRes" +
      "ponse\022\030\n\020cells_per_result\030\001 \003(\r\022\022\n\nscann" +
      "er_id\030\002 \001(\004\022\024\n\014more_results\030\003 \001(\010\022\013\n\003ttl" +
      "\030\004 \001(\r\022!\n\007results\030\005 \003(\0132\020.hbase.pb.Resul" +
      "t\022\r\n\005stale\030\006 \001(\010\022\037\n\027partial_flag_per_res" +
      "ult\030\007 \003(\010\022\036\n\026more_results_in_region\030\010 \001(" +
      "\010\022\031\n\021heartbeat_message\030\t \001(\010\022+\n\014scan_met" +
      "rics\030\n \001(\0132\025.hbase.pb.ScanMetrics\022\032\n\017mvc" +
      "c_read_point\030\013 \001(\004:\0010\022 \n\006cursor\030\014 \001(\0132\020." +
      "hbase.pb.Cursor\"\316\002\n\024BulkLoadHFileRequest" +
      "\022)\n\006region\030\001 \002(\0132\031.hbase.pb.RegionSpecif" +
      "ier\022>\n\013family_path\030\002 \003(\0132).hbase.pb.Bulk" +
      "LoadHFileRequest.FamilyPath\022\026\n\016assign_se" +
      "q_num\030\003 \001(\010\022+\n\010fs_token\030\004 \001(\0132\031.hbase.pb" +
      ".DelegationToken\022\022\n\nbulk_token\030\005 \001(\t\022\030\n\t" +
      "copy_file\030\006 \001(\010:\005false\022\023\n\013cluster_ids\030\007 " +
      "\003(\t\022\027\n\treplicate\030\010 \001(\010:\004true\032*\n\nFamilyPa" +
      "th\022\016\n\006family\030\001 \002(\014\022\014\n\004path\030\002 \002(\t\"\'\n\025Bulk" +
      "LoadHFileResponse\022\016\n\006loaded\030\001 \002(\010\"V\n\017Del" +
      "egationToken\022\022\n\nidentifier\030\001 \001(\014\022\020\n\010pass" +
      "word\030\002 \001(\014\022\014\n\004kind\030\003 \001(\t\022\017\n\007service\030\004 \001(" +
      "\t\"l\n\026PrepareBulkLoadRequest\022\'\n\ntable_nam" +
      "e\030\001 \002(\0132\023.hbase.pb.TableName\022)\n\006region\030\002" +
      " \001(\0132\031.hbase.pb.RegionSpecifier\"-\n\027Prepa" +
      "reBulkLoadResponse\022\022\n\nbulk_token\030\001 \002(\t\"W" +
      "\n\026CleanupBulkLoadRequest\022\022\n\nbulk_token\030\001" +
      " \002(\t\022)\n\006region\030\002 \001(\0132\031.hbase.pb.RegionSp" +
      "ecifier\"\031\n\027CleanupBulkLoadResponse\"a\n\026Co" +
      "processorServiceCall\022\013\n\003row\030\001 \002(\014\022\024\n\014ser" +
      "vice_name\030\002 \002(\t\022\023\n\013method_name\030\003 \002(\t\022\017\n\007" +
      "request\030\004 \002(\014\"B\n\030CoprocessorServiceResul" +
      "t\022&\n\005value\030\001 \001(\0132\027.hbase.pb.NameBytesPai" +
      "r\"v\n\031CoprocessorServiceRequest\022)\n\006region" +
      "\030\001 \002(\0132\031.hbase.pb.RegionSpecifier\022.\n\004cal" +
      "l\030\002 \002(\0132 .hbase.pb.CoprocessorServiceCal" +
      "l\"o\n\032CoprocessorServiceResponse\022)\n\006regio" +
      "n\030\001 \002(\0132\031.hbase.pb.RegionSpecifier\022&\n\005va" +
      "lue\030\002 \002(\0132\027.hbase.pb.NameBytesPair\"\226\001\n\006A" +
      "ction\022\r\n\005index\030\001 \001(\r\022)\n\010mutation\030\002 \001(\0132\027" +
      ".hbase.pb.MutationProto\022\032\n\003get\030\003 \001(\0132\r.h" +
      "base.pb.Get\0226\n\014service_call\030\004 \001(\0132 .hbas" +
      "e.pb.CoprocessorServiceCall\"\223\001\n\014RegionAc" +
      "tion\022)\n\006region\030\001 \002(\0132\031.hbase.pb.RegionSp" +
      "ecifier\022\016\n\006atomic\030\002 \001(\010\022 \n\006action\030\003 \003(\0132" +
      "\020.hbase.pb.Action\022&\n\tcondition\030\004 \001(\0132\023.h" +
      "base.pb.Condition\"c\n\017RegionLoadStats\022\027\n\014" +
      "memStoreLoad\030\001 \001(\005:\0010\022\030\n\rheapOccupancy\030\002" +
      " \001(\005:\0010\022\035\n\022compactionPressure\030\003 \001(\005:\0010\"j" +
      "\n\024MultiRegionLoadStats\022)\n\006region\030\001 \003(\0132\031" +
      ".hbase.pb.RegionSpecifier\022\'\n\004stat\030\002 \003(\0132" +
      "\031.hbase.pb.RegionLoadStats\"\336\001\n\021ResultOrE" +
      "xception\022\r\n\005index\030\001 \001(\r\022 \n\006result\030\002 \001(\0132" +
      "\020.hbase.pb.Result\022*\n\texception\030\003 \001(\0132\027.h" +
      "base.pb.NameBytesPair\022:\n\016service_result\030" +
      "\004 \001(\0132\".hbase.pb.CoprocessorServiceResul" +
      "t\0220\n\tloadStats\030\005 \001(\0132\031.hbase.pb.RegionLo" +
      "adStatsB\002\030\001\"\213\001\n\022RegionActionResult\0226\n\021re" +
      "sultOrException\030\001 \003(\0132\033.hbase.pb.ResultO" +
      "rException\022*\n\texception\030\002 \001(\0132\027.hbase.pb" +
      ".NameBytesPair\022\021\n\tprocessed\030\003 \001(\010\"|\n\014Mul" +
      "tiRequest\022,\n\014regionAction\030\001 \003(\0132\026.hbase." +
      "pb.RegionAction\022\022\n\nnonceGroup\030\002 \001(\004\022*\n\tc" +
      "ondition\030\003 \001(\0132\023.hbase.pb.ConditionB\002\030\001\"" +
      "\232\001\n\rMultiResponse\0228\n\022regionActionResult\030" +
      "\001 \003(\0132\034.hbase.pb.RegionActionResult\022\025\n\tp" +
      "rocessed\030\002 \001(\010B\002\030\001\0228\n\020regionStatistics\030\003" +
      " \001(\0132\036.hbase.pb.MultiRegionLoadStats*\'\n\013" +
      "Consistency\022\n\n\006STRONG\020\000\022\014\n\010TIMELINE\020\0012\263\005" +
      "\n\rClientService\0222\n\003Get\022\024.hbase.pb.GetReq" +
      "uest\032\025.hbase.pb.GetResponse\022;\n\006Mutate\022\027." +
      "hbase.pb.MutateRequest\032\030.hbase.pb.Mutate" +
      "Response\0225\n\004Scan\022\025.hbase.pb.ScanRequest\032" +
      "\026.hbase.pb.ScanResponse\022P\n\rBulkLoadHFile" +
      "\022\036.hbase.pb.BulkLoadHFileRequest\032\037.hbase" +
      ".pb.BulkLoadHFileResponse\022V\n\017PrepareBulk" +
      "Load\022 .hbase.pb.PrepareBulkLoadRequest\032!" +
      ".hbase.pb.PrepareBulkLoadResponse\022V\n\017Cle" +
      "anupBulkLoad\022 .hbase.pb.CleanupBulkLoadR" +
      "equest\032!.hbase.pb.CleanupBulkLoadRespons" +
      "e\022X\n\013ExecService\022#.hbase.pb.CoprocessorS" +
      "erviceRequest\032$.hbase.pb.CoprocessorServ" +
      "iceResponse\022d\n\027ExecRegionServerService\022#" +
      ".hbase.pb.CoprocessorServiceRequest\032$.hb" +
      "ase.pb.CoprocessorServiceResponse\0228\n\005Mul" +
      "ti\022\026.hbase.pb.MultiRequest\032\027.hbase.pb.Mu" +
      "ltiResponseBI\n1org.apache.hadoop.hbase.s" +
      "haded.protobuf.generatedB\014ClientProtosH\001" +
      "\210\001\001\240\001\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.getDescriptor(),
        });
    internal_static_hbase_pb_Authorizations_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_Authorizations_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Authorizations_descriptor,
        new java.lang.String[] { "Label", });
    internal_static_hbase_pb_CellVisibility_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_CellVisibility_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CellVisibility_descriptor,
        new java.lang.String[] { "Expression", });
    internal_static_hbase_pb_Column_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_Column_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Column_descriptor,
        new java.lang.String[] { "Family", "Qualifier", });
    internal_static_hbase_pb_Get_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_Get_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Get_descriptor,
        new java.lang.String[] { "Row", "Column", "Attribute", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "StoreLimit", "StoreOffset", "ExistenceOnly", "ClosestRowBefore", "Consistency", "CfTimeRange", "LoadColumnFamiliesOnDemand", });
    internal_static_hbase_pb_Result_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_Result_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Result_descriptor,
        new java.lang.String[] { "Cell", "AssociatedCellCount", "Exists", "Stale", "Partial", });
    internal_static_hbase_pb_GetRequest_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_GetRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetRequest_descriptor,
        new java.lang.String[] { "Region", "Get", });
    internal_static_hbase_pb_GetResponse_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_GetResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetResponse_descriptor,
        new java.lang.String[] { "Result", });
    internal_static_hbase_pb_Condition_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_Condition_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Condition_descriptor,
        new java.lang.String[] { "Row", "Family", "Qualifier", "CompareType", "Comparator", "TimeRange", "Filter", });
    internal_static_hbase_pb_MutationProto_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_MutationProto_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MutationProto_descriptor,
        new java.lang.String[] { "Row", "MutateType", "ColumnValue", "Timestamp", "Attribute", "Durability", "TimeRange", "AssociatedCellCount", "Nonce", });
    internal_static_hbase_pb_MutationProto_ColumnValue_descriptor =
      internal_static_hbase_pb_MutationProto_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_MutationProto_ColumnValue_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MutationProto_ColumnValue_descriptor,
        new java.lang.String[] { "Family", "QualifierValue", });
    internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor =
      internal_static_hbase_pb_MutationProto_ColumnValue_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MutationProto_ColumnValue_QualifierValue_descriptor,
        new java.lang.String[] { "Qualifier", "Value", "Timestamp", "DeleteType", "Tags", });
    internal_static_hbase_pb_MutateRequest_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_MutateRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MutateRequest_descriptor,
        new java.lang.String[] { "Region", "Mutation", "Condition", "NonceGroup", });
    internal_static_hbase_pb_MutateResponse_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_MutateResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MutateResponse_descriptor,
        new java.lang.String[] { "Result", "Processed", });
    internal_static_hbase_pb_Scan_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_Scan_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Scan_descriptor,
        new java.lang.String[] { "Column", "Attribute", "StartRow", "StopRow", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "BatchSize", "MaxResultSize", "StoreLimit", "StoreOffset", "LoadColumnFamiliesOnDemand", "Small", "Reversed", "Consistency", "Caching", "AllowPartialResults", "CfTimeRange", "MvccReadPoint", "IncludeStartRow", "IncludeStopRow", "ReadType", "NeedCursorResult", });
    internal_static_hbase_pb_ScanRequest_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_ScanRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ScanRequest_descriptor,
        new java.lang.String[] { "Region", "Scan", "ScannerId", "NumberOfRows", "CloseScanner", "NextCallSeq", "ClientHandlesPartials", "ClientHandlesHeartbeats", "TrackScanMetrics", "Renew", "LimitOfRows", });
    internal_static_hbase_pb_Cursor_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hbase_pb_Cursor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Cursor_descriptor,
        new java.lang.String[] { "Row", });
    internal_static_hbase_pb_ScanResponse_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hbase_pb_ScanResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ScanResponse_descriptor,
        new java.lang.String[] { "CellsPerResult", "ScannerId", "MoreResults", "Ttl", "Results", "Stale", "PartialFlagPerResult", "MoreResultsInRegion", "HeartbeatMessage", "ScanMetrics", "MvccReadPoint", "Cursor", });
    internal_static_hbase_pb_BulkLoadHFileRequest_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hbase_pb_BulkLoadHFileRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BulkLoadHFileRequest_descriptor,
        new java.lang.String[] { "Region", "FamilyPath", "AssignSeqNum", "FsToken", "BulkToken", "CopyFile", "ClusterIds", "Replicate", });
    internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor =
      internal_static_hbase_pb_BulkLoadHFileRequest_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BulkLoadHFileRequest_FamilyPath_descriptor,
        new java.lang.String[] { "Family", "Path", });
    internal_static_hbase_pb_BulkLoadHFileResponse_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hbase_pb_BulkLoadHFileResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BulkLoadHFileResponse_descriptor,
        new java.lang.String[] { "Loaded", });
    internal_static_hbase_pb_DelegationToken_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hbase_pb_DelegationToken_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DelegationToken_descriptor,
        new java.lang.String[] { "Identifier", "Password", "Kind", "Service", });
    internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hbase_pb_PrepareBulkLoadRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PrepareBulkLoadRequest_descriptor,
        new java.lang.String[] { "TableName", "Region", });
    internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hbase_pb_PrepareBulkLoadResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PrepareBulkLoadResponse_descriptor,
        new java.lang.String[] { "BulkToken", });
    internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hbase_pb_CleanupBulkLoadRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CleanupBulkLoadRequest_descriptor,
        new java.lang.String[] { "BulkToken", "Region", });
    internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hbase_pb_CleanupBulkLoadResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CleanupBulkLoadResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_CoprocessorServiceCall_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hbase_pb_CoprocessorServiceCall_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CoprocessorServiceCall_descriptor,
        new java.lang.String[] { "Row", "ServiceName", "MethodName", "Request", });
    internal_static_hbase_pb_CoprocessorServiceResult_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hbase_pb_CoprocessorServiceResult_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CoprocessorServiceResult_descriptor,
        new java.lang.String[] { "Value", });
    internal_static_hbase_pb_CoprocessorServiceRequest_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hbase_pb_CoprocessorServiceRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CoprocessorServiceRequest_descriptor,
        new java.lang.String[] { "Region", "Call", });
    internal_static_hbase_pb_CoprocessorServiceResponse_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hbase_pb_CoprocessorServiceResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CoprocessorServiceResponse_descriptor,
        new java.lang.String[] { "Region", "Value", });
    internal_static_hbase_pb_Action_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hbase_pb_Action_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Action_descriptor,
        new java.lang.String[] { "Index", "Mutation", "Get", "ServiceCall", });
    internal_static_hbase_pb_RegionAction_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hbase_pb_RegionAction_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionAction_descriptor,
        new java.lang.String[] { "Region", "Atomic", "Action", "Condition", });
    internal_static_hbase_pb_RegionLoadStats_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hbase_pb_RegionLoadStats_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionLoadStats_descriptor,
        new java.lang.String[] { "MemStoreLoad", "HeapOccupancy", "CompactionPressure", });
    internal_static_hbase_pb_MultiRegionLoadStats_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hbase_pb_MultiRegionLoadStats_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MultiRegionLoadStats_descriptor,
        new java.lang.String[] { "Region", "Stat", });
    internal_static_hbase_pb_ResultOrException_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hbase_pb_ResultOrException_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ResultOrException_descriptor,
        new java.lang.String[] { "Index", "Result", "Exception", "ServiceResult", "LoadStats", });
    internal_static_hbase_pb_RegionActionResult_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hbase_pb_RegionActionResult_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionActionResult_descriptor,
        new java.lang.String[] { "ResultOrException", "Exception", "Processed", });
    internal_static_hbase_pb_MultiRequest_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hbase_pb_MultiRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MultiRequest_descriptor,
        new java.lang.String[] { "RegionAction", "NonceGroup", "Condition", });
    internal_static_hbase_pb_MultiResponse_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hbase_pb_MultiResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MultiResponse_descriptor,
        new java.lang.String[] { "RegionActionResult", "Processed", "RegionStatistics", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.CellProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.MapReduceProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
