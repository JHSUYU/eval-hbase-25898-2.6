// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Filter.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class FilterProtos {
  private FilterProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface FilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Filter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string name = 1;</code>
     * @return Whether the name field is set.
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     * @return The bytes for name.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <code>optional bytes serialized_filter = 2;</code>
     * @return Whether the serializedFilter field is set.
     */
    boolean hasSerializedFilter();
    /**
     * <code>optional bytes serialized_filter = 2;</code>
     * @return The serializedFilter.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSerializedFilter();
  }
  /**
   * Protobuf type {@code hbase.pb.Filter}
   */
  @javax.annotation.Generated("proto") public static final class Filter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Filter)
      FilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Filter.newBuilder() to construct.
    private Filter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Filter() {
      name_ = "";
      serializedFilter_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Filter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_Filter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_Filter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder.class);
    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object name_ = "";
    /**
     * <code>required string name = 1;</code>
     * @return Whether the name field is set.
     */
    @java.lang.Override
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string name = 1;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SERIALIZED_FILTER_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString serializedFilter_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes serialized_filter = 2;</code>
     * @return Whether the serializedFilter field is set.
     */
    @java.lang.Override
    public boolean hasSerializedFilter() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes serialized_filter = 2;</code>
     * @return The serializedFilter.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSerializedFilter() {
      return serializedFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, serializedFilter_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, serializedFilter_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter) obj;

      if (hasName() != other.hasName()) return false;
      if (hasName()) {
        if (!getName()
            .equals(other.getName())) return false;
      }
      if (hasSerializedFilter() != other.hasSerializedFilter()) return false;
      if (hasSerializedFilter()) {
        if (!getSerializedFilter()
            .equals(other.getSerializedFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasSerializedFilter()) {
        hash = (37 * hash) + SERIALIZED_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getSerializedFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Filter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Filter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_Filter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_Filter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        name_ = "";
        serializedFilter_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_Filter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.name_ = name_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.serializedFilter_ = serializedFilter_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) return this;
        if (other.hasName()) {
          name_ = other.name_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasSerializedFilter()) {
          setSerializedFilter(other.getSerializedFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasName()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                name_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                serializedFilter_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       * @return Whether the name field is set.
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            name_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       * @return The bytes for name.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        name_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        name_ = getDefaultInstance().getName();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        name_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString serializedFilter_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes serialized_filter = 2;</code>
       * @return Whether the serializedFilter field is set.
       */
      @java.lang.Override
      public boolean hasSerializedFilter() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes serialized_filter = 2;</code>
       * @return The serializedFilter.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSerializedFilter() {
        return serializedFilter_;
      }
      /**
       * <code>optional bytes serialized_filter = 2;</code>
       * @param value The serializedFilter to set.
       * @return This builder for chaining.
       */
      public Builder setSerializedFilter(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        serializedFilter_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes serialized_filter = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearSerializedFilter() {
        bitField0_ = (bitField0_ & ~0x00000002);
        serializedFilter_ = getDefaultInstance().getSerializedFilter();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Filter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Filter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Filter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Filter>() {
      @java.lang.Override
      public Filter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Filter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Filter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnCountGetFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ColumnCountGetFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int32 limit = 1;</code>
     * @return Whether the limit field is set.
     */
    boolean hasLimit();
    /**
     * <code>required int32 limit = 1;</code>
     * @return The limit.
     */
    int getLimit();
  }
  /**
   * Protobuf type {@code hbase.pb.ColumnCountGetFilter}
   */
  @javax.annotation.Generated("proto") public static final class ColumnCountGetFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ColumnCountGetFilter)
      ColumnCountGetFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ColumnCountGetFilter.newBuilder() to construct.
    private ColumnCountGetFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ColumnCountGetFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ColumnCountGetFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnCountGetFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnCountGetFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.Builder.class);
    }

    private int bitField0_;
    public static final int LIMIT_FIELD_NUMBER = 1;
    private int limit_ = 0;
    /**
     * <code>required int32 limit = 1;</code>
     * @return Whether the limit field is set.
     */
    @java.lang.Override
    public boolean hasLimit() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required int32 limit = 1;</code>
     * @return The limit.
     */
    @java.lang.Override
    public int getLimit() {
      return limit_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasLimit()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, limit_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, limit_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter) obj;

      if (hasLimit() != other.hasLimit()) return false;
      if (hasLimit()) {
        if (getLimit()
            != other.getLimit()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLimit()) {
        hash = (37 * hash) + LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getLimit();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ColumnCountGetFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ColumnCountGetFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnCountGetFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnCountGetFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        limit_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnCountGetFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.limit_ = limit_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter.getDefaultInstance()) return this;
        if (other.hasLimit()) {
          setLimit(other.getLimit());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasLimit()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                limit_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int limit_ ;
      /**
       * <code>required int32 limit = 1;</code>
       * @return Whether the limit field is set.
       */
      @java.lang.Override
      public boolean hasLimit() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @return The limit.
       */
      @java.lang.Override
      public int getLimit() {
        return limit_;
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @param value The limit to set.
       * @return This builder for chaining.
       */
      public Builder setLimit(int value) {

        limit_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLimit() {
        bitField0_ = (bitField0_ & ~0x00000001);
        limit_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ColumnCountGetFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ColumnCountGetFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnCountGetFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnCountGetFilter>() {
      @java.lang.Override
      public ColumnCountGetFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnCountGetFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnCountGetFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnCountGetFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnPaginationFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ColumnPaginationFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int32 limit = 1;</code>
     * @return Whether the limit field is set.
     */
    boolean hasLimit();
    /**
     * <code>required int32 limit = 1;</code>
     * @return The limit.
     */
    int getLimit();

    /**
     * <code>optional int32 offset = 2;</code>
     * @return Whether the offset field is set.
     */
    boolean hasOffset();
    /**
     * <code>optional int32 offset = 2;</code>
     * @return The offset.
     */
    int getOffset();

    /**
     * <code>optional bytes column_offset = 3;</code>
     * @return Whether the columnOffset field is set.
     */
    boolean hasColumnOffset();
    /**
     * <code>optional bytes column_offset = 3;</code>
     * @return The columnOffset.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnOffset();
  }
  /**
   * Protobuf type {@code hbase.pb.ColumnPaginationFilter}
   */
  @javax.annotation.Generated("proto") public static final class ColumnPaginationFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ColumnPaginationFilter)
      ColumnPaginationFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ColumnPaginationFilter.newBuilder() to construct.
    private ColumnPaginationFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ColumnPaginationFilter() {
      columnOffset_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ColumnPaginationFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPaginationFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPaginationFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.Builder.class);
    }

    private int bitField0_;
    public static final int LIMIT_FIELD_NUMBER = 1;
    private int limit_ = 0;
    /**
     * <code>required int32 limit = 1;</code>
     * @return Whether the limit field is set.
     */
    @java.lang.Override
    public boolean hasLimit() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required int32 limit = 1;</code>
     * @return The limit.
     */
    @java.lang.Override
    public int getLimit() {
      return limit_;
    }

    public static final int OFFSET_FIELD_NUMBER = 2;
    private int offset_ = 0;
    /**
     * <code>optional int32 offset = 2;</code>
     * @return Whether the offset field is set.
     */
    @java.lang.Override
    public boolean hasOffset() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional int32 offset = 2;</code>
     * @return The offset.
     */
    @java.lang.Override
    public int getOffset() {
      return offset_;
    }

    public static final int COLUMN_OFFSET_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnOffset_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes column_offset = 3;</code>
     * @return Whether the columnOffset field is set.
     */
    @java.lang.Override
    public boolean hasColumnOffset() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes column_offset = 3;</code>
     * @return The columnOffset.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnOffset() {
      return columnOffset_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasLimit()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(1, limit_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(2, offset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, columnOffset_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, limit_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, offset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, columnOffset_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter) obj;

      if (hasLimit() != other.hasLimit()) return false;
      if (hasLimit()) {
        if (getLimit()
            != other.getLimit()) return false;
      }
      if (hasOffset() != other.hasOffset()) return false;
      if (hasOffset()) {
        if (getOffset()
            != other.getOffset()) return false;
      }
      if (hasColumnOffset() != other.hasColumnOffset()) return false;
      if (hasColumnOffset()) {
        if (!getColumnOffset()
            .equals(other.getColumnOffset())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLimit()) {
        hash = (37 * hash) + LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getLimit();
      }
      if (hasOffset()) {
        hash = (37 * hash) + OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getOffset();
      }
      if (hasColumnOffset()) {
        hash = (37 * hash) + COLUMN_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getColumnOffset().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ColumnPaginationFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ColumnPaginationFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPaginationFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPaginationFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        limit_ = 0;
        offset_ = 0;
        columnOffset_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPaginationFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.limit_ = limit_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.offset_ = offset_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.columnOffset_ = columnOffset_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter.getDefaultInstance()) return this;
        if (other.hasLimit()) {
          setLimit(other.getLimit());
        }
        if (other.hasOffset()) {
          setOffset(other.getOffset());
        }
        if (other.hasColumnOffset()) {
          setColumnOffset(other.getColumnOffset());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasLimit()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                limit_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                offset_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                columnOffset_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int limit_ ;
      /**
       * <code>required int32 limit = 1;</code>
       * @return Whether the limit field is set.
       */
      @java.lang.Override
      public boolean hasLimit() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @return The limit.
       */
      @java.lang.Override
      public int getLimit() {
        return limit_;
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @param value The limit to set.
       * @return This builder for chaining.
       */
      public Builder setLimit(int value) {

        limit_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required int32 limit = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLimit() {
        bitField0_ = (bitField0_ & ~0x00000001);
        limit_ = 0;
        onChanged();
        return this;
      }

      private int offset_ ;
      /**
       * <code>optional int32 offset = 2;</code>
       * @return Whether the offset field is set.
       */
      @java.lang.Override
      public boolean hasOffset() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int32 offset = 2;</code>
       * @return The offset.
       */
      @java.lang.Override
      public int getOffset() {
        return offset_;
      }
      /**
       * <code>optional int32 offset = 2;</code>
       * @param value The offset to set.
       * @return This builder for chaining.
       */
      public Builder setOffset(int value) {

        offset_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 offset = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearOffset() {
        bitField0_ = (bitField0_ & ~0x00000002);
        offset_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnOffset_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes column_offset = 3;</code>
       * @return Whether the columnOffset field is set.
       */
      @java.lang.Override
      public boolean hasColumnOffset() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes column_offset = 3;</code>
       * @return The columnOffset.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnOffset() {
        return columnOffset_;
      }
      /**
       * <code>optional bytes column_offset = 3;</code>
       * @param value The columnOffset to set.
       * @return This builder for chaining.
       */
      public Builder setColumnOffset(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        columnOffset_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes column_offset = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnOffset() {
        bitField0_ = (bitField0_ & ~0x00000004);
        columnOffset_ = getDefaultInstance().getColumnOffset();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ColumnPaginationFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ColumnPaginationFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPaginationFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnPaginationFilter>() {
      @java.lang.Override
      public ColumnPaginationFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPaginationFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPaginationFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPaginationFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnPrefixFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ColumnPrefixFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes prefix = 1;</code>
     * @return Whether the prefix field is set.
     */
    boolean hasPrefix();
    /**
     * <code>required bytes prefix = 1;</code>
     * @return The prefix.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix();
  }
  /**
   * Protobuf type {@code hbase.pb.ColumnPrefixFilter}
   */
  @javax.annotation.Generated("proto") public static final class ColumnPrefixFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ColumnPrefixFilter)
      ColumnPrefixFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ColumnPrefixFilter.newBuilder() to construct.
    private ColumnPrefixFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ColumnPrefixFilter() {
      prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ColumnPrefixFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPrefixFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPrefixFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.Builder.class);
    }

    private int bitField0_;
    public static final int PREFIX_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes prefix = 1;</code>
     * @return Whether the prefix field is set.
     */
    @java.lang.Override
    public boolean hasPrefix() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes prefix = 1;</code>
     * @return The prefix.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix() {
      return prefix_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPrefix()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, prefix_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, prefix_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter) obj;

      if (hasPrefix() != other.hasPrefix()) return false;
      if (hasPrefix()) {
        if (!getPrefix()
            .equals(other.getPrefix())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPrefix()) {
        hash = (37 * hash) + PREFIX_FIELD_NUMBER;
        hash = (53 * hash) + getPrefix().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ColumnPrefixFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ColumnPrefixFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPrefixFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPrefixFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnPrefixFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.prefix_ = prefix_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter.getDefaultInstance()) return this;
        if (other.hasPrefix()) {
          setPrefix(other.getPrefix());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPrefix()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                prefix_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes prefix = 1;</code>
       * @return Whether the prefix field is set.
       */
      @java.lang.Override
      public boolean hasPrefix() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes prefix = 1;</code>
       * @return The prefix.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix() {
        return prefix_;
      }
      /**
       * <code>required bytes prefix = 1;</code>
       * @param value The prefix to set.
       * @return This builder for chaining.
       */
      public Builder setPrefix(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        prefix_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes prefix = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPrefix() {
        bitField0_ = (bitField0_ & ~0x00000001);
        prefix_ = getDefaultInstance().getPrefix();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ColumnPrefixFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ColumnPrefixFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPrefixFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnPrefixFilter>() {
      @java.lang.Override
      public ColumnPrefixFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPrefixFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnPrefixFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnPrefixFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnRangeFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ColumnRangeFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes min_column = 1;</code>
     * @return Whether the minColumn field is set.
     */
    boolean hasMinColumn();
    /**
     * <code>optional bytes min_column = 1;</code>
     * @return The minColumn.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMinColumn();

    /**
     * <code>optional bool min_column_inclusive = 2;</code>
     * @return Whether the minColumnInclusive field is set.
     */
    boolean hasMinColumnInclusive();
    /**
     * <code>optional bool min_column_inclusive = 2;</code>
     * @return The minColumnInclusive.
     */
    boolean getMinColumnInclusive();

    /**
     * <code>optional bytes max_column = 3;</code>
     * @return Whether the maxColumn field is set.
     */
    boolean hasMaxColumn();
    /**
     * <code>optional bytes max_column = 3;</code>
     * @return The maxColumn.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMaxColumn();

    /**
     * <code>optional bool max_column_inclusive = 4;</code>
     * @return Whether the maxColumnInclusive field is set.
     */
    boolean hasMaxColumnInclusive();
    /**
     * <code>optional bool max_column_inclusive = 4;</code>
     * @return The maxColumnInclusive.
     */
    boolean getMaxColumnInclusive();
  }
  /**
   * Protobuf type {@code hbase.pb.ColumnRangeFilter}
   */
  @javax.annotation.Generated("proto") public static final class ColumnRangeFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ColumnRangeFilter)
      ColumnRangeFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ColumnRangeFilter.newBuilder() to construct.
    private ColumnRangeFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ColumnRangeFilter() {
      minColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      maxColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ColumnRangeFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnRangeFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnRangeFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.Builder.class);
    }

    private int bitField0_;
    public static final int MIN_COLUMN_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString minColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes min_column = 1;</code>
     * @return Whether the minColumn field is set.
     */
    @java.lang.Override
    public boolean hasMinColumn() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes min_column = 1;</code>
     * @return The minColumn.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMinColumn() {
      return minColumn_;
    }

    public static final int MIN_COLUMN_INCLUSIVE_FIELD_NUMBER = 2;
    private boolean minColumnInclusive_ = false;
    /**
     * <code>optional bool min_column_inclusive = 2;</code>
     * @return Whether the minColumnInclusive field is set.
     */
    @java.lang.Override
    public boolean hasMinColumnInclusive() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool min_column_inclusive = 2;</code>
     * @return The minColumnInclusive.
     */
    @java.lang.Override
    public boolean getMinColumnInclusive() {
      return minColumnInclusive_;
    }

    public static final int MAX_COLUMN_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString maxColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes max_column = 3;</code>
     * @return Whether the maxColumn field is set.
     */
    @java.lang.Override
    public boolean hasMaxColumn() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes max_column = 3;</code>
     * @return The maxColumn.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMaxColumn() {
      return maxColumn_;
    }

    public static final int MAX_COLUMN_INCLUSIVE_FIELD_NUMBER = 4;
    private boolean maxColumnInclusive_ = false;
    /**
     * <code>optional bool max_column_inclusive = 4;</code>
     * @return Whether the maxColumnInclusive field is set.
     */
    @java.lang.Override
    public boolean hasMaxColumnInclusive() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool max_column_inclusive = 4;</code>
     * @return The maxColumnInclusive.
     */
    @java.lang.Override
    public boolean getMaxColumnInclusive() {
      return maxColumnInclusive_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, minColumn_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, minColumnInclusive_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, maxColumn_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(4, maxColumnInclusive_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, minColumn_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, minColumnInclusive_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, maxColumn_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, maxColumnInclusive_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter) obj;

      if (hasMinColumn() != other.hasMinColumn()) return false;
      if (hasMinColumn()) {
        if (!getMinColumn()
            .equals(other.getMinColumn())) return false;
      }
      if (hasMinColumnInclusive() != other.hasMinColumnInclusive()) return false;
      if (hasMinColumnInclusive()) {
        if (getMinColumnInclusive()
            != other.getMinColumnInclusive()) return false;
      }
      if (hasMaxColumn() != other.hasMaxColumn()) return false;
      if (hasMaxColumn()) {
        if (!getMaxColumn()
            .equals(other.getMaxColumn())) return false;
      }
      if (hasMaxColumnInclusive() != other.hasMaxColumnInclusive()) return false;
      if (hasMaxColumnInclusive()) {
        if (getMaxColumnInclusive()
            != other.getMaxColumnInclusive()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMinColumn()) {
        hash = (37 * hash) + MIN_COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getMinColumn().hashCode();
      }
      if (hasMinColumnInclusive()) {
        hash = (37 * hash) + MIN_COLUMN_INCLUSIVE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMinColumnInclusive());
      }
      if (hasMaxColumn()) {
        hash = (37 * hash) + MAX_COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getMaxColumn().hashCode();
      }
      if (hasMaxColumnInclusive()) {
        hash = (37 * hash) + MAX_COLUMN_INCLUSIVE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMaxColumnInclusive());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ColumnRangeFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ColumnRangeFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnRangeFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnRangeFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        minColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        minColumnInclusive_ = false;
        maxColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        maxColumnInclusive_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnRangeFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.minColumn_ = minColumn_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.minColumnInclusive_ = minColumnInclusive_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.maxColumn_ = maxColumn_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.maxColumnInclusive_ = maxColumnInclusive_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter.getDefaultInstance()) return this;
        if (other.hasMinColumn()) {
          setMinColumn(other.getMinColumn());
        }
        if (other.hasMinColumnInclusive()) {
          setMinColumnInclusive(other.getMinColumnInclusive());
        }
        if (other.hasMaxColumn()) {
          setMaxColumn(other.getMaxColumn());
        }
        if (other.hasMaxColumnInclusive()) {
          setMaxColumnInclusive(other.getMaxColumnInclusive());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                minColumn_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                minColumnInclusive_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                maxColumn_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                maxColumnInclusive_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString minColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes min_column = 1;</code>
       * @return Whether the minColumn field is set.
       */
      @java.lang.Override
      public boolean hasMinColumn() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes min_column = 1;</code>
       * @return The minColumn.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMinColumn() {
        return minColumn_;
      }
      /**
       * <code>optional bytes min_column = 1;</code>
       * @param value The minColumn to set.
       * @return This builder for chaining.
       */
      public Builder setMinColumn(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        minColumn_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes min_column = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearMinColumn() {
        bitField0_ = (bitField0_ & ~0x00000001);
        minColumn_ = getDefaultInstance().getMinColumn();
        onChanged();
        return this;
      }

      private boolean minColumnInclusive_ ;
      /**
       * <code>optional bool min_column_inclusive = 2;</code>
       * @return Whether the minColumnInclusive field is set.
       */
      @java.lang.Override
      public boolean hasMinColumnInclusive() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool min_column_inclusive = 2;</code>
       * @return The minColumnInclusive.
       */
      @java.lang.Override
      public boolean getMinColumnInclusive() {
        return minColumnInclusive_;
      }
      /**
       * <code>optional bool min_column_inclusive = 2;</code>
       * @param value The minColumnInclusive to set.
       * @return This builder for chaining.
       */
      public Builder setMinColumnInclusive(boolean value) {

        minColumnInclusive_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool min_column_inclusive = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearMinColumnInclusive() {
        bitField0_ = (bitField0_ & ~0x00000002);
        minColumnInclusive_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString maxColumn_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes max_column = 3;</code>
       * @return Whether the maxColumn field is set.
       */
      @java.lang.Override
      public boolean hasMaxColumn() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes max_column = 3;</code>
       * @return The maxColumn.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getMaxColumn() {
        return maxColumn_;
      }
      /**
       * <code>optional bytes max_column = 3;</code>
       * @param value The maxColumn to set.
       * @return This builder for chaining.
       */
      public Builder setMaxColumn(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        maxColumn_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes max_column = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxColumn() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maxColumn_ = getDefaultInstance().getMaxColumn();
        onChanged();
        return this;
      }

      private boolean maxColumnInclusive_ ;
      /**
       * <code>optional bool max_column_inclusive = 4;</code>
       * @return Whether the maxColumnInclusive field is set.
       */
      @java.lang.Override
      public boolean hasMaxColumnInclusive() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool max_column_inclusive = 4;</code>
       * @return The maxColumnInclusive.
       */
      @java.lang.Override
      public boolean getMaxColumnInclusive() {
        return maxColumnInclusive_;
      }
      /**
       * <code>optional bool max_column_inclusive = 4;</code>
       * @param value The maxColumnInclusive to set.
       * @return This builder for chaining.
       */
      public Builder setMaxColumnInclusive(boolean value) {

        maxColumnInclusive_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool max_column_inclusive = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxColumnInclusive() {
        bitField0_ = (bitField0_ & ~0x00000008);
        maxColumnInclusive_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ColumnRangeFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ColumnRangeFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnRangeFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnRangeFilter>() {
      @java.lang.Override
      public ColumnRangeFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnRangeFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnRangeFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnRangeFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompareFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompareFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareType compare_op = 1;</code>
     * @return Whether the compareOp field is set.
     */
    boolean hasCompareOp();
    /**
     * <code>required .hbase.pb.CompareType compare_op = 1;</code>
     * @return The compareOp.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp();

    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     * @return Whether the comparator field is set.
     */
    boolean hasComparator();
    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     * @return The comparator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator();
    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CompareFilter}
   */
  @javax.annotation.Generated("proto") public static final class CompareFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompareFilter)
      CompareFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompareFilter.newBuilder() to construct.
    private CompareFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompareFilter() {
      compareOp_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompareFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_CompareFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_CompareFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_OP_FIELD_NUMBER = 1;
    private int compareOp_ = 0;
    /**
     * <code>required .hbase.pb.CompareType compare_op = 1;</code>
     * @return Whether the compareOp field is set.
     */
    @java.lang.Override public boolean hasCompareOp() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareType compare_op = 1;</code>
     * @return The compareOp.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
    }

    public static final int COMPARATOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     * @return Whether the comparator field is set.
     */
    @java.lang.Override
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     * @return The comparator.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }
    /**
     * <code>optional .hbase.pb.Comparator comparator = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareOp()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasComparator()) {
        if (!getComparator().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, compareOp_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getComparator());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compareOp_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getComparator());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter) obj;

      if (hasCompareOp() != other.hasCompareOp()) return false;
      if (hasCompareOp()) {
        if (compareOp_ != other.compareOp_) return false;
      }
      if (hasComparator() != other.hasComparator()) return false;
      if (hasComparator()) {
        if (!getComparator()
            .equals(other.getComparator())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareOp()) {
        hash = (37 * hash) + COMPARE_OP_FIELD_NUMBER;
        hash = (53 * hash) + compareOp_;
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CompareFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompareFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_CompareFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_CompareFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareOp_ = 0;
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_CompareFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareOp_ = compareOp_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.comparator_ = comparatorBuilder_ == null
              ? comparator_
              : comparatorBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) return this;
        if (other.hasCompareOp()) {
          setCompareOp(other.getCompareOp());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareOp()) {
          return false;
        }
        if (hasComparator()) {
          if (!getComparator().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  compareOp_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                input.readMessage(
                    getComparatorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int compareOp_ = 0;
      /**
       * <code>required .hbase.pb.CompareType compare_op = 1;</code>
       * @return Whether the compareOp field is set.
       */
      @java.lang.Override public boolean hasCompareOp() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 1;</code>
       * @return The compareOp.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 1;</code>
       * @param value The compareOp to set.
       * @return This builder for chaining.
       */
      public Builder setCompareOp(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        compareOp_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompareOp() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareOp_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       * @return Whether the comparator field is set.
       */
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       * @return The comparator.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public Builder setComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public Builder setComparator(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public Builder mergeComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            comparator_ != null &&
            comparator_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            getComparatorBuilder().mergeFrom(value);
          } else {
            comparator_ = value;
          }
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        if (comparator_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public Builder clearComparator() {
        bitField0_ = (bitField0_ & ~0x00000002);
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        }
      }
      /**
       * <code>optional .hbase.pb.Comparator comparator = 2;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  getComparator(),
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompareFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompareFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompareFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompareFilter>() {
      @java.lang.Override
      public CompareFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompareFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompareFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DependentColumnFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DependentColumnFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    boolean hasCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder();

    /**
     * <code>optional bytes column_family = 2;</code>
     * @return Whether the columnFamily field is set.
     */
    boolean hasColumnFamily();
    /**
     * <code>optional bytes column_family = 2;</code>
     * @return The columnFamily.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily();

    /**
     * <code>optional bytes column_qualifier = 3;</code>
     * @return Whether the columnQualifier field is set.
     */
    boolean hasColumnQualifier();
    /**
     * <code>optional bytes column_qualifier = 3;</code>
     * @return The columnQualifier.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier();

    /**
     * <code>optional bool drop_dependent_column = 4;</code>
     * @return Whether the dropDependentColumn field is set.
     */
    boolean hasDropDependentColumn();
    /**
     * <code>optional bool drop_dependent_column = 4;</code>
     * @return The dropDependentColumn.
     */
    boolean getDropDependentColumn();
  }
  /**
   * Protobuf type {@code hbase.pb.DependentColumnFilter}
   */
  @javax.annotation.Generated("proto") public static final class DependentColumnFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DependentColumnFilter)
      DependentColumnFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DependentColumnFilter.newBuilder() to construct.
    private DependentColumnFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DependentColumnFilter() {
      columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DependentColumnFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_DependentColumnFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_DependentColumnFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    @java.lang.Override
    public boolean hasCompareFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }

    public static final int COLUMN_FAMILY_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes column_family = 2;</code>
     * @return Whether the columnFamily field is set.
     */
    @java.lang.Override
    public boolean hasColumnFamily() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes column_family = 2;</code>
     * @return The columnFamily.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily() {
      return columnFamily_;
    }

    public static final int COLUMN_QUALIFIER_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes column_qualifier = 3;</code>
     * @return Whether the columnQualifier field is set.
     */
    @java.lang.Override
    public boolean hasColumnQualifier() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes column_qualifier = 3;</code>
     * @return The columnQualifier.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier() {
      return columnQualifier_;
    }

    public static final int DROP_DEPENDENT_COLUMN_FIELD_NUMBER = 4;
    private boolean dropDependentColumn_ = false;
    /**
     * <code>optional bool drop_dependent_column = 4;</code>
     * @return Whether the dropDependentColumn field is set.
     */
    @java.lang.Override
    public boolean hasDropDependentColumn() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool drop_dependent_column = 4;</code>
     * @return The dropDependentColumn.
     */
    @java.lang.Override
    public boolean getDropDependentColumn() {
      return dropDependentColumn_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCompareFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCompareFilter());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, columnFamily_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, columnQualifier_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(4, dropDependentColumn_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCompareFilter());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, columnFamily_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, columnQualifier_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, dropDependentColumn_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter) obj;

      if (hasCompareFilter() != other.hasCompareFilter()) return false;
      if (hasCompareFilter()) {
        if (!getCompareFilter()
            .equals(other.getCompareFilter())) return false;
      }
      if (hasColumnFamily() != other.hasColumnFamily()) return false;
      if (hasColumnFamily()) {
        if (!getColumnFamily()
            .equals(other.getColumnFamily())) return false;
      }
      if (hasColumnQualifier() != other.hasColumnQualifier()) return false;
      if (hasColumnQualifier()) {
        if (!getColumnQualifier()
            .equals(other.getColumnQualifier())) return false;
      }
      if (hasDropDependentColumn() != other.hasDropDependentColumn()) return false;
      if (hasDropDependentColumn()) {
        if (getDropDependentColumn()
            != other.getDropDependentColumn()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareFilter()) {
        hash = (37 * hash) + COMPARE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getCompareFilter().hashCode();
      }
      if (hasColumnFamily()) {
        hash = (37 * hash) + COLUMN_FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getColumnFamily().hashCode();
      }
      if (hasColumnQualifier()) {
        hash = (37 * hash) + COLUMN_QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getColumnQualifier().hashCode();
      }
      if (hasDropDependentColumn()) {
        hash = (37 * hash) + DROP_DEPENDENT_COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getDropDependentColumn());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DependentColumnFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DependentColumnFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_DependentColumnFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_DependentColumnFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCompareFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        dropDependentColumn_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_DependentColumnFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareFilter_ = compareFilterBuilder_ == null
              ? compareFilter_
              : compareFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.columnFamily_ = columnFamily_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.columnQualifier_ = columnQualifier_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.dropDependentColumn_ = dropDependentColumn_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter.getDefaultInstance()) return this;
        if (other.hasCompareFilter()) {
          mergeCompareFilter(other.getCompareFilter());
        }
        if (other.hasColumnFamily()) {
          setColumnFamily(other.getColumnFamily());
        }
        if (other.hasColumnQualifier()) {
          setColumnQualifier(other.getColumnQualifier());
        }
        if (other.hasDropDependentColumn()) {
          setDropDependentColumn(other.getDropDependentColumn());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareFilter()) {
          return false;
        }
        if (!getCompareFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCompareFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                columnFamily_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                columnQualifier_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                dropDependentColumn_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> compareFilterBuilder_;
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return Whether the compareFilter field is set.
       */
      public boolean hasCompareFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return The compareFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
        if (compareFilterBuilder_ == null) {
          return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        } else {
          return compareFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compareFilter_ = value;
        } else {
          compareFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder builderForValue) {
        if (compareFilterBuilder_ == null) {
          compareFilter_ = builderForValue.build();
        } else {
          compareFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder mergeCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            compareFilter_ != null &&
            compareFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) {
            getCompareFilterBuilder().mergeFrom(value);
          } else {
            compareFilter_ = value;
          }
        } else {
          compareFilterBuilder_.mergeFrom(value);
        }
        if (compareFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder clearCompareFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder getCompareFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCompareFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
        if (compareFilterBuilder_ != null) {
          return compareFilterBuilder_.getMessageOrBuilder();
        } else {
          return compareFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> 
          getCompareFilterFieldBuilder() {
        if (compareFilterBuilder_ == null) {
          compareFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder>(
                  getCompareFilter(),
                  getParentForChildren(),
                  isClean());
          compareFilter_ = null;
        }
        return compareFilterBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes column_family = 2;</code>
       * @return Whether the columnFamily field is set.
       */
      @java.lang.Override
      public boolean hasColumnFamily() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes column_family = 2;</code>
       * @return The columnFamily.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily() {
        return columnFamily_;
      }
      /**
       * <code>optional bytes column_family = 2;</code>
       * @param value The columnFamily to set.
       * @return This builder for chaining.
       */
      public Builder setColumnFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        columnFamily_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes column_family = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        columnFamily_ = getDefaultInstance().getColumnFamily();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes column_qualifier = 3;</code>
       * @return Whether the columnQualifier field is set.
       */
      @java.lang.Override
      public boolean hasColumnQualifier() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes column_qualifier = 3;</code>
       * @return The columnQualifier.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier() {
        return columnQualifier_;
      }
      /**
       * <code>optional bytes column_qualifier = 3;</code>
       * @param value The columnQualifier to set.
       * @return This builder for chaining.
       */
      public Builder setColumnQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        columnQualifier_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes column_qualifier = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        columnQualifier_ = getDefaultInstance().getColumnQualifier();
        onChanged();
        return this;
      }

      private boolean dropDependentColumn_ ;
      /**
       * <code>optional bool drop_dependent_column = 4;</code>
       * @return Whether the dropDependentColumn field is set.
       */
      @java.lang.Override
      public boolean hasDropDependentColumn() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool drop_dependent_column = 4;</code>
       * @return The dropDependentColumn.
       */
      @java.lang.Override
      public boolean getDropDependentColumn() {
        return dropDependentColumn_;
      }
      /**
       * <code>optional bool drop_dependent_column = 4;</code>
       * @param value The dropDependentColumn to set.
       * @return This builder for chaining.
       */
      public Builder setDropDependentColumn(boolean value) {

        dropDependentColumn_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool drop_dependent_column = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearDropDependentColumn() {
        bitField0_ = (bitField0_ & ~0x00000008);
        dropDependentColumn_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DependentColumnFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DependentColumnFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<DependentColumnFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<DependentColumnFilter>() {
      @java.lang.Override
      public DependentColumnFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<DependentColumnFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<DependentColumnFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.DependentColumnFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FamilyFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FamilyFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    boolean hasCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.FamilyFilter}
   */
  @javax.annotation.Generated("proto") public static final class FamilyFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FamilyFilter)
      FamilyFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FamilyFilter.newBuilder() to construct.
    private FamilyFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FamilyFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FamilyFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FamilyFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FamilyFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    @java.lang.Override
    public boolean hasCompareFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCompareFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCompareFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCompareFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter) obj;

      if (hasCompareFilter() != other.hasCompareFilter()) return false;
      if (hasCompareFilter()) {
        if (!getCompareFilter()
            .equals(other.getCompareFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareFilter()) {
        hash = (37 * hash) + COMPARE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getCompareFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FamilyFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FamilyFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FamilyFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FamilyFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCompareFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FamilyFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareFilter_ = compareFilterBuilder_ == null
              ? compareFilter_
              : compareFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter.getDefaultInstance()) return this;
        if (other.hasCompareFilter()) {
          mergeCompareFilter(other.getCompareFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareFilter()) {
          return false;
        }
        if (!getCompareFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCompareFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> compareFilterBuilder_;
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return Whether the compareFilter field is set.
       */
      public boolean hasCompareFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return The compareFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
        if (compareFilterBuilder_ == null) {
          return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        } else {
          return compareFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compareFilter_ = value;
        } else {
          compareFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder builderForValue) {
        if (compareFilterBuilder_ == null) {
          compareFilter_ = builderForValue.build();
        } else {
          compareFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder mergeCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            compareFilter_ != null &&
            compareFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) {
            getCompareFilterBuilder().mergeFrom(value);
          } else {
            compareFilter_ = value;
          }
        } else {
          compareFilterBuilder_.mergeFrom(value);
        }
        if (compareFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder clearCompareFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder getCompareFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCompareFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
        if (compareFilterBuilder_ != null) {
          return compareFilterBuilder_.getMessageOrBuilder();
        } else {
          return compareFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> 
          getCompareFilterFieldBuilder() {
        if (compareFilterBuilder_ == null) {
          compareFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder>(
                  getCompareFilter(),
                  getParentForChildren(),
                  isClean());
          compareFilter_ = null;
        }
        return compareFilterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FamilyFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FamilyFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FamilyFilter>() {
      @java.lang.Override
      public FamilyFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FamilyFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FilterListOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FilterList)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
     * @return Whether the operator field is set.
     */
    boolean hasOperator();
    /**
     * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
     * @return The operator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator getOperator();

    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> 
        getFiltersList();
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilters(int index);
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    int getFiltersCount();
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
        getFiltersOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFiltersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.FilterList}
   */
  @javax.annotation.Generated("proto") public static final class FilterList extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FilterList)
      FilterListOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FilterList.newBuilder() to construct.
    private FilterList(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FilterList() {
      operator_ = 1;
      filters_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FilterList();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterList_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterList_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.FilterList.Operator}
     */
    public enum Operator
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>MUST_PASS_ALL = 1;</code>
       */
      MUST_PASS_ALL(1),
      /**
       * <code>MUST_PASS_ONE = 2;</code>
       */
      MUST_PASS_ONE(2),
      ;

      /**
       * <code>MUST_PASS_ALL = 1;</code>
       */
      public static final int MUST_PASS_ALL_VALUE = 1;
      /**
       * <code>MUST_PASS_ONE = 2;</code>
       */
      public static final int MUST_PASS_ONE_VALUE = 2;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Operator valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Operator forNumber(int value) {
        switch (value) {
          case 1: return MUST_PASS_ALL;
          case 2: return MUST_PASS_ONE;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Operator>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          Operator> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<Operator>() {
              public Operator findValueByNumber(int number) {
                return Operator.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.getDescriptor().getEnumTypes().get(0);
      }

      private static final Operator[] VALUES = values();

      public static Operator valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Operator(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.FilterList.Operator)
    }

    private int bitField0_;
    public static final int OPERATOR_FIELD_NUMBER = 1;
    private int operator_ = 1;
    /**
     * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
     * @return Whether the operator field is set.
     */
    @java.lang.Override public boolean hasOperator() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
     * @return The operator.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator getOperator() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator result = org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator.forNumber(operator_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator.MUST_PASS_ALL : result;
    }

    public static final int FILTERS_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> filters_;
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> getFiltersList() {
      return filters_;
    }
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
        getFiltersOrBuilderList() {
      return filters_;
    }
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    @java.lang.Override
    public int getFiltersCount() {
      return filters_.size();
    }
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilters(int index) {
      return filters_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Filter filters = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFiltersOrBuilder(
        int index) {
      return filters_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasOperator()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getFiltersCount(); i++) {
        if (!getFilters(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, operator_);
      }
      for (int i = 0; i < filters_.size(); i++) {
        output.writeMessage(2, filters_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, operator_);
      }
      for (int i = 0; i < filters_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, filters_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList) obj;

      if (hasOperator() != other.hasOperator()) return false;
      if (hasOperator()) {
        if (operator_ != other.operator_) return false;
      }
      if (!getFiltersList()
          .equals(other.getFiltersList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasOperator()) {
        hash = (37 * hash) + OPERATOR_FIELD_NUMBER;
        hash = (53 * hash) + operator_;
      }
      if (getFiltersCount() > 0) {
        hash = (37 * hash) + FILTERS_FIELD_NUMBER;
        hash = (53 * hash) + getFiltersList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FilterList}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FilterList)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterListOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterList_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterList_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        operator_ = 1;
        if (filtersBuilder_ == null) {
          filters_ = java.util.Collections.emptyList();
        } else {
          filters_ = null;
          filtersBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterList_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList result) {
        if (filtersBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            filters_ = java.util.Collections.unmodifiableList(filters_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.filters_ = filters_;
        } else {
          result.filters_ = filtersBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.operator_ = operator_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.getDefaultInstance()) return this;
        if (other.hasOperator()) {
          setOperator(other.getOperator());
        }
        if (filtersBuilder_ == null) {
          if (!other.filters_.isEmpty()) {
            if (filters_.isEmpty()) {
              filters_ = other.filters_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFiltersIsMutable();
              filters_.addAll(other.filters_);
            }
            onChanged();
          }
        } else {
          if (!other.filters_.isEmpty()) {
            if (filtersBuilder_.isEmpty()) {
              filtersBuilder_.dispose();
              filtersBuilder_ = null;
              filters_ = other.filters_;
              bitField0_ = (bitField0_ & ~0x00000002);
              filtersBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFiltersFieldBuilder() : null;
            } else {
              filtersBuilder_.addAllMessages(other.filters_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasOperator()) {
          return false;
        }
        for (int i = 0; i < getFiltersCount(); i++) {
          if (!getFilters(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  operator_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.PARSER,
                        extensionRegistry);
                if (filtersBuilder_ == null) {
                  ensureFiltersIsMutable();
                  filters_.add(m);
                } else {
                  filtersBuilder_.addMessage(m);
                }
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int operator_ = 1;
      /**
       * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
       * @return Whether the operator field is set.
       */
      @java.lang.Override public boolean hasOperator() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
       * @return The operator.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator getOperator() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator result = org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator.forNumber(operator_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator.MUST_PASS_ALL : result;
      }
      /**
       * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
       * @param value The operator to set.
       * @return This builder for chaining.
       */
      public Builder setOperator(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList.Operator value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        operator_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.FilterList.Operator operator = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearOperator() {
        bitField0_ = (bitField0_ & ~0x00000001);
        operator_ = 1;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> filters_ =
        java.util.Collections.emptyList();
      private void ensureFiltersIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          filters_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter>(filters_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filtersBuilder_;

      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> getFiltersList() {
        if (filtersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(filters_);
        } else {
          return filtersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public int getFiltersCount() {
        if (filtersBuilder_ == null) {
          return filters_.size();
        } else {
          return filtersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilters(int index) {
        if (filtersBuilder_ == null) {
          return filters_.get(index);
        } else {
          return filtersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder setFilters(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filtersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFiltersIsMutable();
          filters_.set(index, value);
          onChanged();
        } else {
          filtersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder setFilters(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filtersBuilder_ == null) {
          ensureFiltersIsMutable();
          filters_.set(index, builderForValue.build());
          onChanged();
        } else {
          filtersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder addFilters(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filtersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFiltersIsMutable();
          filters_.add(value);
          onChanged();
        } else {
          filtersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder addFilters(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filtersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFiltersIsMutable();
          filters_.add(index, value);
          onChanged();
        } else {
          filtersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder addFilters(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filtersBuilder_ == null) {
          ensureFiltersIsMutable();
          filters_.add(builderForValue.build());
          onChanged();
        } else {
          filtersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder addFilters(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filtersBuilder_ == null) {
          ensureFiltersIsMutable();
          filters_.add(index, builderForValue.build());
          onChanged();
        } else {
          filtersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder addAllFilters(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter> values) {
        if (filtersBuilder_ == null) {
          ensureFiltersIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, filters_);
          onChanged();
        } else {
          filtersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder clearFilters() {
        if (filtersBuilder_ == null) {
          filters_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          filtersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public Builder removeFilters(int index) {
        if (filtersBuilder_ == null) {
          ensureFiltersIsMutable();
          filters_.remove(index);
          onChanged();
        } else {
          filtersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFiltersBuilder(
          int index) {
        return getFiltersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFiltersOrBuilder(
          int index) {
        if (filtersBuilder_ == null) {
          return filters_.get(index);  } else {
          return filtersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
           getFiltersOrBuilderList() {
        if (filtersBuilder_ != null) {
          return filtersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(filters_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder addFiltersBuilder() {
        return getFiltersFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder addFiltersBuilder(
          int index) {
        return getFiltersFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Filter filters = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder> 
           getFiltersBuilderList() {
        return getFiltersFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFiltersFieldBuilder() {
        if (filtersBuilder_ == null) {
          filtersBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  filters_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          filters_ = null;
        }
        return filtersBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FilterList)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FilterList)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterList>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FilterList>() {
      @java.lang.Override
      public FilterList parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterList> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterList> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterList getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FilterWrapperOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FilterWrapper)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.FilterWrapper}
   */
  @javax.annotation.Generated("proto") public static final class FilterWrapper extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FilterWrapper)
      FilterWrapperOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FilterWrapper.newBuilder() to construct.
    private FilterWrapper(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FilterWrapper() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FilterWrapper();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterWrapper_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterWrapper_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.Builder.class);
    }

    private int bitField0_;
    public static final int FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper) obj;

      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FilterWrapper}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FilterWrapper)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapperOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterWrapper_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterWrapper_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterWrapper_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper.getDefaultInstance()) return this;
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFilter()) {
          return false;
        }
        if (!getFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FilterWrapper)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FilterWrapper)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterWrapper>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FilterWrapper>() {
      @java.lang.Override
      public FilterWrapper parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterWrapper> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterWrapper> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterWrapper getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FirstKeyOnlyFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FirstKeyOnlyFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.FirstKeyOnlyFilter}
   */
  @javax.annotation.Generated("proto") public static final class FirstKeyOnlyFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FirstKeyOnlyFilter)
      FirstKeyOnlyFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FirstKeyOnlyFilter.newBuilder() to construct.
    private FirstKeyOnlyFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FirstKeyOnlyFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FirstKeyOnlyFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyOnlyFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FirstKeyOnlyFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FirstKeyOnlyFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyOnlyFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FirstKeyOnlyFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FirstKeyOnlyFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyOnlyFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FirstKeyOnlyFilter>() {
      @java.lang.Override
      public FirstKeyOnlyFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyOnlyFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyOnlyFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyOnlyFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FirstKeyValueMatchingQualifiersFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FirstKeyValueMatchingQualifiersFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @return A list containing the qualifiers.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getQualifiersList();
    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @return The count of qualifiers.
     */
    int getQualifiersCount();
    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @param index The index of the element to return.
     * @return The qualifiers at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifiers(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.FirstKeyValueMatchingQualifiersFilter}
   */
  @javax.annotation.Generated("proto") public static final class FirstKeyValueMatchingQualifiersFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FirstKeyValueMatchingQualifiersFilter)
      FirstKeyValueMatchingQualifiersFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FirstKeyValueMatchingQualifiersFilter.newBuilder() to construct.
    private FirstKeyValueMatchingQualifiersFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FirstKeyValueMatchingQualifiersFilter() {
      qualifiers_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FirstKeyValueMatchingQualifiersFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.Builder.class);
    }

    public static final int QUALIFIERS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> qualifiers_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @return A list containing the qualifiers.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getQualifiersList() {
      return qualifiers_;
    }
    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @return The count of qualifiers.
     */
    public int getQualifiersCount() {
      return qualifiers_.size();
    }
    /**
     * <code>repeated bytes qualifiers = 1;</code>
     * @param index The index of the element to return.
     * @return The qualifiers at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifiers(int index) {
      return qualifiers_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < qualifiers_.size(); i++) {
        output.writeBytes(1, qualifiers_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < qualifiers_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(qualifiers_.get(i));
        }
        size += dataSize;
        size += 1 * getQualifiersList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter) obj;

      if (!getQualifiersList()
          .equals(other.getQualifiersList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getQualifiersCount() > 0) {
        hash = (37 * hash) + QUALIFIERS_FIELD_NUMBER;
        hash = (53 * hash) + getQualifiersList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FirstKeyValueMatchingQualifiersFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FirstKeyValueMatchingQualifiersFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        qualifiers_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          qualifiers_.makeImmutable();
          result.qualifiers_ = qualifiers_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter.getDefaultInstance()) return this;
        if (!other.qualifiers_.isEmpty()) {
          if (qualifiers_.isEmpty()) {
            qualifiers_ = other.qualifiers_;
            qualifiers_.makeImmutable();
            bitField0_ |= 0x00000001;
          } else {
            ensureQualifiersIsMutable();
            qualifiers_.addAll(other.qualifiers_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureQualifiersIsMutable();
                qualifiers_.add(v);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> qualifiers_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureQualifiersIsMutable() {
        if (!qualifiers_.isModifiable()) {
          qualifiers_ = makeMutableCopy(qualifiers_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @return A list containing the qualifiers.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getQualifiersList() {
        qualifiers_.makeImmutable();
        return qualifiers_;
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @return The count of qualifiers.
       */
      public int getQualifiersCount() {
        return qualifiers_.size();
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @param index The index of the element to return.
       * @return The qualifiers at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifiers(int index) {
        return qualifiers_.get(index);
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @param index The index to set the value at.
       * @param value The qualifiers to set.
       * @return This builder for chaining.
       */
      public Builder setQualifiers(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQualifiersIsMutable();
        qualifiers_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @param value The qualifiers to add.
       * @return This builder for chaining.
       */
      public Builder addQualifiers(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQualifiersIsMutable();
        qualifiers_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @param values The qualifiers to add.
       * @return This builder for chaining.
       */
      public Builder addAllQualifiers(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureQualifiersIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, qualifiers_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifiers = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearQualifiers() {
        qualifiers_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FirstKeyValueMatchingQualifiersFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FirstKeyValueMatchingQualifiersFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyValueMatchingQualifiersFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FirstKeyValueMatchingQualifiersFilter>() {
      @java.lang.Override
      public FirstKeyValueMatchingQualifiersFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyValueMatchingQualifiersFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FirstKeyValueMatchingQualifiersFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FirstKeyValueMatchingQualifiersFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FuzzyRowFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FuzzyRowFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> 
        getFuzzyKeysDataList();
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair getFuzzyKeysData(int index);
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    int getFuzzyKeysDataCount();
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getFuzzyKeysDataOrBuilderList();
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getFuzzyKeysDataOrBuilder(
        int index);

    /**
     * <code>optional bool is_mask_v2 = 2;</code>
     * @return Whether the isMaskV2 field is set.
     */
    boolean hasIsMaskV2();
    /**
     * <code>optional bool is_mask_v2 = 2;</code>
     * @return The isMaskV2.
     */
    boolean getIsMaskV2();
  }
  /**
   * Protobuf type {@code hbase.pb.FuzzyRowFilter}
   */
  @javax.annotation.Generated("proto") public static final class FuzzyRowFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FuzzyRowFilter)
      FuzzyRowFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FuzzyRowFilter.newBuilder() to construct.
    private FuzzyRowFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FuzzyRowFilter() {
      fuzzyKeysData_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FuzzyRowFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FuzzyRowFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FuzzyRowFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.Builder.class);
    }

    private int bitField0_;
    public static final int FUZZY_KEYS_DATA_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> fuzzyKeysData_;
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> getFuzzyKeysDataList() {
      return fuzzyKeysData_;
    }
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getFuzzyKeysDataOrBuilderList() {
      return fuzzyKeysData_;
    }
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    @java.lang.Override
    public int getFuzzyKeysDataCount() {
      return fuzzyKeysData_.size();
    }
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair getFuzzyKeysData(int index) {
      return fuzzyKeysData_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getFuzzyKeysDataOrBuilder(
        int index) {
      return fuzzyKeysData_.get(index);
    }

    public static final int IS_MASK_V2_FIELD_NUMBER = 2;
    private boolean isMaskV2_ = false;
    /**
     * <code>optional bool is_mask_v2 = 2;</code>
     * @return Whether the isMaskV2 field is set.
     */
    @java.lang.Override
    public boolean hasIsMaskV2() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bool is_mask_v2 = 2;</code>
     * @return The isMaskV2.
     */
    @java.lang.Override
    public boolean getIsMaskV2() {
      return isMaskV2_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getFuzzyKeysDataCount(); i++) {
        if (!getFuzzyKeysData(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < fuzzyKeysData_.size(); i++) {
        output.writeMessage(1, fuzzyKeysData_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(2, isMaskV2_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < fuzzyKeysData_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, fuzzyKeysData_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isMaskV2_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter) obj;

      if (!getFuzzyKeysDataList()
          .equals(other.getFuzzyKeysDataList())) return false;
      if (hasIsMaskV2() != other.hasIsMaskV2()) return false;
      if (hasIsMaskV2()) {
        if (getIsMaskV2()
            != other.getIsMaskV2()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getFuzzyKeysDataCount() > 0) {
        hash = (37 * hash) + FUZZY_KEYS_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getFuzzyKeysDataList().hashCode();
      }
      if (hasIsMaskV2()) {
        hash = (37 * hash) + IS_MASK_V2_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getIsMaskV2());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FuzzyRowFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FuzzyRowFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FuzzyRowFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FuzzyRowFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (fuzzyKeysDataBuilder_ == null) {
          fuzzyKeysData_ = java.util.Collections.emptyList();
        } else {
          fuzzyKeysData_ = null;
          fuzzyKeysDataBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        isMaskV2_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FuzzyRowFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter result) {
        if (fuzzyKeysDataBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            fuzzyKeysData_ = java.util.Collections.unmodifiableList(fuzzyKeysData_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.fuzzyKeysData_ = fuzzyKeysData_;
        } else {
          result.fuzzyKeysData_ = fuzzyKeysDataBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.isMaskV2_ = isMaskV2_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter.getDefaultInstance()) return this;
        if (fuzzyKeysDataBuilder_ == null) {
          if (!other.fuzzyKeysData_.isEmpty()) {
            if (fuzzyKeysData_.isEmpty()) {
              fuzzyKeysData_ = other.fuzzyKeysData_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureFuzzyKeysDataIsMutable();
              fuzzyKeysData_.addAll(other.fuzzyKeysData_);
            }
            onChanged();
          }
        } else {
          if (!other.fuzzyKeysData_.isEmpty()) {
            if (fuzzyKeysDataBuilder_.isEmpty()) {
              fuzzyKeysDataBuilder_.dispose();
              fuzzyKeysDataBuilder_ = null;
              fuzzyKeysData_ = other.fuzzyKeysData_;
              bitField0_ = (bitField0_ & ~0x00000001);
              fuzzyKeysDataBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getFuzzyKeysDataFieldBuilder() : null;
            } else {
              fuzzyKeysDataBuilder_.addAllMessages(other.fuzzyKeysData_);
            }
          }
        }
        if (other.hasIsMaskV2()) {
          setIsMaskV2(other.getIsMaskV2());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getFuzzyKeysDataCount(); i++) {
          if (!getFuzzyKeysData(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.PARSER,
                        extensionRegistry);
                if (fuzzyKeysDataBuilder_ == null) {
                  ensureFuzzyKeysDataIsMutable();
                  fuzzyKeysData_.add(m);
                } else {
                  fuzzyKeysDataBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                isMaskV2_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> fuzzyKeysData_ =
        java.util.Collections.emptyList();
      private void ensureFuzzyKeysDataIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          fuzzyKeysData_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair>(fuzzyKeysData_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> fuzzyKeysDataBuilder_;

      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> getFuzzyKeysDataList() {
        if (fuzzyKeysDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(fuzzyKeysData_);
        } else {
          return fuzzyKeysDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public int getFuzzyKeysDataCount() {
        if (fuzzyKeysDataBuilder_ == null) {
          return fuzzyKeysData_.size();
        } else {
          return fuzzyKeysDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair getFuzzyKeysData(int index) {
        if (fuzzyKeysDataBuilder_ == null) {
          return fuzzyKeysData_.get(index);
        } else {
          return fuzzyKeysDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder setFuzzyKeysData(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (fuzzyKeysDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.set(index, value);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder setFuzzyKeysData(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (fuzzyKeysDataBuilder_ == null) {
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.set(index, builderForValue.build());
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder addFuzzyKeysData(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (fuzzyKeysDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.add(value);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder addFuzzyKeysData(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (fuzzyKeysDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.add(index, value);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder addFuzzyKeysData(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (fuzzyKeysDataBuilder_ == null) {
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.add(builderForValue.build());
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder addFuzzyKeysData(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (fuzzyKeysDataBuilder_ == null) {
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.add(index, builderForValue.build());
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder addAllFuzzyKeysData(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair> values) {
        if (fuzzyKeysDataBuilder_ == null) {
          ensureFuzzyKeysDataIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, fuzzyKeysData_);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder clearFuzzyKeysData() {
        if (fuzzyKeysDataBuilder_ == null) {
          fuzzyKeysData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public Builder removeFuzzyKeysData(int index) {
        if (fuzzyKeysDataBuilder_ == null) {
          ensureFuzzyKeysDataIsMutable();
          fuzzyKeysData_.remove(index);
          onChanged();
        } else {
          fuzzyKeysDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder getFuzzyKeysDataBuilder(
          int index) {
        return getFuzzyKeysDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getFuzzyKeysDataOrBuilder(
          int index) {
        if (fuzzyKeysDataBuilder_ == null) {
          return fuzzyKeysData_.get(index);  } else {
          return fuzzyKeysDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
           getFuzzyKeysDataOrBuilderList() {
        if (fuzzyKeysDataBuilder_ != null) {
          return fuzzyKeysDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(fuzzyKeysData_);
        }
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addFuzzyKeysDataBuilder() {
        return getFuzzyKeysDataFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addFuzzyKeysDataBuilder(
          int index) {
        return getFuzzyKeysDataFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.BytesBytesPair fuzzy_keys_data = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder> 
           getFuzzyKeysDataBuilderList() {
        return getFuzzyKeysDataFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
          getFuzzyKeysDataFieldBuilder() {
        if (fuzzyKeysDataBuilder_ == null) {
          fuzzyKeysDataBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder>(
                  fuzzyKeysData_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          fuzzyKeysData_ = null;
        }
        return fuzzyKeysDataBuilder_;
      }

      private boolean isMaskV2_ ;
      /**
       * <code>optional bool is_mask_v2 = 2;</code>
       * @return Whether the isMaskV2 field is set.
       */
      @java.lang.Override
      public boolean hasIsMaskV2() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool is_mask_v2 = 2;</code>
       * @return The isMaskV2.
       */
      @java.lang.Override
      public boolean getIsMaskV2() {
        return isMaskV2_;
      }
      /**
       * <code>optional bool is_mask_v2 = 2;</code>
       * @param value The isMaskV2 to set.
       * @return This builder for chaining.
       */
      public Builder setIsMaskV2(boolean value) {

        isMaskV2_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool is_mask_v2 = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsMaskV2() {
        bitField0_ = (bitField0_ & ~0x00000002);
        isMaskV2_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FuzzyRowFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FuzzyRowFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FuzzyRowFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FuzzyRowFilter>() {
      @java.lang.Override
      public FuzzyRowFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FuzzyRowFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FuzzyRowFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FuzzyRowFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InclusiveStopFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.InclusiveStopFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes stop_row_key = 1;</code>
     * @return Whether the stopRowKey field is set.
     */
    boolean hasStopRowKey();
    /**
     * <code>optional bytes stop_row_key = 1;</code>
     * @return The stopRowKey.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRowKey();
  }
  /**
   * Protobuf type {@code hbase.pb.InclusiveStopFilter}
   */
  @javax.annotation.Generated("proto") public static final class InclusiveStopFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.InclusiveStopFilter)
      InclusiveStopFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InclusiveStopFilter.newBuilder() to construct.
    private InclusiveStopFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InclusiveStopFilter() {
      stopRowKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new InclusiveStopFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_InclusiveStopFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_InclusiveStopFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.Builder.class);
    }

    private int bitField0_;
    public static final int STOP_ROW_KEY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRowKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes stop_row_key = 1;</code>
     * @return Whether the stopRowKey field is set.
     */
    @java.lang.Override
    public boolean hasStopRowKey() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes stop_row_key = 1;</code>
     * @return The stopRowKey.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRowKey() {
      return stopRowKey_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, stopRowKey_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, stopRowKey_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter) obj;

      if (hasStopRowKey() != other.hasStopRowKey()) return false;
      if (hasStopRowKey()) {
        if (!getStopRowKey()
            .equals(other.getStopRowKey())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStopRowKey()) {
        hash = (37 * hash) + STOP_ROW_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getStopRowKey().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.InclusiveStopFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.InclusiveStopFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_InclusiveStopFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_InclusiveStopFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        stopRowKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_InclusiveStopFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.stopRowKey_ = stopRowKey_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter.getDefaultInstance()) return this;
        if (other.hasStopRowKey()) {
          setStopRowKey(other.getStopRowKey());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                stopRowKey_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRowKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes stop_row_key = 1;</code>
       * @return Whether the stopRowKey field is set.
       */
      @java.lang.Override
      public boolean hasStopRowKey() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes stop_row_key = 1;</code>
       * @return The stopRowKey.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRowKey() {
        return stopRowKey_;
      }
      /**
       * <code>optional bytes stop_row_key = 1;</code>
       * @param value The stopRowKey to set.
       * @return This builder for chaining.
       */
      public Builder setStopRowKey(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        stopRowKey_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes stop_row_key = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearStopRowKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        stopRowKey_ = getDefaultInstance().getStopRowKey();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.InclusiveStopFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.InclusiveStopFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<InclusiveStopFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<InclusiveStopFilter>() {
      @java.lang.Override
      public InclusiveStopFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<InclusiveStopFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<InclusiveStopFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.InclusiveStopFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KeyOnlyFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.KeyOnlyFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool len_as_val = 1;</code>
     * @return Whether the lenAsVal field is set.
     */
    boolean hasLenAsVal();
    /**
     * <code>required bool len_as_val = 1;</code>
     * @return The lenAsVal.
     */
    boolean getLenAsVal();
  }
  /**
   * Protobuf type {@code hbase.pb.KeyOnlyFilter}
   */
  @javax.annotation.Generated("proto") public static final class KeyOnlyFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.KeyOnlyFilter)
      KeyOnlyFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KeyOnlyFilter.newBuilder() to construct.
    private KeyOnlyFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KeyOnlyFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new KeyOnlyFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_KeyOnlyFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_KeyOnlyFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.Builder.class);
    }

    private int bitField0_;
    public static final int LEN_AS_VAL_FIELD_NUMBER = 1;
    private boolean lenAsVal_ = false;
    /**
     * <code>required bool len_as_val = 1;</code>
     * @return Whether the lenAsVal field is set.
     */
    @java.lang.Override
    public boolean hasLenAsVal() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool len_as_val = 1;</code>
     * @return The lenAsVal.
     */
    @java.lang.Override
    public boolean getLenAsVal() {
      return lenAsVal_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasLenAsVal()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, lenAsVal_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, lenAsVal_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter) obj;

      if (hasLenAsVal() != other.hasLenAsVal()) return false;
      if (hasLenAsVal()) {
        if (getLenAsVal()
            != other.getLenAsVal()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLenAsVal()) {
        hash = (37 * hash) + LEN_AS_VAL_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getLenAsVal());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.KeyOnlyFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.KeyOnlyFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_KeyOnlyFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_KeyOnlyFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        lenAsVal_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_KeyOnlyFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.lenAsVal_ = lenAsVal_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter.getDefaultInstance()) return this;
        if (other.hasLenAsVal()) {
          setLenAsVal(other.getLenAsVal());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasLenAsVal()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                lenAsVal_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean lenAsVal_ ;
      /**
       * <code>required bool len_as_val = 1;</code>
       * @return Whether the lenAsVal field is set.
       */
      @java.lang.Override
      public boolean hasLenAsVal() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool len_as_val = 1;</code>
       * @return The lenAsVal.
       */
      @java.lang.Override
      public boolean getLenAsVal() {
        return lenAsVal_;
      }
      /**
       * <code>required bool len_as_val = 1;</code>
       * @param value The lenAsVal to set.
       * @return This builder for chaining.
       */
      public Builder setLenAsVal(boolean value) {

        lenAsVal_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool len_as_val = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLenAsVal() {
        bitField0_ = (bitField0_ & ~0x00000001);
        lenAsVal_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.KeyOnlyFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.KeyOnlyFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<KeyOnlyFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<KeyOnlyFilter>() {
      @java.lang.Override
      public KeyOnlyFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<KeyOnlyFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<KeyOnlyFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.KeyOnlyFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MultipleColumnPrefixFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MultipleColumnPrefixFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @return A list containing the sortedPrefixes.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getSortedPrefixesList();
    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @return The count of sortedPrefixes.
     */
    int getSortedPrefixesCount();
    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @param index The index of the element to return.
     * @return The sortedPrefixes at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSortedPrefixes(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.MultipleColumnPrefixFilter}
   */
  @javax.annotation.Generated("proto") public static final class MultipleColumnPrefixFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MultipleColumnPrefixFilter)
      MultipleColumnPrefixFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MultipleColumnPrefixFilter.newBuilder() to construct.
    private MultipleColumnPrefixFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MultipleColumnPrefixFilter() {
      sortedPrefixes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MultipleColumnPrefixFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultipleColumnPrefixFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.Builder.class);
    }

    public static final int SORTED_PREFIXES_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> sortedPrefixes_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @return A list containing the sortedPrefixes.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getSortedPrefixesList() {
      return sortedPrefixes_;
    }
    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @return The count of sortedPrefixes.
     */
    public int getSortedPrefixesCount() {
      return sortedPrefixes_.size();
    }
    /**
     * <code>repeated bytes sorted_prefixes = 1;</code>
     * @param index The index of the element to return.
     * @return The sortedPrefixes at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSortedPrefixes(int index) {
      return sortedPrefixes_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < sortedPrefixes_.size(); i++) {
        output.writeBytes(1, sortedPrefixes_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < sortedPrefixes_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(sortedPrefixes_.get(i));
        }
        size += dataSize;
        size += 1 * getSortedPrefixesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter) obj;

      if (!getSortedPrefixesList()
          .equals(other.getSortedPrefixesList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getSortedPrefixesCount() > 0) {
        hash = (37 * hash) + SORTED_PREFIXES_FIELD_NUMBER;
        hash = (53 * hash) + getSortedPrefixesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MultipleColumnPrefixFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MultipleColumnPrefixFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultipleColumnPrefixFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        sortedPrefixes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          sortedPrefixes_.makeImmutable();
          result.sortedPrefixes_ = sortedPrefixes_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter.getDefaultInstance()) return this;
        if (!other.sortedPrefixes_.isEmpty()) {
          if (sortedPrefixes_.isEmpty()) {
            sortedPrefixes_ = other.sortedPrefixes_;
            sortedPrefixes_.makeImmutable();
            bitField0_ |= 0x00000001;
          } else {
            ensureSortedPrefixesIsMutable();
            sortedPrefixes_.addAll(other.sortedPrefixes_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureSortedPrefixesIsMutable();
                sortedPrefixes_.add(v);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> sortedPrefixes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureSortedPrefixesIsMutable() {
        if (!sortedPrefixes_.isModifiable()) {
          sortedPrefixes_ = makeMutableCopy(sortedPrefixes_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @return A list containing the sortedPrefixes.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getSortedPrefixesList() {
        sortedPrefixes_.makeImmutable();
        return sortedPrefixes_;
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @return The count of sortedPrefixes.
       */
      public int getSortedPrefixesCount() {
        return sortedPrefixes_.size();
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @param index The index of the element to return.
       * @return The sortedPrefixes at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getSortedPrefixes(int index) {
        return sortedPrefixes_.get(index);
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @param index The index to set the value at.
       * @param value The sortedPrefixes to set.
       * @return This builder for chaining.
       */
      public Builder setSortedPrefixes(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureSortedPrefixesIsMutable();
        sortedPrefixes_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @param value The sortedPrefixes to add.
       * @return This builder for chaining.
       */
      public Builder addSortedPrefixes(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureSortedPrefixesIsMutable();
        sortedPrefixes_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @param values The sortedPrefixes to add.
       * @return This builder for chaining.
       */
      public Builder addAllSortedPrefixes(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureSortedPrefixesIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, sortedPrefixes_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes sorted_prefixes = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearSortedPrefixes() {
        sortedPrefixes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MultipleColumnPrefixFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MultipleColumnPrefixFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultipleColumnPrefixFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MultipleColumnPrefixFilter>() {
      @java.lang.Override
      public MultipleColumnPrefixFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultipleColumnPrefixFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultipleColumnPrefixFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultipleColumnPrefixFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PageFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PageFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required int64 page_size = 1;</code>
     * @return Whether the pageSize field is set.
     */
    boolean hasPageSize();
    /**
     * <code>required int64 page_size = 1;</code>
     * @return The pageSize.
     */
    long getPageSize();
  }
  /**
   * Protobuf type {@code hbase.pb.PageFilter}
   */
  @javax.annotation.Generated("proto") public static final class PageFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PageFilter)
      PageFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PageFilter.newBuilder() to construct.
    private PageFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PageFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PageFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PageFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PageFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.Builder.class);
    }

    private int bitField0_;
    public static final int PAGE_SIZE_FIELD_NUMBER = 1;
    private long pageSize_ = 0L;
    /**
     * <code>required int64 page_size = 1;</code>
     * @return Whether the pageSize field is set.
     */
    @java.lang.Override
    public boolean hasPageSize() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required int64 page_size = 1;</code>
     * @return The pageSize.
     */
    @java.lang.Override
    public long getPageSize() {
      return pageSize_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPageSize()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt64(1, pageSize_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, pageSize_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter) obj;

      if (hasPageSize() != other.hasPageSize()) return false;
      if (hasPageSize()) {
        if (getPageSize()
            != other.getPageSize()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPageSize()) {
        hash = (37 * hash) + PAGE_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getPageSize());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PageFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PageFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PageFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PageFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        pageSize_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PageFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.pageSize_ = pageSize_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter.getDefaultInstance()) return this;
        if (other.hasPageSize()) {
          setPageSize(other.getPageSize());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPageSize()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                pageSize_ = input.readInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long pageSize_ ;
      /**
       * <code>required int64 page_size = 1;</code>
       * @return Whether the pageSize field is set.
       */
      @java.lang.Override
      public boolean hasPageSize() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required int64 page_size = 1;</code>
       * @return The pageSize.
       */
      @java.lang.Override
      public long getPageSize() {
        return pageSize_;
      }
      /**
       * <code>required int64 page_size = 1;</code>
       * @param value The pageSize to set.
       * @return This builder for chaining.
       */
      public Builder setPageSize(long value) {

        pageSize_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 page_size = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPageSize() {
        bitField0_ = (bitField0_ & ~0x00000001);
        pageSize_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PageFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PageFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PageFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PageFilter>() {
      @java.lang.Override
      public PageFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PageFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PageFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PageFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PrefixFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.PrefixFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes prefix = 1;</code>
     * @return Whether the prefix field is set.
     */
    boolean hasPrefix();
    /**
     * <code>optional bytes prefix = 1;</code>
     * @return The prefix.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix();
  }
  /**
   * Protobuf type {@code hbase.pb.PrefixFilter}
   */
  @javax.annotation.Generated("proto") public static final class PrefixFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.PrefixFilter)
      PrefixFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PrefixFilter.newBuilder() to construct.
    private PrefixFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PrefixFilter() {
      prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PrefixFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PrefixFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PrefixFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.Builder.class);
    }

    private int bitField0_;
    public static final int PREFIX_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes prefix = 1;</code>
     * @return Whether the prefix field is set.
     */
    @java.lang.Override
    public boolean hasPrefix() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes prefix = 1;</code>
     * @return The prefix.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix() {
      return prefix_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, prefix_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, prefix_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter) obj;

      if (hasPrefix() != other.hasPrefix()) return false;
      if (hasPrefix()) {
        if (!getPrefix()
            .equals(other.getPrefix())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPrefix()) {
        hash = (37 * hash) + PREFIX_FIELD_NUMBER;
        hash = (53 * hash) + getPrefix().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.PrefixFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.PrefixFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PrefixFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PrefixFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_PrefixFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.prefix_ = prefix_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter.getDefaultInstance()) return this;
        if (other.hasPrefix()) {
          setPrefix(other.getPrefix());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                prefix_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString prefix_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes prefix = 1;</code>
       * @return Whether the prefix field is set.
       */
      @java.lang.Override
      public boolean hasPrefix() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes prefix = 1;</code>
       * @return The prefix.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getPrefix() {
        return prefix_;
      }
      /**
       * <code>optional bytes prefix = 1;</code>
       * @param value The prefix to set.
       * @return This builder for chaining.
       */
      public Builder setPrefix(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        prefix_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes prefix = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPrefix() {
        bitField0_ = (bitField0_ & ~0x00000001);
        prefix_ = getDefaultInstance().getPrefix();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.PrefixFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.PrefixFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrefixFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<PrefixFilter>() {
      @java.lang.Override
      public PrefixFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrefixFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<PrefixFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.PrefixFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface QualifierFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.QualifierFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    boolean hasCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.QualifierFilter}
   */
  @javax.annotation.Generated("proto") public static final class QualifierFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.QualifierFilter)
      QualifierFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use QualifierFilter.newBuilder() to construct.
    private QualifierFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private QualifierFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new QualifierFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_QualifierFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_QualifierFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    @java.lang.Override
    public boolean hasCompareFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCompareFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCompareFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCompareFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter) obj;

      if (hasCompareFilter() != other.hasCompareFilter()) return false;
      if (hasCompareFilter()) {
        if (!getCompareFilter()
            .equals(other.getCompareFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareFilter()) {
        hash = (37 * hash) + COMPARE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getCompareFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.QualifierFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.QualifierFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_QualifierFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_QualifierFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCompareFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_QualifierFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareFilter_ = compareFilterBuilder_ == null
              ? compareFilter_
              : compareFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter.getDefaultInstance()) return this;
        if (other.hasCompareFilter()) {
          mergeCompareFilter(other.getCompareFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareFilter()) {
          return false;
        }
        if (!getCompareFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCompareFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> compareFilterBuilder_;
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return Whether the compareFilter field is set.
       */
      public boolean hasCompareFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return The compareFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
        if (compareFilterBuilder_ == null) {
          return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        } else {
          return compareFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compareFilter_ = value;
        } else {
          compareFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder builderForValue) {
        if (compareFilterBuilder_ == null) {
          compareFilter_ = builderForValue.build();
        } else {
          compareFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder mergeCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            compareFilter_ != null &&
            compareFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) {
            getCompareFilterBuilder().mergeFrom(value);
          } else {
            compareFilter_ = value;
          }
        } else {
          compareFilterBuilder_.mergeFrom(value);
        }
        if (compareFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder clearCompareFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder getCompareFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCompareFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
        if (compareFilterBuilder_ != null) {
          return compareFilterBuilder_.getMessageOrBuilder();
        } else {
          return compareFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> 
          getCompareFilterFieldBuilder() {
        if (compareFilterBuilder_ == null) {
          compareFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder>(
                  getCompareFilter(),
                  getParentForChildren(),
                  isClean());
          compareFilter_ = null;
        }
        return compareFilterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.QualifierFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.QualifierFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<QualifierFilter>() {
      @java.lang.Override
      public QualifierFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<QualifierFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.QualifierFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RandomRowFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RandomRowFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required float chance = 1;</code>
     * @return Whether the chance field is set.
     */
    boolean hasChance();
    /**
     * <code>required float chance = 1;</code>
     * @return The chance.
     */
    float getChance();
  }
  /**
   * Protobuf type {@code hbase.pb.RandomRowFilter}
   */
  @javax.annotation.Generated("proto") public static final class RandomRowFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RandomRowFilter)
      RandomRowFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RandomRowFilter.newBuilder() to construct.
    private RandomRowFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RandomRowFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RandomRowFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RandomRowFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RandomRowFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.Builder.class);
    }

    private int bitField0_;
    public static final int CHANCE_FIELD_NUMBER = 1;
    private float chance_ = 0F;
    /**
     * <code>required float chance = 1;</code>
     * @return Whether the chance field is set.
     */
    @java.lang.Override
    public boolean hasChance() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required float chance = 1;</code>
     * @return The chance.
     */
    @java.lang.Override
    public float getChance() {
      return chance_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasChance()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeFloat(1, chance_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeFloatSize(1, chance_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter) obj;

      if (hasChance() != other.hasChance()) return false;
      if (hasChance()) {
        if (java.lang.Float.floatToIntBits(getChance())
            != java.lang.Float.floatToIntBits(
                other.getChance())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasChance()) {
        hash = (37 * hash) + CHANCE_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getChance());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RandomRowFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RandomRowFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RandomRowFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RandomRowFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        chance_ = 0F;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RandomRowFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.chance_ = chance_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter.getDefaultInstance()) return this;
        if (other.hasChance()) {
          setChance(other.getChance());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasChance()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 13: {
                chance_ = input.readFloat();
                bitField0_ |= 0x00000001;
                break;
              } // case 13
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private float chance_ ;
      /**
       * <code>required float chance = 1;</code>
       * @return Whether the chance field is set.
       */
      @java.lang.Override
      public boolean hasChance() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required float chance = 1;</code>
       * @return The chance.
       */
      @java.lang.Override
      public float getChance() {
        return chance_;
      }
      /**
       * <code>required float chance = 1;</code>
       * @param value The chance to set.
       * @return This builder for chaining.
       */
      public Builder setChance(float value) {

        chance_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required float chance = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearChance() {
        bitField0_ = (bitField0_ & ~0x00000001);
        chance_ = 0F;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RandomRowFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RandomRowFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RandomRowFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RandomRowFilter>() {
      @java.lang.Override
      public RandomRowFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RandomRowFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RandomRowFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RandomRowFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RowFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RowFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    boolean hasCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RowFilter}
   */
  @javax.annotation.Generated("proto") public static final class RowFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RowFilter)
      RowFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RowFilter.newBuilder() to construct.
    private RowFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RowFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RowFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    @java.lang.Override
    public boolean hasCompareFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCompareFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCompareFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCompareFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter) obj;

      if (hasCompareFilter() != other.hasCompareFilter()) return false;
      if (hasCompareFilter()) {
        if (!getCompareFilter()
            .equals(other.getCompareFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareFilter()) {
        hash = (37 * hash) + COMPARE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getCompareFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RowFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RowFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCompareFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareFilter_ = compareFilterBuilder_ == null
              ? compareFilter_
              : compareFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter.getDefaultInstance()) return this;
        if (other.hasCompareFilter()) {
          mergeCompareFilter(other.getCompareFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareFilter()) {
          return false;
        }
        if (!getCompareFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCompareFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> compareFilterBuilder_;
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return Whether the compareFilter field is set.
       */
      public boolean hasCompareFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return The compareFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
        if (compareFilterBuilder_ == null) {
          return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        } else {
          return compareFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compareFilter_ = value;
        } else {
          compareFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder builderForValue) {
        if (compareFilterBuilder_ == null) {
          compareFilter_ = builderForValue.build();
        } else {
          compareFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder mergeCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            compareFilter_ != null &&
            compareFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) {
            getCompareFilterBuilder().mergeFrom(value);
          } else {
            compareFilter_ = value;
          }
        } else {
          compareFilterBuilder_.mergeFrom(value);
        }
        if (compareFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder clearCompareFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder getCompareFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCompareFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
        if (compareFilterBuilder_ != null) {
          return compareFilterBuilder_.getMessageOrBuilder();
        } else {
          return compareFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> 
          getCompareFilterFieldBuilder() {
        if (compareFilterBuilder_ == null) {
          compareFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder>(
                  getCompareFilter(),
                  getParentForChildren(),
                  isClean());
          compareFilter_ = null;
        }
        return compareFilterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RowFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RowFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RowFilter>() {
      @java.lang.Override
      public RowFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SingleColumnValueExcludeFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SingleColumnValueExcludeFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     * @return Whether the singleColumnValueFilter field is set.
     */
    boolean hasSingleColumnValueFilter();
    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     * @return The singleColumnValueFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getSingleColumnValueFilter();
    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder getSingleColumnValueFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SingleColumnValueExcludeFilter}
   */
  @javax.annotation.Generated("proto") public static final class SingleColumnValueExcludeFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SingleColumnValueExcludeFilter)
      SingleColumnValueExcludeFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SingleColumnValueExcludeFilter.newBuilder() to construct.
    private SingleColumnValueExcludeFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SingleColumnValueExcludeFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SingleColumnValueExcludeFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueExcludeFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.Builder.class);
    }

    private int bitField0_;
    public static final int SINGLE_COLUMN_VALUE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter singleColumnValueFilter_;
    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     * @return Whether the singleColumnValueFilter field is set.
     */
    @java.lang.Override
    public boolean hasSingleColumnValueFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     * @return The singleColumnValueFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getSingleColumnValueFilter() {
      return singleColumnValueFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance() : singleColumnValueFilter_;
    }
    /**
     * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder getSingleColumnValueFilterOrBuilder() {
      return singleColumnValueFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance() : singleColumnValueFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasSingleColumnValueFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSingleColumnValueFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getSingleColumnValueFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSingleColumnValueFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter) obj;

      if (hasSingleColumnValueFilter() != other.hasSingleColumnValueFilter()) return false;
      if (hasSingleColumnValueFilter()) {
        if (!getSingleColumnValueFilter()
            .equals(other.getSingleColumnValueFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSingleColumnValueFilter()) {
        hash = (37 * hash) + SINGLE_COLUMN_VALUE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getSingleColumnValueFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SingleColumnValueExcludeFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SingleColumnValueExcludeFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueExcludeFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSingleColumnValueFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        singleColumnValueFilter_ = null;
        if (singleColumnValueFilterBuilder_ != null) {
          singleColumnValueFilterBuilder_.dispose();
          singleColumnValueFilterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.singleColumnValueFilter_ = singleColumnValueFilterBuilder_ == null
              ? singleColumnValueFilter_
              : singleColumnValueFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter.getDefaultInstance()) return this;
        if (other.hasSingleColumnValueFilter()) {
          mergeSingleColumnValueFilter(other.getSingleColumnValueFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasSingleColumnValueFilter()) {
          return false;
        }
        if (!getSingleColumnValueFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getSingleColumnValueFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter singleColumnValueFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder> singleColumnValueFilterBuilder_;
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       * @return Whether the singleColumnValueFilter field is set.
       */
      public boolean hasSingleColumnValueFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       * @return The singleColumnValueFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getSingleColumnValueFilter() {
        if (singleColumnValueFilterBuilder_ == null) {
          return singleColumnValueFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance() : singleColumnValueFilter_;
        } else {
          return singleColumnValueFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public Builder setSingleColumnValueFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter value) {
        if (singleColumnValueFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          singleColumnValueFilter_ = value;
        } else {
          singleColumnValueFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public Builder setSingleColumnValueFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder builderForValue) {
        if (singleColumnValueFilterBuilder_ == null) {
          singleColumnValueFilter_ = builderForValue.build();
        } else {
          singleColumnValueFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public Builder mergeSingleColumnValueFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter value) {
        if (singleColumnValueFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            singleColumnValueFilter_ != null &&
            singleColumnValueFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance()) {
            getSingleColumnValueFilterBuilder().mergeFrom(value);
          } else {
            singleColumnValueFilter_ = value;
          }
        } else {
          singleColumnValueFilterBuilder_.mergeFrom(value);
        }
        if (singleColumnValueFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public Builder clearSingleColumnValueFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        singleColumnValueFilter_ = null;
        if (singleColumnValueFilterBuilder_ != null) {
          singleColumnValueFilterBuilder_.dispose();
          singleColumnValueFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder getSingleColumnValueFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getSingleColumnValueFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder getSingleColumnValueFilterOrBuilder() {
        if (singleColumnValueFilterBuilder_ != null) {
          return singleColumnValueFilterBuilder_.getMessageOrBuilder();
        } else {
          return singleColumnValueFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance() : singleColumnValueFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.SingleColumnValueFilter single_column_value_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder> 
          getSingleColumnValueFilterFieldBuilder() {
        if (singleColumnValueFilterBuilder_ == null) {
          singleColumnValueFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder>(
                  getSingleColumnValueFilter(),
                  getParentForChildren(),
                  isClean());
          singleColumnValueFilter_ = null;
        }
        return singleColumnValueFilterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SingleColumnValueExcludeFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SingleColumnValueExcludeFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueExcludeFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SingleColumnValueExcludeFilter>() {
      @java.lang.Override
      public SingleColumnValueExcludeFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueExcludeFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueExcludeFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueExcludeFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SingleColumnValueFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SingleColumnValueFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes column_family = 1;</code>
     * @return Whether the columnFamily field is set.
     */
    boolean hasColumnFamily();
    /**
     * <code>optional bytes column_family = 1;</code>
     * @return The columnFamily.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily();

    /**
     * <code>optional bytes column_qualifier = 2;</code>
     * @return Whether the columnQualifier field is set.
     */
    boolean hasColumnQualifier();
    /**
     * <code>optional bytes column_qualifier = 2;</code>
     * @return The columnQualifier.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier();

    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return Whether the compareOp field is set.
     */
    boolean hasCompareOp();
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return The compareOp.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp();

    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return Whether the comparator field is set.
     */
    boolean hasComparator();
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return The comparator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator();
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();

    /**
     * <code>optional bool filter_if_missing = 5;</code>
     * @return Whether the filterIfMissing field is set.
     */
    boolean hasFilterIfMissing();
    /**
     * <code>optional bool filter_if_missing = 5;</code>
     * @return The filterIfMissing.
     */
    boolean getFilterIfMissing();

    /**
     * <code>optional bool latest_version_only = 6;</code>
     * @return Whether the latestVersionOnly field is set.
     */
    boolean hasLatestVersionOnly();
    /**
     * <code>optional bool latest_version_only = 6;</code>
     * @return The latestVersionOnly.
     */
    boolean getLatestVersionOnly();
  }
  /**
   * Protobuf type {@code hbase.pb.SingleColumnValueFilter}
   */
  @javax.annotation.Generated("proto") public static final class SingleColumnValueFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SingleColumnValueFilter)
      SingleColumnValueFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SingleColumnValueFilter.newBuilder() to construct.
    private SingleColumnValueFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SingleColumnValueFilter() {
      columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      compareOp_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SingleColumnValueFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COLUMN_FAMILY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes column_family = 1;</code>
     * @return Whether the columnFamily field is set.
     */
    @java.lang.Override
    public boolean hasColumnFamily() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes column_family = 1;</code>
     * @return The columnFamily.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily() {
      return columnFamily_;
    }

    public static final int COLUMN_QUALIFIER_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes column_qualifier = 2;</code>
     * @return Whether the columnQualifier field is set.
     */
    @java.lang.Override
    public boolean hasColumnQualifier() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes column_qualifier = 2;</code>
     * @return The columnQualifier.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier() {
      return columnQualifier_;
    }

    public static final int COMPARE_OP_FIELD_NUMBER = 3;
    private int compareOp_ = 0;
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return Whether the compareOp field is set.
     */
    @java.lang.Override public boolean hasCompareOp() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return The compareOp.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
    }

    public static final int COMPARATOR_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return Whether the comparator field is set.
     */
    @java.lang.Override
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return The comparator.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }

    public static final int FILTER_IF_MISSING_FIELD_NUMBER = 5;
    private boolean filterIfMissing_ = false;
    /**
     * <code>optional bool filter_if_missing = 5;</code>
     * @return Whether the filterIfMissing field is set.
     */
    @java.lang.Override
    public boolean hasFilterIfMissing() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional bool filter_if_missing = 5;</code>
     * @return The filterIfMissing.
     */
    @java.lang.Override
    public boolean getFilterIfMissing() {
      return filterIfMissing_;
    }

    public static final int LATEST_VERSION_ONLY_FIELD_NUMBER = 6;
    private boolean latestVersionOnly_ = false;
    /**
     * <code>optional bool latest_version_only = 6;</code>
     * @return Whether the latestVersionOnly field is set.
     */
    @java.lang.Override
    public boolean hasLatestVersionOnly() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool latest_version_only = 6;</code>
     * @return The latestVersionOnly.
     */
    @java.lang.Override
    public boolean getLatestVersionOnly() {
      return latestVersionOnly_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareOp()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasComparator()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getComparator().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, columnFamily_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, columnQualifier_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeEnum(3, compareOp_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getComparator());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBool(5, filterIfMissing_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(6, latestVersionOnly_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, columnFamily_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, columnQualifier_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, compareOp_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getComparator());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, filterIfMissing_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, latestVersionOnly_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter) obj;

      if (hasColumnFamily() != other.hasColumnFamily()) return false;
      if (hasColumnFamily()) {
        if (!getColumnFamily()
            .equals(other.getColumnFamily())) return false;
      }
      if (hasColumnQualifier() != other.hasColumnQualifier()) return false;
      if (hasColumnQualifier()) {
        if (!getColumnQualifier()
            .equals(other.getColumnQualifier())) return false;
      }
      if (hasCompareOp() != other.hasCompareOp()) return false;
      if (hasCompareOp()) {
        if (compareOp_ != other.compareOp_) return false;
      }
      if (hasComparator() != other.hasComparator()) return false;
      if (hasComparator()) {
        if (!getComparator()
            .equals(other.getComparator())) return false;
      }
      if (hasFilterIfMissing() != other.hasFilterIfMissing()) return false;
      if (hasFilterIfMissing()) {
        if (getFilterIfMissing()
            != other.getFilterIfMissing()) return false;
      }
      if (hasLatestVersionOnly() != other.hasLatestVersionOnly()) return false;
      if (hasLatestVersionOnly()) {
        if (getLatestVersionOnly()
            != other.getLatestVersionOnly()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasColumnFamily()) {
        hash = (37 * hash) + COLUMN_FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getColumnFamily().hashCode();
      }
      if (hasColumnQualifier()) {
        hash = (37 * hash) + COLUMN_QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getColumnQualifier().hashCode();
      }
      if (hasCompareOp()) {
        hash = (37 * hash) + COMPARE_OP_FIELD_NUMBER;
        hash = (53 * hash) + compareOp_;
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      if (hasFilterIfMissing()) {
        hash = (37 * hash) + FILTER_IF_MISSING_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getFilterIfMissing());
      }
      if (hasLatestVersionOnly()) {
        hash = (37 * hash) + LATEST_VERSION_ONLY_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getLatestVersionOnly());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SingleColumnValueFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SingleColumnValueFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        compareOp_ = 0;
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        filterIfMissing_ = false;
        latestVersionOnly_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SingleColumnValueFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.columnFamily_ = columnFamily_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.columnQualifier_ = columnQualifier_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.compareOp_ = compareOp_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.comparator_ = comparatorBuilder_ == null
              ? comparator_
              : comparatorBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.filterIfMissing_ = filterIfMissing_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.latestVersionOnly_ = latestVersionOnly_;
          to_bitField0_ |= 0x00000020;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter.getDefaultInstance()) return this;
        if (other.hasColumnFamily()) {
          setColumnFamily(other.getColumnFamily());
        }
        if (other.hasColumnQualifier()) {
          setColumnQualifier(other.getColumnQualifier());
        }
        if (other.hasCompareOp()) {
          setCompareOp(other.getCompareOp());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        if (other.hasFilterIfMissing()) {
          setFilterIfMissing(other.getFilterIfMissing());
        }
        if (other.hasLatestVersionOnly()) {
          setLatestVersionOnly(other.getLatestVersionOnly());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareOp()) {
          return false;
        }
        if (!hasComparator()) {
          return false;
        }
        if (!getComparator().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                columnFamily_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                columnQualifier_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(3, tmpRaw);
                } else {
                  compareOp_ = tmpRaw;
                  bitField0_ |= 0x00000004;
                }
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getComparatorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 40: {
                filterIfMissing_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 48: {
                latestVersionOnly_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnFamily_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes column_family = 1;</code>
       * @return Whether the columnFamily field is set.
       */
      @java.lang.Override
      public boolean hasColumnFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes column_family = 1;</code>
       * @return The columnFamily.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnFamily() {
        return columnFamily_;
      }
      /**
       * <code>optional bytes column_family = 1;</code>
       * @param value The columnFamily to set.
       * @return This builder for chaining.
       */
      public Builder setColumnFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        columnFamily_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes column_family = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        columnFamily_ = getDefaultInstance().getColumnFamily();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString columnQualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes column_qualifier = 2;</code>
       * @return Whether the columnQualifier field is set.
       */
      @java.lang.Override
      public boolean hasColumnQualifier() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes column_qualifier = 2;</code>
       * @return The columnQualifier.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getColumnQualifier() {
        return columnQualifier_;
      }
      /**
       * <code>optional bytes column_qualifier = 2;</code>
       * @param value The columnQualifier to set.
       * @return This builder for chaining.
       */
      public Builder setColumnQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        columnQualifier_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes column_qualifier = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnQualifier() {
        bitField0_ = (bitField0_ & ~0x00000002);
        columnQualifier_ = getDefaultInstance().getColumnQualifier();
        onChanged();
        return this;
      }

      private int compareOp_ = 0;
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return Whether the compareOp field is set.
       */
      @java.lang.Override public boolean hasCompareOp() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return The compareOp.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @param value The compareOp to set.
       * @return This builder for chaining.
       */
      public Builder setCompareOp(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        compareOp_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompareOp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        compareOp_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       * @return Whether the comparator field is set.
       */
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       * @return The comparator.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder setComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder setComparator(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder mergeComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            comparator_ != null &&
            comparator_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            getComparatorBuilder().mergeFrom(value);
          } else {
            comparator_ = value;
          }
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        if (comparator_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder clearComparator() {
        bitField0_ = (bitField0_ & ~0x00000008);
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        }
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  getComparator(),
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }

      private boolean filterIfMissing_ ;
      /**
       * <code>optional bool filter_if_missing = 5;</code>
       * @return Whether the filterIfMissing field is set.
       */
      @java.lang.Override
      public boolean hasFilterIfMissing() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional bool filter_if_missing = 5;</code>
       * @return The filterIfMissing.
       */
      @java.lang.Override
      public boolean getFilterIfMissing() {
        return filterIfMissing_;
      }
      /**
       * <code>optional bool filter_if_missing = 5;</code>
       * @param value The filterIfMissing to set.
       * @return This builder for chaining.
       */
      public Builder setFilterIfMissing(boolean value) {

        filterIfMissing_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool filter_if_missing = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearFilterIfMissing() {
        bitField0_ = (bitField0_ & ~0x00000010);
        filterIfMissing_ = false;
        onChanged();
        return this;
      }

      private boolean latestVersionOnly_ ;
      /**
       * <code>optional bool latest_version_only = 6;</code>
       * @return Whether the latestVersionOnly field is set.
       */
      @java.lang.Override
      public boolean hasLatestVersionOnly() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool latest_version_only = 6;</code>
       * @return The latestVersionOnly.
       */
      @java.lang.Override
      public boolean getLatestVersionOnly() {
        return latestVersionOnly_;
      }
      /**
       * <code>optional bool latest_version_only = 6;</code>
       * @param value The latestVersionOnly to set.
       * @return This builder for chaining.
       */
      public Builder setLatestVersionOnly(boolean value) {

        latestVersionOnly_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool latest_version_only = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearLatestVersionOnly() {
        bitField0_ = (bitField0_ & ~0x00000020);
        latestVersionOnly_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SingleColumnValueFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SingleColumnValueFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SingleColumnValueFilter>() {
      @java.lang.Override
      public SingleColumnValueFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SingleColumnValueFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SingleColumnValueFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SkipFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SkipFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.SkipFilter}
   */
  @javax.annotation.Generated("proto") public static final class SkipFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SkipFilter)
      SkipFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SkipFilter.newBuilder() to construct.
    private SkipFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SkipFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SkipFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SkipFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SkipFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.Builder.class);
    }

    private int bitField0_;
    public static final int FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter) obj;

      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.SkipFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SkipFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SkipFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SkipFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_SkipFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter.getDefaultInstance()) return this;
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFilter()) {
          return false;
        }
        if (!getFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SkipFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SkipFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SkipFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SkipFilter>() {
      @java.lang.Override
      public SkipFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SkipFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SkipFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.SkipFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TimestampsFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TimestampsFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @return A list containing the timestamps.
     */
    java.util.List<java.lang.Long> getTimestampsList();
    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @return The count of timestamps.
     */
    int getTimestampsCount();
    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @param index The index of the element to return.
     * @return The timestamps at the given index.
     */
    long getTimestamps(int index);

    /**
     * <code>optional bool can_hint = 2;</code>
     * @return Whether the canHint field is set.
     */
    boolean hasCanHint();
    /**
     * <code>optional bool can_hint = 2;</code>
     * @return The canHint.
     */
    boolean getCanHint();
  }
  /**
   * Protobuf type {@code hbase.pb.TimestampsFilter}
   */
  @javax.annotation.Generated("proto") public static final class TimestampsFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TimestampsFilter)
      TimestampsFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TimestampsFilter.newBuilder() to construct.
    private TimestampsFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TimestampsFilter() {
      timestamps_ = emptyLongList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TimestampsFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_TimestampsFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_TimestampsFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.Builder.class);
    }

    private int bitField0_;
    public static final int TIMESTAMPS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.LongList timestamps_ =
        emptyLongList();
    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @return A list containing the timestamps.
     */
    @java.lang.Override
    public java.util.List<java.lang.Long>
        getTimestampsList() {
      return timestamps_;
    }
    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @return The count of timestamps.
     */
    public int getTimestampsCount() {
      return timestamps_.size();
    }
    /**
     * <code>repeated int64 timestamps = 1 [packed = true];</code>
     * @param index The index of the element to return.
     * @return The timestamps at the given index.
     */
    public long getTimestamps(int index) {
      return timestamps_.getLong(index);
    }
    private int timestampsMemoizedSerializedSize = -1;

    public static final int CAN_HINT_FIELD_NUMBER = 2;
    private boolean canHint_ = false;
    /**
     * <code>optional bool can_hint = 2;</code>
     * @return Whether the canHint field is set.
     */
    @java.lang.Override
    public boolean hasCanHint() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bool can_hint = 2;</code>
     * @return The canHint.
     */
    @java.lang.Override
    public boolean getCanHint() {
      return canHint_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (getTimestampsList().size() > 0) {
        output.writeUInt32NoTag(10);
        output.writeUInt32NoTag(timestampsMemoizedSerializedSize);
      }
      for (int i = 0; i < timestamps_.size(); i++) {
        output.writeInt64NoTag(timestamps_.getLong(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(2, canHint_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < timestamps_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeInt64SizeNoTag(timestamps_.getLong(i));
        }
        size += dataSize;
        if (!getTimestampsList().isEmpty()) {
          size += 1;
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        timestampsMemoizedSerializedSize = dataSize;
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, canHint_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter) obj;

      if (!getTimestampsList()
          .equals(other.getTimestampsList())) return false;
      if (hasCanHint() != other.hasCanHint()) return false;
      if (hasCanHint()) {
        if (getCanHint()
            != other.getCanHint()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getTimestampsCount() > 0) {
        hash = (37 * hash) + TIMESTAMPS_FIELD_NUMBER;
        hash = (53 * hash) + getTimestampsList().hashCode();
      }
      if (hasCanHint()) {
        hash = (37 * hash) + CAN_HINT_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCanHint());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TimestampsFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TimestampsFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_TimestampsFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_TimestampsFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        timestamps_ = emptyLongList();
        canHint_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_TimestampsFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          timestamps_.makeImmutable();
          result.timestamps_ = timestamps_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.canHint_ = canHint_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter.getDefaultInstance()) return this;
        if (!other.timestamps_.isEmpty()) {
          if (timestamps_.isEmpty()) {
            timestamps_ = other.timestamps_;
            timestamps_.makeImmutable();
            bitField0_ |= 0x00000001;
          } else {
            ensureTimestampsIsMutable();
            timestamps_.addAll(other.timestamps_);
          }
          onChanged();
        }
        if (other.hasCanHint()) {
          setCanHint(other.getCanHint());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                long v = input.readInt64();
                ensureTimestampsIsMutable();
                timestamps_.addLong(v);
                break;
              } // case 8
              case 10: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                ensureTimestampsIsMutable();
                while (input.getBytesUntilLimit() > 0) {
                  timestamps_.addLong(input.readInt64());
                }
                input.popLimit(limit);
                break;
              } // case 10
              case 16: {
                canHint_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.LongList timestamps_ = emptyLongList();
      private void ensureTimestampsIsMutable() {
        if (!timestamps_.isModifiable()) {
          timestamps_ = makeMutableCopy(timestamps_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @return A list containing the timestamps.
       */
      public java.util.List<java.lang.Long>
          getTimestampsList() {
        timestamps_.makeImmutable();
        return timestamps_;
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @return The count of timestamps.
       */
      public int getTimestampsCount() {
        return timestamps_.size();
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @param index The index of the element to return.
       * @return The timestamps at the given index.
       */
      public long getTimestamps(int index) {
        return timestamps_.getLong(index);
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @param index The index to set the value at.
       * @param value The timestamps to set.
       * @return This builder for chaining.
       */
      public Builder setTimestamps(
          int index, long value) {

        ensureTimestampsIsMutable();
        timestamps_.setLong(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @param value The timestamps to add.
       * @return This builder for chaining.
       */
      public Builder addTimestamps(long value) {

        ensureTimestampsIsMutable();
        timestamps_.addLong(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @param values The timestamps to add.
       * @return This builder for chaining.
       */
      public Builder addAllTimestamps(
          java.lang.Iterable<? extends java.lang.Long> values) {
        ensureTimestampsIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, timestamps_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated int64 timestamps = 1 [packed = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearTimestamps() {
        timestamps_ = emptyLongList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      private boolean canHint_ ;
      /**
       * <code>optional bool can_hint = 2;</code>
       * @return Whether the canHint field is set.
       */
      @java.lang.Override
      public boolean hasCanHint() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool can_hint = 2;</code>
       * @return The canHint.
       */
      @java.lang.Override
      public boolean getCanHint() {
        return canHint_;
      }
      /**
       * <code>optional bool can_hint = 2;</code>
       * @param value The canHint to set.
       * @return This builder for chaining.
       */
      public Builder setCanHint(boolean value) {

        canHint_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool can_hint = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearCanHint() {
        bitField0_ = (bitField0_ & ~0x00000002);
        canHint_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TimestampsFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TimestampsFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<TimestampsFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<TimestampsFilter>() {
      @java.lang.Override
      public TimestampsFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<TimestampsFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<TimestampsFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.TimestampsFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ValueFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ValueFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    boolean hasCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter();
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ValueFilter}
   */
  @javax.annotation.Generated("proto") public static final class ValueFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ValueFilter)
      ValueFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ValueFilter.newBuilder() to construct.
    private ValueFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ValueFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ValueFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ValueFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ValueFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.Builder.class);
    }

    private int bitField0_;
    public static final int COMPARE_FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return Whether the compareFilter field is set.
     */
    @java.lang.Override
    public boolean hasCompareFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     * @return The compareFilter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }
    /**
     * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
      return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasCompareFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCompareFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getCompareFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCompareFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter) obj;

      if (hasCompareFilter() != other.hasCompareFilter()) return false;
      if (hasCompareFilter()) {
        if (!getCompareFilter()
            .equals(other.getCompareFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCompareFilter()) {
        hash = (37 * hash) + COMPARE_FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getCompareFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ValueFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ValueFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ValueFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ValueFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCompareFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ValueFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.compareFilter_ = compareFilterBuilder_ == null
              ? compareFilter_
              : compareFilterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter.getDefaultInstance()) return this;
        if (other.hasCompareFilter()) {
          mergeCompareFilter(other.getCompareFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasCompareFilter()) {
          return false;
        }
        if (!getCompareFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getCompareFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter compareFilter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> compareFilterBuilder_;
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return Whether the compareFilter field is set.
       */
      public boolean hasCompareFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       * @return The compareFilter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter getCompareFilter() {
        if (compareFilterBuilder_ == null) {
          return compareFilter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        } else {
          return compareFilterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compareFilter_ = value;
        } else {
          compareFilterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder setCompareFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder builderForValue) {
        if (compareFilterBuilder_ == null) {
          compareFilter_ = builderForValue.build();
        } else {
          compareFilterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder mergeCompareFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter value) {
        if (compareFilterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            compareFilter_ != null &&
            compareFilter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance()) {
            getCompareFilterBuilder().mergeFrom(value);
          } else {
            compareFilter_ = value;
          }
        } else {
          compareFilterBuilder_.mergeFrom(value);
        }
        if (compareFilter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public Builder clearCompareFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        compareFilter_ = null;
        if (compareFilterBuilder_ != null) {
          compareFilterBuilder_.dispose();
          compareFilterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder getCompareFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCompareFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder getCompareFilterOrBuilder() {
        if (compareFilterBuilder_ != null) {
          return compareFilterBuilder_.getMessageOrBuilder();
        } else {
          return compareFilter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.getDefaultInstance() : compareFilter_;
        }
      }
      /**
       * <code>required .hbase.pb.CompareFilter compare_filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder> 
          getCompareFilterFieldBuilder() {
        if (compareFilterBuilder_ == null) {
          compareFilterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.CompareFilterOrBuilder>(
                  getCompareFilter(),
                  getParentForChildren(),
                  isClean());
          compareFilter_ = null;
        }
        return compareFilterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ValueFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ValueFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ValueFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ValueFilter>() {
      @java.lang.Override
      public ValueFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ValueFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ValueFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ValueFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WhileMatchFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WhileMatchFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    boolean hasFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.WhileMatchFilter}
   */
  @javax.annotation.Generated("proto") public static final class WhileMatchFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WhileMatchFilter)
      WhileMatchFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WhileMatchFilter.newBuilder() to construct.
    private WhileMatchFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WhileMatchFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WhileMatchFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_WhileMatchFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_WhileMatchFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.Builder.class);
    }

    private int bitField0_;
    public static final int FILTER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return Whether the filter field is set.
     */
    @java.lang.Override
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     * @return The filter.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }
    /**
     * <code>required .hbase.pb.Filter filter = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFilter()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getFilter().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getFilter());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getFilter());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter) obj;

      if (hasFilter() != other.hasFilter()) return false;
      if (hasFilter()) {
        if (!getFilter()
            .equals(other.getFilter())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.WhileMatchFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WhileMatchFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_WhileMatchFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_WhileMatchFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getFilterFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_WhileMatchFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.filter_ = filterBuilder_ == null
              ? filter_
              : filterBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter.getDefaultInstance()) return this;
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFilter()) {
          return false;
        }
        if (!getFilter().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getFilterFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter filter_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return Whether the filter field is set.
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       * @return The filter.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            filter_ != null &&
            filter_ != org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            getFilterBuilder().mergeFrom(value);
          } else {
            filter_ = value;
          }
        } else {
          filterBuilder_.mergeFrom(value);
        }
        if (filter_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public Builder clearFilter() {
        bitField0_ = (bitField0_ & ~0x00000001);
        filter_ = null;
        if (filterBuilder_ != null) {
          filterBuilder_.dispose();
          filterBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.getDefaultInstance() : filter_;
        }
      }
      /**
       * <code>required .hbase.pb.Filter filter = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  getFilter(),
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WhileMatchFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WhileMatchFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WhileMatchFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WhileMatchFilter>() {
      @java.lang.Override
      public WhileMatchFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WhileMatchFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WhileMatchFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.WhileMatchFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FilterAllFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FilterAllFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.FilterAllFilter}
   */
  @javax.annotation.Generated("proto") public static final class FilterAllFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FilterAllFilter)
      FilterAllFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FilterAllFilter.newBuilder() to construct.
    private FilterAllFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FilterAllFilter() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FilterAllFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterAllFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterAllFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FilterAllFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FilterAllFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterAllFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterAllFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_FilterAllFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FilterAllFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FilterAllFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterAllFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FilterAllFilter>() {
      @java.lang.Override
      public FilterAllFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterAllFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FilterAllFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.FilterAllFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RowRangeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RowRange)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bytes start_row = 1;</code>
     * @return Whether the startRow field is set.
     */
    boolean hasStartRow();
    /**
     * <code>optional bytes start_row = 1;</code>
     * @return The startRow.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow();

    /**
     * <code>optional bool start_row_inclusive = 2;</code>
     * @return Whether the startRowInclusive field is set.
     */
    boolean hasStartRowInclusive();
    /**
     * <code>optional bool start_row_inclusive = 2;</code>
     * @return The startRowInclusive.
     */
    boolean getStartRowInclusive();

    /**
     * <code>optional bytes stop_row = 3;</code>
     * @return Whether the stopRow field is set.
     */
    boolean hasStopRow();
    /**
     * <code>optional bytes stop_row = 3;</code>
     * @return The stopRow.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow();

    /**
     * <code>optional bool stop_row_inclusive = 4;</code>
     * @return Whether the stopRowInclusive field is set.
     */
    boolean hasStopRowInclusive();
    /**
     * <code>optional bool stop_row_inclusive = 4;</code>
     * @return The stopRowInclusive.
     */
    boolean getStopRowInclusive();
  }
  /**
   * Protobuf type {@code hbase.pb.RowRange}
   */
  @javax.annotation.Generated("proto") public static final class RowRange extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RowRange)
      RowRangeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RowRange.newBuilder() to construct.
    private RowRange(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RowRange() {
      startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RowRange();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowRange_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowRange_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder.class);
    }

    private int bitField0_;
    public static final int START_ROW_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes start_row = 1;</code>
     * @return Whether the startRow field is set.
     */
    @java.lang.Override
    public boolean hasStartRow() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bytes start_row = 1;</code>
     * @return The startRow.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow() {
      return startRow_;
    }

    public static final int START_ROW_INCLUSIVE_FIELD_NUMBER = 2;
    private boolean startRowInclusive_ = false;
    /**
     * <code>optional bool start_row_inclusive = 2;</code>
     * @return Whether the startRowInclusive field is set.
     */
    @java.lang.Override
    public boolean hasStartRowInclusive() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool start_row_inclusive = 2;</code>
     * @return The startRowInclusive.
     */
    @java.lang.Override
    public boolean getStartRowInclusive() {
      return startRowInclusive_;
    }

    public static final int STOP_ROW_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes stop_row = 3;</code>
     * @return Whether the stopRow field is set.
     */
    @java.lang.Override
    public boolean hasStopRow() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes stop_row = 3;</code>
     * @return The stopRow.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow() {
      return stopRow_;
    }

    public static final int STOP_ROW_INCLUSIVE_FIELD_NUMBER = 4;
    private boolean stopRowInclusive_ = false;
    /**
     * <code>optional bool stop_row_inclusive = 4;</code>
     * @return Whether the stopRowInclusive field is set.
     */
    @java.lang.Override
    public boolean hasStopRowInclusive() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool stop_row_inclusive = 4;</code>
     * @return The stopRowInclusive.
     */
    @java.lang.Override
    public boolean getStopRowInclusive() {
      return stopRowInclusive_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, startRow_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, startRowInclusive_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, stopRow_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(4, stopRowInclusive_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, startRow_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, startRowInclusive_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, stopRow_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, stopRowInclusive_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange) obj;

      if (hasStartRow() != other.hasStartRow()) return false;
      if (hasStartRow()) {
        if (!getStartRow()
            .equals(other.getStartRow())) return false;
      }
      if (hasStartRowInclusive() != other.hasStartRowInclusive()) return false;
      if (hasStartRowInclusive()) {
        if (getStartRowInclusive()
            != other.getStartRowInclusive()) return false;
      }
      if (hasStopRow() != other.hasStopRow()) return false;
      if (hasStopRow()) {
        if (!getStopRow()
            .equals(other.getStopRow())) return false;
      }
      if (hasStopRowInclusive() != other.hasStopRowInclusive()) return false;
      if (hasStopRowInclusive()) {
        if (getStopRowInclusive()
            != other.getStopRowInclusive()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStartRow()) {
        hash = (37 * hash) + START_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStartRow().hashCode();
      }
      if (hasStartRowInclusive()) {
        hash = (37 * hash) + START_ROW_INCLUSIVE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getStartRowInclusive());
      }
      if (hasStopRow()) {
        hash = (37 * hash) + STOP_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStopRow().hashCode();
      }
      if (hasStopRowInclusive()) {
        hash = (37 * hash) + STOP_ROW_INCLUSIVE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getStopRowInclusive());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RowRange}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RowRange)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowRange_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowRange_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        startRowInclusive_ = false;
        stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        stopRowInclusive_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_RowRange_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.startRow_ = startRow_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.startRowInclusive_ = startRowInclusive_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.stopRow_ = stopRow_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.stopRowInclusive_ = stopRowInclusive_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.getDefaultInstance()) return this;
        if (other.hasStartRow()) {
          setStartRow(other.getStartRow());
        }
        if (other.hasStartRowInclusive()) {
          setStartRowInclusive(other.getStartRowInclusive());
        }
        if (other.hasStopRow()) {
          setStopRow(other.getStopRow());
        }
        if (other.hasStopRowInclusive()) {
          setStopRowInclusive(other.getStopRowInclusive());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                startRow_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                startRowInclusive_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                stopRow_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                stopRowInclusive_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString startRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes start_row = 1;</code>
       * @return Whether the startRow field is set.
       */
      @java.lang.Override
      public boolean hasStartRow() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bytes start_row = 1;</code>
       * @return The startRow.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStartRow() {
        return startRow_;
      }
      /**
       * <code>optional bytes start_row = 1;</code>
       * @param value The startRow to set.
       * @return This builder for chaining.
       */
      public Builder setStartRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        startRow_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes start_row = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearStartRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        startRow_ = getDefaultInstance().getStartRow();
        onChanged();
        return this;
      }

      private boolean startRowInclusive_ ;
      /**
       * <code>optional bool start_row_inclusive = 2;</code>
       * @return Whether the startRowInclusive field is set.
       */
      @java.lang.Override
      public boolean hasStartRowInclusive() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool start_row_inclusive = 2;</code>
       * @return The startRowInclusive.
       */
      @java.lang.Override
      public boolean getStartRowInclusive() {
        return startRowInclusive_;
      }
      /**
       * <code>optional bool start_row_inclusive = 2;</code>
       * @param value The startRowInclusive to set.
       * @return This builder for chaining.
       */
      public Builder setStartRowInclusive(boolean value) {

        startRowInclusive_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool start_row_inclusive = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearStartRowInclusive() {
        bitField0_ = (bitField0_ & ~0x00000002);
        startRowInclusive_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString stopRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes stop_row = 3;</code>
       * @return Whether the stopRow field is set.
       */
      @java.lang.Override
      public boolean hasStopRow() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes stop_row = 3;</code>
       * @return The stopRow.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getStopRow() {
        return stopRow_;
      }
      /**
       * <code>optional bytes stop_row = 3;</code>
       * @param value The stopRow to set.
       * @return This builder for chaining.
       */
      public Builder setStopRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        stopRow_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes stop_row = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearStopRow() {
        bitField0_ = (bitField0_ & ~0x00000004);
        stopRow_ = getDefaultInstance().getStopRow();
        onChanged();
        return this;
      }

      private boolean stopRowInclusive_ ;
      /**
       * <code>optional bool stop_row_inclusive = 4;</code>
       * @return Whether the stopRowInclusive field is set.
       */
      @java.lang.Override
      public boolean hasStopRowInclusive() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bool stop_row_inclusive = 4;</code>
       * @return The stopRowInclusive.
       */
      @java.lang.Override
      public boolean getStopRowInclusive() {
        return stopRowInclusive_;
      }
      /**
       * <code>optional bool stop_row_inclusive = 4;</code>
       * @param value The stopRowInclusive to set.
       * @return This builder for chaining.
       */
      public Builder setStopRowInclusive(boolean value) {

        stopRowInclusive_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool stop_row_inclusive = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearStopRowInclusive() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stopRowInclusive_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RowRange)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RowRange)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowRange>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RowRange>() {
      @java.lang.Override
      public RowRange parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowRange> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RowRange> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MultiRowRangeFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.MultiRowRangeFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> 
        getRowRangeListList();
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getRowRangeList(int index);
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    int getRowRangeListCount();
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder> 
        getRowRangeListOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder getRowRangeListOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.MultiRowRangeFilter}
   */
  @javax.annotation.Generated("proto") public static final class MultiRowRangeFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.MultiRowRangeFilter)
      MultiRowRangeFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use MultiRowRangeFilter.newBuilder() to construct.
    private MultiRowRangeFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private MultiRowRangeFilter() {
      rowRangeList_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new MultiRowRangeFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultiRowRangeFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultiRowRangeFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.Builder.class);
    }

    public static final int ROW_RANGE_LIST_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> rowRangeList_;
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> getRowRangeListList() {
      return rowRangeList_;
    }
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder> 
        getRowRangeListOrBuilderList() {
      return rowRangeList_;
    }
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    @java.lang.Override
    public int getRowRangeListCount() {
      return rowRangeList_.size();
    }
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getRowRangeList(int index) {
      return rowRangeList_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder getRowRangeListOrBuilder(
        int index) {
      return rowRangeList_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < rowRangeList_.size(); i++) {
        output.writeMessage(1, rowRangeList_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < rowRangeList_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, rowRangeList_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter) obj;

      if (!getRowRangeListList()
          .equals(other.getRowRangeListList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRowRangeListCount() > 0) {
        hash = (37 * hash) + ROW_RANGE_LIST_FIELD_NUMBER;
        hash = (53 * hash) + getRowRangeListList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.MultiRowRangeFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.MultiRowRangeFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultiRowRangeFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultiRowRangeFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (rowRangeListBuilder_ == null) {
          rowRangeList_ = java.util.Collections.emptyList();
        } else {
          rowRangeList_ = null;
          rowRangeListBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_MultiRowRangeFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter result) {
        if (rowRangeListBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            rowRangeList_ = java.util.Collections.unmodifiableList(rowRangeList_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.rowRangeList_ = rowRangeList_;
        } else {
          result.rowRangeList_ = rowRangeListBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter.getDefaultInstance()) return this;
        if (rowRangeListBuilder_ == null) {
          if (!other.rowRangeList_.isEmpty()) {
            if (rowRangeList_.isEmpty()) {
              rowRangeList_ = other.rowRangeList_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRowRangeListIsMutable();
              rowRangeList_.addAll(other.rowRangeList_);
            }
            onChanged();
          }
        } else {
          if (!other.rowRangeList_.isEmpty()) {
            if (rowRangeListBuilder_.isEmpty()) {
              rowRangeListBuilder_.dispose();
              rowRangeListBuilder_ = null;
              rowRangeList_ = other.rowRangeList_;
              bitField0_ = (bitField0_ & ~0x00000001);
              rowRangeListBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRowRangeListFieldBuilder() : null;
            } else {
              rowRangeListBuilder_.addAllMessages(other.rowRangeList_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.PARSER,
                        extensionRegistry);
                if (rowRangeListBuilder_ == null) {
                  ensureRowRangeListIsMutable();
                  rowRangeList_.add(m);
                } else {
                  rowRangeListBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> rowRangeList_ =
        java.util.Collections.emptyList();
      private void ensureRowRangeListIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          rowRangeList_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange>(rowRangeList_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder> rowRangeListBuilder_;

      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> getRowRangeListList() {
        if (rowRangeListBuilder_ == null) {
          return java.util.Collections.unmodifiableList(rowRangeList_);
        } else {
          return rowRangeListBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public int getRowRangeListCount() {
        if (rowRangeListBuilder_ == null) {
          return rowRangeList_.size();
        } else {
          return rowRangeListBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange getRowRangeList(int index) {
        if (rowRangeListBuilder_ == null) {
          return rowRangeList_.get(index);
        } else {
          return rowRangeListBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder setRowRangeList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange value) {
        if (rowRangeListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRowRangeListIsMutable();
          rowRangeList_.set(index, value);
          onChanged();
        } else {
          rowRangeListBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder setRowRangeList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder builderForValue) {
        if (rowRangeListBuilder_ == null) {
          ensureRowRangeListIsMutable();
          rowRangeList_.set(index, builderForValue.build());
          onChanged();
        } else {
          rowRangeListBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder addRowRangeList(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange value) {
        if (rowRangeListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRowRangeListIsMutable();
          rowRangeList_.add(value);
          onChanged();
        } else {
          rowRangeListBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder addRowRangeList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange value) {
        if (rowRangeListBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRowRangeListIsMutable();
          rowRangeList_.add(index, value);
          onChanged();
        } else {
          rowRangeListBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder addRowRangeList(
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder builderForValue) {
        if (rowRangeListBuilder_ == null) {
          ensureRowRangeListIsMutable();
          rowRangeList_.add(builderForValue.build());
          onChanged();
        } else {
          rowRangeListBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder addRowRangeList(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder builderForValue) {
        if (rowRangeListBuilder_ == null) {
          ensureRowRangeListIsMutable();
          rowRangeList_.add(index, builderForValue.build());
          onChanged();
        } else {
          rowRangeListBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder addAllRowRangeList(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange> values) {
        if (rowRangeListBuilder_ == null) {
          ensureRowRangeListIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, rowRangeList_);
          onChanged();
        } else {
          rowRangeListBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder clearRowRangeList() {
        if (rowRangeListBuilder_ == null) {
          rowRangeList_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          rowRangeListBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public Builder removeRowRangeList(int index) {
        if (rowRangeListBuilder_ == null) {
          ensureRowRangeListIsMutable();
          rowRangeList_.remove(index);
          onChanged();
        } else {
          rowRangeListBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder getRowRangeListBuilder(
          int index) {
        return getRowRangeListFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder getRowRangeListOrBuilder(
          int index) {
        if (rowRangeListBuilder_ == null) {
          return rowRangeList_.get(index);  } else {
          return rowRangeListBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder> 
           getRowRangeListOrBuilderList() {
        if (rowRangeListBuilder_ != null) {
          return rowRangeListBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(rowRangeList_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder addRowRangeListBuilder() {
        return getRowRangeListFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder addRowRangeListBuilder(
          int index) {
        return getRowRangeListFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RowRange row_range_list = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder> 
           getRowRangeListBuilderList() {
        return getRowRangeListFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder> 
          getRowRangeListFieldBuilder() {
        if (rowRangeListBuilder_ == null) {
          rowRangeListBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRange.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.RowRangeOrBuilder>(
                  rowRangeList_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          rowRangeList_ = null;
        }
        return rowRangeListBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.MultiRowRangeFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.MultiRowRangeFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRowRangeFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<MultiRowRangeFilter>() {
      @java.lang.Override
      public MultiRowRangeFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRowRangeFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<MultiRowRangeFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.MultiRowRangeFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ColumnValueFilterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ColumnValueFilter)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

    /**
     * <code>required bytes qualifier = 2;</code>
     * @return Whether the qualifier field is set.
     */
    boolean hasQualifier();
    /**
     * <code>required bytes qualifier = 2;</code>
     * @return The qualifier.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier();

    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return Whether the compareOp field is set.
     */
    boolean hasCompareOp();
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return The compareOp.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp();

    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return Whether the comparator field is set.
     */
    boolean hasComparator();
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return The comparator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator();
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ColumnValueFilter}
   */
  @javax.annotation.Generated("proto") public static final class ColumnValueFilter extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ColumnValueFilter)
      ColumnValueFilterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ColumnValueFilter.newBuilder() to construct.
    private ColumnValueFilter(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ColumnValueFilter() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      compareOp_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ColumnValueFilter();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnValueFilter_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnValueFilter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.Builder.class);
    }

    private int bitField0_;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    public static final int QUALIFIER_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes qualifier = 2;</code>
     * @return Whether the qualifier field is set.
     */
    @java.lang.Override
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes qualifier = 2;</code>
     * @return The qualifier.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    public static final int COMPARE_OP_FIELD_NUMBER = 3;
    private int compareOp_ = 0;
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return Whether the compareOp field is set.
     */
    @java.lang.Override public boolean hasCompareOp() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.CompareType compare_op = 3;</code>
     * @return The compareOp.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
    }

    public static final int COMPARATOR_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return Whether the comparator field is set.
     */
    @java.lang.Override
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     * @return The comparator.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }
    /**
     * <code>required .hbase.pb.Comparator comparator = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQualifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCompareOp()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasComparator()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getComparator().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, family_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, qualifier_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeEnum(3, compareOp_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getComparator());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, qualifier_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, compareOp_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getComparator());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter other = (org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter) obj;

      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (hasQualifier() != other.hasQualifier()) return false;
      if (hasQualifier()) {
        if (!getQualifier()
            .equals(other.getQualifier())) return false;
      }
      if (hasCompareOp() != other.hasCompareOp()) return false;
      if (hasCompareOp()) {
        if (compareOp_ != other.compareOp_) return false;
      }
      if (hasComparator() != other.hasComparator()) return false;
      if (hasComparator()) {
        if (!getComparator()
            .equals(other.getComparator())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasCompareOp()) {
        hash = (37 * hash) + COMPARE_OP_FIELD_NUMBER;
        hash = (53 * hash) + compareOp_;
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ColumnValueFilter}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ColumnValueFilter)
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilterOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnValueFilter_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnValueFilter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.class, org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        compareOp_ = 0;
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.internal_static_hbase_pb_ColumnValueFilter_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter result = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.qualifier_ = qualifier_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.compareOp_ = compareOp_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.comparator_ = comparatorBuilder_ == null
              ? comparator_
              : comparatorBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasCompareOp()) {
          setCompareOp(other.getCompareOp());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFamily()) {
          return false;
        }
        if (!hasQualifier()) {
          return false;
        }
        if (!hasCompareOp()) {
          return false;
        }
        if (!hasComparator()) {
          return false;
        }
        if (!getComparator().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                qualifier_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(3, tmpRaw);
                } else {
                  compareOp_ = tmpRaw;
                  bitField0_ |= 0x00000004;
                }
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getComparatorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString qualifier_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes qualifier = 2;</code>
       * @return Whether the qualifier field is set.
       */
      @java.lang.Override
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes qualifier = 2;</code>
       * @return The qualifier.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>required bytes qualifier = 2;</code>
       * @param value The qualifier to set.
       * @return This builder for chaining.
       */
      public Builder setQualifier(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        qualifier_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes qualifier = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      private int compareOp_ = 0;
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return Whether the compareOp field is set.
       */
      @java.lang.Override public boolean hasCompareOp() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return The compareOp.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType getCompareOp() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType result = org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.forNumber(compareOp_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType.LESS : result;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @param value The compareOp to set.
       * @return This builder for chaining.
       */
      public Builder setCompareOp(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        compareOp_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CompareType compare_op = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompareOp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        compareOp_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator comparator_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       * @return Whether the comparator field is set.
       */
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       * @return The comparator.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder setComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder setComparator(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder mergeComparator(org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            comparator_ != null &&
            comparator_ != org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            getComparatorBuilder().mergeFrom(value);
          } else {
            comparator_ = value;
          }
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        if (comparator_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public Builder clearComparator() {
        bitField0_ = (bitField0_ & ~0x00000008);
        comparator_ = null;
        if (comparatorBuilder_ != null) {
          comparatorBuilder_.dispose();
          comparatorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance() : comparator_;
        }
      }
      /**
       * <code>required .hbase.pb.Comparator comparator = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  getComparator(),
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ColumnValueFilter)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ColumnValueFilter)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValueFilter>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ColumnValueFilter>() {
      @java.lang.Override
      public ColumnValueFilter parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValueFilter> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ColumnValueFilter> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.FilterProtos.ColumnValueFilter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Filter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Filter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ColumnCountGetFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ColumnCountGetFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ColumnPaginationFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ColumnPaginationFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ColumnPrefixFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ColumnPrefixFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ColumnRangeFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ColumnRangeFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompareFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompareFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DependentColumnFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DependentColumnFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FamilyFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FamilyFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FilterList_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FilterList_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FilterWrapper_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FilterWrapper_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FirstKeyOnlyFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FuzzyRowFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FuzzyRowFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_InclusiveStopFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_InclusiveStopFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_KeyOnlyFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_KeyOnlyFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MultipleColumnPrefixFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PageFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PageFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_PrefixFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_PrefixFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_QualifierFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_QualifierFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RandomRowFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RandomRowFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RowFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RowFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SingleColumnValueExcludeFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SingleColumnValueFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SingleColumnValueFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SkipFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SkipFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TimestampsFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TimestampsFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ValueFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ValueFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WhileMatchFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WhileMatchFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FilterAllFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FilterAllFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RowRange_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RowRange_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_MultiRowRangeFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_MultiRowRangeFilter_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ColumnValueFilter_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ColumnValueFilter_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\014Filter.proto\022\010hbase.pb\032\013HBase.proto\032\020C" +
      "omparator.proto\"1\n\006Filter\022\014\n\004name\030\001 \002(\t\022" +
      "\031\n\021serialized_filter\030\002 \001(\014\"%\n\024ColumnCoun" +
      "tGetFilter\022\r\n\005limit\030\001 \002(\005\"N\n\026ColumnPagin" +
      "ationFilter\022\r\n\005limit\030\001 \002(\005\022\016\n\006offset\030\002 \001" +
      "(\005\022\025\n\rcolumn_offset\030\003 \001(\014\"$\n\022ColumnPrefi" +
      "xFilter\022\016\n\006prefix\030\001 \002(\014\"w\n\021ColumnRangeFi" +
      "lter\022\022\n\nmin_column\030\001 \001(\014\022\034\n\024min_column_i" +
      "nclusive\030\002 \001(\010\022\022\n\nmax_column\030\003 \001(\014\022\034\n\024ma" +
      "x_column_inclusive\030\004 \001(\010\"d\n\rCompareFilte" +
      "r\022)\n\ncompare_op\030\001 \002(\0162\025.hbase.pb.Compare" +
      "Type\022(\n\ncomparator\030\002 \001(\0132\024.hbase.pb.Comp" +
      "arator\"\230\001\n\025DependentColumnFilter\022/\n\016comp" +
      "are_filter\030\001 \002(\0132\027.hbase.pb.CompareFilte" +
      "r\022\025\n\rcolumn_family\030\002 \001(\014\022\030\n\020column_quali" +
      "fier\030\003 \001(\014\022\035\n\025drop_dependent_column\030\004 \001(" +
      "\010\"?\n\014FamilyFilter\022/\n\016compare_filter\030\001 \002(" +
      "\0132\027.hbase.pb.CompareFilter\"\222\001\n\nFilterLis" +
      "t\022/\n\010operator\030\001 \002(\0162\035.hbase.pb.FilterLis" +
      "t.Operator\022!\n\007filters\030\002 \003(\0132\020.hbase.pb.F" +
      "ilter\"0\n\010Operator\022\021\n\rMUST_PASS_ALL\020\001\022\021\n\r" +
      "MUST_PASS_ONE\020\002\"1\n\rFilterWrapper\022 \n\006filt" +
      "er\030\001 \002(\0132\020.hbase.pb.Filter\"\024\n\022FirstKeyOn" +
      "lyFilter\";\n%FirstKeyValueMatchingQualifi" +
      "ersFilter\022\022\n\nqualifiers\030\001 \003(\014\"W\n\016FuzzyRo" +
      "wFilter\0221\n\017fuzzy_keys_data\030\001 \003(\0132\030.hbase" +
      ".pb.BytesBytesPair\022\022\n\nis_mask_v2\030\002 \001(\010\"+" +
      "\n\023InclusiveStopFilter\022\024\n\014stop_row_key\030\001 " +
      "\001(\014\"#\n\rKeyOnlyFilter\022\022\n\nlen_as_val\030\001 \002(\010" +
      "\"5\n\032MultipleColumnPrefixFilter\022\027\n\017sorted" +
      "_prefixes\030\001 \003(\014\"\037\n\nPageFilter\022\021\n\tpage_si" +
      "ze\030\001 \002(\003\"\036\n\014PrefixFilter\022\016\n\006prefix\030\001 \001(\014" +
      "\"B\n\017QualifierFilter\022/\n\016compare_filter\030\001 " +
      "\002(\0132\027.hbase.pb.CompareFilter\"!\n\017RandomRo" +
      "wFilter\022\016\n\006chance\030\001 \002(\002\"<\n\tRowFilter\022/\n\016" +
      "compare_filter\030\001 \002(\0132\027.hbase.pb.CompareF" +
      "ilter\"g\n\036SingleColumnValueExcludeFilter\022" +
      "E\n\032single_column_value_filter\030\001 \002(\0132!.hb" +
      "ase.pb.SingleColumnValueFilter\"\327\001\n\027Singl" +
      "eColumnValueFilter\022\025\n\rcolumn_family\030\001 \001(" +
      "\014\022\030\n\020column_qualifier\030\002 \001(\014\022)\n\ncompare_o" +
      "p\030\003 \002(\0162\025.hbase.pb.CompareType\022(\n\ncompar" +
      "ator\030\004 \002(\0132\024.hbase.pb.Comparator\022\031\n\021filt" +
      "er_if_missing\030\005 \001(\010\022\033\n\023latest_version_on" +
      "ly\030\006 \001(\010\".\n\nSkipFilter\022 \n\006filter\030\001 \002(\0132\020" +
      ".hbase.pb.Filter\"<\n\020TimestampsFilter\022\026\n\n" +
      "timestamps\030\001 \003(\003B\002\020\001\022\020\n\010can_hint\030\002 \001(\010\">" +
      "\n\013ValueFilter\022/\n\016compare_filter\030\001 \002(\0132\027." +
      "hbase.pb.CompareFilter\"4\n\020WhileMatchFilt" +
      "er\022 \n\006filter\030\001 \002(\0132\020.hbase.pb.Filter\"\021\n\017" +
      "FilterAllFilter\"h\n\010RowRange\022\021\n\tstart_row" +
      "\030\001 \001(\014\022\033\n\023start_row_inclusive\030\002 \001(\010\022\020\n\010s" +
      "top_row\030\003 \001(\014\022\032\n\022stop_row_inclusive\030\004 \001(" +
      "\010\"A\n\023MultiRowRangeFilter\022*\n\016row_range_li" +
      "st\030\001 \003(\0132\022.hbase.pb.RowRange\"\213\001\n\021ColumnV" +
      "alueFilter\022\016\n\006family\030\001 \002(\014\022\021\n\tqualifier\030" +
      "\002 \002(\014\022)\n\ncompare_op\030\003 \002(\0162\025.hbase.pb.Com" +
      "pareType\022(\n\ncomparator\030\004 \002(\0132\024.hbase.pb." +
      "ComparatorBI\n1org.apache.hadoop.hbase.sh" +
      "aded.protobuf.generatedB\014FilterProtosH\001\210" +
      "\001\001\240\001\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.getDescriptor(),
        });
    internal_static_hbase_pb_Filter_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_Filter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Filter_descriptor,
        new java.lang.String[] { "Name", "SerializedFilter", });
    internal_static_hbase_pb_ColumnCountGetFilter_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_ColumnCountGetFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ColumnCountGetFilter_descriptor,
        new java.lang.String[] { "Limit", });
    internal_static_hbase_pb_ColumnPaginationFilter_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_ColumnPaginationFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ColumnPaginationFilter_descriptor,
        new java.lang.String[] { "Limit", "Offset", "ColumnOffset", });
    internal_static_hbase_pb_ColumnPrefixFilter_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_ColumnPrefixFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ColumnPrefixFilter_descriptor,
        new java.lang.String[] { "Prefix", });
    internal_static_hbase_pb_ColumnRangeFilter_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_ColumnRangeFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ColumnRangeFilter_descriptor,
        new java.lang.String[] { "MinColumn", "MinColumnInclusive", "MaxColumn", "MaxColumnInclusive", });
    internal_static_hbase_pb_CompareFilter_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_CompareFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompareFilter_descriptor,
        new java.lang.String[] { "CompareOp", "Comparator", });
    internal_static_hbase_pb_DependentColumnFilter_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_DependentColumnFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DependentColumnFilter_descriptor,
        new java.lang.String[] { "CompareFilter", "ColumnFamily", "ColumnQualifier", "DropDependentColumn", });
    internal_static_hbase_pb_FamilyFilter_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_FamilyFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FamilyFilter_descriptor,
        new java.lang.String[] { "CompareFilter", });
    internal_static_hbase_pb_FilterList_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_FilterList_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FilterList_descriptor,
        new java.lang.String[] { "Operator", "Filters", });
    internal_static_hbase_pb_FilterWrapper_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_FilterWrapper_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FilterWrapper_descriptor,
        new java.lang.String[] { "Filter", });
    internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_FirstKeyOnlyFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FirstKeyOnlyFilter_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FirstKeyValueMatchingQualifiersFilter_descriptor,
        new java.lang.String[] { "Qualifiers", });
    internal_static_hbase_pb_FuzzyRowFilter_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_FuzzyRowFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FuzzyRowFilter_descriptor,
        new java.lang.String[] { "FuzzyKeysData", "IsMaskV2", });
    internal_static_hbase_pb_InclusiveStopFilter_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hbase_pb_InclusiveStopFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_InclusiveStopFilter_descriptor,
        new java.lang.String[] { "StopRowKey", });
    internal_static_hbase_pb_KeyOnlyFilter_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hbase_pb_KeyOnlyFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_KeyOnlyFilter_descriptor,
        new java.lang.String[] { "LenAsVal", });
    internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hbase_pb_MultipleColumnPrefixFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MultipleColumnPrefixFilter_descriptor,
        new java.lang.String[] { "SortedPrefixes", });
    internal_static_hbase_pb_PageFilter_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hbase_pb_PageFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PageFilter_descriptor,
        new java.lang.String[] { "PageSize", });
    internal_static_hbase_pb_PrefixFilter_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hbase_pb_PrefixFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_PrefixFilter_descriptor,
        new java.lang.String[] { "Prefix", });
    internal_static_hbase_pb_QualifierFilter_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hbase_pb_QualifierFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_QualifierFilter_descriptor,
        new java.lang.String[] { "CompareFilter", });
    internal_static_hbase_pb_RandomRowFilter_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hbase_pb_RandomRowFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RandomRowFilter_descriptor,
        new java.lang.String[] { "Chance", });
    internal_static_hbase_pb_RowFilter_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hbase_pb_RowFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RowFilter_descriptor,
        new java.lang.String[] { "CompareFilter", });
    internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hbase_pb_SingleColumnValueExcludeFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SingleColumnValueExcludeFilter_descriptor,
        new java.lang.String[] { "SingleColumnValueFilter", });
    internal_static_hbase_pb_SingleColumnValueFilter_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hbase_pb_SingleColumnValueFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SingleColumnValueFilter_descriptor,
        new java.lang.String[] { "ColumnFamily", "ColumnQualifier", "CompareOp", "Comparator", "FilterIfMissing", "LatestVersionOnly", });
    internal_static_hbase_pb_SkipFilter_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hbase_pb_SkipFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SkipFilter_descriptor,
        new java.lang.String[] { "Filter", });
    internal_static_hbase_pb_TimestampsFilter_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hbase_pb_TimestampsFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TimestampsFilter_descriptor,
        new java.lang.String[] { "Timestamps", "CanHint", });
    internal_static_hbase_pb_ValueFilter_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hbase_pb_ValueFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ValueFilter_descriptor,
        new java.lang.String[] { "CompareFilter", });
    internal_static_hbase_pb_WhileMatchFilter_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hbase_pb_WhileMatchFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WhileMatchFilter_descriptor,
        new java.lang.String[] { "Filter", });
    internal_static_hbase_pb_FilterAllFilter_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hbase_pb_FilterAllFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FilterAllFilter_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_RowRange_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hbase_pb_RowRange_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RowRange_descriptor,
        new java.lang.String[] { "StartRow", "StartRowInclusive", "StopRow", "StopRowInclusive", });
    internal_static_hbase_pb_MultiRowRangeFilter_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hbase_pb_MultiRowRangeFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_MultiRowRangeFilter_descriptor,
        new java.lang.String[] { "RowRangeList", });
    internal_static_hbase_pb_ColumnValueFilter_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hbase_pb_ColumnValueFilter_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ColumnValueFilter_descriptor,
        new java.lang.String[] { "Family", "Qualifier", "CompareOp", "Comparator", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.ComparatorProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
