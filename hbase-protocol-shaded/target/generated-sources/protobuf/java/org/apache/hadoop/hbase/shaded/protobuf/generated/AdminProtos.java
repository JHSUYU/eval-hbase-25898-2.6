// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Admin.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class AdminProtos {
  private AdminProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface GetRegionInfoRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetRegionInfoRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>optional bool compaction_state = 2;</code>
     * @return Whether the compactionState field is set.
     */
    boolean hasCompactionState();
    /**
     * <code>optional bool compaction_state = 2;</code>
     * @return The compactionState.
     */
    boolean getCompactionState();

    /**
     * <code>optional bool best_split_row = 3;</code>
     * @return Whether the bestSplitRow field is set.
     */
    boolean hasBestSplitRow();
    /**
     * <code>optional bool best_split_row = 3;</code>
     * @return The bestSplitRow.
     */
    boolean getBestSplitRow();
  }
  /**
   * Protobuf type {@code hbase.pb.GetRegionInfoRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetRegionInfoRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetRegionInfoRequest)
      GetRegionInfoRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetRegionInfoRequest.newBuilder() to construct.
    private GetRegionInfoRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetRegionInfoRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetRegionInfoRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int COMPACTION_STATE_FIELD_NUMBER = 2;
    private boolean compactionState_ = false;
    /**
     * <code>optional bool compaction_state = 2;</code>
     * @return Whether the compactionState field is set.
     */
    @java.lang.Override
    public boolean hasCompactionState() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool compaction_state = 2;</code>
     * @return The compactionState.
     */
    @java.lang.Override
    public boolean getCompactionState() {
      return compactionState_;
    }

    public static final int BEST_SPLIT_ROW_FIELD_NUMBER = 3;
    private boolean bestSplitRow_ = false;
    /**
     * <code>optional bool best_split_row = 3;</code>
     * @return Whether the bestSplitRow field is set.
     */
    @java.lang.Override
    public boolean hasBestSplitRow() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool best_split_row = 3;</code>
     * @return The bestSplitRow.
     */
    @java.lang.Override
    public boolean getBestSplitRow() {
      return bestSplitRow_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, compactionState_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, bestSplitRow_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, compactionState_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, bestSplitRow_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasCompactionState() != other.hasCompactionState()) return false;
      if (hasCompactionState()) {
        if (getCompactionState()
            != other.getCompactionState()) return false;
      }
      if (hasBestSplitRow() != other.hasBestSplitRow()) return false;
      if (hasBestSplitRow()) {
        if (getBestSplitRow()
            != other.getBestSplitRow()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasCompactionState()) {
        hash = (37 * hash) + COMPACTION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getCompactionState());
      }
      if (hasBestSplitRow()) {
        hash = (37 * hash) + BEST_SPLIT_ROW_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getBestSplitRow());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetRegionInfoRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetRegionInfoRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        compactionState_ = false;
        bestSplitRow_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.compactionState_ = compactionState_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.bestSplitRow_ = bestSplitRow_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasCompactionState()) {
          setCompactionState(other.getCompactionState());
        }
        if (other.hasBestSplitRow()) {
          setBestSplitRow(other.getBestSplitRow());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                compactionState_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                bestSplitRow_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private boolean compactionState_ ;
      /**
       * <code>optional bool compaction_state = 2;</code>
       * @return Whether the compactionState field is set.
       */
      @java.lang.Override
      public boolean hasCompactionState() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool compaction_state = 2;</code>
       * @return The compactionState.
       */
      @java.lang.Override
      public boolean getCompactionState() {
        return compactionState_;
      }
      /**
       * <code>optional bool compaction_state = 2;</code>
       * @param value The compactionState to set.
       * @return This builder for chaining.
       */
      public Builder setCompactionState(boolean value) {

        compactionState_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool compaction_state = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompactionState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        compactionState_ = false;
        onChanged();
        return this;
      }

      private boolean bestSplitRow_ ;
      /**
       * <code>optional bool best_split_row = 3;</code>
       * @return Whether the bestSplitRow field is set.
       */
      @java.lang.Override
      public boolean hasBestSplitRow() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool best_split_row = 3;</code>
       * @return The bestSplitRow.
       */
      @java.lang.Override
      public boolean getBestSplitRow() {
        return bestSplitRow_;
      }
      /**
       * <code>optional bool best_split_row = 3;</code>
       * @param value The bestSplitRow to set.
       * @return This builder for chaining.
       */
      public Builder setBestSplitRow(boolean value) {

        bestSplitRow_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool best_split_row = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearBestSplitRow() {
        bitField0_ = (bitField0_ & ~0x00000004);
        bestSplitRow_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetRegionInfoRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetRegionInfoRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetRegionInfoRequest>() {
      @java.lang.Override
      public GetRegionInfoRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetRegionInfoResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetRegionInfoResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();

    /**
     * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
     * @return Whether the compactionState field is set.
     */
    boolean hasCompactionState();
    /**
     * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
     * @return The compactionState.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState getCompactionState();

    /**
     * <pre>
     * optional bool DEPRECATED_isRecovering = 3;
     * True if region is splittable, false otherwise.
     * </pre>
     *
     * <code>optional bool splittable = 4;</code>
     * @return Whether the splittable field is set.
     */
    boolean hasSplittable();
    /**
     * <pre>
     * optional bool DEPRECATED_isRecovering = 3;
     * True if region is splittable, false otherwise.
     * </pre>
     *
     * <code>optional bool splittable = 4;</code>
     * @return The splittable.
     */
    boolean getSplittable();

    /**
     * <pre>
     * True if region is mergeable, false otherwise.
     * </pre>
     *
     * <code>optional bool mergeable = 5;</code>
     * @return Whether the mergeable field is set.
     */
    boolean hasMergeable();
    /**
     * <pre>
     * True if region is mergeable, false otherwise.
     * </pre>
     *
     * <code>optional bool mergeable = 5;</code>
     * @return The mergeable.
     */
    boolean getMergeable();

    /**
     * <pre>
     * Get bestSplitRow
     * </pre>
     *
     * <code>optional bytes best_split_row = 6;</code>
     * @return Whether the bestSplitRow field is set.
     */
    boolean hasBestSplitRow();
    /**
     * <pre>
     * Get bestSplitRow
     * </pre>
     *
     * <code>optional bytes best_split_row = 6;</code>
     * @return The bestSplitRow.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getBestSplitRow();
  }
  /**
   * Protobuf type {@code hbase.pb.GetRegionInfoResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetRegionInfoResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetRegionInfoResponse)
      GetRegionInfoResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetRegionInfoResponse.newBuilder() to construct.
    private GetRegionInfoResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetRegionInfoResponse() {
      compactionState_ = 0;
      bestSplitRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetRegionInfoResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.GetRegionInfoResponse.CompactionState}
     */
    public enum CompactionState
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>NONE = 0;</code>
       */
      NONE(0),
      /**
       * <code>MINOR = 1;</code>
       */
      MINOR(1),
      /**
       * <code>MAJOR = 2;</code>
       */
      MAJOR(2),
      /**
       * <code>MAJOR_AND_MINOR = 3;</code>
       */
      MAJOR_AND_MINOR(3),
      ;

      /**
       * <code>NONE = 0;</code>
       */
      public static final int NONE_VALUE = 0;
      /**
       * <code>MINOR = 1;</code>
       */
      public static final int MINOR_VALUE = 1;
      /**
       * <code>MAJOR = 2;</code>
       */
      public static final int MAJOR_VALUE = 2;
      /**
       * <code>MAJOR_AND_MINOR = 3;</code>
       */
      public static final int MAJOR_AND_MINOR_VALUE = 3;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static CompactionState valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static CompactionState forNumber(int value) {
        switch (value) {
          case 0: return NONE;
          case 1: return MINOR;
          case 2: return MAJOR;
          case 3: return MAJOR_AND_MINOR;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CompactionState>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          CompactionState> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<CompactionState>() {
              public CompactionState findValueByNumber(int number) {
                return CompactionState.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDescriptor().getEnumTypes().get(0);
      }

      private static final CompactionState[] VALUES = values();

      public static CompactionState valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private CompactionState(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.GetRegionInfoResponse.CompactionState)
    }

    private int bitField0_;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    public static final int COMPACTION_STATE_FIELD_NUMBER = 2;
    private int compactionState_ = 0;
    /**
     * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
     * @return Whether the compactionState field is set.
     */
    @java.lang.Override public boolean hasCompactionState() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
     * @return The compactionState.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState getCompactionState() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState.forNumber(compactionState_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState.NONE : result;
    }

    public static final int SPLITTABLE_FIELD_NUMBER = 4;
    private boolean splittable_ = false;
    /**
     * <pre>
     * optional bool DEPRECATED_isRecovering = 3;
     * True if region is splittable, false otherwise.
     * </pre>
     *
     * <code>optional bool splittable = 4;</code>
     * @return Whether the splittable field is set.
     */
    @java.lang.Override
    public boolean hasSplittable() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * optional bool DEPRECATED_isRecovering = 3;
     * True if region is splittable, false otherwise.
     * </pre>
     *
     * <code>optional bool splittable = 4;</code>
     * @return The splittable.
     */
    @java.lang.Override
    public boolean getSplittable() {
      return splittable_;
    }

    public static final int MERGEABLE_FIELD_NUMBER = 5;
    private boolean mergeable_ = false;
    /**
     * <pre>
     * True if region is mergeable, false otherwise.
     * </pre>
     *
     * <code>optional bool mergeable = 5;</code>
     * @return Whether the mergeable field is set.
     */
    @java.lang.Override
    public boolean hasMergeable() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * True if region is mergeable, false otherwise.
     * </pre>
     *
     * <code>optional bool mergeable = 5;</code>
     * @return The mergeable.
     */
    @java.lang.Override
    public boolean getMergeable() {
      return mergeable_;
    }

    public static final int BEST_SPLIT_ROW_FIELD_NUMBER = 6;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString bestSplitRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * Get bestSplitRow
     * </pre>
     *
     * <code>optional bytes best_split_row = 6;</code>
     * @return Whether the bestSplitRow field is set.
     */
    @java.lang.Override
    public boolean hasBestSplitRow() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * Get bestSplitRow
     * </pre>
     *
     * <code>optional bytes best_split_row = 6;</code>
     * @return The bestSplitRow.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getBestSplitRow() {
      return bestSplitRow_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, compactionState_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(4, splittable_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(5, mergeable_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBytes(6, bestSplitRow_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, compactionState_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, splittable_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, mergeable_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, bestSplitRow_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse) obj;

      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (hasCompactionState() != other.hasCompactionState()) return false;
      if (hasCompactionState()) {
        if (compactionState_ != other.compactionState_) return false;
      }
      if (hasSplittable() != other.hasSplittable()) return false;
      if (hasSplittable()) {
        if (getSplittable()
            != other.getSplittable()) return false;
      }
      if (hasMergeable() != other.hasMergeable()) return false;
      if (hasMergeable()) {
        if (getMergeable()
            != other.getMergeable()) return false;
      }
      if (hasBestSplitRow() != other.hasBestSplitRow()) return false;
      if (hasBestSplitRow()) {
        if (!getBestSplitRow()
            .equals(other.getBestSplitRow())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasCompactionState()) {
        hash = (37 * hash) + COMPACTION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + compactionState_;
      }
      if (hasSplittable()) {
        hash = (37 * hash) + SPLITTABLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getSplittable());
      }
      if (hasMergeable()) {
        hash = (37 * hash) + MERGEABLE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMergeable());
      }
      if (hasBestSplitRow()) {
        hash = (37 * hash) + BEST_SPLIT_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getBestSplitRow().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetRegionInfoResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetRegionInfoResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        compactionState_ = 0;
        splittable_ = false;
        mergeable_ = false;
        bestSplitRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionInfoResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.compactionState_ = compactionState_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.splittable_ = splittable_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.mergeable_ = mergeable_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.bestSplitRow_ = bestSplitRow_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasCompactionState()) {
          setCompactionState(other.getCompactionState());
        }
        if (other.hasSplittable()) {
          setSplittable(other.getSplittable());
        }
        if (other.hasMergeable()) {
          setMergeable(other.getMergeable());
        }
        if (other.hasBestSplitRow()) {
          setBestSplitRow(other.getBestSplitRow());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(2, tmpRaw);
                } else {
                  compactionState_ = tmpRaw;
                  bitField0_ |= 0x00000002;
                }
                break;
              } // case 16
              case 32: {
                splittable_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 32
              case 40: {
                mergeable_ = input.readBool();
                bitField0_ |= 0x00000008;
                break;
              } // case 40
              case 50: {
                bestSplitRow_ = input.readBytes();
                bitField0_ |= 0x00000010;
                break;
              } // case 50
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo region_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      private int compactionState_ = 0;
      /**
       * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
       * @return Whether the compactionState field is set.
       */
      @java.lang.Override public boolean hasCompactionState() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
       * @return The compactionState.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState getCompactionState() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState.forNumber(compactionState_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState.NONE : result;
      }
      /**
       * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
       * @param value The compactionState to set.
       * @return This builder for chaining.
       */
      public Builder setCompactionState(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.CompactionState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        compactionState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.GetRegionInfoResponse.CompactionState compaction_state = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompactionState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        compactionState_ = 0;
        onChanged();
        return this;
      }

      private boolean splittable_ ;
      /**
       * <pre>
       * optional bool DEPRECATED_isRecovering = 3;
       * True if region is splittable, false otherwise.
       * </pre>
       *
       * <code>optional bool splittable = 4;</code>
       * @return Whether the splittable field is set.
       */
      @java.lang.Override
      public boolean hasSplittable() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * optional bool DEPRECATED_isRecovering = 3;
       * True if region is splittable, false otherwise.
       * </pre>
       *
       * <code>optional bool splittable = 4;</code>
       * @return The splittable.
       */
      @java.lang.Override
      public boolean getSplittable() {
        return splittable_;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_isRecovering = 3;
       * True if region is splittable, false otherwise.
       * </pre>
       *
       * <code>optional bool splittable = 4;</code>
       * @param value The splittable to set.
       * @return This builder for chaining.
       */
      public Builder setSplittable(boolean value) {

        splittable_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * optional bool DEPRECATED_isRecovering = 3;
       * True if region is splittable, false otherwise.
       * </pre>
       *
       * <code>optional bool splittable = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearSplittable() {
        bitField0_ = (bitField0_ & ~0x00000004);
        splittable_ = false;
        onChanged();
        return this;
      }

      private boolean mergeable_ ;
      /**
       * <pre>
       * True if region is mergeable, false otherwise.
       * </pre>
       *
       * <code>optional bool mergeable = 5;</code>
       * @return Whether the mergeable field is set.
       */
      @java.lang.Override
      public boolean hasMergeable() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * True if region is mergeable, false otherwise.
       * </pre>
       *
       * <code>optional bool mergeable = 5;</code>
       * @return The mergeable.
       */
      @java.lang.Override
      public boolean getMergeable() {
        return mergeable_;
      }
      /**
       * <pre>
       * True if region is mergeable, false otherwise.
       * </pre>
       *
       * <code>optional bool mergeable = 5;</code>
       * @param value The mergeable to set.
       * @return This builder for chaining.
       */
      public Builder setMergeable(boolean value) {

        mergeable_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * True if region is mergeable, false otherwise.
       * </pre>
       *
       * <code>optional bool mergeable = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearMergeable() {
        bitField0_ = (bitField0_ & ~0x00000008);
        mergeable_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString bestSplitRow_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * Get bestSplitRow
       * </pre>
       *
       * <code>optional bytes best_split_row = 6;</code>
       * @return Whether the bestSplitRow field is set.
       */
      @java.lang.Override
      public boolean hasBestSplitRow() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * Get bestSplitRow
       * </pre>
       *
       * <code>optional bytes best_split_row = 6;</code>
       * @return The bestSplitRow.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getBestSplitRow() {
        return bestSplitRow_;
      }
      /**
       * <pre>
       * Get bestSplitRow
       * </pre>
       *
       * <code>optional bytes best_split_row = 6;</code>
       * @param value The bestSplitRow to set.
       * @return This builder for chaining.
       */
      public Builder setBestSplitRow(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        bestSplitRow_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Get bestSplitRow
       * </pre>
       *
       * <code>optional bytes best_split_row = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearBestSplitRow() {
        bitField0_ = (bitField0_ & ~0x00000010);
        bestSplitRow_ = getDefaultInstance().getBestSplitRow();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetRegionInfoResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetRegionInfoResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetRegionInfoResponse>() {
      @java.lang.Override
      public GetRegionInfoResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionInfoResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetStoreFileRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetStoreFileRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>repeated bytes family = 2;</code>
     * @return A list containing the family.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getFamilyList();
    /**
     * <code>repeated bytes family = 2;</code>
     * @return The count of family.
     */
    int getFamilyCount();
    /**
     * <code>repeated bytes family = 2;</code>
     * @param index The index of the element to return.
     * @return The family at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily(int index);
  }
  /**
   * <pre>
   **
   * Get a list of store files for a set of column families in a particular region.
   * If no column family is specified, get the store files for all column families.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.GetStoreFileRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetStoreFileRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetStoreFileRequest)
      GetStoreFileRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetStoreFileRequest.newBuilder() to construct.
    private GetStoreFileRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetStoreFileRequest() {
      family_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetStoreFileRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int FAMILY_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> family_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <code>repeated bytes family = 2;</code>
     * @return A list containing the family.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getFamilyList() {
      return family_;
    }
    /**
     * <code>repeated bytes family = 2;</code>
     * @return The count of family.
     */
    public int getFamilyCount() {
      return family_.size();
    }
    /**
     * <code>repeated bytes family = 2;</code>
     * @param index The index of the element to return.
     * @return The family at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily(int index) {
      return family_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      for (int i = 0; i < family_.size(); i++) {
        output.writeBytes(2, family_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < family_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(family_.get(i));
        }
        size += dataSize;
        size += 1 * getFamilyList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (!getFamilyList()
          .equals(other.getFamilyList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getFamilyCount() > 0) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Get a list of store files for a set of column families in a particular region.
     * If no column family is specified, get the store files for all column families.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.GetStoreFileRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetStoreFileRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        family_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          family_.makeImmutable();
          result.family_ = family_;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (!other.family_.isEmpty()) {
          if (family_.isEmpty()) {
            family_ = other.family_;
            family_.makeImmutable();
            bitField0_ |= 0x00000002;
          } else {
            ensureFamilyIsMutable();
            family_.addAll(other.family_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureFamilyIsMutable();
                family_.add(v);
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> family_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureFamilyIsMutable() {
        if (!family_.isModifiable()) {
          family_ = makeMutableCopy(family_);
        }
        bitField0_ |= 0x00000002;
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @return A list containing the family.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getFamilyList() {
        family_.makeImmutable();
        return family_;
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @return The count of family.
       */
      public int getFamilyCount() {
        return family_.size();
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @param index The index of the element to return.
       * @return The family at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily(int index) {
        return family_.get(index);
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @param index The index to set the value at.
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureFamilyIsMutable();
        family_.set(index, value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @param value The family to add.
       * @return This builder for chaining.
       */
      public Builder addFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureFamilyIsMutable();
        family_.add(value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @param values The family to add.
       * @return This builder for chaining.
       */
      public Builder addAllFamily(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureFamilyIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, family_);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes family = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        family_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetStoreFileRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetStoreFileRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetStoreFileRequest>() {
      @java.lang.Override
      public GetStoreFileRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetStoreFileResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetStoreFileResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string store_file = 1;</code>
     * @return A list containing the storeFile.
     */
    java.util.List<java.lang.String>
        getStoreFileList();
    /**
     * <code>repeated string store_file = 1;</code>
     * @return The count of storeFile.
     */
    int getStoreFileCount();
    /**
     * <code>repeated string store_file = 1;</code>
     * @param index The index of the element to return.
     * @return The storeFile at the given index.
     */
    java.lang.String getStoreFile(int index);
    /**
     * <code>repeated string store_file = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the storeFile at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreFileBytes(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetStoreFileResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetStoreFileResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetStoreFileResponse)
      GetStoreFileResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetStoreFileResponse.newBuilder() to construct.
    private GetStoreFileResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetStoreFileResponse() {
      storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetStoreFileResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.Builder.class);
    }

    public static final int STORE_FILE_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList storeFile_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string store_file = 1;</code>
     * @return A list containing the storeFile.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getStoreFileList() {
      return storeFile_;
    }
    /**
     * <code>repeated string store_file = 1;</code>
     * @return The count of storeFile.
     */
    public int getStoreFileCount() {
      return storeFile_.size();
    }
    /**
     * <code>repeated string store_file = 1;</code>
     * @param index The index of the element to return.
     * @return The storeFile at the given index.
     */
    public java.lang.String getStoreFile(int index) {
      return storeFile_.get(index);
    }
    /**
     * <code>repeated string store_file = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the storeFile at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreFileBytes(int index) {
      return storeFile_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < storeFile_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, storeFile_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < storeFile_.size(); i++) {
          dataSize += computeStringSizeNoTag(storeFile_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getStoreFileList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse) obj;

      if (!getStoreFileList()
          .equals(other.getStoreFileList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getStoreFileCount() > 0) {
        hash = (37 * hash) + STORE_FILE_FIELD_NUMBER;
        hash = (53 * hash) + getStoreFileList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetStoreFileResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetStoreFileResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        storeFile_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetStoreFileResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          storeFile_.makeImmutable();
          result.storeFile_ = storeFile_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance()) return this;
        if (!other.storeFile_.isEmpty()) {
          if (storeFile_.isEmpty()) {
            storeFile_ = other.storeFile_;
            bitField0_ |= 0x00000001;
          } else {
            ensureStoreFileIsMutable();
            storeFile_.addAll(other.storeFile_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureStoreFileIsMutable();
                storeFile_.add(bs);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureStoreFileIsMutable() {
        if (!storeFile_.isModifiable()) {
          storeFile_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(storeFile_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @return A list containing the storeFile.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getStoreFileList() {
        storeFile_.makeImmutable();
        return storeFile_;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @return The count of storeFile.
       */
      public int getStoreFileCount() {
        return storeFile_.size();
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param index The index of the element to return.
       * @return The storeFile at the given index.
       */
      public java.lang.String getStoreFile(int index) {
        return storeFile_.get(index);
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the storeFile at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreFileBytes(int index) {
        return storeFile_.getByteString(index);
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param index The index to set the value at.
       * @param value The storeFile to set.
       * @return This builder for chaining.
       */
      public Builder setStoreFile(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param value The storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addStoreFile(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param values The storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addAllStoreFile(
          java.lang.Iterable<java.lang.String> values) {
        ensureStoreFileIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, storeFile_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreFile() {
        storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string store_file = 1;</code>
       * @param value The bytes of the storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addStoreFileBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetStoreFileResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetStoreFileResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetStoreFileResponse>() {
      @java.lang.Override
      public GetStoreFileResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetStoreFileResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetOnlineRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetOnlineRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.GetOnlineRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetOnlineRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetOnlineRegionRequest)
      GetOnlineRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetOnlineRegionRequest.newBuilder() to construct.
    private GetOnlineRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetOnlineRegionRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetOnlineRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetOnlineRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetOnlineRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetOnlineRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetOnlineRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetOnlineRegionRequest>() {
      @java.lang.Override
      public GetOnlineRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetOnlineRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetOnlineRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetOnlineRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetOnlineRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetOnlineRegionResponse)
      GetOnlineRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetOnlineRegionResponse.newBuilder() to construct.
    private GetOnlineRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetOnlineRegionResponse() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetOnlineRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.Builder.class);
    }

    public static final int REGION_INFO_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(1, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse) obj;

      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetOnlineRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetOnlineRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
        } else {
          regionInfo_ = null;
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetOnlineRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse result) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance()) return this;
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.PARSER,
                        extensionRegistry);
                if (regionInfoBuilder_ == null) {
                  ensureRegionInfoIsMutable();
                  regionInfo_.add(m);
                } else {
                  regionInfoBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetOnlineRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetOnlineRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetOnlineRegionResponse>() {
      @java.lang.Override
      public GetOnlineRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetOnlineRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface OpenRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.OpenRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> 
        getOpenInfoList();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getOpenInfo(int index);
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    int getOpenInfoCount();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder> 
        getOpenInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder getOpenInfoOrBuilder(
        int index);

    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 2;</code>
     * @return Whether the serverStartCode field is set.
     */
    boolean hasServerStartCode();
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 2;</code>
     * @return The serverStartCode.
     */
    long getServerStartCode();

    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 3;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    boolean hasInitiatingMasterActiveTime();
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 3;</code>
     * @return The initiatingMasterActiveTime.
     */
    long getInitiatingMasterActiveTime();

    /**
     * <pre>
     * wall clock time from master
     * </pre>
     *
     * <code>optional uint64 master_system_time = 5;</code>
     * @return Whether the masterSystemTime field is set.
     */
    boolean hasMasterSystemTime();
    /**
     * <pre>
     * wall clock time from master
     * </pre>
     *
     * <code>optional uint64 master_system_time = 5;</code>
     * @return The masterSystemTime.
     */
    long getMasterSystemTime();
  }
  /**
   * Protobuf type {@code hbase.pb.OpenRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class OpenRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.OpenRegionRequest)
      OpenRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenRegionRequest.newBuilder() to construct.
    private OpenRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenRegionRequest() {
      openInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new OpenRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder.class);
    }

    public interface RegionOpenInfoOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hbase.pb.OpenRegionRequest.RegionOpenInfo)
        org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return Whether the region field is set.
       */
      boolean hasRegion();
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return The region.
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion();
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder();

      /**
       * <code>optional uint32 version_of_offline_node = 2;</code>
       * @return Whether the versionOfOfflineNode field is set.
       */
      boolean hasVersionOfOfflineNode();
      /**
       * <code>optional uint32 version_of_offline_node = 2;</code>
       * @return The versionOfOfflineNode.
       */
      int getVersionOfOfflineNode();

      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> 
          getFavoredNodesList();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index);
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      int getFavoredNodesCount();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFavoredNodesOrBuilderList();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
          int index);

      /**
       * <pre>
       * open region for distributedLogReplay
       * optional bool DEPRECATED_openForDistributedLogReplay = 4;
       * </pre>
       *
       * <code>optional int64 open_proc_id = 5 [default = -1];</code>
       * @return Whether the openProcId field is set.
       */
      boolean hasOpenProcId();
      /**
       * <pre>
       * open region for distributedLogReplay
       * optional bool DEPRECATED_openForDistributedLogReplay = 4;
       * </pre>
       *
       * <code>optional int64 open_proc_id = 5 [default = -1];</code>
       * @return The openProcId.
       */
      long getOpenProcId();
    }
    /**
     * Protobuf type {@code hbase.pb.OpenRegionRequest.RegionOpenInfo}
     */
    @javax.annotation.Generated("proto") public static final class RegionOpenInfo extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hbase.pb.OpenRegionRequest.RegionOpenInfo)
        RegionOpenInfoOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use RegionOpenInfo.newBuilder() to construct.
      private RegionOpenInfo(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private RegionOpenInfo() {
        favoredNodes_ = java.util.Collections.emptyList();
        openProcId_ = -1L;
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new RegionOpenInfo();
      }

      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder.class);
      }

      private int bitField0_;
      public static final int REGION_FIELD_NUMBER = 1;
      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return Whether the region field is set.
       */
      @java.lang.Override
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return The region.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
        return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
        return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
      }

      public static final int VERSION_OF_OFFLINE_NODE_FIELD_NUMBER = 2;
      private int versionOfOfflineNode_ = 0;
      /**
       * <code>optional uint32 version_of_offline_node = 2;</code>
       * @return Whether the versionOfOfflineNode field is set.
       */
      @java.lang.Override
      public boolean hasVersionOfOfflineNode() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint32 version_of_offline_node = 2;</code>
       * @return The versionOfOfflineNode.
       */
      @java.lang.Override
      public int getVersionOfOfflineNode() {
        return versionOfOfflineNode_;
      }

      public static final int FAVORED_NODES_FIELD_NUMBER = 3;
      @SuppressWarnings("serial")
      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes_;
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      @java.lang.Override
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getFavoredNodesList() {
        return favoredNodes_;
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      @java.lang.Override
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFavoredNodesOrBuilderList() {
        return favoredNodes_;
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      @java.lang.Override
      public int getFavoredNodesCount() {
        return favoredNodes_.size();
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index) {
        return favoredNodes_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
          int index) {
        return favoredNodes_.get(index);
      }

      public static final int OPEN_PROC_ID_FIELD_NUMBER = 5;
      private long openProcId_ = -1L;
      /**
       * <pre>
       * open region for distributedLogReplay
       * optional bool DEPRECATED_openForDistributedLogReplay = 4;
       * </pre>
       *
       * <code>optional int64 open_proc_id = 5 [default = -1];</code>
       * @return Whether the openProcId field is set.
       */
      @java.lang.Override
      public boolean hasOpenProcId() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * open region for distributedLogReplay
       * optional bool DEPRECATED_openForDistributedLogReplay = 4;
       * </pre>
       *
       * <code>optional int64 open_proc_id = 5 [default = -1];</code>
       * @return The openProcId.
       */
      @java.lang.Override
      public long getOpenProcId() {
        return openProcId_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasRegion()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
        for (int i = 0; i < getFavoredNodesCount(); i++) {
          if (!getFavoredNodes(i).isInitialized()) {
            memoizedIsInitialized = 0;
            return false;
          }
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeMessage(1, getRegion());
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          output.writeUInt32(2, versionOfOfflineNode_);
        }
        for (int i = 0; i < favoredNodes_.size(); i++) {
          output.writeMessage(3, favoredNodes_.get(i));
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          output.writeInt64(5, openProcId_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getRegion());
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeUInt32Size(2, versionOfOfflineNode_);
        }
        for (int i = 0; i < favoredNodes_.size(); i++) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeMessageSize(3, favoredNodes_.get(i));
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeInt64Size(5, openProcId_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo) obj;

        if (hasRegion() != other.hasRegion()) return false;
        if (hasRegion()) {
          if (!getRegion()
              .equals(other.getRegion())) return false;
        }
        if (hasVersionOfOfflineNode() != other.hasVersionOfOfflineNode()) return false;
        if (hasVersionOfOfflineNode()) {
          if (getVersionOfOfflineNode()
              != other.getVersionOfOfflineNode()) return false;
        }
        if (!getFavoredNodesList()
            .equals(other.getFavoredNodesList())) return false;
        if (hasOpenProcId() != other.hasOpenProcId()) return false;
        if (hasOpenProcId()) {
          if (getOpenProcId()
              != other.getOpenProcId()) return false;
        }
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasRegion()) {
          hash = (37 * hash) + REGION_FIELD_NUMBER;
          hash = (53 * hash) + getRegion().hashCode();
        }
        if (hasVersionOfOfflineNode()) {
          hash = (37 * hash) + VERSION_OF_OFFLINE_NODE_FIELD_NUMBER;
          hash = (53 * hash) + getVersionOfOfflineNode();
        }
        if (getFavoredNodesCount() > 0) {
          hash = (37 * hash) + FAVORED_NODES_FIELD_NUMBER;
          hash = (53 * hash) + getFavoredNodesList().hashCode();
        }
        if (hasOpenProcId()) {
          hash = (37 * hash) + OPEN_PROC_ID_FIELD_NUMBER;
          hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
              getOpenProcId());
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          java.nio.ByteBuffer data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          java.nio.ByteBuffer data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(byte[] data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          byte[] data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseDelimitedFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.OpenRegionRequest.RegionOpenInfo}
       */
      @javax.annotation.Generated("proto") public static final class Builder extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hbase.pb.OpenRegionRequest.RegionOpenInfo)
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder {
        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getRegionFieldBuilder();
            getFavoredNodesFieldBuilder();
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          region_ = null;
          if (regionBuilder_ != null) {
            regionBuilder_.dispose();
            regionBuilder_ = null;
          }
          versionOfOfflineNode_ = 0;
          if (favoredNodesBuilder_ == null) {
            favoredNodes_ = java.util.Collections.emptyList();
          } else {
            favoredNodes_ = null;
            favoredNodesBuilder_.clear();
          }
          bitField0_ = (bitField0_ & ~0x00000004);
          openProcId_ = -1L;
          return this;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo build() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo buildPartial() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo(this);
          buildPartialRepeatedFields(result);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo result) {
          if (favoredNodesBuilder_ == null) {
            if (((bitField0_ & 0x00000004) != 0)) {
              favoredNodes_ = java.util.Collections.unmodifiableList(favoredNodes_);
              bitField0_ = (bitField0_ & ~0x00000004);
            }
            result.favoredNodes_ = favoredNodes_;
          } else {
            result.favoredNodes_ = favoredNodesBuilder_.build();
          }
        }

        private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo result) {
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.region_ = regionBuilder_ == null
                ? region_
                : regionBuilder_.build();
            to_bitField0_ |= 0x00000001;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.versionOfOfflineNode_ = versionOfOfflineNode_;
            to_bitField0_ |= 0x00000002;
          }
          if (((from_bitField0_ & 0x00000008) != 0)) {
            result.openProcId_ = openProcId_;
            to_bitField0_ |= 0x00000004;
          }
          result.bitField0_ |= to_bitField0_;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo) {
            return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo other) {
          if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.getDefaultInstance()) return this;
          if (other.hasRegion()) {
            mergeRegion(other.getRegion());
          }
          if (other.hasVersionOfOfflineNode()) {
            setVersionOfOfflineNode(other.getVersionOfOfflineNode());
          }
          if (favoredNodesBuilder_ == null) {
            if (!other.favoredNodes_.isEmpty()) {
              if (favoredNodes_.isEmpty()) {
                favoredNodes_ = other.favoredNodes_;
                bitField0_ = (bitField0_ & ~0x00000004);
              } else {
                ensureFavoredNodesIsMutable();
                favoredNodes_.addAll(other.favoredNodes_);
              }
              onChanged();
            }
          } else {
            if (!other.favoredNodes_.isEmpty()) {
              if (favoredNodesBuilder_.isEmpty()) {
                favoredNodesBuilder_.dispose();
                favoredNodesBuilder_ = null;
                favoredNodes_ = other.favoredNodes_;
                bitField0_ = (bitField0_ & ~0x00000004);
                favoredNodesBuilder_ = 
                  org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getFavoredNodesFieldBuilder() : null;
              } else {
                favoredNodesBuilder_.addAllMessages(other.favoredNodes_);
              }
            }
          }
          if (other.hasOpenProcId()) {
            setOpenProcId(other.getOpenProcId());
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasRegion()) {
            return false;
          }
          if (!getRegion().isInitialized()) {
            return false;
          }
          for (int i = 0; i < getFavoredNodesCount(); i++) {
            if (!getFavoredNodes(i).isInitialized()) {
              return false;
            }
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  input.readMessage(
                      getRegionFieldBuilder().getBuilder(),
                      extensionRegistry);
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 16: {
                  versionOfOfflineNode_ = input.readUInt32();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 16
                case 26: {
                  org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName m =
                      input.readMessage(
                          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER,
                          extensionRegistry);
                  if (favoredNodesBuilder_ == null) {
                    ensureFavoredNodesIsMutable();
                    favoredNodes_.add(m);
                  } else {
                    favoredNodesBuilder_.addMessage(m);
                  }
                  break;
                } // case 26
                case 40: {
                  openProcId_ = input.readInt64();
                  bitField0_ |= 0x00000008;
                  break;
                } // case 40
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
        private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionBuilder_;
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         * @return Whether the region field is set.
         */
        public boolean hasRegion() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         * @return The region.
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
          if (regionBuilder_ == null) {
            return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
          } else {
            return regionBuilder_.getMessage();
          }
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
          if (regionBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            region_ = value;
          } else {
            regionBuilder_.setMessage(value);
          }
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder setRegion(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
          if (regionBuilder_ == null) {
            region_ = builderForValue.build();
          } else {
            regionBuilder_.setMessage(builderForValue.build());
          }
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
          if (regionBuilder_ == null) {
            if (((bitField0_ & 0x00000001) != 0) &&
              region_ != null &&
              region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
              getRegionBuilder().mergeFrom(value);
            } else {
              region_ = value;
            }
          } else {
            regionBuilder_.mergeFrom(value);
          }
          if (region_ != null) {
            bitField0_ |= 0x00000001;
            onChanged();
          }
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder clearRegion() {
          bitField0_ = (bitField0_ & ~0x00000001);
          region_ = null;
          if (regionBuilder_ != null) {
            regionBuilder_.dispose();
            regionBuilder_ = null;
          }
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionBuilder() {
          bitField0_ |= 0x00000001;
          onChanged();
          return getRegionFieldBuilder().getBuilder();
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
          if (regionBuilder_ != null) {
            return regionBuilder_.getMessageOrBuilder();
          } else {
            return region_ == null ?
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
          }
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
            getRegionFieldBuilder() {
          if (regionBuilder_ == null) {
            regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                    getRegion(),
                    getParentForChildren(),
                    isClean());
            region_ = null;
          }
          return regionBuilder_;
        }

        private int versionOfOfflineNode_ ;
        /**
         * <code>optional uint32 version_of_offline_node = 2;</code>
         * @return Whether the versionOfOfflineNode field is set.
         */
        @java.lang.Override
        public boolean hasVersionOfOfflineNode() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional uint32 version_of_offline_node = 2;</code>
         * @return The versionOfOfflineNode.
         */
        @java.lang.Override
        public int getVersionOfOfflineNode() {
          return versionOfOfflineNode_;
        }
        /**
         * <code>optional uint32 version_of_offline_node = 2;</code>
         * @param value The versionOfOfflineNode to set.
         * @return This builder for chaining.
         */
        public Builder setVersionOfOfflineNode(int value) {

          versionOfOfflineNode_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         * <code>optional uint32 version_of_offline_node = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearVersionOfOfflineNode() {
          bitField0_ = (bitField0_ & ~0x00000002);
          versionOfOfflineNode_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes_ =
          java.util.Collections.emptyList();
        private void ensureFavoredNodesIsMutable() {
          if (!((bitField0_ & 0x00000004) != 0)) {
            favoredNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName>(favoredNodes_);
            bitField0_ |= 0x00000004;
           }
        }

        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> favoredNodesBuilder_;

        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getFavoredNodesList() {
          if (favoredNodesBuilder_ == null) {
            return java.util.Collections.unmodifiableList(favoredNodes_);
          } else {
            return favoredNodesBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public int getFavoredNodesCount() {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.size();
          } else {
            return favoredNodesBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index) {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.get(index);
          } else {
            return favoredNodesBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder setFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.set(index, value);
            onChanged();
          } else {
            favoredNodesBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder setFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.set(index, builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder addFavoredNodes(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(value);
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder addFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(index, value);
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder addFavoredNodes(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder addFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(index, builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder addAllFavoredNodes(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> values) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, favoredNodes_);
            onChanged();
          } else {
            favoredNodesBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder clearFavoredNodes() {
          if (favoredNodesBuilder_ == null) {
            favoredNodes_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000004);
            onChanged();
          } else {
            favoredNodesBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public Builder removeFavoredNodes(int index) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.remove(index);
            onChanged();
          } else {
            favoredNodesBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getFavoredNodesBuilder(
            int index) {
          return getFavoredNodesFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
            int index) {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.get(index);  } else {
            return favoredNodesBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
             getFavoredNodesOrBuilderList() {
          if (favoredNodesBuilder_ != null) {
            return favoredNodesBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(favoredNodes_);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addFavoredNodesBuilder() {
          return getFavoredNodesFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addFavoredNodesBuilder(
            int index) {
          return getFavoredNodesFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 3;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder> 
             getFavoredNodesBuilderList() {
          return getFavoredNodesFieldBuilder().getBuilderList();
        }
        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
            getFavoredNodesFieldBuilder() {
          if (favoredNodesBuilder_ == null) {
            favoredNodesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                    favoredNodes_,
                    ((bitField0_ & 0x00000004) != 0),
                    getParentForChildren(),
                    isClean());
            favoredNodes_ = null;
          }
          return favoredNodesBuilder_;
        }

        private long openProcId_ = -1L;
        /**
         * <pre>
         * open region for distributedLogReplay
         * optional bool DEPRECATED_openForDistributedLogReplay = 4;
         * </pre>
         *
         * <code>optional int64 open_proc_id = 5 [default = -1];</code>
         * @return Whether the openProcId field is set.
         */
        @java.lang.Override
        public boolean hasOpenProcId() {
          return ((bitField0_ & 0x00000008) != 0);
        }
        /**
         * <pre>
         * open region for distributedLogReplay
         * optional bool DEPRECATED_openForDistributedLogReplay = 4;
         * </pre>
         *
         * <code>optional int64 open_proc_id = 5 [default = -1];</code>
         * @return The openProcId.
         */
        @java.lang.Override
        public long getOpenProcId() {
          return openProcId_;
        }
        /**
         * <pre>
         * open region for distributedLogReplay
         * optional bool DEPRECATED_openForDistributedLogReplay = 4;
         * </pre>
         *
         * <code>optional int64 open_proc_id = 5 [default = -1];</code>
         * @param value The openProcId to set.
         * @return This builder for chaining.
         */
        public Builder setOpenProcId(long value) {

          openProcId_ = value;
          bitField0_ |= 0x00000008;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * open region for distributedLogReplay
         * optional bool DEPRECATED_openForDistributedLogReplay = 4;
         * </pre>
         *
         * <code>optional int64 open_proc_id = 5 [default = -1];</code>
         * @return This builder for chaining.
         */
        public Builder clearOpenProcId() {
          bitField0_ = (bitField0_ & ~0x00000008);
          openProcId_ = -1L;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hbase.pb.OpenRegionRequest.RegionOpenInfo)
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.OpenRegionRequest.RegionOpenInfo)
      private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo();
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionOpenInfo>
          PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionOpenInfo>() {
        @java.lang.Override
        public RegionOpenInfo parsePartialFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionOpenInfo> parser() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionOpenInfo> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int OPEN_INFO_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> openInfo_;
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> getOpenInfoList() {
      return openInfo_;
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder> 
        getOpenInfoOrBuilderList() {
      return openInfo_;
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    @java.lang.Override
    public int getOpenInfoCount() {
      return openInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getOpenInfo(int index) {
      return openInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder getOpenInfoOrBuilder(
        int index) {
      return openInfo_.get(index);
    }

    public static final int SERVERSTARTCODE_FIELD_NUMBER = 2;
    private long serverStartCode_ = 0L;
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 2;</code>
     * @return Whether the serverStartCode field is set.
     */
    @java.lang.Override
    public boolean hasServerStartCode() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 2;</code>
     * @return The serverStartCode.
     */
    @java.lang.Override
    public long getServerStartCode() {
      return serverStartCode_;
    }

    public static final int INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER = 3;
    private long initiatingMasterActiveTime_ = 0L;
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 3;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    @java.lang.Override
    public boolean hasInitiatingMasterActiveTime() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 3;</code>
     * @return The initiatingMasterActiveTime.
     */
    @java.lang.Override
    public long getInitiatingMasterActiveTime() {
      return initiatingMasterActiveTime_;
    }

    public static final int MASTER_SYSTEM_TIME_FIELD_NUMBER = 5;
    private long masterSystemTime_ = 0L;
    /**
     * <pre>
     * wall clock time from master
     * </pre>
     *
     * <code>optional uint64 master_system_time = 5;</code>
     * @return Whether the masterSystemTime field is set.
     */
    @java.lang.Override
    public boolean hasMasterSystemTime() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * wall clock time from master
     * </pre>
     *
     * <code>optional uint64 master_system_time = 5;</code>
     * @return The masterSystemTime.
     */
    @java.lang.Override
    public long getMasterSystemTime() {
      return masterSystemTime_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getOpenInfoCount(); i++) {
        if (!getOpenInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < openInfo_.size(); i++) {
        output.writeMessage(1, openInfo_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(2, serverStartCode_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt64(3, initiatingMasterActiveTime_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(5, masterSystemTime_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < openInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, openInfo_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, serverStartCode_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, initiatingMasterActiveTime_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, masterSystemTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest) obj;

      if (!getOpenInfoList()
          .equals(other.getOpenInfoList())) return false;
      if (hasServerStartCode() != other.hasServerStartCode()) return false;
      if (hasServerStartCode()) {
        if (getServerStartCode()
            != other.getServerStartCode()) return false;
      }
      if (hasInitiatingMasterActiveTime() != other.hasInitiatingMasterActiveTime()) return false;
      if (hasInitiatingMasterActiveTime()) {
        if (getInitiatingMasterActiveTime()
            != other.getInitiatingMasterActiveTime()) return false;
      }
      if (hasMasterSystemTime() != other.hasMasterSystemTime()) return false;
      if (hasMasterSystemTime()) {
        if (getMasterSystemTime()
            != other.getMasterSystemTime()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getOpenInfoCount() > 0) {
        hash = (37 * hash) + OPEN_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getOpenInfoList().hashCode();
      }
      if (hasServerStartCode()) {
        hash = (37 * hash) + SERVERSTARTCODE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getServerStartCode());
      }
      if (hasInitiatingMasterActiveTime()) {
        hash = (37 * hash) + INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getInitiatingMasterActiveTime());
      }
      if (hasMasterSystemTime()) {
        hash = (37 * hash) + MASTER_SYSTEM_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getMasterSystemTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.OpenRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.OpenRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (openInfoBuilder_ == null) {
          openInfo_ = java.util.Collections.emptyList();
        } else {
          openInfo_ = null;
          openInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        serverStartCode_ = 0L;
        initiatingMasterActiveTime_ = 0L;
        masterSystemTime_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest result) {
        if (openInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            openInfo_ = java.util.Collections.unmodifiableList(openInfo_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.openInfo_ = openInfo_;
        } else {
          result.openInfo_ = openInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.serverStartCode_ = serverStartCode_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.initiatingMasterActiveTime_ = initiatingMasterActiveTime_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.masterSystemTime_ = masterSystemTime_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance()) return this;
        if (openInfoBuilder_ == null) {
          if (!other.openInfo_.isEmpty()) {
            if (openInfo_.isEmpty()) {
              openInfo_ = other.openInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureOpenInfoIsMutable();
              openInfo_.addAll(other.openInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.openInfo_.isEmpty()) {
            if (openInfoBuilder_.isEmpty()) {
              openInfoBuilder_.dispose();
              openInfoBuilder_ = null;
              openInfo_ = other.openInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
              openInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getOpenInfoFieldBuilder() : null;
            } else {
              openInfoBuilder_.addAllMessages(other.openInfo_);
            }
          }
        }
        if (other.hasServerStartCode()) {
          setServerStartCode(other.getServerStartCode());
        }
        if (other.hasInitiatingMasterActiveTime()) {
          setInitiatingMasterActiveTime(other.getInitiatingMasterActiveTime());
        }
        if (other.hasMasterSystemTime()) {
          setMasterSystemTime(other.getMasterSystemTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getOpenInfoCount(); i++) {
          if (!getOpenInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.PARSER,
                        extensionRegistry);
                if (openInfoBuilder_ == null) {
                  ensureOpenInfoIsMutable();
                  openInfo_.add(m);
                } else {
                  openInfoBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                serverStartCode_ = input.readUInt64();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                initiatingMasterActiveTime_ = input.readInt64();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 40: {
                masterSystemTime_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 40
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> openInfo_ =
        java.util.Collections.emptyList();
      private void ensureOpenInfoIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          openInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo>(openInfo_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder> openInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> getOpenInfoList() {
        if (openInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(openInfo_);
        } else {
          return openInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public int getOpenInfoCount() {
        if (openInfoBuilder_ == null) {
          return openInfo_.size();
        } else {
          return openInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo getOpenInfo(int index) {
        if (openInfoBuilder_ == null) {
          return openInfo_.get(index);
        } else {
          return openInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder setOpenInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo value) {
        if (openInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenInfoIsMutable();
          openInfo_.set(index, value);
          onChanged();
        } else {
          openInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder setOpenInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder builderForValue) {
        if (openInfoBuilder_ == null) {
          ensureOpenInfoIsMutable();
          openInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          openInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder addOpenInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo value) {
        if (openInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenInfoIsMutable();
          openInfo_.add(value);
          onChanged();
        } else {
          openInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder addOpenInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo value) {
        if (openInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenInfoIsMutable();
          openInfo_.add(index, value);
          onChanged();
        } else {
          openInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder addOpenInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder builderForValue) {
        if (openInfoBuilder_ == null) {
          ensureOpenInfoIsMutable();
          openInfo_.add(builderForValue.build());
          onChanged();
        } else {
          openInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder addOpenInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder builderForValue) {
        if (openInfoBuilder_ == null) {
          ensureOpenInfoIsMutable();
          openInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          openInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder addAllOpenInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo> values) {
        if (openInfoBuilder_ == null) {
          ensureOpenInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, openInfo_);
          onChanged();
        } else {
          openInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder clearOpenInfo() {
        if (openInfoBuilder_ == null) {
          openInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          openInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public Builder removeOpenInfo(int index) {
        if (openInfoBuilder_ == null) {
          ensureOpenInfoIsMutable();
          openInfo_.remove(index);
          onChanged();
        } else {
          openInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder getOpenInfoBuilder(
          int index) {
        return getOpenInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder getOpenInfoOrBuilder(
          int index) {
        if (openInfoBuilder_ == null) {
          return openInfo_.get(index);  } else {
          return openInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder> 
           getOpenInfoOrBuilderList() {
        if (openInfoBuilder_ != null) {
          return openInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(openInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder addOpenInfoBuilder() {
        return getOpenInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder addOpenInfoBuilder(
          int index) {
        return getOpenInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest.RegionOpenInfo open_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder> 
           getOpenInfoBuilderList() {
        return getOpenInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder> 
          getOpenInfoFieldBuilder() {
        if (openInfoBuilder_ == null) {
          openInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.RegionOpenInfoOrBuilder>(
                  openInfo_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          openInfo_ = null;
        }
        return openInfoBuilder_;
      }

      private long serverStartCode_ ;
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 2;</code>
       * @return Whether the serverStartCode field is set.
       */
      @java.lang.Override
      public boolean hasServerStartCode() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 2;</code>
       * @return The serverStartCode.
       */
      @java.lang.Override
      public long getServerStartCode() {
        return serverStartCode_;
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 2;</code>
       * @param value The serverStartCode to set.
       * @return This builder for chaining.
       */
      public Builder setServerStartCode(long value) {

        serverStartCode_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearServerStartCode() {
        bitField0_ = (bitField0_ & ~0x00000002);
        serverStartCode_ = 0L;
        onChanged();
        return this;
      }

      private long initiatingMasterActiveTime_ ;
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 3;</code>
       * @return Whether the initiatingMasterActiveTime field is set.
       */
      @java.lang.Override
      public boolean hasInitiatingMasterActiveTime() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 3;</code>
       * @return The initiatingMasterActiveTime.
       */
      @java.lang.Override
      public long getInitiatingMasterActiveTime() {
        return initiatingMasterActiveTime_;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 3;</code>
       * @param value The initiatingMasterActiveTime to set.
       * @return This builder for chaining.
       */
      public Builder setInitiatingMasterActiveTime(long value) {

        initiatingMasterActiveTime_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearInitiatingMasterActiveTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        initiatingMasterActiveTime_ = 0L;
        onChanged();
        return this;
      }

      private long masterSystemTime_ ;
      /**
       * <pre>
       * wall clock time from master
       * </pre>
       *
       * <code>optional uint64 master_system_time = 5;</code>
       * @return Whether the masterSystemTime field is set.
       */
      @java.lang.Override
      public boolean hasMasterSystemTime() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * wall clock time from master
       * </pre>
       *
       * <code>optional uint64 master_system_time = 5;</code>
       * @return The masterSystemTime.
       */
      @java.lang.Override
      public long getMasterSystemTime() {
        return masterSystemTime_;
      }
      /**
       * <pre>
       * wall clock time from master
       * </pre>
       *
       * <code>optional uint64 master_system_time = 5;</code>
       * @param value The masterSystemTime to set.
       * @return This builder for chaining.
       */
      public Builder setMasterSystemTime(long value) {

        masterSystemTime_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * wall clock time from master
       * </pre>
       *
       * <code>optional uint64 master_system_time = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearMasterSystemTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        masterSystemTime_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.OpenRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.OpenRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<OpenRegionRequest>() {
      @java.lang.Override
      public OpenRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface OpenRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.OpenRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @return A list containing the openingState.
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState> getOpeningStateList();
    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @return The count of openingState.
     */
    int getOpeningStateCount();
    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @param index The index of the element to return.
     * @return The openingState at the given index.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState getOpeningState(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.OpenRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class OpenRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.OpenRegionResponse)
      OpenRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use OpenRegionResponse.newBuilder() to construct.
    private OpenRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private OpenRegionResponse() {
      openingState_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new OpenRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.OpenRegionResponse.RegionOpeningState}
     */
    public enum RegionOpeningState
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>OPENED = 0;</code>
       */
      OPENED(0),
      /**
       * <code>ALREADY_OPENED = 1;</code>
       */
      ALREADY_OPENED(1),
      /**
       * <code>FAILED_OPENING = 2;</code>
       */
      FAILED_OPENING(2),
      ;

      /**
       * <code>OPENED = 0;</code>
       */
      public static final int OPENED_VALUE = 0;
      /**
       * <code>ALREADY_OPENED = 1;</code>
       */
      public static final int ALREADY_OPENED_VALUE = 1;
      /**
       * <code>FAILED_OPENING = 2;</code>
       */
      public static final int FAILED_OPENING_VALUE = 2;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static RegionOpeningState valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static RegionOpeningState forNumber(int value) {
        switch (value) {
          case 0: return OPENED;
          case 1: return ALREADY_OPENED;
          case 2: return FAILED_OPENING;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionOpeningState>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          RegionOpeningState> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<RegionOpeningState>() {
              public RegionOpeningState findValueByNumber(int number) {
                return RegionOpeningState.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDescriptor().getEnumTypes().get(0);
      }

      private static final RegionOpeningState[] VALUES = values();

      public static RegionOpeningState valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private RegionOpeningState(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.OpenRegionResponse.RegionOpeningState)
    }

    public static final int OPENING_STATE_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<java.lang.Integer> openingState_;
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState> openingState_converter_ =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState>() {
              public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState convert(java.lang.Integer from) {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState.forNumber(from);
                return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState.OPENED : result;
              }
            };
    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @return A list containing the openingState.
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState> getOpeningStateList() {
      return new org.apache.hbase.thirdparty.com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState>(openingState_, openingState_converter_);
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @return The count of openingState.
     */
    @java.lang.Override
    public int getOpeningStateCount() {
      return openingState_.size();
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
     * @param index The index of the element to return.
     * @return The openingState at the given index.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState getOpeningState(int index) {
      return openingState_converter_.convert(openingState_.get(index));
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < openingState_.size(); i++) {
        output.writeEnum(1, openingState_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < openingState_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(openingState_.get(i));
        }
        size += dataSize;
        size += 1 * openingState_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse) obj;

      if (!openingState_.equals(other.openingState_)) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getOpeningStateCount() > 0) {
        hash = (37 * hash) + OPENING_STATE_FIELD_NUMBER;
        hash = (53 * hash) + openingState_.hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.OpenRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.OpenRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        openingState_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_OpenRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse result) {
        if (((bitField0_ & 0x00000001) != 0)) {
          openingState_ = java.util.Collections.unmodifiableList(openingState_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.openingState_ = openingState_;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance()) return this;
        if (!other.openingState_.isEmpty()) {
          if (openingState_.isEmpty()) {
            openingState_ = other.openingState_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureOpeningStateIsMutable();
            openingState_.addAll(other.openingState_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  ensureOpeningStateIsMutable();
                  openingState_.add(tmpRaw);
                }
                break;
              } // case 8
              case 10: {
                int length = input.readRawVarint32();
                int oldLimit = input.pushLimit(length);
                while(input.getBytesUntilLimit() > 0) {
                  int tmpRaw = input.readEnum();
                  org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState tmpValue =
                      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState.forNumber(tmpRaw);
                  if (tmpValue == null) {
                    mergeUnknownVarintField(1, tmpRaw);
                  } else {
                    ensureOpeningStateIsMutable();
                    openingState_.add(tmpRaw);
                  }
                }
                input.popLimit(oldLimit);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<java.lang.Integer> openingState_ =
        java.util.Collections.emptyList();
      private void ensureOpeningStateIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          openingState_ = new java.util.ArrayList<java.lang.Integer>(openingState_);
          bitField0_ |= 0x00000001;
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @return A list containing the openingState.
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState> getOpeningStateList() {
        return new org.apache.hbase.thirdparty.com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState>(openingState_, openingState_converter_);
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @return The count of openingState.
       */
      public int getOpeningStateCount() {
        return openingState_.size();
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @param index The index of the element to return.
       * @return The openingState at the given index.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState getOpeningState(int index) {
        return openingState_converter_.convert(openingState_.get(index));
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @param index The index to set the value at.
       * @param value The openingState to set.
       * @return This builder for chaining.
       */
      public Builder setOpeningState(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureOpeningStateIsMutable();
        openingState_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @param value The openingState to add.
       * @return This builder for chaining.
       */
      public Builder addOpeningState(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureOpeningStateIsMutable();
        openingState_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @param values The openingState to add.
       * @return This builder for chaining.
       */
      public Builder addAllOpeningState(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState> values) {
        ensureOpeningStateIsMutable();
        for (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.RegionOpeningState value : values) {
          openingState_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionResponse.RegionOpeningState opening_state = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearOpeningState() {
        openingState_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.OpenRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.OpenRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<OpenRegionResponse>() {
      @java.lang.Override
      public OpenRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<OpenRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WarmupRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WarmupRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    boolean hasRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     * @return The regionInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.WarmupRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class WarmupRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WarmupRegionRequest)
      WarmupRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WarmupRegionRequest.newBuilder() to construct.
    private WarmupRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WarmupRegionRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WarmupRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGIONINFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     * @return Whether the regionInfo field is set.
     */
    @java.lang.Override
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     * @return The regionInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }
    /**
     * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegionInfo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegionInfo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest) obj;

      if (hasRegionInfo() != other.hasRegionInfo()) return false;
      if (hasRegionInfo()) {
        if (!getRegionInfo()
            .equals(other.getRegionInfo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGIONINFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.WarmupRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WarmupRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.regionInfo_ = regionInfoBuilder_ == null
              ? regionInfo_
              : regionInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegionInfo()) {
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       * @return Whether the regionInfo field is set.
       */
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       * @return The regionInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public Builder setRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            regionInfo_ != null &&
            regionInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            getRegionInfoBuilder().mergeFrom(value);
          } else {
            regionInfo_ = value;
          }
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        if (regionInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public Builder clearRegionInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        regionInfo_ = null;
        if (regionInfoBuilder_ != null) {
          regionInfoBuilder_.dispose();
          regionInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : regionInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionInfo regionInfo = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  getRegionInfo(),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WarmupRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WarmupRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WarmupRegionRequest>() {
      @java.lang.Override
      public WarmupRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WarmupRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WarmupRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.WarmupRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class WarmupRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WarmupRegionResponse)
      WarmupRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WarmupRegionResponse.newBuilder() to construct.
    private WarmupRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WarmupRegionResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WarmupRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.WarmupRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WarmupRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WarmupRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WarmupRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WarmupRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WarmupRegionResponse>() {
      @java.lang.Override
      public WarmupRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WarmupRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>optional uint32 version_of_closing_node = 2;</code>
     * @return Whether the versionOfClosingNode field is set.
     */
    boolean hasVersionOfClosingNode();
    /**
     * <code>optional uint32 version_of_closing_node = 2;</code>
     * @return The versionOfClosingNode.
     */
    int getVersionOfClosingNode();

    /**
     * <code>optional bool transition_in_ZK = 3 [default = true];</code>
     * @return Whether the transitionInZK field is set.
     */
    boolean hasTransitionInZK();
    /**
     * <code>optional bool transition_in_ZK = 3 [default = true];</code>
     * @return The transitionInZK.
     */
    boolean getTransitionInZK();

    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     * @return Whether the destinationServer field is set.
     */
    boolean hasDestinationServer();
    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     * @return The destinationServer.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer();
    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder();

    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 5;</code>
     * @return Whether the serverStartCode field is set.
     */
    boolean hasServerStartCode();
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 5;</code>
     * @return The serverStartCode.
     */
    long getServerStartCode();

    /**
     * <code>optional int64 close_proc_id = 6 [default = -1];</code>
     * @return Whether the closeProcId field is set.
     */
    boolean hasCloseProcId();
    /**
     * <code>optional int64 close_proc_id = 6 [default = -1];</code>
     * @return The closeProcId.
     */
    long getCloseProcId();

    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 8;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    boolean hasInitiatingMasterActiveTime();
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 8;</code>
     * @return The initiatingMasterActiveTime.
     */
    long getInitiatingMasterActiveTime();
  }
  /**
   * <pre>
   **
   * Closes the specified region and will use or not use ZK during the close
   * according to the specified flag.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.CloseRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class CloseRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseRegionRequest)
      CloseRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseRegionRequest.newBuilder() to construct.
    private CloseRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseRegionRequest() {
      transitionInZK_ = true;
      closeProcId_ = -1L;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int VERSION_OF_CLOSING_NODE_FIELD_NUMBER = 2;
    private int versionOfClosingNode_ = 0;
    /**
     * <code>optional uint32 version_of_closing_node = 2;</code>
     * @return Whether the versionOfClosingNode field is set.
     */
    @java.lang.Override
    public boolean hasVersionOfClosingNode() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional uint32 version_of_closing_node = 2;</code>
     * @return The versionOfClosingNode.
     */
    @java.lang.Override
    public int getVersionOfClosingNode() {
      return versionOfClosingNode_;
    }

    public static final int TRANSITION_IN_ZK_FIELD_NUMBER = 3;
    private boolean transitionInZK_ = true;
    /**
     * <code>optional bool transition_in_ZK = 3 [default = true];</code>
     * @return Whether the transitionInZK field is set.
     */
    @java.lang.Override
    public boolean hasTransitionInZK() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool transition_in_ZK = 3 [default = true];</code>
     * @return The transitionInZK.
     */
    @java.lang.Override
    public boolean getTransitionInZK() {
      return transitionInZK_;
    }

    public static final int DESTINATION_SERVER_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     * @return Whether the destinationServer field is set.
     */
    @java.lang.Override
    public boolean hasDestinationServer() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     * @return The destinationServer.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }
    /**
     * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
      return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
    }

    public static final int SERVERSTARTCODE_FIELD_NUMBER = 5;
    private long serverStartCode_ = 0L;
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 5;</code>
     * @return Whether the serverStartCode field is set.
     */
    @java.lang.Override
    public boolean hasServerStartCode() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * the intended server for this RPC.
     * </pre>
     *
     * <code>optional uint64 serverStartCode = 5;</code>
     * @return The serverStartCode.
     */
    @java.lang.Override
    public long getServerStartCode() {
      return serverStartCode_;
    }

    public static final int CLOSE_PROC_ID_FIELD_NUMBER = 6;
    private long closeProcId_ = -1L;
    /**
     * <code>optional int64 close_proc_id = 6 [default = -1];</code>
     * @return Whether the closeProcId field is set.
     */
    @java.lang.Override
    public boolean hasCloseProcId() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional int64 close_proc_id = 6 [default = -1];</code>
     * @return The closeProcId.
     */
    @java.lang.Override
    public long getCloseProcId() {
      return closeProcId_;
    }

    public static final int INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER = 8;
    private long initiatingMasterActiveTime_ = 0L;
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 8;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    @java.lang.Override
    public boolean hasInitiatingMasterActiveTime() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 8;</code>
     * @return The initiatingMasterActiveTime.
     */
    @java.lang.Override
    public long getInitiatingMasterActiveTime() {
      return initiatingMasterActiveTime_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasDestinationServer()) {
        if (!getDestinationServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt32(2, versionOfClosingNode_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, transitionInZK_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeUInt64(5, serverStartCode_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeInt64(6, closeProcId_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeInt64(8, initiatingMasterActiveTime_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, versionOfClosingNode_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, transitionInZK_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getDestinationServer());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, serverStartCode_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, closeProcId_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(8, initiatingMasterActiveTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasVersionOfClosingNode() != other.hasVersionOfClosingNode()) return false;
      if (hasVersionOfClosingNode()) {
        if (getVersionOfClosingNode()
            != other.getVersionOfClosingNode()) return false;
      }
      if (hasTransitionInZK() != other.hasTransitionInZK()) return false;
      if (hasTransitionInZK()) {
        if (getTransitionInZK()
            != other.getTransitionInZK()) return false;
      }
      if (hasDestinationServer() != other.hasDestinationServer()) return false;
      if (hasDestinationServer()) {
        if (!getDestinationServer()
            .equals(other.getDestinationServer())) return false;
      }
      if (hasServerStartCode() != other.hasServerStartCode()) return false;
      if (hasServerStartCode()) {
        if (getServerStartCode()
            != other.getServerStartCode()) return false;
      }
      if (hasCloseProcId() != other.hasCloseProcId()) return false;
      if (hasCloseProcId()) {
        if (getCloseProcId()
            != other.getCloseProcId()) return false;
      }
      if (hasInitiatingMasterActiveTime() != other.hasInitiatingMasterActiveTime()) return false;
      if (hasInitiatingMasterActiveTime()) {
        if (getInitiatingMasterActiveTime()
            != other.getInitiatingMasterActiveTime()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasVersionOfClosingNode()) {
        hash = (37 * hash) + VERSION_OF_CLOSING_NODE_FIELD_NUMBER;
        hash = (53 * hash) + getVersionOfClosingNode();
      }
      if (hasTransitionInZK()) {
        hash = (37 * hash) + TRANSITION_IN_ZK_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getTransitionInZK());
      }
      if (hasDestinationServer()) {
        hash = (37 * hash) + DESTINATION_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getDestinationServer().hashCode();
      }
      if (hasServerStartCode()) {
        hash = (37 * hash) + SERVERSTARTCODE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getServerStartCode());
      }
      if (hasCloseProcId()) {
        hash = (37 * hash) + CLOSE_PROC_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getCloseProcId());
      }
      if (hasInitiatingMasterActiveTime()) {
        hash = (37 * hash) + INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getInitiatingMasterActiveTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Closes the specified region and will use or not use ZK during the close
     * according to the specified flag.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.CloseRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getDestinationServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        versionOfClosingNode_ = 0;
        transitionInZK_ = true;
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        serverStartCode_ = 0L;
        closeProcId_ = -1L;
        initiatingMasterActiveTime_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.versionOfClosingNode_ = versionOfClosingNode_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.transitionInZK_ = transitionInZK_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.destinationServer_ = destinationServerBuilder_ == null
              ? destinationServer_
              : destinationServerBuilder_.build();
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.serverStartCode_ = serverStartCode_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.closeProcId_ = closeProcId_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.initiatingMasterActiveTime_ = initiatingMasterActiveTime_;
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasVersionOfClosingNode()) {
          setVersionOfClosingNode(other.getVersionOfClosingNode());
        }
        if (other.hasTransitionInZK()) {
          setTransitionInZK(other.getTransitionInZK());
        }
        if (other.hasDestinationServer()) {
          mergeDestinationServer(other.getDestinationServer());
        }
        if (other.hasServerStartCode()) {
          setServerStartCode(other.getServerStartCode());
        }
        if (other.hasCloseProcId()) {
          setCloseProcId(other.getCloseProcId());
        }
        if (other.hasInitiatingMasterActiveTime()) {
          setInitiatingMasterActiveTime(other.getInitiatingMasterActiveTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        if (hasDestinationServer()) {
          if (!getDestinationServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                versionOfClosingNode_ = input.readUInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                transitionInZK_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 34: {
                input.readMessage(
                    getDestinationServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 40: {
                serverStartCode_ = input.readUInt64();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 48: {
                closeProcId_ = input.readInt64();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 64: {
                initiatingMasterActiveTime_ = input.readInt64();
                bitField0_ |= 0x00000040;
                break;
              } // case 64
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private int versionOfClosingNode_ ;
      /**
       * <code>optional uint32 version_of_closing_node = 2;</code>
       * @return Whether the versionOfClosingNode field is set.
       */
      @java.lang.Override
      public boolean hasVersionOfClosingNode() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint32 version_of_closing_node = 2;</code>
       * @return The versionOfClosingNode.
       */
      @java.lang.Override
      public int getVersionOfClosingNode() {
        return versionOfClosingNode_;
      }
      /**
       * <code>optional uint32 version_of_closing_node = 2;</code>
       * @param value The versionOfClosingNode to set.
       * @return This builder for chaining.
       */
      public Builder setVersionOfClosingNode(int value) {

        versionOfClosingNode_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 version_of_closing_node = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearVersionOfClosingNode() {
        bitField0_ = (bitField0_ & ~0x00000002);
        versionOfClosingNode_ = 0;
        onChanged();
        return this;
      }

      private boolean transitionInZK_ = true;
      /**
       * <code>optional bool transition_in_ZK = 3 [default = true];</code>
       * @return Whether the transitionInZK field is set.
       */
      @java.lang.Override
      public boolean hasTransitionInZK() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool transition_in_ZK = 3 [default = true];</code>
       * @return The transitionInZK.
       */
      @java.lang.Override
      public boolean getTransitionInZK() {
        return transitionInZK_;
      }
      /**
       * <code>optional bool transition_in_ZK = 3 [default = true];</code>
       * @param value The transitionInZK to set.
       * @return This builder for chaining.
       */
      public Builder setTransitionInZK(boolean value) {

        transitionInZK_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool transition_in_ZK = 3 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearTransitionInZK() {
        bitField0_ = (bitField0_ & ~0x00000004);
        transitionInZK_ = true;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName destinationServer_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> destinationServerBuilder_;
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       * @return Whether the destinationServer field is set.
       */
      public boolean hasDestinationServer() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       * @return The destinationServer.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getDestinationServer() {
        if (destinationServerBuilder_ == null) {
          return destinationServer_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        } else {
          return destinationServerBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public Builder setDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          destinationServer_ = value;
        } else {
          destinationServerBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public Builder setDestinationServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (destinationServerBuilder_ == null) {
          destinationServer_ = builderForValue.build();
        } else {
          destinationServerBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public Builder mergeDestinationServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (destinationServerBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
            destinationServer_ != null &&
            destinationServer_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getDestinationServerBuilder().mergeFrom(value);
          } else {
            destinationServer_ = value;
          }
        } else {
          destinationServerBuilder_.mergeFrom(value);
        }
        if (destinationServer_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public Builder clearDestinationServer() {
        bitField0_ = (bitField0_ & ~0x00000008);
        destinationServer_ = null;
        if (destinationServerBuilder_ != null) {
          destinationServerBuilder_.dispose();
          destinationServerBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getDestinationServerBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getDestinationServerFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDestinationServerOrBuilder() {
        if (destinationServerBuilder_ != null) {
          return destinationServerBuilder_.getMessageOrBuilder();
        } else {
          return destinationServer_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : destinationServer_;
        }
      }
      /**
       * <code>optional .hbase.pb.ServerName destination_server = 4;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDestinationServerFieldBuilder() {
        if (destinationServerBuilder_ == null) {
          destinationServerBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getDestinationServer(),
                  getParentForChildren(),
                  isClean());
          destinationServer_ = null;
        }
        return destinationServerBuilder_;
      }

      private long serverStartCode_ ;
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 5;</code>
       * @return Whether the serverStartCode field is set.
       */
      @java.lang.Override
      public boolean hasServerStartCode() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 5;</code>
       * @return The serverStartCode.
       */
      @java.lang.Override
      public long getServerStartCode() {
        return serverStartCode_;
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 5;</code>
       * @param value The serverStartCode to set.
       * @return This builder for chaining.
       */
      public Builder setServerStartCode(long value) {

        serverStartCode_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * the intended server for this RPC.
       * </pre>
       *
       * <code>optional uint64 serverStartCode = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearServerStartCode() {
        bitField0_ = (bitField0_ & ~0x00000010);
        serverStartCode_ = 0L;
        onChanged();
        return this;
      }

      private long closeProcId_ = -1L;
      /**
       * <code>optional int64 close_proc_id = 6 [default = -1];</code>
       * @return Whether the closeProcId field is set.
       */
      @java.lang.Override
      public boolean hasCloseProcId() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional int64 close_proc_id = 6 [default = -1];</code>
       * @return The closeProcId.
       */
      @java.lang.Override
      public long getCloseProcId() {
        return closeProcId_;
      }
      /**
       * <code>optional int64 close_proc_id = 6 [default = -1];</code>
       * @param value The closeProcId to set.
       * @return This builder for chaining.
       */
      public Builder setCloseProcId(long value) {

        closeProcId_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 close_proc_id = 6 [default = -1];</code>
       * @return This builder for chaining.
       */
      public Builder clearCloseProcId() {
        bitField0_ = (bitField0_ & ~0x00000020);
        closeProcId_ = -1L;
        onChanged();
        return this;
      }

      private long initiatingMasterActiveTime_ ;
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 8;</code>
       * @return Whether the initiatingMasterActiveTime field is set.
       */
      @java.lang.Override
      public boolean hasInitiatingMasterActiveTime() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 8;</code>
       * @return The initiatingMasterActiveTime.
       */
      @java.lang.Override
      public long getInitiatingMasterActiveTime() {
        return initiatingMasterActiveTime_;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 8;</code>
       * @param value The initiatingMasterActiveTime to set.
       * @return This builder for chaining.
       */
      public Builder setInitiatingMasterActiveTime(long value) {

        initiatingMasterActiveTime_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearInitiatingMasterActiveTime() {
        bitField0_ = (bitField0_ & ~0x00000040);
        initiatingMasterActiveTime_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseRegionRequest>() {
      @java.lang.Override
      public CloseRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CloseRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CloseRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool closed = 1;</code>
     * @return Whether the closed field is set.
     */
    boolean hasClosed();
    /**
     * <code>required bool closed = 1;</code>
     * @return The closed.
     */
    boolean getClosed();
  }
  /**
   * Protobuf type {@code hbase.pb.CloseRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class CloseRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CloseRegionResponse)
      CloseRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CloseRegionResponse.newBuilder() to construct.
    private CloseRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CloseRegionResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CloseRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.Builder.class);
    }

    private int bitField0_;
    public static final int CLOSED_FIELD_NUMBER = 1;
    private boolean closed_ = false;
    /**
     * <code>required bool closed = 1;</code>
     * @return Whether the closed field is set.
     */
    @java.lang.Override
    public boolean hasClosed() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool closed = 1;</code>
     * @return The closed.
     */
    @java.lang.Override
    public boolean getClosed() {
      return closed_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasClosed()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, closed_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, closed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse) obj;

      if (hasClosed() != other.hasClosed()) return false;
      if (hasClosed()) {
        if (getClosed()
            != other.getClosed()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasClosed()) {
        hash = (37 * hash) + CLOSED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getClosed());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CloseRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CloseRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        closed_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CloseRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.closed_ = closed_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance()) return this;
        if (other.hasClosed()) {
          setClosed(other.getClosed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasClosed()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                closed_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean closed_ ;
      /**
       * <code>required bool closed = 1;</code>
       * @return Whether the closed field is set.
       */
      @java.lang.Override
      public boolean hasClosed() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool closed = 1;</code>
       * @return The closed.
       */
      @java.lang.Override
      public boolean getClosed() {
        return closed_;
      }
      /**
       * <code>required bool closed = 1;</code>
       * @param value The closed to set.
       * @return This builder for chaining.
       */
      public Builder setClosed(boolean value) {

        closed_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool closed = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearClosed() {
        bitField0_ = (bitField0_ & ~0x00000001);
        closed_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CloseRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CloseRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CloseRegionResponse>() {
      @java.lang.Override
      public CloseRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CloseRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FlushRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FlushRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>optional uint64 if_older_than_ts = 2;</code>
     * @return Whether the ifOlderThanTs field is set.
     */
    boolean hasIfOlderThanTs();
    /**
     * <code>optional uint64 if_older_than_ts = 2;</code>
     * @return The ifOlderThanTs.
     */
    long getIfOlderThanTs();

    /**
     * <pre>
     * whether to write a marker to WAL even if not flushed
     * </pre>
     *
     * <code>optional bool write_flush_wal_marker = 3;</code>
     * @return Whether the writeFlushWalMarker field is set.
     */
    boolean hasWriteFlushWalMarker();
    /**
     * <pre>
     * whether to write a marker to WAL even if not flushed
     * </pre>
     *
     * <code>optional bool write_flush_wal_marker = 3;</code>
     * @return The writeFlushWalMarker.
     */
    boolean getWriteFlushWalMarker();

    /**
     * <code>optional bytes family = 4;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>optional bytes family = 4;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();
  }
  /**
   * <pre>
   **
   * Flushes the MemStore of the specified region.
   * &lt;p&gt;
   * This method is synchronous.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.FlushRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class FlushRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FlushRegionRequest)
      FlushRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FlushRegionRequest.newBuilder() to construct.
    private FlushRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FlushRegionRequest() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FlushRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int IF_OLDER_THAN_TS_FIELD_NUMBER = 2;
    private long ifOlderThanTs_ = 0L;
    /**
     * <code>optional uint64 if_older_than_ts = 2;</code>
     * @return Whether the ifOlderThanTs field is set.
     */
    @java.lang.Override
    public boolean hasIfOlderThanTs() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional uint64 if_older_than_ts = 2;</code>
     * @return The ifOlderThanTs.
     */
    @java.lang.Override
    public long getIfOlderThanTs() {
      return ifOlderThanTs_;
    }

    public static final int WRITE_FLUSH_WAL_MARKER_FIELD_NUMBER = 3;
    private boolean writeFlushWalMarker_ = false;
    /**
     * <pre>
     * whether to write a marker to WAL even if not flushed
     * </pre>
     *
     * <code>optional bool write_flush_wal_marker = 3;</code>
     * @return Whether the writeFlushWalMarker field is set.
     */
    @java.lang.Override
    public boolean hasWriteFlushWalMarker() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * whether to write a marker to WAL even if not flushed
     * </pre>
     *
     * <code>optional bool write_flush_wal_marker = 3;</code>
     * @return The writeFlushWalMarker.
     */
    @java.lang.Override
    public boolean getWriteFlushWalMarker() {
      return writeFlushWalMarker_;
    }

    public static final int FAMILY_FIELD_NUMBER = 4;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes family = 4;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bytes family = 4;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(2, ifOlderThanTs_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, writeFlushWalMarker_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBytes(4, family_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, ifOlderThanTs_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, writeFlushWalMarker_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, family_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasIfOlderThanTs() != other.hasIfOlderThanTs()) return false;
      if (hasIfOlderThanTs()) {
        if (getIfOlderThanTs()
            != other.getIfOlderThanTs()) return false;
      }
      if (hasWriteFlushWalMarker() != other.hasWriteFlushWalMarker()) return false;
      if (hasWriteFlushWalMarker()) {
        if (getWriteFlushWalMarker()
            != other.getWriteFlushWalMarker()) return false;
      }
      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasIfOlderThanTs()) {
        hash = (37 * hash) + IF_OLDER_THAN_TS_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getIfOlderThanTs());
      }
      if (hasWriteFlushWalMarker()) {
        hash = (37 * hash) + WRITE_FLUSH_WAL_MARKER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getWriteFlushWalMarker());
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Flushes the MemStore of the specified region.
     * &lt;p&gt;
     * This method is synchronous.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.FlushRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FlushRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        ifOlderThanTs_ = 0L;
        writeFlushWalMarker_ = false;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.ifOlderThanTs_ = ifOlderThanTs_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.writeFlushWalMarker_ = writeFlushWalMarker_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasIfOlderThanTs()) {
          setIfOlderThanTs(other.getIfOlderThanTs());
        }
        if (other.hasWriteFlushWalMarker()) {
          setWriteFlushWalMarker(other.getWriteFlushWalMarker());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                ifOlderThanTs_ = input.readUInt64();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                writeFlushWalMarker_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 34: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private long ifOlderThanTs_ ;
      /**
       * <code>optional uint64 if_older_than_ts = 2;</code>
       * @return Whether the ifOlderThanTs field is set.
       */
      @java.lang.Override
      public boolean hasIfOlderThanTs() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint64 if_older_than_ts = 2;</code>
       * @return The ifOlderThanTs.
       */
      @java.lang.Override
      public long getIfOlderThanTs() {
        return ifOlderThanTs_;
      }
      /**
       * <code>optional uint64 if_older_than_ts = 2;</code>
       * @param value The ifOlderThanTs to set.
       * @return This builder for chaining.
       */
      public Builder setIfOlderThanTs(long value) {

        ifOlderThanTs_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 if_older_than_ts = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIfOlderThanTs() {
        bitField0_ = (bitField0_ & ~0x00000002);
        ifOlderThanTs_ = 0L;
        onChanged();
        return this;
      }

      private boolean writeFlushWalMarker_ ;
      /**
       * <pre>
       * whether to write a marker to WAL even if not flushed
       * </pre>
       *
       * <code>optional bool write_flush_wal_marker = 3;</code>
       * @return Whether the writeFlushWalMarker field is set.
       */
      @java.lang.Override
      public boolean hasWriteFlushWalMarker() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * whether to write a marker to WAL even if not flushed
       * </pre>
       *
       * <code>optional bool write_flush_wal_marker = 3;</code>
       * @return The writeFlushWalMarker.
       */
      @java.lang.Override
      public boolean getWriteFlushWalMarker() {
        return writeFlushWalMarker_;
      }
      /**
       * <pre>
       * whether to write a marker to WAL even if not flushed
       * </pre>
       *
       * <code>optional bool write_flush_wal_marker = 3;</code>
       * @param value The writeFlushWalMarker to set.
       * @return This builder for chaining.
       */
      public Builder setWriteFlushWalMarker(boolean value) {

        writeFlushWalMarker_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * whether to write a marker to WAL even if not flushed
       * </pre>
       *
       * <code>optional bool write_flush_wal_marker = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearWriteFlushWalMarker() {
        bitField0_ = (bitField0_ & ~0x00000004);
        writeFlushWalMarker_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes family = 4;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional bytes family = 4;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>optional bytes family = 4;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes family = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000008);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FlushRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FlushRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FlushRegionRequest>() {
      @java.lang.Override
      public FlushRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FlushRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FlushRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required uint64 last_flush_time = 1;</code>
     * @return Whether the lastFlushTime field is set.
     */
    boolean hasLastFlushTime();
    /**
     * <code>required uint64 last_flush_time = 1;</code>
     * @return The lastFlushTime.
     */
    long getLastFlushTime();

    /**
     * <code>optional bool flushed = 2;</code>
     * @return Whether the flushed field is set.
     */
    boolean hasFlushed();
    /**
     * <code>optional bool flushed = 2;</code>
     * @return The flushed.
     */
    boolean getFlushed();

    /**
     * <code>optional bool wrote_flush_wal_marker = 3;</code>
     * @return Whether the wroteFlushWalMarker field is set.
     */
    boolean hasWroteFlushWalMarker();
    /**
     * <code>optional bool wrote_flush_wal_marker = 3;</code>
     * @return The wroteFlushWalMarker.
     */
    boolean getWroteFlushWalMarker();
  }
  /**
   * Protobuf type {@code hbase.pb.FlushRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class FlushRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FlushRegionResponse)
      FlushRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FlushRegionResponse.newBuilder() to construct.
    private FlushRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FlushRegionResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FlushRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.Builder.class);
    }

    private int bitField0_;
    public static final int LAST_FLUSH_TIME_FIELD_NUMBER = 1;
    private long lastFlushTime_ = 0L;
    /**
     * <code>required uint64 last_flush_time = 1;</code>
     * @return Whether the lastFlushTime field is set.
     */
    @java.lang.Override
    public boolean hasLastFlushTime() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required uint64 last_flush_time = 1;</code>
     * @return The lastFlushTime.
     */
    @java.lang.Override
    public long getLastFlushTime() {
      return lastFlushTime_;
    }

    public static final int FLUSHED_FIELD_NUMBER = 2;
    private boolean flushed_ = false;
    /**
     * <code>optional bool flushed = 2;</code>
     * @return Whether the flushed field is set.
     */
    @java.lang.Override
    public boolean hasFlushed() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool flushed = 2;</code>
     * @return The flushed.
     */
    @java.lang.Override
    public boolean getFlushed() {
      return flushed_;
    }

    public static final int WROTE_FLUSH_WAL_MARKER_FIELD_NUMBER = 3;
    private boolean wroteFlushWalMarker_ = false;
    /**
     * <code>optional bool wrote_flush_wal_marker = 3;</code>
     * @return Whether the wroteFlushWalMarker field is set.
     */
    @java.lang.Override
    public boolean hasWroteFlushWalMarker() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool wrote_flush_wal_marker = 3;</code>
     * @return The wroteFlushWalMarker.
     */
    @java.lang.Override
    public boolean getWroteFlushWalMarker() {
      return wroteFlushWalMarker_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasLastFlushTime()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(1, lastFlushTime_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, flushed_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, wroteFlushWalMarker_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, lastFlushTime_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, flushed_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, wroteFlushWalMarker_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse) obj;

      if (hasLastFlushTime() != other.hasLastFlushTime()) return false;
      if (hasLastFlushTime()) {
        if (getLastFlushTime()
            != other.getLastFlushTime()) return false;
      }
      if (hasFlushed() != other.hasFlushed()) return false;
      if (hasFlushed()) {
        if (getFlushed()
            != other.getFlushed()) return false;
      }
      if (hasWroteFlushWalMarker() != other.hasWroteFlushWalMarker()) return false;
      if (hasWroteFlushWalMarker()) {
        if (getWroteFlushWalMarker()
            != other.getWroteFlushWalMarker()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasLastFlushTime()) {
        hash = (37 * hash) + LAST_FLUSH_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getLastFlushTime());
      }
      if (hasFlushed()) {
        hash = (37 * hash) + FLUSHED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getFlushed());
      }
      if (hasWroteFlushWalMarker()) {
        hash = (37 * hash) + WROTE_FLUSH_WAL_MARKER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getWroteFlushWalMarker());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FlushRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FlushRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        lastFlushTime_ = 0L;
        flushed_ = false;
        wroteFlushWalMarker_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_FlushRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.lastFlushTime_ = lastFlushTime_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.flushed_ = flushed_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.wroteFlushWalMarker_ = wroteFlushWalMarker_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance()) return this;
        if (other.hasLastFlushTime()) {
          setLastFlushTime(other.getLastFlushTime());
        }
        if (other.hasFlushed()) {
          setFlushed(other.getFlushed());
        }
        if (other.hasWroteFlushWalMarker()) {
          setWroteFlushWalMarker(other.getWroteFlushWalMarker());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasLastFlushTime()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                lastFlushTime_ = input.readUInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                flushed_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 24: {
                wroteFlushWalMarker_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long lastFlushTime_ ;
      /**
       * <code>required uint64 last_flush_time = 1;</code>
       * @return Whether the lastFlushTime field is set.
       */
      @java.lang.Override
      public boolean hasLastFlushTime() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required uint64 last_flush_time = 1;</code>
       * @return The lastFlushTime.
       */
      @java.lang.Override
      public long getLastFlushTime() {
        return lastFlushTime_;
      }
      /**
       * <code>required uint64 last_flush_time = 1;</code>
       * @param value The lastFlushTime to set.
       * @return This builder for chaining.
       */
      public Builder setLastFlushTime(long value) {

        lastFlushTime_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required uint64 last_flush_time = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearLastFlushTime() {
        bitField0_ = (bitField0_ & ~0x00000001);
        lastFlushTime_ = 0L;
        onChanged();
        return this;
      }

      private boolean flushed_ ;
      /**
       * <code>optional bool flushed = 2;</code>
       * @return Whether the flushed field is set.
       */
      @java.lang.Override
      public boolean hasFlushed() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool flushed = 2;</code>
       * @return The flushed.
       */
      @java.lang.Override
      public boolean getFlushed() {
        return flushed_;
      }
      /**
       * <code>optional bool flushed = 2;</code>
       * @param value The flushed to set.
       * @return This builder for chaining.
       */
      public Builder setFlushed(boolean value) {

        flushed_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool flushed = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearFlushed() {
        bitField0_ = (bitField0_ & ~0x00000002);
        flushed_ = false;
        onChanged();
        return this;
      }

      private boolean wroteFlushWalMarker_ ;
      /**
       * <code>optional bool wrote_flush_wal_marker = 3;</code>
       * @return Whether the wroteFlushWalMarker field is set.
       */
      @java.lang.Override
      public boolean hasWroteFlushWalMarker() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool wrote_flush_wal_marker = 3;</code>
       * @return The wroteFlushWalMarker.
       */
      @java.lang.Override
      public boolean getWroteFlushWalMarker() {
        return wroteFlushWalMarker_;
      }
      /**
       * <code>optional bool wrote_flush_wal_marker = 3;</code>
       * @param value The wroteFlushWalMarker to set.
       * @return This builder for chaining.
       */
      public Builder setWroteFlushWalMarker(boolean value) {

        wroteFlushWalMarker_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool wrote_flush_wal_marker = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearWroteFlushWalMarker() {
        bitField0_ = (bitField0_ & ~0x00000004);
        wroteFlushWalMarker_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FlushRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FlushRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FlushRegionResponse>() {
      @java.lang.Override
      public FlushRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompactRegionRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompactRegionRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    boolean hasRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    /**
     * <code>optional bool major = 2;</code>
     * @return Whether the major field is set.
     */
    boolean hasMajor();
    /**
     * <code>optional bool major = 2;</code>
     * @return The major.
     */
    boolean getMajor();

    /**
     * <code>optional bytes family = 3;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>optional bytes family = 3;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();
  }
  /**
   * <pre>
   **
   * Compacts the specified region.  Performs a major compaction if specified.
   * &lt;p&gt;
   * This method is asynchronous.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.CompactRegionRequest}
   */
  @javax.annotation.Generated("proto") public static final class CompactRegionRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompactRegionRequest)
      CompactRegionRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompactRegionRequest.newBuilder() to construct.
    private CompactRegionRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompactRegionRequest() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompactRegionRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return Whether the region field is set.
     */
    @java.lang.Override
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     * @return The region.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }
    /**
     * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
    }

    public static final int MAJOR_FIELD_NUMBER = 2;
    private boolean major_ = false;
    /**
     * <code>optional bool major = 2;</code>
     * @return Whether the major field is set.
     */
    @java.lang.Override
    public boolean hasMajor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool major = 2;</code>
     * @return The major.
     */
    @java.lang.Override
    public boolean getMajor() {
      return major_;
    }

    public static final int FAMILY_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes family = 3;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes family = 3;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, major_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, family_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getRegion());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, major_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, family_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest) obj;

      if (hasRegion() != other.hasRegion()) return false;
      if (hasRegion()) {
        if (!getRegion()
            .equals(other.getRegion())) return false;
      }
      if (hasMajor() != other.hasMajor()) return false;
      if (hasMajor()) {
        if (getMajor()
            != other.getMajor()) return false;
      }
      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasMajor()) {
        hash = (37 * hash) + MAJOR_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getMajor());
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Compacts the specified region.  Performs a major compaction if specified.
     * &lt;p&gt;
     * This method is asynchronous.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.CompactRegionRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompactRegionRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        major_ = false;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.region_ = regionBuilder_ == null
              ? region_
              : regionBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.major_ = major_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasMajor()) {
          setMajor(other.getMajor());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasRegion()) {
          return false;
        }
        if (!getRegion().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getRegionFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                major_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier region_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return Whether the region field is set.
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       * @return The region.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            region_ != null &&
            region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            getRegionBuilder().mergeFrom(value);
          } else {
            region_ = value;
          }
        } else {
          regionBuilder_.mergeFrom(value);
        }
        if (region_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        bitField0_ = (bitField0_ & ~0x00000001);
        region_ = null;
        if (regionBuilder_ != null) {
          regionBuilder_.dispose();
          regionBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance() : region_;
        }
      }
      /**
       * <code>required .hbase.pb.RegionSpecifier region = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  getRegion(),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      private boolean major_ ;
      /**
       * <code>optional bool major = 2;</code>
       * @return Whether the major field is set.
       */
      @java.lang.Override
      public boolean hasMajor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool major = 2;</code>
       * @return The major.
       */
      @java.lang.Override
      public boolean getMajor() {
        return major_;
      }
      /**
       * <code>optional bool major = 2;</code>
       * @param value The major to set.
       * @return This builder for chaining.
       */
      public Builder setMajor(boolean value) {

        major_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool major = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearMajor() {
        bitField0_ = (bitField0_ & ~0x00000002);
        major_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes family = 3;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes family = 3;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>optional bytes family = 3;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes family = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000004);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompactRegionRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompactRegionRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompactRegionRequest>() {
      @java.lang.Override
      public CompactRegionRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompactRegionResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompactRegionResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.CompactRegionResponse}
   */
  @javax.annotation.Generated("proto") public static final class CompactRegionResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompactRegionResponse)
      CompactRegionResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompactRegionResponse.newBuilder() to construct.
    private CompactRegionResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompactRegionResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompactRegionResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CompactRegionResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompactRegionResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactRegionResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompactRegionResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompactRegionResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompactRegionResponse>() {
      @java.lang.Override
      public CompactRegionResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactRegionResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompactionSwitchRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompactionSwitchRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool enabled = 1;</code>
     * @return Whether the enabled field is set.
     */
    boolean hasEnabled();
    /**
     * <code>required bool enabled = 1;</code>
     * @return The enabled.
     */
    boolean getEnabled();
  }
  /**
   * Protobuf type {@code hbase.pb.CompactionSwitchRequest}
   */
  @javax.annotation.Generated("proto") public static final class CompactionSwitchRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompactionSwitchRequest)
      CompactionSwitchRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompactionSwitchRequest.newBuilder() to construct.
    private CompactionSwitchRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompactionSwitchRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompactionSwitchRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.Builder.class);
    }

    private int bitField0_;
    public static final int ENABLED_FIELD_NUMBER = 1;
    private boolean enabled_ = false;
    /**
     * <code>required bool enabled = 1;</code>
     * @return Whether the enabled field is set.
     */
    @java.lang.Override
    public boolean hasEnabled() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool enabled = 1;</code>
     * @return The enabled.
     */
    @java.lang.Override
    public boolean getEnabled() {
      return enabled_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasEnabled()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, enabled_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, enabled_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest) obj;

      if (hasEnabled() != other.hasEnabled()) return false;
      if (hasEnabled()) {
        if (getEnabled()
            != other.getEnabled()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasEnabled()) {
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getEnabled());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CompactionSwitchRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompactionSwitchRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        enabled_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.enabled_ = enabled_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.getDefaultInstance()) return this;
        if (other.hasEnabled()) {
          setEnabled(other.getEnabled());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasEnabled()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                enabled_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean enabled_ ;
      /**
       * <code>required bool enabled = 1;</code>
       * @return Whether the enabled field is set.
       */
      @java.lang.Override
      public boolean hasEnabled() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool enabled = 1;</code>
       * @return The enabled.
       */
      @java.lang.Override
      public boolean getEnabled() {
        return enabled_;
      }
      /**
       * <code>required bool enabled = 1;</code>
       * @param value The enabled to set.
       * @return This builder for chaining.
       */
      public Builder setEnabled(boolean value) {

        enabled_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool enabled = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnabled() {
        bitField0_ = (bitField0_ & ~0x00000001);
        enabled_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompactionSwitchRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompactionSwitchRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompactionSwitchRequest>() {
      @java.lang.Override
      public CompactionSwitchRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompactionSwitchResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompactionSwitchResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool prev_state = 1;</code>
     * @return Whether the prevState field is set.
     */
    boolean hasPrevState();
    /**
     * <code>required bool prev_state = 1;</code>
     * @return The prevState.
     */
    boolean getPrevState();
  }
  /**
   * Protobuf type {@code hbase.pb.CompactionSwitchResponse}
   */
  @javax.annotation.Generated("proto") public static final class CompactionSwitchResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompactionSwitchResponse)
      CompactionSwitchResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompactionSwitchResponse.newBuilder() to construct.
    private CompactionSwitchResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompactionSwitchResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompactionSwitchResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.Builder.class);
    }

    private int bitField0_;
    public static final int PREV_STATE_FIELD_NUMBER = 1;
    private boolean prevState_ = false;
    /**
     * <code>required bool prev_state = 1;</code>
     * @return Whether the prevState field is set.
     */
    @java.lang.Override
    public boolean hasPrevState() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool prev_state = 1;</code>
     * @return The prevState.
     */
    @java.lang.Override
    public boolean getPrevState() {
      return prevState_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPrevState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, prevState_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, prevState_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse) obj;

      if (hasPrevState() != other.hasPrevState()) return false;
      if (hasPrevState()) {
        if (getPrevState()
            != other.getPrevState()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPrevState()) {
        hash = (37 * hash) + PREV_STATE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getPrevState());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CompactionSwitchResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompactionSwitchResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        prevState_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_CompactionSwitchResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.prevState_ = prevState_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance()) return this;
        if (other.hasPrevState()) {
          setPrevState(other.getPrevState());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPrevState()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                prevState_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean prevState_ ;
      /**
       * <code>required bool prev_state = 1;</code>
       * @return Whether the prevState field is set.
       */
      @java.lang.Override
      public boolean hasPrevState() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool prev_state = 1;</code>
       * @return The prevState.
       */
      @java.lang.Override
      public boolean getPrevState() {
        return prevState_;
      }
      /**
       * <code>required bool prev_state = 1;</code>
       * @param value The prevState to set.
       * @return This builder for chaining.
       */
      public Builder setPrevState(boolean value) {

        prevState_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool prev_state = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPrevState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        prevState_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompactionSwitchResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompactionSwitchResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompactionSwitchResponse>() {
      @java.lang.Override
      public CompactionSwitchResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionSwitchResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateFavoredNodesRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdateFavoredNodesRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> 
        getUpdateInfoList();
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getUpdateInfo(int index);
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    int getUpdateInfoCount();
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder> 
        getUpdateInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder getUpdateInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.UpdateFavoredNodesRequest}
   */
  @javax.annotation.Generated("proto") public static final class UpdateFavoredNodesRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdateFavoredNodesRequest)
      UpdateFavoredNodesRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdateFavoredNodesRequest.newBuilder() to construct.
    private UpdateFavoredNodesRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateFavoredNodesRequest() {
      updateInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UpdateFavoredNodesRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.Builder.class);
    }

    public interface RegionUpdateInfoOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo)
        org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return Whether the region field is set.
       */
      boolean hasRegion();
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return The region.
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion();
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder();

      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> 
          getFavoredNodesList();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index);
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      int getFavoredNodesCount();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFavoredNodesOrBuilderList();
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo}
     */
    @javax.annotation.Generated("proto") public static final class RegionUpdateInfo extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo)
        RegionUpdateInfoOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use RegionUpdateInfo.newBuilder() to construct.
      private RegionUpdateInfo(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private RegionUpdateInfo() {
        favoredNodes_ = java.util.Collections.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new RegionUpdateInfo();
      }

      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder.class);
      }

      private int bitField0_;
      public static final int REGION_FIELD_NUMBER = 1;
      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return Whether the region field is set.
       */
      @java.lang.Override
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       * @return The region.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
        return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
      }
      /**
       * <code>required .hbase.pb.RegionInfo region = 1;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
        return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
      }

      public static final int FAVORED_NODES_FIELD_NUMBER = 2;
      @SuppressWarnings("serial")
      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes_;
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      @java.lang.Override
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getFavoredNodesList() {
        return favoredNodes_;
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      @java.lang.Override
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getFavoredNodesOrBuilderList() {
        return favoredNodes_;
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      @java.lang.Override
      public int getFavoredNodesCount() {
        return favoredNodes_.size();
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index) {
        return favoredNodes_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
          int index) {
        return favoredNodes_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasRegion()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
        for (int i = 0; i < getFavoredNodesCount(); i++) {
          if (!getFavoredNodes(i).isInitialized()) {
            memoizedIsInitialized = 0;
            return false;
          }
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeMessage(1, getRegion());
        }
        for (int i = 0; i < favoredNodes_.size(); i++) {
          output.writeMessage(2, favoredNodes_.get(i));
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getRegion());
        }
        for (int i = 0; i < favoredNodes_.size(); i++) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, favoredNodes_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo) obj;

        if (hasRegion() != other.hasRegion()) return false;
        if (hasRegion()) {
          if (!getRegion()
              .equals(other.getRegion())) return false;
        }
        if (!getFavoredNodesList()
            .equals(other.getFavoredNodesList())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasRegion()) {
          hash = (37 * hash) + REGION_FIELD_NUMBER;
          hash = (53 * hash) + getRegion().hashCode();
        }
        if (getFavoredNodesCount() > 0) {
          hash = (37 * hash) + FAVORED_NODES_FIELD_NUMBER;
          hash = (53 * hash) + getFavoredNodesList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          java.nio.ByteBuffer data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          java.nio.ByteBuffer data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(byte[] data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          byte[] data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseDelimitedFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo}
       */
      @javax.annotation.Generated("proto") public static final class Builder extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo)
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder {
        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getRegionFieldBuilder();
            getFavoredNodesFieldBuilder();
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          region_ = null;
          if (regionBuilder_ != null) {
            regionBuilder_.dispose();
            regionBuilder_ = null;
          }
          if (favoredNodesBuilder_ == null) {
            favoredNodes_ = java.util.Collections.emptyList();
          } else {
            favoredNodes_ = null;
            favoredNodesBuilder_.clear();
          }
          bitField0_ = (bitField0_ & ~0x00000002);
          return this;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo build() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo buildPartial() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo(this);
          buildPartialRepeatedFields(result);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo result) {
          if (favoredNodesBuilder_ == null) {
            if (((bitField0_ & 0x00000002) != 0)) {
              favoredNodes_ = java.util.Collections.unmodifiableList(favoredNodes_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.favoredNodes_ = favoredNodes_;
          } else {
            result.favoredNodes_ = favoredNodesBuilder_.build();
          }
        }

        private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo result) {
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.region_ = regionBuilder_ == null
                ? region_
                : regionBuilder_.build();
            to_bitField0_ |= 0x00000001;
          }
          result.bitField0_ |= to_bitField0_;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo) {
            return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo other) {
          if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.getDefaultInstance()) return this;
          if (other.hasRegion()) {
            mergeRegion(other.getRegion());
          }
          if (favoredNodesBuilder_ == null) {
            if (!other.favoredNodes_.isEmpty()) {
              if (favoredNodes_.isEmpty()) {
                favoredNodes_ = other.favoredNodes_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureFavoredNodesIsMutable();
                favoredNodes_.addAll(other.favoredNodes_);
              }
              onChanged();
            }
          } else {
            if (!other.favoredNodes_.isEmpty()) {
              if (favoredNodesBuilder_.isEmpty()) {
                favoredNodesBuilder_.dispose();
                favoredNodesBuilder_ = null;
                favoredNodes_ = other.favoredNodes_;
                bitField0_ = (bitField0_ & ~0x00000002);
                favoredNodesBuilder_ = 
                  org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getFavoredNodesFieldBuilder() : null;
              } else {
                favoredNodesBuilder_.addAllMessages(other.favoredNodes_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasRegion()) {
            return false;
          }
          if (!getRegion().isInitialized()) {
            return false;
          }
          for (int i = 0; i < getFavoredNodesCount(); i++) {
            if (!getFavoredNodes(i).isInitialized()) {
              return false;
            }
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  input.readMessage(
                      getRegionFieldBuilder().getBuilder(),
                      extensionRegistry);
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 18: {
                  org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName m =
                      input.readMessage(
                          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.PARSER,
                          extensionRegistry);
                  if (favoredNodesBuilder_ == null) {
                    ensureFavoredNodesIsMutable();
                    favoredNodes_.add(m);
                  } else {
                    favoredNodesBuilder_.addMessage(m);
                  }
                  break;
                } // case 18
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo region_;
        private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionBuilder_;
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         * @return Whether the region field is set.
         */
        public boolean hasRegion() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         * @return The region.
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo getRegion() {
          if (regionBuilder_ == null) {
            return region_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
          } else {
            return regionBuilder_.getMessage();
          }
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder setRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
          if (regionBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            region_ = value;
          } else {
            regionBuilder_.setMessage(value);
          }
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder setRegion(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
          if (regionBuilder_ == null) {
            region_ = builderForValue.build();
          } else {
            regionBuilder_.setMessage(builderForValue.build());
          }
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder mergeRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo value) {
          if (regionBuilder_ == null) {
            if (((bitField0_ & 0x00000001) != 0) &&
              region_ != null &&
              region_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
              getRegionBuilder().mergeFrom(value);
            } else {
              region_ = value;
            }
          } else {
            regionBuilder_.mergeFrom(value);
          }
          if (region_ != null) {
            bitField0_ |= 0x00000001;
            onChanged();
          }
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public Builder clearRegion() {
          bitField0_ = (bitField0_ & ~0x00000001);
          region_ = null;
          if (regionBuilder_ != null) {
            regionBuilder_.dispose();
            regionBuilder_ = null;
          }
          onChanged();
          return this;
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionBuilder() {
          bitField0_ |= 0x00000001;
          onChanged();
          return getRegionFieldBuilder().getBuilder();
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionOrBuilder() {
          if (regionBuilder_ != null) {
            return regionBuilder_.getMessageOrBuilder();
          } else {
            return region_ == null ?
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance() : region_;
          }
        }
        /**
         * <code>required .hbase.pb.RegionInfo region = 1;</code>
         */
        private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
            getRegionFieldBuilder() {
          if (regionBuilder_ == null) {
            regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                    getRegion(),
                    getParentForChildren(),
                    isClean());
            region_ = null;
          }
          return regionBuilder_;
        }

        private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes_ =
          java.util.Collections.emptyList();
        private void ensureFavoredNodesIsMutable() {
          if (!((bitField0_ & 0x00000002) != 0)) {
            favoredNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName>(favoredNodes_);
            bitField0_ |= 0x00000002;
           }
        }

        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> favoredNodesBuilder_;

        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> getFavoredNodesList() {
          if (favoredNodesBuilder_ == null) {
            return java.util.Collections.unmodifiableList(favoredNodes_);
          } else {
            return favoredNodesBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public int getFavoredNodesCount() {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.size();
          } else {
            return favoredNodesBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getFavoredNodes(int index) {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.get(index);
          } else {
            return favoredNodesBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder setFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.set(index, value);
            onChanged();
          } else {
            favoredNodesBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder setFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.set(index, builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder addFavoredNodes(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(value);
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder addFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
          if (favoredNodesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(index, value);
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder addFavoredNodes(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder addFavoredNodes(
            int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.add(index, builderForValue.build());
            onChanged();
          } else {
            favoredNodesBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder addAllFavoredNodes(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> values) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, favoredNodes_);
            onChanged();
          } else {
            favoredNodesBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder clearFavoredNodes() {
          if (favoredNodesBuilder_ == null) {
            favoredNodes_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            favoredNodesBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public Builder removeFavoredNodes(int index) {
          if (favoredNodesBuilder_ == null) {
            ensureFavoredNodesIsMutable();
            favoredNodes_.remove(index);
            onChanged();
          } else {
            favoredNodesBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getFavoredNodesBuilder(
            int index) {
          return getFavoredNodesFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getFavoredNodesOrBuilder(
            int index) {
          if (favoredNodesBuilder_ == null) {
            return favoredNodes_.get(index);  } else {
            return favoredNodesBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
             getFavoredNodesOrBuilderList() {
          if (favoredNodesBuilder_ != null) {
            return favoredNodesBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(favoredNodes_);
          }
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addFavoredNodesBuilder() {
          return getFavoredNodesFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder addFavoredNodesBuilder(
            int index) {
          return getFavoredNodesFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.ServerName favored_nodes = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder> 
             getFavoredNodesBuilderList() {
          return getFavoredNodesFieldBuilder().getBuilderList();
        }
        private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
            getFavoredNodesFieldBuilder() {
          if (favoredNodesBuilder_ == null) {
            favoredNodesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                    favoredNodes_,
                    ((bitField0_ & 0x00000002) != 0),
                    getParentForChildren(),
                    isClean());
            favoredNodes_ = null;
          }
          return favoredNodesBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo)
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo)
      private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo();
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionUpdateInfo>
          PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionUpdateInfo>() {
        @java.lang.Override
        public RegionUpdateInfo parsePartialFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionUpdateInfo> parser() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionUpdateInfo> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int UPDATE_INFO_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> updateInfo_;
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> getUpdateInfoList() {
      return updateInfo_;
    }
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder> 
        getUpdateInfoOrBuilderList() {
      return updateInfo_;
    }
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    @java.lang.Override
    public int getUpdateInfoCount() {
      return updateInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getUpdateInfo(int index) {
      return updateInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder getUpdateInfoOrBuilder(
        int index) {
      return updateInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getUpdateInfoCount(); i++) {
        if (!getUpdateInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < updateInfo_.size(); i++) {
        output.writeMessage(1, updateInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < updateInfo_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, updateInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest) obj;

      if (!getUpdateInfoList()
          .equals(other.getUpdateInfoList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getUpdateInfoCount() > 0) {
        hash = (37 * hash) + UPDATE_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUpdateInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdateFavoredNodesRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdateFavoredNodesRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (updateInfoBuilder_ == null) {
          updateInfo_ = java.util.Collections.emptyList();
        } else {
          updateInfo_ = null;
          updateInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest result) {
        if (updateInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            updateInfo_ = java.util.Collections.unmodifiableList(updateInfo_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.updateInfo_ = updateInfo_;
        } else {
          result.updateInfo_ = updateInfoBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.getDefaultInstance()) return this;
        if (updateInfoBuilder_ == null) {
          if (!other.updateInfo_.isEmpty()) {
            if (updateInfo_.isEmpty()) {
              updateInfo_ = other.updateInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureUpdateInfoIsMutable();
              updateInfo_.addAll(other.updateInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.updateInfo_.isEmpty()) {
            if (updateInfoBuilder_.isEmpty()) {
              updateInfoBuilder_.dispose();
              updateInfoBuilder_ = null;
              updateInfo_ = other.updateInfo_;
              bitField0_ = (bitField0_ & ~0x00000001);
              updateInfoBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getUpdateInfoFieldBuilder() : null;
            } else {
              updateInfoBuilder_.addAllMessages(other.updateInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getUpdateInfoCount(); i++) {
          if (!getUpdateInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.PARSER,
                        extensionRegistry);
                if (updateInfoBuilder_ == null) {
                  ensureUpdateInfoIsMutable();
                  updateInfo_.add(m);
                } else {
                  updateInfoBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> updateInfo_ =
        java.util.Collections.emptyList();
      private void ensureUpdateInfoIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          updateInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo>(updateInfo_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder> updateInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> getUpdateInfoList() {
        if (updateInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(updateInfo_);
        } else {
          return updateInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public int getUpdateInfoCount() {
        if (updateInfoBuilder_ == null) {
          return updateInfo_.size();
        } else {
          return updateInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo getUpdateInfo(int index) {
        if (updateInfoBuilder_ == null) {
          return updateInfo_.get(index);
        } else {
          return updateInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder setUpdateInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo value) {
        if (updateInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdateInfoIsMutable();
          updateInfo_.set(index, value);
          onChanged();
        } else {
          updateInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder setUpdateInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder builderForValue) {
        if (updateInfoBuilder_ == null) {
          ensureUpdateInfoIsMutable();
          updateInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          updateInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder addUpdateInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo value) {
        if (updateInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdateInfoIsMutable();
          updateInfo_.add(value);
          onChanged();
        } else {
          updateInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder addUpdateInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo value) {
        if (updateInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUpdateInfoIsMutable();
          updateInfo_.add(index, value);
          onChanged();
        } else {
          updateInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder addUpdateInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder builderForValue) {
        if (updateInfoBuilder_ == null) {
          ensureUpdateInfoIsMutable();
          updateInfo_.add(builderForValue.build());
          onChanged();
        } else {
          updateInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder addUpdateInfo(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder builderForValue) {
        if (updateInfoBuilder_ == null) {
          ensureUpdateInfoIsMutable();
          updateInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          updateInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder addAllUpdateInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo> values) {
        if (updateInfoBuilder_ == null) {
          ensureUpdateInfoIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, updateInfo_);
          onChanged();
        } else {
          updateInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder clearUpdateInfo() {
        if (updateInfoBuilder_ == null) {
          updateInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          updateInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public Builder removeUpdateInfo(int index) {
        if (updateInfoBuilder_ == null) {
          ensureUpdateInfoIsMutable();
          updateInfo_.remove(index);
          onChanged();
        } else {
          updateInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder getUpdateInfoBuilder(
          int index) {
        return getUpdateInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder getUpdateInfoOrBuilder(
          int index) {
        if (updateInfoBuilder_ == null) {
          return updateInfo_.get(index);  } else {
          return updateInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder> 
           getUpdateInfoOrBuilderList() {
        if (updateInfoBuilder_ != null) {
          return updateInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(updateInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder addUpdateInfoBuilder() {
        return getUpdateInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder addUpdateInfoBuilder(
          int index) {
        return getUpdateInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UpdateFavoredNodesRequest.RegionUpdateInfo update_info = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder> 
           getUpdateInfoBuilderList() {
        return getUpdateInfoFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder> 
          getUpdateInfoFieldBuilder() {
        if (updateInfoBuilder_ == null) {
          updateInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.RegionUpdateInfoOrBuilder>(
                  updateInfo_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          updateInfo_ = null;
        }
        return updateInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdateFavoredNodesRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdateFavoredNodesRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdateFavoredNodesRequest>() {
      @java.lang.Override
      public UpdateFavoredNodesRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateFavoredNodesResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdateFavoredNodesResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional uint32 response = 1;</code>
     * @return Whether the response field is set.
     */
    boolean hasResponse();
    /**
     * <code>optional uint32 response = 1;</code>
     * @return The response.
     */
    int getResponse();
  }
  /**
   * Protobuf type {@code hbase.pb.UpdateFavoredNodesResponse}
   */
  @javax.annotation.Generated("proto") public static final class UpdateFavoredNodesResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdateFavoredNodesResponse)
      UpdateFavoredNodesResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdateFavoredNodesResponse.newBuilder() to construct.
    private UpdateFavoredNodesResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateFavoredNodesResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UpdateFavoredNodesResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.Builder.class);
    }

    private int bitField0_;
    public static final int RESPONSE_FIELD_NUMBER = 1;
    private int response_ = 0;
    /**
     * <code>optional uint32 response = 1;</code>
     * @return Whether the response field is set.
     */
    @java.lang.Override
    public boolean hasResponse() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional uint32 response = 1;</code>
     * @return The response.
     */
    @java.lang.Override
    public int getResponse() {
      return response_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt32(1, response_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, response_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse) obj;

      if (hasResponse() != other.hasResponse()) return false;
      if (hasResponse()) {
        if (getResponse()
            != other.getResponse()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResponse()) {
        hash = (37 * hash) + RESPONSE_FIELD_NUMBER;
        hash = (53 * hash) + getResponse();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdateFavoredNodesResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdateFavoredNodesResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        response_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.response_ = response_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance()) return this;
        if (other.hasResponse()) {
          setResponse(other.getResponse());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                response_ = input.readUInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int response_ ;
      /**
       * <code>optional uint32 response = 1;</code>
       * @return Whether the response field is set.
       */
      @java.lang.Override
      public boolean hasResponse() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional uint32 response = 1;</code>
       * @return The response.
       */
      @java.lang.Override
      public int getResponse() {
        return response_;
      }
      /**
       * <code>optional uint32 response = 1;</code>
       * @param value The response to set.
       * @return This builder for chaining.
       */
      public Builder setResponse(int value) {

        response_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 response = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearResponse() {
        bitField0_ = (bitField0_ & ~0x00000001);
        response_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdateFavoredNodesResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdateFavoredNodesResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdateFavoredNodesResponse>() {
      @java.lang.Override
      public UpdateFavoredNodesResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateFavoredNodesResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WALEntryOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WALEntry)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     * @return Whether the key field is set.
     */
    boolean hasKey();
    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     * @return The key.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getKey();
    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder getKeyOrBuilder();

    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @return A list containing the keyValueBytes.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getKeyValueBytesList();
    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @return The count of keyValueBytes.
     */
    int getKeyValueBytesCount();
    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @param index The index of the element to return.
     * @return The keyValueBytes at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getKeyValueBytes(int index);

    /**
     * <pre>
     * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 3;</code>
     * @return Whether the associatedCellCount field is set.
     */
    boolean hasAssociatedCellCount();
    /**
     * <pre>
     * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 3;</code>
     * @return The associatedCellCount.
     */
    int getAssociatedCellCount();
  }
  /**
   * <pre>
   * Protocol buffer version of WAL for replication
   * </pre>
   *
   * Protobuf type {@code hbase.pb.WALEntry}
   */
  @javax.annotation.Generated("proto") public static final class WALEntry extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WALEntry)
      WALEntryOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WALEntry.newBuilder() to construct.
    private WALEntry(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WALEntry() {
      keyValueBytes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WALEntry();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WALEntry_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WALEntry_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey key_;
    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     * @return Whether the key field is set.
     */
    @java.lang.Override
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     * @return The key.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getKey() {
      return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance() : key_;
    }
    /**
     * <code>required .hbase.pb.WALKey key = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder getKeyOrBuilder() {
      return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance() : key_;
    }

    public static final int KEY_VALUE_BYTES_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> keyValueBytes_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @return A list containing the keyValueBytes.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getKeyValueBytesList() {
      return keyValueBytes_;
    }
    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @return The count of keyValueBytes.
     */
    public int getKeyValueBytesCount() {
      return keyValueBytes_.size();
    }
    /**
     * <pre>
     * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
     * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
     * and associated_cell_count has count of Cells associated w/ this WALEntry
     * </pre>
     *
     * <code>repeated bytes key_value_bytes = 2;</code>
     * @param index The index of the element to return.
     * @return The keyValueBytes at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getKeyValueBytes(int index) {
      return keyValueBytes_.get(index);
    }

    public static final int ASSOCIATED_CELL_COUNT_FIELD_NUMBER = 3;
    private int associatedCellCount_ = 0;
    /**
     * <pre>
     * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 3;</code>
     * @return Whether the associatedCellCount field is set.
     */
    @java.lang.Override
    public boolean hasAssociatedCellCount() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
     * </pre>
     *
     * <code>optional int32 associated_cell_count = 3;</code>
     * @return The associatedCellCount.
     */
    @java.lang.Override
    public int getAssociatedCellCount() {
      return associatedCellCount_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasKey()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getKey().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getKey());
      }
      for (int i = 0; i < keyValueBytes_.size(); i++) {
        output.writeBytes(2, keyValueBytes_.get(i));
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt32(3, associatedCellCount_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getKey());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < keyValueBytes_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(keyValueBytes_.get(i));
        }
        size += dataSize;
        size += 1 * getKeyValueBytesList().size();
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, associatedCellCount_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry) obj;

      if (hasKey() != other.hasKey()) return false;
      if (hasKey()) {
        if (!getKey()
            .equals(other.getKey())) return false;
      }
      if (!getKeyValueBytesList()
          .equals(other.getKeyValueBytesList())) return false;
      if (hasAssociatedCellCount() != other.hasAssociatedCellCount()) return false;
      if (hasAssociatedCellCount()) {
        if (getAssociatedCellCount()
            != other.getAssociatedCellCount()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (getKeyValueBytesCount() > 0) {
        hash = (37 * hash) + KEY_VALUE_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getKeyValueBytesList().hashCode();
      }
      if (hasAssociatedCellCount()) {
        hash = (37 * hash) + ASSOCIATED_CELL_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getAssociatedCellCount();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Protocol buffer version of WAL for replication
     * </pre>
     *
     * Protobuf type {@code hbase.pb.WALEntry}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WALEntry)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WALEntry_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WALEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getKeyFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        key_ = null;
        if (keyBuilder_ != null) {
          keyBuilder_.dispose();
          keyBuilder_ = null;
        }
        keyValueBytes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        associatedCellCount_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_WALEntry_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.key_ = keyBuilder_ == null
              ? key_
              : keyBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          keyValueBytes_.makeImmutable();
          result.keyValueBytes_ = keyValueBytes_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.associatedCellCount_ = associatedCellCount_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.getDefaultInstance()) return this;
        if (other.hasKey()) {
          mergeKey(other.getKey());
        }
        if (!other.keyValueBytes_.isEmpty()) {
          if (keyValueBytes_.isEmpty()) {
            keyValueBytes_ = other.keyValueBytes_;
            keyValueBytes_.makeImmutable();
            bitField0_ |= 0x00000002;
          } else {
            ensureKeyValueBytesIsMutable();
            keyValueBytes_.addAll(other.keyValueBytes_);
          }
          onChanged();
        }
        if (other.hasAssociatedCellCount()) {
          setAssociatedCellCount(other.getAssociatedCellCount());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasKey()) {
          return false;
        }
        if (!getKey().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getKeyFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureKeyValueBytesIsMutable();
                keyValueBytes_.add(v);
                break;
              } // case 18
              case 24: {
                associatedCellCount_ = input.readInt32();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey key_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder> keyBuilder_;
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       * @return Whether the key field is set.
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       * @return The key.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getKey() {
        if (keyBuilder_ == null) {
          return key_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance() : key_;
        } else {
          return keyBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public Builder setKey(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey value) {
        if (keyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          key_ = value;
        } else {
          keyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public Builder setKey(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder builderForValue) {
        if (keyBuilder_ == null) {
          key_ = builderForValue.build();
        } else {
          keyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public Builder mergeKey(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey value) {
        if (keyBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            key_ != null &&
            key_ != org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance()) {
            getKeyBuilder().mergeFrom(value);
          } else {
            key_ = value;
          }
        } else {
          keyBuilder_.mergeFrom(value);
        }
        if (key_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = null;
        if (keyBuilder_ != null) {
          keyBuilder_.dispose();
          keyBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder getKeyBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder getKeyOrBuilder() {
        if (keyBuilder_ != null) {
          return keyBuilder_.getMessageOrBuilder();
        } else {
          return key_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance() : key_;
        }
      }
      /**
       * <code>required .hbase.pb.WALKey key = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder> 
          getKeyFieldBuilder() {
        if (keyBuilder_ == null) {
          keyBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder>(
                  getKey(),
                  getParentForChildren(),
                  isClean());
          key_ = null;
        }
        return keyBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> keyValueBytes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureKeyValueBytesIsMutable() {
        if (!keyValueBytes_.isModifiable()) {
          keyValueBytes_ = makeMutableCopy(keyValueBytes_);
        }
        bitField0_ |= 0x00000002;
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @return A list containing the keyValueBytes.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getKeyValueBytesList() {
        keyValueBytes_.makeImmutable();
        return keyValueBytes_;
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @return The count of keyValueBytes.
       */
      public int getKeyValueBytesCount() {
        return keyValueBytes_.size();
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @param index The index of the element to return.
       * @return The keyValueBytes at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getKeyValueBytes(int index) {
        return keyValueBytes_.get(index);
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @param index The index to set the value at.
       * @param value The keyValueBytes to set.
       * @return This builder for chaining.
       */
      public Builder setKeyValueBytes(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureKeyValueBytesIsMutable();
        keyValueBytes_.set(index, value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @param value The keyValueBytes to add.
       * @return This builder for chaining.
       */
      public Builder addKeyValueBytes(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureKeyValueBytesIsMutable();
        keyValueBytes_.add(value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @param values The keyValueBytes to add.
       * @return This builder for chaining.
       */
      public Builder addAllKeyValueBytes(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureKeyValueBytesIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, keyValueBytes_);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Following may be null if the KVs/Cells are carried along the side in a cellblock (See
       * RPC for more on cellblocks). If Cells/KVs are in a cellblock, this next field is null
       * and associated_cell_count has count of Cells associated w/ this WALEntry
       * </pre>
       *
       * <code>repeated bytes key_value_bytes = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearKeyValueBytes() {
        keyValueBytes_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      private int associatedCellCount_ ;
      /**
       * <pre>
       * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 3;</code>
       * @return Whether the associatedCellCount field is set.
       */
      @java.lang.Override
      public boolean hasAssociatedCellCount() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 3;</code>
       * @return The associatedCellCount.
       */
      @java.lang.Override
      public int getAssociatedCellCount() {
        return associatedCellCount_;
      }
      /**
       * <pre>
       * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 3;</code>
       * @param value The associatedCellCount to set.
       * @return This builder for chaining.
       */
      public Builder setAssociatedCellCount(int value) {

        associatedCellCount_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If Cell data is carried alongside in a cellblock, this is count of Cells in the cellblock.
       * </pre>
       *
       * <code>optional int32 associated_cell_count = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssociatedCellCount() {
        bitField0_ = (bitField0_ & ~0x00000004);
        associatedCellCount_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WALEntry)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WALEntry)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALEntry>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WALEntry>() {
      @java.lang.Override
      public WALEntry parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALEntry> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALEntry> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReplicateWALEntryRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ReplicateWALEntryRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> 
        getEntryList();
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getEntry(int index);
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    int getEntryCount();
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder> 
        getEntryOrBuilderList();
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder getEntryOrBuilder(
        int index);

    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return Whether the replicationClusterId field is set.
     */
    boolean hasReplicationClusterId();
    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return The replicationClusterId.
     */
    java.lang.String getReplicationClusterId();
    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return The bytes for replicationClusterId.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getReplicationClusterIdBytes();

    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return Whether the sourceBaseNamespaceDirPath field is set.
     */
    boolean hasSourceBaseNamespaceDirPath();
    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return The sourceBaseNamespaceDirPath.
     */
    java.lang.String getSourceBaseNamespaceDirPath();
    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return The bytes for sourceBaseNamespaceDirPath.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getSourceBaseNamespaceDirPathBytes();

    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return Whether the sourceHFileArchiveDirPath field is set.
     */
    boolean hasSourceHFileArchiveDirPath();
    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return The sourceHFileArchiveDirPath.
     */
    java.lang.String getSourceHFileArchiveDirPath();
    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return The bytes for sourceHFileArchiveDirPath.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getSourceHFileArchiveDirPathBytes();
  }
  /**
   * <pre>
   **
   * Replicates the given entries. The guarantee is that the given entries
   * will be durable on the slave cluster if this method returns without
   * any exception.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.ReplicateWALEntryRequest}
   */
  @javax.annotation.Generated("proto") public static final class ReplicateWALEntryRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ReplicateWALEntryRequest)
      ReplicateWALEntryRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReplicateWALEntryRequest.newBuilder() to construct.
    private ReplicateWALEntryRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReplicateWALEntryRequest() {
      entry_ = java.util.Collections.emptyList();
      replicationClusterId_ = "";
      sourceBaseNamespaceDirPath_ = "";
      sourceHFileArchiveDirPath_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ReplicateWALEntryRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.Builder.class);
    }

    private int bitField0_;
    public static final int ENTRY_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> entry_;
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> getEntryList() {
      return entry_;
    }
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder> 
        getEntryOrBuilderList() {
      return entry_;
    }
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    @java.lang.Override
    public int getEntryCount() {
      return entry_.size();
    }
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getEntry(int index) {
      return entry_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder getEntryOrBuilder(
        int index) {
      return entry_.get(index);
    }

    public static final int REPLICATIONCLUSTERID_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object replicationClusterId_ = "";
    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return Whether the replicationClusterId field is set.
     */
    @java.lang.Override
    public boolean hasReplicationClusterId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return The replicationClusterId.
     */
    @java.lang.Override
    public java.lang.String getReplicationClusterId() {
      java.lang.Object ref = replicationClusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          replicationClusterId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string replicationClusterId = 2;</code>
     * @return The bytes for replicationClusterId.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getReplicationClusterIdBytes() {
      java.lang.Object ref = replicationClusterId_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        replicationClusterId_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SOURCEBASENAMESPACEDIRPATH_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object sourceBaseNamespaceDirPath_ = "";
    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return Whether the sourceBaseNamespaceDirPath field is set.
     */
    @java.lang.Override
    public boolean hasSourceBaseNamespaceDirPath() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return The sourceBaseNamespaceDirPath.
     */
    @java.lang.Override
    public java.lang.String getSourceBaseNamespaceDirPath() {
      java.lang.Object ref = sourceBaseNamespaceDirPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          sourceBaseNamespaceDirPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
     * @return The bytes for sourceBaseNamespaceDirPath.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getSourceBaseNamespaceDirPathBytes() {
      java.lang.Object ref = sourceBaseNamespaceDirPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        sourceBaseNamespaceDirPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SOURCEHFILEARCHIVEDIRPATH_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object sourceHFileArchiveDirPath_ = "";
    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return Whether the sourceHFileArchiveDirPath field is set.
     */
    @java.lang.Override
    public boolean hasSourceHFileArchiveDirPath() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return The sourceHFileArchiveDirPath.
     */
    @java.lang.Override
    public java.lang.String getSourceHFileArchiveDirPath() {
      java.lang.Object ref = sourceHFileArchiveDirPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          sourceHFileArchiveDirPath_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string sourceHFileArchiveDirPath = 4;</code>
     * @return The bytes for sourceHFileArchiveDirPath.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getSourceHFileArchiveDirPathBytes() {
      java.lang.Object ref = sourceHFileArchiveDirPath_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        sourceHFileArchiveDirPath_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getEntryCount(); i++) {
        if (!getEntry(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < entry_.size(); i++) {
        output.writeMessage(1, entry_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, replicationClusterId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, sourceBaseNamespaceDirPath_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 4, sourceHFileArchiveDirPath_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < entry_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, entry_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, replicationClusterId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, sourceBaseNamespaceDirPath_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(4, sourceHFileArchiveDirPath_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest) obj;

      if (!getEntryList()
          .equals(other.getEntryList())) return false;
      if (hasReplicationClusterId() != other.hasReplicationClusterId()) return false;
      if (hasReplicationClusterId()) {
        if (!getReplicationClusterId()
            .equals(other.getReplicationClusterId())) return false;
      }
      if (hasSourceBaseNamespaceDirPath() != other.hasSourceBaseNamespaceDirPath()) return false;
      if (hasSourceBaseNamespaceDirPath()) {
        if (!getSourceBaseNamespaceDirPath()
            .equals(other.getSourceBaseNamespaceDirPath())) return false;
      }
      if (hasSourceHFileArchiveDirPath() != other.hasSourceHFileArchiveDirPath()) return false;
      if (hasSourceHFileArchiveDirPath()) {
        if (!getSourceHFileArchiveDirPath()
            .equals(other.getSourceHFileArchiveDirPath())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getEntryCount() > 0) {
        hash = (37 * hash) + ENTRY_FIELD_NUMBER;
        hash = (53 * hash) + getEntryList().hashCode();
      }
      if (hasReplicationClusterId()) {
        hash = (37 * hash) + REPLICATIONCLUSTERID_FIELD_NUMBER;
        hash = (53 * hash) + getReplicationClusterId().hashCode();
      }
      if (hasSourceBaseNamespaceDirPath()) {
        hash = (37 * hash) + SOURCEBASENAMESPACEDIRPATH_FIELD_NUMBER;
        hash = (53 * hash) + getSourceBaseNamespaceDirPath().hashCode();
      }
      if (hasSourceHFileArchiveDirPath()) {
        hash = (37 * hash) + SOURCEHFILEARCHIVEDIRPATH_FIELD_NUMBER;
        hash = (53 * hash) + getSourceHFileArchiveDirPath().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Replicates the given entries. The guarantee is that the given entries
     * will be durable on the slave cluster if this method returns without
     * any exception.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.ReplicateWALEntryRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ReplicateWALEntryRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
        } else {
          entry_ = null;
          entryBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        replicationClusterId_ = "";
        sourceBaseNamespaceDirPath_ = "";
        sourceHFileArchiveDirPath_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest result) {
        if (entryBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            entry_ = java.util.Collections.unmodifiableList(entry_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.entry_ = entry_;
        } else {
          result.entry_ = entryBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.replicationClusterId_ = replicationClusterId_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.sourceBaseNamespaceDirPath_ = sourceBaseNamespaceDirPath_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.sourceHFileArchiveDirPath_ = sourceHFileArchiveDirPath_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance()) return this;
        if (entryBuilder_ == null) {
          if (!other.entry_.isEmpty()) {
            if (entry_.isEmpty()) {
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureEntryIsMutable();
              entry_.addAll(other.entry_);
            }
            onChanged();
          }
        } else {
          if (!other.entry_.isEmpty()) {
            if (entryBuilder_.isEmpty()) {
              entryBuilder_.dispose();
              entryBuilder_ = null;
              entry_ = other.entry_;
              bitField0_ = (bitField0_ & ~0x00000001);
              entryBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getEntryFieldBuilder() : null;
            } else {
              entryBuilder_.addAllMessages(other.entry_);
            }
          }
        }
        if (other.hasReplicationClusterId()) {
          replicationClusterId_ = other.replicationClusterId_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasSourceBaseNamespaceDirPath()) {
          sourceBaseNamespaceDirPath_ = other.sourceBaseNamespaceDirPath_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.hasSourceHFileArchiveDirPath()) {
          sourceHFileArchiveDirPath_ = other.sourceHFileArchiveDirPath_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getEntryCount(); i++) {
          if (!getEntry(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.PARSER,
                        extensionRegistry);
                if (entryBuilder_ == null) {
                  ensureEntryIsMutable();
                  entry_.add(m);
                } else {
                  entryBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                replicationClusterId_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                sourceBaseNamespaceDirPath_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                sourceHFileArchiveDirPath_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> entry_ =
        java.util.Collections.emptyList();
      private void ensureEntryIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          entry_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry>(entry_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder> entryBuilder_;

      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> getEntryList() {
        if (entryBuilder_ == null) {
          return java.util.Collections.unmodifiableList(entry_);
        } else {
          return entryBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public int getEntryCount() {
        if (entryBuilder_ == null) {
          return entry_.size();
        } else {
          return entryBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry getEntry(int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);
        } else {
          return entryBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder setEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.set(index, value);
          onChanged();
        } else {
          entryBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder setEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.set(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder addEntry(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(value);
          onChanged();
        } else {
          entryBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder addEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry value) {
        if (entryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryIsMutable();
          entry_.add(index, value);
          onChanged();
        } else {
          entryBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder addEntry(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder addEntry(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder builderForValue) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.add(index, builderForValue.build());
          onChanged();
        } else {
          entryBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder addAllEntry(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry> values) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, entry_);
          onChanged();
        } else {
          entryBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder clearEntry() {
        if (entryBuilder_ == null) {
          entry_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          entryBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public Builder removeEntry(int index) {
        if (entryBuilder_ == null) {
          ensureEntryIsMutable();
          entry_.remove(index);
          onChanged();
        } else {
          entryBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder getEntryBuilder(
          int index) {
        return getEntryFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder getEntryOrBuilder(
          int index) {
        if (entryBuilder_ == null) {
          return entry_.get(index);  } else {
          return entryBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder> 
           getEntryOrBuilderList() {
        if (entryBuilder_ != null) {
          return entryBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(entry_);
        }
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder addEntryBuilder() {
        return getEntryFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder addEntryBuilder(
          int index) {
        return getEntryFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.WALEntry entry = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder> 
           getEntryBuilderList() {
        return getEntryFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder> 
          getEntryFieldBuilder() {
        if (entryBuilder_ == null) {
          entryBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntry.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WALEntryOrBuilder>(
                  entry_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          entry_ = null;
        }
        return entryBuilder_;
      }

      private java.lang.Object replicationClusterId_ = "";
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @return Whether the replicationClusterId field is set.
       */
      public boolean hasReplicationClusterId() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @return The replicationClusterId.
       */
      public java.lang.String getReplicationClusterId() {
        java.lang.Object ref = replicationClusterId_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            replicationClusterId_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @return The bytes for replicationClusterId.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getReplicationClusterIdBytes() {
        java.lang.Object ref = replicationClusterId_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          replicationClusterId_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @param value The replicationClusterId to set.
       * @return This builder for chaining.
       */
      public Builder setReplicationClusterId(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        replicationClusterId_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearReplicationClusterId() {
        replicationClusterId_ = getDefaultInstance().getReplicationClusterId();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>optional string replicationClusterId = 2;</code>
       * @param value The bytes for replicationClusterId to set.
       * @return This builder for chaining.
       */
      public Builder setReplicationClusterIdBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        replicationClusterId_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object sourceBaseNamespaceDirPath_ = "";
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @return Whether the sourceBaseNamespaceDirPath field is set.
       */
      public boolean hasSourceBaseNamespaceDirPath() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @return The sourceBaseNamespaceDirPath.
       */
      public java.lang.String getSourceBaseNamespaceDirPath() {
        java.lang.Object ref = sourceBaseNamespaceDirPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            sourceBaseNamespaceDirPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @return The bytes for sourceBaseNamespaceDirPath.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getSourceBaseNamespaceDirPathBytes() {
        java.lang.Object ref = sourceBaseNamespaceDirPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          sourceBaseNamespaceDirPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @param value The sourceBaseNamespaceDirPath to set.
       * @return This builder for chaining.
       */
      public Builder setSourceBaseNamespaceDirPath(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        sourceBaseNamespaceDirPath_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearSourceBaseNamespaceDirPath() {
        sourceBaseNamespaceDirPath_ = getDefaultInstance().getSourceBaseNamespaceDirPath();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>optional string sourceBaseNamespaceDirPath = 3;</code>
       * @param value The bytes for sourceBaseNamespaceDirPath to set.
       * @return This builder for chaining.
       */
      public Builder setSourceBaseNamespaceDirPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        sourceBaseNamespaceDirPath_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private java.lang.Object sourceHFileArchiveDirPath_ = "";
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @return Whether the sourceHFileArchiveDirPath field is set.
       */
      public boolean hasSourceHFileArchiveDirPath() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @return The sourceHFileArchiveDirPath.
       */
      public java.lang.String getSourceHFileArchiveDirPath() {
        java.lang.Object ref = sourceHFileArchiveDirPath_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            sourceHFileArchiveDirPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @return The bytes for sourceHFileArchiveDirPath.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getSourceHFileArchiveDirPathBytes() {
        java.lang.Object ref = sourceHFileArchiveDirPath_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          sourceHFileArchiveDirPath_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @param value The sourceHFileArchiveDirPath to set.
       * @return This builder for chaining.
       */
      public Builder setSourceHFileArchiveDirPath(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        sourceHFileArchiveDirPath_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearSourceHFileArchiveDirPath() {
        sourceHFileArchiveDirPath_ = getDefaultInstance().getSourceHFileArchiveDirPath();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <code>optional string sourceHFileArchiveDirPath = 4;</code>
       * @param value The bytes for sourceHFileArchiveDirPath to set.
       * @return This builder for chaining.
       */
      public Builder setSourceHFileArchiveDirPathBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        sourceHFileArchiveDirPath_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ReplicateWALEntryRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ReplicateWALEntryRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ReplicateWALEntryRequest>() {
      @java.lang.Override
      public ReplicateWALEntryRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReplicateWALEntryResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ReplicateWALEntryResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.ReplicateWALEntryResponse}
   */
  @javax.annotation.Generated("proto") public static final class ReplicateWALEntryResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ReplicateWALEntryResponse)
      ReplicateWALEntryResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReplicateWALEntryResponse.newBuilder() to construct.
    private ReplicateWALEntryResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReplicateWALEntryResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ReplicateWALEntryResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ReplicateWALEntryResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ReplicateWALEntryResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ReplicateWALEntryResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ReplicateWALEntryResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ReplicateWALEntryResponse>() {
      @java.lang.Override
      public ReplicateWALEntryResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ReplicateWALEntryResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RollWALWriterRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RollWALWriterRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.RollWALWriterRequest}
   */
  @javax.annotation.Generated("proto") public static final class RollWALWriterRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RollWALWriterRequest)
      RollWALWriterRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RollWALWriterRequest.newBuilder() to construct.
    private RollWALWriterRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RollWALWriterRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RollWALWriterRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RollWALWriterRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RollWALWriterRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RollWALWriterRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RollWALWriterRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RollWALWriterRequest>() {
      @java.lang.Override
      public RollWALWriterRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RollWALWriterResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RollWALWriterResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @return A list containing the regionToFlush.
     */
    java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> getRegionToFlushList();
    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @return The count of regionToFlush.
     */
    int getRegionToFlushCount();
    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @param index The index of the element to return.
     * @return The regionToFlush at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionToFlush(int index);
  }
  /**
   * <pre>
   *
   * Roll request responses no longer include regions to flush
   * this list will always be empty when talking to a 1.0 server
   * </pre>
   *
   * Protobuf type {@code hbase.pb.RollWALWriterResponse}
   */
  @javax.annotation.Generated("proto") public static final class RollWALWriterResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RollWALWriterResponse)
      RollWALWriterResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RollWALWriterResponse.newBuilder() to construct.
    private RollWALWriterResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RollWALWriterResponse() {
      regionToFlush_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RollWALWriterResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.Builder.class);
    }

    public static final int REGION_TO_FLUSH_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> regionToFlush_ =
        emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @return A list containing the regionToFlush.
     */
    @java.lang.Override
    public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
        getRegionToFlushList() {
      return regionToFlush_;
    }
    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @return The count of regionToFlush.
     */
    public int getRegionToFlushCount() {
      return regionToFlush_.size();
    }
    /**
     * <pre>
     * A list of encoded name of regions to flush
     * </pre>
     *
     * <code>repeated bytes region_to_flush = 1;</code>
     * @param index The index of the element to return.
     * @return The regionToFlush at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionToFlush(int index) {
      return regionToFlush_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < regionToFlush_.size(); i++) {
        output.writeBytes(1, regionToFlush_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < regionToFlush_.size(); i++) {
          dataSize += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(regionToFlush_.get(i));
        }
        size += dataSize;
        size += 1 * getRegionToFlushList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse) obj;

      if (!getRegionToFlushList()
          .equals(other.getRegionToFlushList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionToFlushCount() > 0) {
        hash = (37 * hash) + REGION_TO_FLUSH_FIELD_NUMBER;
        hash = (53 * hash) + getRegionToFlushList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *
     * Roll request responses no longer include regions to flush
     * this list will always be empty when talking to a 1.0 server
     * </pre>
     *
     * Protobuf type {@code hbase.pb.RollWALWriterResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RollWALWriterResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionToFlush_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RollWALWriterResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          regionToFlush_.makeImmutable();
          result.regionToFlush_ = regionToFlush_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance()) return this;
        if (!other.regionToFlush_.isEmpty()) {
          if (regionToFlush_.isEmpty()) {
            regionToFlush_ = other.regionToFlush_;
            regionToFlush_.makeImmutable();
            bitField0_ |= 0x00000001;
          } else {
            ensureRegionToFlushIsMutable();
            regionToFlush_.addAll(other.regionToFlush_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString v = input.readBytes();
                ensureRegionToFlushIsMutable();
                regionToFlush_.add(v);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.Internal.ProtobufList<org.apache.hbase.thirdparty.com.google.protobuf.ByteString> regionToFlush_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
      private void ensureRegionToFlushIsMutable() {
        if (!regionToFlush_.isModifiable()) {
          regionToFlush_ = makeMutableCopy(regionToFlush_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @return A list containing the regionToFlush.
       */
      public java.util.List<org.apache.hbase.thirdparty.com.google.protobuf.ByteString>
          getRegionToFlushList() {
        regionToFlush_.makeImmutable();
        return regionToFlush_;
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @return The count of regionToFlush.
       */
      public int getRegionToFlushCount() {
        return regionToFlush_.size();
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @param index The index of the element to return.
       * @return The regionToFlush at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionToFlush(int index) {
        return regionToFlush_.get(index);
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @param index The index to set the value at.
       * @param value The regionToFlush to set.
       * @return This builder for chaining.
       */
      public Builder setRegionToFlush(
          int index, org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureRegionToFlushIsMutable();
        regionToFlush_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @param value The regionToFlush to add.
       * @return This builder for chaining.
       */
      public Builder addRegionToFlush(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureRegionToFlushIsMutable();
        regionToFlush_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @param values The regionToFlush to add.
       * @return This builder for chaining.
       */
      public Builder addAllRegionToFlush(
          java.lang.Iterable<? extends org.apache.hbase.thirdparty.com.google.protobuf.ByteString> values) {
        ensureRegionToFlushIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, regionToFlush_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of encoded name of regions to flush
       * </pre>
       *
       * <code>repeated bytes region_to_flush = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionToFlush() {
        regionToFlush_ = emptyList(org.apache.hbase.thirdparty.com.google.protobuf.ByteString.class);
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RollWALWriterResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RollWALWriterResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RollWALWriterResponse>() {
      @java.lang.Override
      public RollWALWriterResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RollWALWriterResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopServerRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.StopServerRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string reason = 1;</code>
     * @return Whether the reason field is set.
     */
    boolean hasReason();
    /**
     * <code>required string reason = 1;</code>
     * @return The reason.
     */
    java.lang.String getReason();
    /**
     * <code>required string reason = 1;</code>
     * @return The bytes for reason.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getReasonBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.StopServerRequest}
   */
  @javax.annotation.Generated("proto") public static final class StopServerRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.StopServerRequest)
      StopServerRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StopServerRequest.newBuilder() to construct.
    private StopServerRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopServerRequest() {
      reason_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StopServerRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.Builder.class);
    }

    private int bitField0_;
    public static final int REASON_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object reason_ = "";
    /**
     * <code>required string reason = 1;</code>
     * @return Whether the reason field is set.
     */
    @java.lang.Override
    public boolean hasReason() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string reason = 1;</code>
     * @return The reason.
     */
    @java.lang.Override
    public java.lang.String getReason() {
      java.lang.Object ref = reason_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          reason_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string reason = 1;</code>
     * @return The bytes for reason.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getReasonBytes() {
      java.lang.Object ref = reason_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        reason_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasReason()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, reason_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, reason_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest) obj;

      if (hasReason() != other.hasReason()) return false;
      if (hasReason()) {
        if (!getReason()
            .equals(other.getReason())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasReason()) {
        hash = (37 * hash) + REASON_FIELD_NUMBER;
        hash = (53 * hash) + getReason().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.StopServerRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.StopServerRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        reason_ = "";
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.reason_ = reason_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.getDefaultInstance()) return this;
        if (other.hasReason()) {
          reason_ = other.reason_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasReason()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                reason_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object reason_ = "";
      /**
       * <code>required string reason = 1;</code>
       * @return Whether the reason field is set.
       */
      public boolean hasReason() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string reason = 1;</code>
       * @return The reason.
       */
      public java.lang.String getReason() {
        java.lang.Object ref = reason_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            reason_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string reason = 1;</code>
       * @return The bytes for reason.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getReasonBytes() {
        java.lang.Object ref = reason_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          reason_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string reason = 1;</code>
       * @param value The reason to set.
       * @return This builder for chaining.
       */
      public Builder setReason(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        reason_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string reason = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearReason() {
        reason_ = getDefaultInstance().getReason();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string reason = 1;</code>
       * @param value The bytes for reason to set.
       * @return This builder for chaining.
       */
      public Builder setReasonBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        reason_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.StopServerRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.StopServerRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<StopServerRequest>() {
      @java.lang.Override
      public StopServerRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StopServerResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.StopServerResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.StopServerResponse}
   */
  @javax.annotation.Generated("proto") public static final class StopServerResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.StopServerResponse)
      StopServerResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StopServerResponse.newBuilder() to construct.
    private StopServerResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StopServerResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StopServerResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.StopServerResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.StopServerResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_StopServerResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.StopServerResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.StopServerResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<StopServerResponse>() {
      @java.lang.Override
      public StopServerResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<StopServerResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetServerInfoRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetServerInfoRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.GetServerInfoRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetServerInfoRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetServerInfoRequest)
      GetServerInfoRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetServerInfoRequest.newBuilder() to construct.
    private GetServerInfoRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetServerInfoRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetServerInfoRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetServerInfoRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetServerInfoRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetServerInfoRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetServerInfoRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetServerInfoRequest>() {
      @java.lang.Override
      public GetServerInfoRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ServerInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ServerInfo)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    /**
     * <code>optional uint32 webui_port = 2;</code>
     * @return Whether the webuiPort field is set.
     */
    boolean hasWebuiPort();
    /**
     * <code>optional uint32 webui_port = 2;</code>
     * @return The webuiPort.
     */
    int getWebuiPort();
  }
  /**
   * Protobuf type {@code hbase.pb.ServerInfo}
   */
  @javax.annotation.Generated("proto") public static final class ServerInfo extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ServerInfo)
      ServerInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ServerInfo.newBuilder() to construct.
    private ServerInfo(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ServerInfo() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ServerInfo();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ServerInfo_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ServerInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    @java.lang.Override
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    public static final int WEBUI_PORT_FIELD_NUMBER = 2;
    private int webuiPort_ = 0;
    /**
     * <code>optional uint32 webui_port = 2;</code>
     * @return Whether the webuiPort field is set.
     */
    @java.lang.Override
    public boolean hasWebuiPort() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional uint32 webui_port = 2;</code>
     * @return The webuiPort.
     */
    @java.lang.Override
    public int getWebuiPort() {
      return webuiPort_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt32(2, webuiPort_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, webuiPort_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo) obj;

      if (hasServerName() != other.hasServerName()) return false;
      if (hasServerName()) {
        if (!getServerName()
            .equals(other.getServerName())) return false;
      }
      if (hasWebuiPort() != other.hasWebuiPort()) return false;
      if (hasWebuiPort()) {
        if (getWebuiPort()
            != other.getWebuiPort()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (hasWebuiPort()) {
        hash = (37 * hash) + WEBUI_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getWebuiPort();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ServerInfo}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ServerInfo)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ServerInfo_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ServerInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        webuiPort_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ServerInfo_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.serverName_ = serverNameBuilder_ == null
              ? serverName_
              : serverNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.webuiPort_ = webuiPort_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (other.hasWebuiPort()) {
          setWebuiPort(other.getWebuiPort());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasServerName()) {
          return false;
        }
        if (!getServerName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getServerNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                webuiPort_ = input.readUInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName serverName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return Whether the serverName field is set.
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return The serverName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            serverName_ != null &&
            serverName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getServerNameBuilder().mergeFrom(value);
          } else {
            serverName_ = value;
          }
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        if (serverName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serverName_ = null;
        if (serverNameBuilder_ != null) {
          serverNameBuilder_.dispose();
          serverNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      private int webuiPort_ ;
      /**
       * <code>optional uint32 webui_port = 2;</code>
       * @return Whether the webuiPort field is set.
       */
      @java.lang.Override
      public boolean hasWebuiPort() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint32 webui_port = 2;</code>
       * @return The webuiPort.
       */
      @java.lang.Override
      public int getWebuiPort() {
        return webuiPort_;
      }
      /**
       * <code>optional uint32 webui_port = 2;</code>
       * @param value The webuiPort to set.
       * @return This builder for chaining.
       */
      public Builder setWebuiPort(int value) {

        webuiPort_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 webui_port = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearWebuiPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        webuiPort_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ServerInfo)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ServerInfo)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerInfo>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ServerInfo>() {
      @java.lang.Override
      public ServerInfo parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ServerInfo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetServerInfoResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetServerInfoResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     * @return Whether the serverInfo field is set.
     */
    boolean hasServerInfo();
    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     * @return The serverInfo.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getServerInfo();
    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder getServerInfoOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GetServerInfoResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetServerInfoResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetServerInfoResponse)
      GetServerInfoResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetServerInfoResponse.newBuilder() to construct.
    private GetServerInfoResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetServerInfoResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetServerInfoResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo serverInfo_;
    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     * @return Whether the serverInfo field is set.
     */
    @java.lang.Override
    public boolean hasServerInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     * @return The serverInfo.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getServerInfo() {
      return serverInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance() : serverInfo_;
    }
    /**
     * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder getServerInfoOrBuilder() {
      return serverInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance() : serverInfo_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerInfo());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerInfo());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse) obj;

      if (hasServerInfo() != other.hasServerInfo()) return false;
      if (hasServerInfo()) {
        if (!getServerInfo()
            .equals(other.getServerInfo())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerInfo()) {
        hash = (37 * hash) + SERVER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getServerInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetServerInfoResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetServerInfoResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        serverInfo_ = null;
        if (serverInfoBuilder_ != null) {
          serverInfoBuilder_.dispose();
          serverInfoBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetServerInfoResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.serverInfo_ = serverInfoBuilder_ == null
              ? serverInfo_
              : serverInfoBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance()) return this;
        if (other.hasServerInfo()) {
          mergeServerInfo(other.getServerInfo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasServerInfo()) {
          return false;
        }
        if (!getServerInfo().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getServerInfoFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo serverInfo_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder> serverInfoBuilder_;
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       * @return Whether the serverInfo field is set.
       */
      public boolean hasServerInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       * @return The serverInfo.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo getServerInfo() {
        if (serverInfoBuilder_ == null) {
          return serverInfo_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance() : serverInfo_;
        } else {
          return serverInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public Builder setServerInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo value) {
        if (serverInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverInfo_ = value;
        } else {
          serverInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public Builder setServerInfo(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder builderForValue) {
        if (serverInfoBuilder_ == null) {
          serverInfo_ = builderForValue.build();
        } else {
          serverInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public Builder mergeServerInfo(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo value) {
        if (serverInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            serverInfo_ != null &&
            serverInfo_ != org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance()) {
            getServerInfoBuilder().mergeFrom(value);
          } else {
            serverInfo_ = value;
          }
        } else {
          serverInfoBuilder_.mergeFrom(value);
        }
        if (serverInfo_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public Builder clearServerInfo() {
        bitField0_ = (bitField0_ & ~0x00000001);
        serverInfo_ = null;
        if (serverInfoBuilder_ != null) {
          serverInfoBuilder_.dispose();
          serverInfoBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder getServerInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder getServerInfoOrBuilder() {
        if (serverInfoBuilder_ != null) {
          return serverInfoBuilder_.getMessageOrBuilder();
        } else {
          return serverInfo_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.getDefaultInstance() : serverInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerInfo server_info = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder> 
          getServerInfoFieldBuilder() {
        if (serverInfoBuilder_ == null) {
          serverInfoBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfo.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ServerInfoOrBuilder>(
                  getServerInfo(),
                  getParentForChildren(),
                  isClean());
          serverInfo_ = null;
        }
        return serverInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetServerInfoResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetServerInfoResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetServerInfoResponse>() {
      @java.lang.Override
      public GetServerInfoResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetServerInfoResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateConfigurationRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdateConfigurationRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.UpdateConfigurationRequest}
   */
  @javax.annotation.Generated("proto") public static final class UpdateConfigurationRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdateConfigurationRequest)
      UpdateConfigurationRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdateConfigurationRequest.newBuilder() to construct.
    private UpdateConfigurationRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateConfigurationRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UpdateConfigurationRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdateConfigurationRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdateConfigurationRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdateConfigurationRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdateConfigurationRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdateConfigurationRequest>() {
      @java.lang.Override
      public UpdateConfigurationRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UpdateConfigurationResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.UpdateConfigurationResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.UpdateConfigurationResponse}
   */
  @javax.annotation.Generated("proto") public static final class UpdateConfigurationResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.UpdateConfigurationResponse)
      UpdateConfigurationResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use UpdateConfigurationResponse.newBuilder() to construct.
    private UpdateConfigurationResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private UpdateConfigurationResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new UpdateConfigurationResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UpdateConfigurationResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.UpdateConfigurationResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_UpdateConfigurationResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.UpdateConfigurationResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UpdateConfigurationResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<UpdateConfigurationResponse>() {
      @java.lang.Override
      public UpdateConfigurationResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<UpdateConfigurationResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetRegionLoadRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetRegionLoadRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.GetRegionLoadRequest}
   */
  @javax.annotation.Generated("proto") public static final class GetRegionLoadRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetRegionLoadRequest)
      GetRegionLoadRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetRegionLoadRequest.newBuilder() to construct.
    private GetRegionLoadRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetRegionLoadRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetRegionLoadRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetRegionLoadRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetRegionLoadRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetRegionLoadRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetRegionLoadRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetRegionLoadRequest>() {
      @java.lang.Override
      public GetRegionLoadRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetRegionLoadResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.GetRegionLoadResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> 
        getRegionLoadsList();
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index);
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    int getRegionLoadsCount();
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetRegionLoadResponse}
   */
  @javax.annotation.Generated("proto") public static final class GetRegionLoadResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.GetRegionLoadResponse)
      GetRegionLoadResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetRegionLoadResponse.newBuilder() to construct.
    private GetRegionLoadResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetRegionLoadResponse() {
      regionLoads_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetRegionLoadResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.Builder.class);
    }

    public static final int REGION_LOADS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> regionLoads_;
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> getRegionLoadsList() {
      return regionLoads_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList() {
      return regionLoads_;
    }
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    @java.lang.Override
    public int getRegionLoadsCount() {
      return regionLoads_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index) {
      return regionLoads_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index) {
      return regionLoads_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionLoadsCount(); i++) {
        if (!getRegionLoads(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < regionLoads_.size(); i++) {
        output.writeMessage(1, regionLoads_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < regionLoads_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionLoads_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse) obj;

      if (!getRegionLoadsList()
          .equals(other.getRegionLoadsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionLoadsCount() > 0) {
        hash = (37 * hash) + REGION_LOADS_FIELD_NUMBER;
        hash = (53 * hash) + getRegionLoadsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetRegionLoadResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.GetRegionLoadResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
        } else {
          regionLoads_ = null;
          regionLoadsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_GetRegionLoadResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse result) {
        if (regionLoadsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            regionLoads_ = java.util.Collections.unmodifiableList(regionLoads_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.regionLoads_ = regionLoads_;
        } else {
          result.regionLoads_ = regionLoadsBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance()) return this;
        if (regionLoadsBuilder_ == null) {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoads_.isEmpty()) {
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionLoadsIsMutable();
              regionLoads_.addAll(other.regionLoads_);
            }
            onChanged();
          }
        } else {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoadsBuilder_.isEmpty()) {
              regionLoadsBuilder_.dispose();
              regionLoadsBuilder_ = null;
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionLoadsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionLoadsFieldBuilder() : null;
            } else {
              regionLoadsBuilder_.addAllMessages(other.regionLoads_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionLoadsCount(); i++) {
          if (!getRegionLoads(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.PARSER,
                        extensionRegistry);
                if (regionLoadsBuilder_ == null) {
                  ensureRegionLoadsIsMutable();
                  regionLoads_.add(m);
                } else {
                  regionLoadsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> regionLoads_ =
        java.util.Collections.emptyList();
      private void ensureRegionLoadsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          regionLoads_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad>(regionLoads_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> regionLoadsBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> getRegionLoadsList() {
        if (regionLoadsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionLoads_);
        } else {
          return regionLoadsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public int getRegionLoadsCount() {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.size();
        } else {
          return regionLoadsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);
        } else {
          return regionLoadsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder addRegionLoads(org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder addRegionLoads(
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder addAllRegionLoads(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad> values) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionLoads_);
          onChanged();
        } else {
          regionLoadsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder clearRegionLoads() {
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionLoadsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public Builder removeRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.remove(index);
          onChanged();
        } else {
          regionLoadsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder getRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
          int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);  } else {
          return regionLoadsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
           getRegionLoadsOrBuilderList() {
        if (regionLoadsBuilder_ != null) {
          return regionLoadsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionLoads_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder addRegionLoadsBuilder() {
        return getRegionLoadsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder addRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionLoad region_loads = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder> 
           getRegionLoadsBuilderList() {
        return getRegionLoadsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
          getRegionLoadsFieldBuilder() {
        if (regionLoadsBuilder_ == null) {
          regionLoadsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder>(
                  regionLoads_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          regionLoads_ = null;
        }
        return regionLoadsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.GetRegionLoadResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetRegionLoadResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<GetRegionLoadResponse>() {
      @java.lang.Override
      public GetRegionLoadResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<GetRegionLoadResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearCompactionQueuesRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearCompactionQueuesRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string queue_name = 1;</code>
     * @return A list containing the queueName.
     */
    java.util.List<java.lang.String>
        getQueueNameList();
    /**
     * <code>repeated string queue_name = 1;</code>
     * @return The count of queueName.
     */
    int getQueueNameCount();
    /**
     * <code>repeated string queue_name = 1;</code>
     * @param index The index of the element to return.
     * @return The queueName at the given index.
     */
    java.lang.String getQueueName(int index);
    /**
     * <code>repeated string queue_name = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the queueName at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueNameBytes(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ClearCompactionQueuesRequest}
   */
  @javax.annotation.Generated("proto") public static final class ClearCompactionQueuesRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearCompactionQueuesRequest)
      ClearCompactionQueuesRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearCompactionQueuesRequest.newBuilder() to construct.
    private ClearCompactionQueuesRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearCompactionQueuesRequest() {
      queueName_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearCompactionQueuesRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.Builder.class);
    }

    public static final int QUEUE_NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList queueName_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string queue_name = 1;</code>
     * @return A list containing the queueName.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getQueueNameList() {
      return queueName_;
    }
    /**
     * <code>repeated string queue_name = 1;</code>
     * @return The count of queueName.
     */
    public int getQueueNameCount() {
      return queueName_.size();
    }
    /**
     * <code>repeated string queue_name = 1;</code>
     * @param index The index of the element to return.
     * @return The queueName at the given index.
     */
    public java.lang.String getQueueName(int index) {
      return queueName_.get(index);
    }
    /**
     * <code>repeated string queue_name = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the queueName at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getQueueNameBytes(int index) {
      return queueName_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < queueName_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queueName_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < queueName_.size(); i++) {
          dataSize += computeStringSizeNoTag(queueName_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getQueueNameList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest) obj;

      if (!getQueueNameList()
          .equals(other.getQueueNameList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getQueueNameCount() > 0) {
        hash = (37 * hash) + QUEUE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueNameList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearCompactionQueuesRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearCompactionQueuesRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        queueName_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          queueName_.makeImmutable();
          result.queueName_ = queueName_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.getDefaultInstance()) return this;
        if (!other.queueName_.isEmpty()) {
          if (queueName_.isEmpty()) {
            queueName_ = other.queueName_;
            bitField0_ |= 0x00000001;
          } else {
            ensureQueueNameIsMutable();
            queueName_.addAll(other.queueName_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureQueueNameIsMutable();
                queueName_.add(bs);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList queueName_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureQueueNameIsMutable() {
        if (!queueName_.isModifiable()) {
          queueName_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(queueName_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @return A list containing the queueName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getQueueNameList() {
        queueName_.makeImmutable();
        return queueName_;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @return The count of queueName.
       */
      public int getQueueNameCount() {
        return queueName_.size();
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param index The index of the element to return.
       * @return The queueName at the given index.
       */
      public java.lang.String getQueueName(int index) {
        return queueName_.get(index);
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the queueName at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getQueueNameBytes(int index) {
        return queueName_.getByteString(index);
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param index The index to set the value at.
       * @param value The queueName to set.
       * @return This builder for chaining.
       */
      public Builder setQueueName(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQueueNameIsMutable();
        queueName_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param value The queueName to add.
       * @return This builder for chaining.
       */
      public Builder addQueueName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQueueNameIsMutable();
        queueName_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param values The queueName to add.
       * @return This builder for chaining.
       */
      public Builder addAllQueueName(
          java.lang.Iterable<java.lang.String> values) {
        ensureQueueNameIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, queueName_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearQueueName() {
        queueName_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string queue_name = 1;</code>
       * @param value The bytes of the queueName to add.
       * @return This builder for chaining.
       */
      public Builder addQueueNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureQueueNameIsMutable();
        queueName_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearCompactionQueuesRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearCompactionQueuesRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearCompactionQueuesRequest>() {
      @java.lang.Override
      public ClearCompactionQueuesRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearCompactionQueuesResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearCompactionQueuesResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.ClearCompactionQueuesResponse}
   */
  @javax.annotation.Generated("proto") public static final class ClearCompactionQueuesResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearCompactionQueuesResponse)
      ClearCompactionQueuesResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearCompactionQueuesResponse.newBuilder() to construct.
    private ClearCompactionQueuesResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearCompactionQueuesResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearCompactionQueuesResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearCompactionQueuesResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearCompactionQueuesResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearCompactionQueuesResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearCompactionQueuesResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearCompactionQueuesResponse>() {
      @java.lang.Override
      public ClearCompactionQueuesResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearCompactionQueuesResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearRegionBlockCacheRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearRegionBlockCacheRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> 
        getRegionList();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index);
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    int getRegionCount();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
        getRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ClearRegionBlockCacheRequest}
   */
  @javax.annotation.Generated("proto") public static final class ClearRegionBlockCacheRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearRegionBlockCacheRequest)
      ClearRegionBlockCacheRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearRegionBlockCacheRequest.newBuilder() to construct.
    private ClearRegionBlockCacheRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearRegionBlockCacheRequest() {
      region_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearRegionBlockCacheRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.Builder.class);
    }

    public static final int REGION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> region_;
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> getRegionList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
        getRegionOrBuilderList() {
      return region_;
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public int getRegionCount() {
      return region_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index) {
      return region_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
        int index) {
      return region_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getRegionCount(); i++) {
        if (!getRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < region_.size(); i++) {
        output.writeMessage(1, region_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < region_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest) obj;

      if (!getRegionList()
          .equals(other.getRegionList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getRegionCount() > 0) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearRegionBlockCacheRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearRegionBlockCacheRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
        } else {
          region_ = null;
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest result) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            region_ = java.util.Collections.unmodifiableList(region_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.getDefaultInstance()) return this;
        if (regionBuilder_ == null) {
          if (!other.region_.isEmpty()) {
            if (region_.isEmpty()) {
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureRegionIsMutable();
              region_.addAll(other.region_);
            }
            onChanged();
          }
        } else {
          if (!other.region_.isEmpty()) {
            if (regionBuilder_.isEmpty()) {
              regionBuilder_.dispose();
              regionBuilder_ = null;
              region_ = other.region_;
              bitField0_ = (bitField0_ & ~0x00000001);
              regionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionFieldBuilder() : null;
            } else {
              regionBuilder_.addAllMessages(other.region_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionCount(); i++) {
          if (!getRegion(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER,
                        extensionRegistry);
                if (regionBuilder_ == null) {
                  ensureRegionIsMutable();
                  region_.add(m);
                } else {
                  regionBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> region_ =
        java.util.Collections.emptyList();
      private void ensureRegionIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          region_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier>(region_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> getRegionList() {
        if (regionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(region_);
        } else {
          return regionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public int getRegionCount() {
        if (regionBuilder_ == null) {
          return region_.size();
        } else {
          return regionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier getRegion(int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);
        } else {
          return regionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.set(index, value);
          onChanged();
        } else {
          regionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(value);
          onChanged();
        } else {
          regionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionIsMutable();
          region_.add(index, value);
          onChanged();
        } else {
          regionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder addAllRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier> values) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, region_);
          onChanged();
        } else {
          regionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public Builder removeRegion(int index) {
        if (regionBuilder_ == null) {
          ensureRegionIsMutable();
          region_.remove(index);
          onChanged();
        } else {
          regionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder(
          int index) {
        return getRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder(
          int index) {
        if (regionBuilder_ == null) {
          return region_.get(index);  } else {
          return regionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
           getRegionOrBuilderList() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(region_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder addRegionBuilder() {
        return getRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder addRegionBuilder(
          int index) {
        return getRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionSpecifier region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder> 
           getRegionBuilderList() {
        return getRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearRegionBlockCacheRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearRegionBlockCacheRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearRegionBlockCacheRequest>() {
      @java.lang.Override
      public ClearRegionBlockCacheRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearRegionBlockCacheResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearRegionBlockCacheResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     * @return Whether the stats field is set.
     */
    boolean hasStats();
    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     * @return The stats.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats getStats();
    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder getStatsOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ClearRegionBlockCacheResponse}
   */
  @javax.annotation.Generated("proto") public static final class ClearRegionBlockCacheResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearRegionBlockCacheResponse)
      ClearRegionBlockCacheResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearRegionBlockCacheResponse.newBuilder() to construct.
    private ClearRegionBlockCacheResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearRegionBlockCacheResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearRegionBlockCacheResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.Builder.class);
    }

    private int bitField0_;
    public static final int STATS_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats stats_;
    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     * @return Whether the stats field is set.
     */
    @java.lang.Override
    public boolean hasStats() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     * @return The stats.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats getStats() {
      return stats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.getDefaultInstance() : stats_;
    }
    /**
     * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder getStatsOrBuilder() {
      return stats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.getDefaultInstance() : stats_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasStats()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getStats().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getStats());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getStats());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse) obj;

      if (hasStats() != other.hasStats()) return false;
      if (hasStats()) {
        if (!getStats()
            .equals(other.getStats())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStats()) {
        hash = (37 * hash) + STATS_FIELD_NUMBER;
        hash = (53 * hash) + getStats().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearRegionBlockCacheResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearRegionBlockCacheResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStatsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        stats_ = null;
        if (statsBuilder_ != null) {
          statsBuilder_.dispose();
          statsBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.stats_ = statsBuilder_ == null
              ? stats_
              : statsBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance()) return this;
        if (other.hasStats()) {
          mergeStats(other.getStats());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasStats()) {
          return false;
        }
        if (!getStats().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getStatsFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats stats_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder> statsBuilder_;
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       * @return Whether the stats field is set.
       */
      public boolean hasStats() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       * @return The stats.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats getStats() {
        if (statsBuilder_ == null) {
          return stats_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.getDefaultInstance() : stats_;
        } else {
          return statsBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public Builder setStats(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats value) {
        if (statsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          stats_ = value;
        } else {
          statsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public Builder setStats(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.Builder builderForValue) {
        if (statsBuilder_ == null) {
          stats_ = builderForValue.build();
        } else {
          statsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public Builder mergeStats(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats value) {
        if (statsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            stats_ != null &&
            stats_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.getDefaultInstance()) {
            getStatsBuilder().mergeFrom(value);
          } else {
            stats_ = value;
          }
        } else {
          statsBuilder_.mergeFrom(value);
        }
        if (stats_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public Builder clearStats() {
        bitField0_ = (bitField0_ & ~0x00000001);
        stats_ = null;
        if (statsBuilder_ != null) {
          statsBuilder_.dispose();
          statsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.Builder getStatsBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getStatsFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder getStatsOrBuilder() {
        if (statsBuilder_ != null) {
          return statsBuilder_.getMessageOrBuilder();
        } else {
          return stats_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.getDefaultInstance() : stats_;
        }
      }
      /**
       * <code>required .hbase.pb.CacheEvictionStats stats = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder> 
          getStatsFieldBuilder() {
        if (statsBuilder_ == null) {
          statsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStats.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.CacheEvictionStatsOrBuilder>(
                  getStats(),
                  getParentForChildren(),
                  isClean());
          stats_ = null;
        }
        return statsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearRegionBlockCacheResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearRegionBlockCacheResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearRegionBlockCacheResponse>() {
      @java.lang.Override
      public ClearRegionBlockCacheResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearRegionBlockCacheResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RemoteProcedureRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RemoteProcedureRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required uint64 proc_id = 1;</code>
     * @return Whether the procId field is set.
     */
    boolean hasProcId();
    /**
     * <code>required uint64 proc_id = 1;</code>
     * @return The procId.
     */
    long getProcId();

    /**
     * <code>required string proc_class = 2;</code>
     * @return Whether the procClass field is set.
     */
    boolean hasProcClass();
    /**
     * <code>required string proc_class = 2;</code>
     * @return The procClass.
     */
    java.lang.String getProcClass();
    /**
     * <code>required string proc_class = 2;</code>
     * @return The bytes for procClass.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getProcClassBytes();

    /**
     * <code>optional bytes proc_data = 3;</code>
     * @return Whether the procData field is set.
     */
    boolean hasProcData();
    /**
     * <code>optional bytes proc_data = 3;</code>
     * @return The procData.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getProcData();

    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 4;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    boolean hasInitiatingMasterActiveTime();
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 4;</code>
     * @return The initiatingMasterActiveTime.
     */
    long getInitiatingMasterActiveTime();
  }
  /**
   * Protobuf type {@code hbase.pb.RemoteProcedureRequest}
   */
  @javax.annotation.Generated("proto") public static final class RemoteProcedureRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RemoteProcedureRequest)
      RemoteProcedureRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RemoteProcedureRequest.newBuilder() to construct.
    private RemoteProcedureRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RemoteProcedureRequest() {
      procClass_ = "";
      procData_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RemoteProcedureRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RemoteProcedureRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RemoteProcedureRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder.class);
    }

    private int bitField0_;
    public static final int PROC_ID_FIELD_NUMBER = 1;
    private long procId_ = 0L;
    /**
     * <code>required uint64 proc_id = 1;</code>
     * @return Whether the procId field is set.
     */
    @java.lang.Override
    public boolean hasProcId() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required uint64 proc_id = 1;</code>
     * @return The procId.
     */
    @java.lang.Override
    public long getProcId() {
      return procId_;
    }

    public static final int PROC_CLASS_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object procClass_ = "";
    /**
     * <code>required string proc_class = 2;</code>
     * @return Whether the procClass field is set.
     */
    @java.lang.Override
    public boolean hasProcClass() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required string proc_class = 2;</code>
     * @return The procClass.
     */
    @java.lang.Override
    public java.lang.String getProcClass() {
      java.lang.Object ref = procClass_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          procClass_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string proc_class = 2;</code>
     * @return The bytes for procClass.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getProcClassBytes() {
      java.lang.Object ref = procClass_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        procClass_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PROC_DATA_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString procData_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes proc_data = 3;</code>
     * @return Whether the procData field is set.
     */
    @java.lang.Override
    public boolean hasProcData() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bytes proc_data = 3;</code>
     * @return The procData.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getProcData() {
      return procData_;
    }

    public static final int INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER = 4;
    private long initiatingMasterActiveTime_ = 0L;
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 4;</code>
     * @return Whether the initiatingMasterActiveTime field is set.
     */
    @java.lang.Override
    public boolean hasInitiatingMasterActiveTime() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * Master active time as fencing token
     * </pre>
     *
     * <code>optional int64 initiating_master_active_time = 4;</code>
     * @return The initiatingMasterActiveTime.
     */
    @java.lang.Override
    public long getInitiatingMasterActiveTime() {
      return initiatingMasterActiveTime_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasProcId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasProcClass()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(1, procId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, procClass_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, procData_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeInt64(4, initiatingMasterActiveTime_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, procId_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, procClass_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, procData_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, initiatingMasterActiveTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest) obj;

      if (hasProcId() != other.hasProcId()) return false;
      if (hasProcId()) {
        if (getProcId()
            != other.getProcId()) return false;
      }
      if (hasProcClass() != other.hasProcClass()) return false;
      if (hasProcClass()) {
        if (!getProcClass()
            .equals(other.getProcClass())) return false;
      }
      if (hasProcData() != other.hasProcData()) return false;
      if (hasProcData()) {
        if (!getProcData()
            .equals(other.getProcData())) return false;
      }
      if (hasInitiatingMasterActiveTime() != other.hasInitiatingMasterActiveTime()) return false;
      if (hasInitiatingMasterActiveTime()) {
        if (getInitiatingMasterActiveTime()
            != other.getInitiatingMasterActiveTime()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasProcId()) {
        hash = (37 * hash) + PROC_ID_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getProcId());
      }
      if (hasProcClass()) {
        hash = (37 * hash) + PROC_CLASS_FIELD_NUMBER;
        hash = (53 * hash) + getProcClass().hashCode();
      }
      if (hasProcData()) {
        hash = (37 * hash) + PROC_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getProcData().hashCode();
      }
      if (hasInitiatingMasterActiveTime()) {
        hash = (37 * hash) + INITIATING_MASTER_ACTIVE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getInitiatingMasterActiveTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RemoteProcedureRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RemoteProcedureRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RemoteProcedureRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RemoteProcedureRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        procId_ = 0L;
        procClass_ = "";
        procData_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        initiatingMasterActiveTime_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_RemoteProcedureRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.procId_ = procId_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.procClass_ = procClass_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.procData_ = procData_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.initiatingMasterActiveTime_ = initiatingMasterActiveTime_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.getDefaultInstance()) return this;
        if (other.hasProcId()) {
          setProcId(other.getProcId());
        }
        if (other.hasProcClass()) {
          procClass_ = other.procClass_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasProcData()) {
          setProcData(other.getProcData());
        }
        if (other.hasInitiatingMasterActiveTime()) {
          setInitiatingMasterActiveTime(other.getInitiatingMasterActiveTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasProcId()) {
          return false;
        }
        if (!hasProcClass()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                procId_ = input.readUInt64();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 18: {
                procClass_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                procData_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                initiatingMasterActiveTime_ = input.readInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private long procId_ ;
      /**
       * <code>required uint64 proc_id = 1;</code>
       * @return Whether the procId field is set.
       */
      @java.lang.Override
      public boolean hasProcId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required uint64 proc_id = 1;</code>
       * @return The procId.
       */
      @java.lang.Override
      public long getProcId() {
        return procId_;
      }
      /**
       * <code>required uint64 proc_id = 1;</code>
       * @param value The procId to set.
       * @return This builder for chaining.
       */
      public Builder setProcId(long value) {

        procId_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required uint64 proc_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearProcId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        procId_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object procClass_ = "";
      /**
       * <code>required string proc_class = 2;</code>
       * @return Whether the procClass field is set.
       */
      public boolean hasProcClass() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required string proc_class = 2;</code>
       * @return The procClass.
       */
      public java.lang.String getProcClass() {
        java.lang.Object ref = procClass_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            procClass_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string proc_class = 2;</code>
       * @return The bytes for procClass.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getProcClassBytes() {
        java.lang.Object ref = procClass_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          procClass_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string proc_class = 2;</code>
       * @param value The procClass to set.
       * @return This builder for chaining.
       */
      public Builder setProcClass(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        procClass_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required string proc_class = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearProcClass() {
        procClass_ = getDefaultInstance().getProcClass();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>required string proc_class = 2;</code>
       * @param value The bytes for procClass to set.
       * @return This builder for chaining.
       */
      public Builder setProcClassBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        procClass_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString procData_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes proc_data = 3;</code>
       * @return Whether the procData field is set.
       */
      @java.lang.Override
      public boolean hasProcData() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bytes proc_data = 3;</code>
       * @return The procData.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getProcData() {
        return procData_;
      }
      /**
       * <code>optional bytes proc_data = 3;</code>
       * @param value The procData to set.
       * @return This builder for chaining.
       */
      public Builder setProcData(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        procData_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes proc_data = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearProcData() {
        bitField0_ = (bitField0_ & ~0x00000004);
        procData_ = getDefaultInstance().getProcData();
        onChanged();
        return this;
      }

      private long initiatingMasterActiveTime_ ;
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 4;</code>
       * @return Whether the initiatingMasterActiveTime field is set.
       */
      @java.lang.Override
      public boolean hasInitiatingMasterActiveTime() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 4;</code>
       * @return The initiatingMasterActiveTime.
       */
      @java.lang.Override
      public long getInitiatingMasterActiveTime() {
        return initiatingMasterActiveTime_;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 4;</code>
       * @param value The initiatingMasterActiveTime to set.
       * @return This builder for chaining.
       */
      public Builder setInitiatingMasterActiveTime(long value) {

        initiatingMasterActiveTime_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Master active time as fencing token
       * </pre>
       *
       * <code>optional int64 initiating_master_active_time = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearInitiatingMasterActiveTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        initiatingMasterActiveTime_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RemoteProcedureRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RemoteProcedureRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemoteProcedureRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RemoteProcedureRequest>() {
      @java.lang.Override
      public RemoteProcedureRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemoteProcedureRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RemoteProcedureRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ExecuteProceduresRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ExecuteProceduresRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> 
        getOpenRegionList();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getOpenRegion(int index);
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    int getOpenRegionCount();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder> 
        getOpenRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder getOpenRegionOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> 
        getCloseRegionList();
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getCloseRegion(int index);
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    int getCloseRegionCount();
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder> 
        getCloseRegionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder getCloseRegionOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> 
        getProcList();
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getProc(int index);
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    int getProcCount();
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder> 
        getProcOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder getProcOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.ExecuteProceduresRequest}
   */
  @javax.annotation.Generated("proto") public static final class ExecuteProceduresRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ExecuteProceduresRequest)
      ExecuteProceduresRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ExecuteProceduresRequest.newBuilder() to construct.
    private ExecuteProceduresRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ExecuteProceduresRequest() {
      openRegion_ = java.util.Collections.emptyList();
      closeRegion_ = java.util.Collections.emptyList();
      proc_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ExecuteProceduresRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.Builder.class);
    }

    public static final int OPEN_REGION_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> openRegion_;
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> getOpenRegionList() {
      return openRegion_;
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder> 
        getOpenRegionOrBuilderList() {
      return openRegion_;
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    @java.lang.Override
    public int getOpenRegionCount() {
      return openRegion_.size();
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getOpenRegion(int index) {
      return openRegion_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder getOpenRegionOrBuilder(
        int index) {
      return openRegion_.get(index);
    }

    public static final int CLOSE_REGION_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> closeRegion_;
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> getCloseRegionList() {
      return closeRegion_;
    }
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder> 
        getCloseRegionOrBuilderList() {
      return closeRegion_;
    }
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    @java.lang.Override
    public int getCloseRegionCount() {
      return closeRegion_.size();
    }
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getCloseRegion(int index) {
      return closeRegion_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder getCloseRegionOrBuilder(
        int index) {
      return closeRegion_.get(index);
    }

    public static final int PROC_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> proc_;
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> getProcList() {
      return proc_;
    }
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder> 
        getProcOrBuilderList() {
      return proc_;
    }
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    @java.lang.Override
    public int getProcCount() {
      return proc_.size();
    }
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getProc(int index) {
      return proc_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder getProcOrBuilder(
        int index) {
      return proc_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getOpenRegionCount(); i++) {
        if (!getOpenRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getCloseRegionCount(); i++) {
        if (!getCloseRegion(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getProcCount(); i++) {
        if (!getProc(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < openRegion_.size(); i++) {
        output.writeMessage(1, openRegion_.get(i));
      }
      for (int i = 0; i < closeRegion_.size(); i++) {
        output.writeMessage(2, closeRegion_.get(i));
      }
      for (int i = 0; i < proc_.size(); i++) {
        output.writeMessage(3, proc_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < openRegion_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, openRegion_.get(i));
      }
      for (int i = 0; i < closeRegion_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, closeRegion_.get(i));
      }
      for (int i = 0; i < proc_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, proc_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest) obj;

      if (!getOpenRegionList()
          .equals(other.getOpenRegionList())) return false;
      if (!getCloseRegionList()
          .equals(other.getCloseRegionList())) return false;
      if (!getProcList()
          .equals(other.getProcList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getOpenRegionCount() > 0) {
        hash = (37 * hash) + OPEN_REGION_FIELD_NUMBER;
        hash = (53 * hash) + getOpenRegionList().hashCode();
      }
      if (getCloseRegionCount() > 0) {
        hash = (37 * hash) + CLOSE_REGION_FIELD_NUMBER;
        hash = (53 * hash) + getCloseRegionList().hashCode();
      }
      if (getProcCount() > 0) {
        hash = (37 * hash) + PROC_FIELD_NUMBER;
        hash = (53 * hash) + getProcList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ExecuteProceduresRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ExecuteProceduresRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (openRegionBuilder_ == null) {
          openRegion_ = java.util.Collections.emptyList();
        } else {
          openRegion_ = null;
          openRegionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (closeRegionBuilder_ == null) {
          closeRegion_ = java.util.Collections.emptyList();
        } else {
          closeRegion_ = null;
          closeRegionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (procBuilder_ == null) {
          proc_ = java.util.Collections.emptyList();
        } else {
          proc_ = null;
          procBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest result) {
        if (openRegionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            openRegion_ = java.util.Collections.unmodifiableList(openRegion_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.openRegion_ = openRegion_;
        } else {
          result.openRegion_ = openRegionBuilder_.build();
        }
        if (closeRegionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            closeRegion_ = java.util.Collections.unmodifiableList(closeRegion_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.closeRegion_ = closeRegion_;
        } else {
          result.closeRegion_ = closeRegionBuilder_.build();
        }
        if (procBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            proc_ = java.util.Collections.unmodifiableList(proc_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.proc_ = proc_;
        } else {
          result.proc_ = procBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.getDefaultInstance()) return this;
        if (openRegionBuilder_ == null) {
          if (!other.openRegion_.isEmpty()) {
            if (openRegion_.isEmpty()) {
              openRegion_ = other.openRegion_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureOpenRegionIsMutable();
              openRegion_.addAll(other.openRegion_);
            }
            onChanged();
          }
        } else {
          if (!other.openRegion_.isEmpty()) {
            if (openRegionBuilder_.isEmpty()) {
              openRegionBuilder_.dispose();
              openRegionBuilder_ = null;
              openRegion_ = other.openRegion_;
              bitField0_ = (bitField0_ & ~0x00000001);
              openRegionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getOpenRegionFieldBuilder() : null;
            } else {
              openRegionBuilder_.addAllMessages(other.openRegion_);
            }
          }
        }
        if (closeRegionBuilder_ == null) {
          if (!other.closeRegion_.isEmpty()) {
            if (closeRegion_.isEmpty()) {
              closeRegion_ = other.closeRegion_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureCloseRegionIsMutable();
              closeRegion_.addAll(other.closeRegion_);
            }
            onChanged();
          }
        } else {
          if (!other.closeRegion_.isEmpty()) {
            if (closeRegionBuilder_.isEmpty()) {
              closeRegionBuilder_.dispose();
              closeRegionBuilder_ = null;
              closeRegion_ = other.closeRegion_;
              bitField0_ = (bitField0_ & ~0x00000002);
              closeRegionBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getCloseRegionFieldBuilder() : null;
            } else {
              closeRegionBuilder_.addAllMessages(other.closeRegion_);
            }
          }
        }
        if (procBuilder_ == null) {
          if (!other.proc_.isEmpty()) {
            if (proc_.isEmpty()) {
              proc_ = other.proc_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureProcIsMutable();
              proc_.addAll(other.proc_);
            }
            onChanged();
          }
        } else {
          if (!other.proc_.isEmpty()) {
            if (procBuilder_.isEmpty()) {
              procBuilder_.dispose();
              procBuilder_ = null;
              proc_ = other.proc_;
              bitField0_ = (bitField0_ & ~0x00000004);
              procBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getProcFieldBuilder() : null;
            } else {
              procBuilder_.addAllMessages(other.proc_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getOpenRegionCount(); i++) {
          if (!getOpenRegion(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getCloseRegionCount(); i++) {
          if (!getCloseRegion(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getProcCount(); i++) {
          if (!getProc(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.PARSER,
                        extensionRegistry);
                if (openRegionBuilder_ == null) {
                  ensureOpenRegionIsMutable();
                  openRegion_.add(m);
                } else {
                  openRegionBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 18: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.PARSER,
                        extensionRegistry);
                if (closeRegionBuilder_ == null) {
                  ensureCloseRegionIsMutable();
                  closeRegion_.add(m);
                } else {
                  closeRegionBuilder_.addMessage(m);
                }
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.PARSER,
                        extensionRegistry);
                if (procBuilder_ == null) {
                  ensureProcIsMutable();
                  proc_.add(m);
                } else {
                  procBuilder_.addMessage(m);
                }
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> openRegion_ =
        java.util.Collections.emptyList();
      private void ensureOpenRegionIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          openRegion_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest>(openRegion_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder> openRegionBuilder_;

      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> getOpenRegionList() {
        if (openRegionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(openRegion_);
        } else {
          return openRegionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public int getOpenRegionCount() {
        if (openRegionBuilder_ == null) {
          return openRegion_.size();
        } else {
          return openRegionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest getOpenRegion(int index) {
        if (openRegionBuilder_ == null) {
          return openRegion_.get(index);
        } else {
          return openRegionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder setOpenRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest value) {
        if (openRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenRegionIsMutable();
          openRegion_.set(index, value);
          onChanged();
        } else {
          openRegionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder setOpenRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder builderForValue) {
        if (openRegionBuilder_ == null) {
          ensureOpenRegionIsMutable();
          openRegion_.set(index, builderForValue.build());
          onChanged();
        } else {
          openRegionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder addOpenRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest value) {
        if (openRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenRegionIsMutable();
          openRegion_.add(value);
          onChanged();
        } else {
          openRegionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder addOpenRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest value) {
        if (openRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOpenRegionIsMutable();
          openRegion_.add(index, value);
          onChanged();
        } else {
          openRegionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder addOpenRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder builderForValue) {
        if (openRegionBuilder_ == null) {
          ensureOpenRegionIsMutable();
          openRegion_.add(builderForValue.build());
          onChanged();
        } else {
          openRegionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder addOpenRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder builderForValue) {
        if (openRegionBuilder_ == null) {
          ensureOpenRegionIsMutable();
          openRegion_.add(index, builderForValue.build());
          onChanged();
        } else {
          openRegionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder addAllOpenRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest> values) {
        if (openRegionBuilder_ == null) {
          ensureOpenRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, openRegion_);
          onChanged();
        } else {
          openRegionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder clearOpenRegion() {
        if (openRegionBuilder_ == null) {
          openRegion_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          openRegionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public Builder removeOpenRegion(int index) {
        if (openRegionBuilder_ == null) {
          ensureOpenRegionIsMutable();
          openRegion_.remove(index);
          onChanged();
        } else {
          openRegionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder getOpenRegionBuilder(
          int index) {
        return getOpenRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder getOpenRegionOrBuilder(
          int index) {
        if (openRegionBuilder_ == null) {
          return openRegion_.get(index);  } else {
          return openRegionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder> 
           getOpenRegionOrBuilderList() {
        if (openRegionBuilder_ != null) {
          return openRegionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(openRegion_);
        }
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder addOpenRegionBuilder() {
        return getOpenRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder addOpenRegionBuilder(
          int index) {
        return getOpenRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.OpenRegionRequest open_region = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder> 
           getOpenRegionBuilderList() {
        return getOpenRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder> 
          getOpenRegionFieldBuilder() {
        if (openRegionBuilder_ == null) {
          openRegionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequestOrBuilder>(
                  openRegion_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          openRegion_ = null;
        }
        return openRegionBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> closeRegion_ =
        java.util.Collections.emptyList();
      private void ensureCloseRegionIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          closeRegion_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest>(closeRegion_);
          bitField0_ |= 0x00000002;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder> closeRegionBuilder_;

      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> getCloseRegionList() {
        if (closeRegionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(closeRegion_);
        } else {
          return closeRegionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public int getCloseRegionCount() {
        if (closeRegionBuilder_ == null) {
          return closeRegion_.size();
        } else {
          return closeRegionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest getCloseRegion(int index) {
        if (closeRegionBuilder_ == null) {
          return closeRegion_.get(index);
        } else {
          return closeRegionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder setCloseRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest value) {
        if (closeRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCloseRegionIsMutable();
          closeRegion_.set(index, value);
          onChanged();
        } else {
          closeRegionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder setCloseRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder builderForValue) {
        if (closeRegionBuilder_ == null) {
          ensureCloseRegionIsMutable();
          closeRegion_.set(index, builderForValue.build());
          onChanged();
        } else {
          closeRegionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder addCloseRegion(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest value) {
        if (closeRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCloseRegionIsMutable();
          closeRegion_.add(value);
          onChanged();
        } else {
          closeRegionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder addCloseRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest value) {
        if (closeRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCloseRegionIsMutable();
          closeRegion_.add(index, value);
          onChanged();
        } else {
          closeRegionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder addCloseRegion(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder builderForValue) {
        if (closeRegionBuilder_ == null) {
          ensureCloseRegionIsMutable();
          closeRegion_.add(builderForValue.build());
          onChanged();
        } else {
          closeRegionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder addCloseRegion(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder builderForValue) {
        if (closeRegionBuilder_ == null) {
          ensureCloseRegionIsMutable();
          closeRegion_.add(index, builderForValue.build());
          onChanged();
        } else {
          closeRegionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder addAllCloseRegion(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest> values) {
        if (closeRegionBuilder_ == null) {
          ensureCloseRegionIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, closeRegion_);
          onChanged();
        } else {
          closeRegionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder clearCloseRegion() {
        if (closeRegionBuilder_ == null) {
          closeRegion_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          closeRegionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public Builder removeCloseRegion(int index) {
        if (closeRegionBuilder_ == null) {
          ensureCloseRegionIsMutable();
          closeRegion_.remove(index);
          onChanged();
        } else {
          closeRegionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder getCloseRegionBuilder(
          int index) {
        return getCloseRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder getCloseRegionOrBuilder(
          int index) {
        if (closeRegionBuilder_ == null) {
          return closeRegion_.get(index);  } else {
          return closeRegionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder> 
           getCloseRegionOrBuilderList() {
        if (closeRegionBuilder_ != null) {
          return closeRegionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(closeRegion_);
        }
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder addCloseRegionBuilder() {
        return getCloseRegionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder addCloseRegionBuilder(
          int index) {
        return getCloseRegionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.CloseRegionRequest close_region = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder> 
           getCloseRegionBuilderList() {
        return getCloseRegionFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder> 
          getCloseRegionFieldBuilder() {
        if (closeRegionBuilder_ == null) {
          closeRegionBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequestOrBuilder>(
                  closeRegion_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          closeRegion_ = null;
        }
        return closeRegionBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> proc_ =
        java.util.Collections.emptyList();
      private void ensureProcIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          proc_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest>(proc_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder> procBuilder_;

      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> getProcList() {
        if (procBuilder_ == null) {
          return java.util.Collections.unmodifiableList(proc_);
        } else {
          return procBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public int getProcCount() {
        if (procBuilder_ == null) {
          return proc_.size();
        } else {
          return procBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest getProc(int index) {
        if (procBuilder_ == null) {
          return proc_.get(index);
        } else {
          return procBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder setProc(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest value) {
        if (procBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureProcIsMutable();
          proc_.set(index, value);
          onChanged();
        } else {
          procBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder setProc(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder builderForValue) {
        if (procBuilder_ == null) {
          ensureProcIsMutable();
          proc_.set(index, builderForValue.build());
          onChanged();
        } else {
          procBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder addProc(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest value) {
        if (procBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureProcIsMutable();
          proc_.add(value);
          onChanged();
        } else {
          procBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder addProc(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest value) {
        if (procBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureProcIsMutable();
          proc_.add(index, value);
          onChanged();
        } else {
          procBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder addProc(
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder builderForValue) {
        if (procBuilder_ == null) {
          ensureProcIsMutable();
          proc_.add(builderForValue.build());
          onChanged();
        } else {
          procBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder addProc(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder builderForValue) {
        if (procBuilder_ == null) {
          ensureProcIsMutable();
          proc_.add(index, builderForValue.build());
          onChanged();
        } else {
          procBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder addAllProc(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest> values) {
        if (procBuilder_ == null) {
          ensureProcIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, proc_);
          onChanged();
        } else {
          procBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder clearProc() {
        if (procBuilder_ == null) {
          proc_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          procBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public Builder removeProc(int index) {
        if (procBuilder_ == null) {
          ensureProcIsMutable();
          proc_.remove(index);
          onChanged();
        } else {
          procBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder getProcBuilder(
          int index) {
        return getProcFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder getProcOrBuilder(
          int index) {
        if (procBuilder_ == null) {
          return proc_.get(index);  } else {
          return procBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder> 
           getProcOrBuilderList() {
        if (procBuilder_ != null) {
          return procBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(proc_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder addProcBuilder() {
        return getProcFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder addProcBuilder(
          int index) {
        return getProcFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RemoteProcedureRequest proc = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder> 
           getProcBuilderList() {
        return getProcFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder> 
          getProcFieldBuilder() {
        if (procBuilder_ == null) {
          procBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequest.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RemoteProcedureRequestOrBuilder>(
                  proc_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          proc_ = null;
        }
        return procBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ExecuteProceduresRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ExecuteProceduresRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ExecuteProceduresRequest>() {
      @java.lang.Override
      public ExecuteProceduresRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ExecuteProceduresResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ExecuteProceduresResponse)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.ExecuteProceduresResponse}
   */
  @javax.annotation.Generated("proto") public static final class ExecuteProceduresResponse extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ExecuteProceduresResponse)
      ExecuteProceduresResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ExecuteProceduresResponse.newBuilder() to construct.
    private ExecuteProceduresResponse(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ExecuteProceduresResponse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ExecuteProceduresResponse();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresResponse_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ExecuteProceduresResponse}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ExecuteProceduresResponse)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponseOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresResponse_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ExecuteProceduresResponse_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ExecuteProceduresResponse)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ExecuteProceduresResponse)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresResponse>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ExecuteProceduresResponse>() {
      @java.lang.Override
      public ExecuteProceduresResponse parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ExecuteProceduresResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SlowLogResponseRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SlowLogResponseRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string region_name = 1;</code>
     * @return Whether the regionName field is set.
     */
    boolean hasRegionName();
    /**
     * <code>optional string region_name = 1;</code>
     * @return The regionName.
     */
    java.lang.String getRegionName();
    /**
     * <code>optional string region_name = 1;</code>
     * @return The bytes for regionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getRegionNameBytes();

    /**
     * <code>optional string table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>optional string table_name = 2;</code>
     * @return The tableName.
     */
    java.lang.String getTableName();
    /**
     * <code>optional string table_name = 2;</code>
     * @return The bytes for tableName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getTableNameBytes();

    /**
     * <code>optional string client_address = 3;</code>
     * @return Whether the clientAddress field is set.
     */
    boolean hasClientAddress();
    /**
     * <code>optional string client_address = 3;</code>
     * @return The clientAddress.
     */
    java.lang.String getClientAddress();
    /**
     * <code>optional string client_address = 3;</code>
     * @return The bytes for clientAddress.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClientAddressBytes();

    /**
     * <code>optional string user_name = 4;</code>
     * @return Whether the userName field is set.
     */
    boolean hasUserName();
    /**
     * <code>optional string user_name = 4;</code>
     * @return The userName.
     */
    java.lang.String getUserName();
    /**
     * <code>optional string user_name = 4;</code>
     * @return The bytes for userName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getUserNameBytes();

    /**
     * <code>optional uint32 limit = 5 [default = 10];</code>
     * @return Whether the limit field is set.
     */
    boolean hasLimit();
    /**
     * <code>optional uint32 limit = 5 [default = 10];</code>
     * @return The limit.
     */
    int getLimit();

    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
     * @return Whether the filterByOperator field is set.
     */
    boolean hasFilterByOperator();
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
     * @return The filterByOperator.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator getFilterByOperator();

    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
     * @return Whether the logType field is set.
     */
    boolean hasLogType();
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
     * @return The logType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType getLogType();
  }
  /**
   * <pre>
   **
   * Slow/Large log (LogRequest) use-case specific RPC request. This request payload will be
   * converted in bytes and sent to generic RPC API: GetLogEntries
   * LogRequest message has two params:
   * 1. log_class_name: SlowLogResponseRequest (for Slow/Large log use-case)
   * 2. log_message: SlowLogResponseRequest converted in bytes (for Slow/Large log use-case)
   * </pre>
   *
   * Protobuf type {@code hbase.pb.SlowLogResponseRequest}
   */
  @javax.annotation.Generated("proto") public static final class SlowLogResponseRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SlowLogResponseRequest)
      SlowLogResponseRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SlowLogResponseRequest.newBuilder() to construct.
    private SlowLogResponseRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SlowLogResponseRequest() {
      regionName_ = "";
      tableName_ = "";
      clientAddress_ = "";
      userName_ = "";
      limit_ = 10;
      filterByOperator_ = 1;
      logType_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SlowLogResponseRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponseRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponseRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.SlowLogResponseRequest.FilterByOperator}
     */
    public enum FilterByOperator
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>AND = 0;</code>
       */
      AND(0),
      /**
       * <code>OR = 1;</code>
       */
      OR(1),
      ;

      /**
       * <code>AND = 0;</code>
       */
      public static final int AND_VALUE = 0;
      /**
       * <code>OR = 1;</code>
       */
      public static final int OR_VALUE = 1;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static FilterByOperator valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static FilterByOperator forNumber(int value) {
        switch (value) {
          case 0: return AND;
          case 1: return OR;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<FilterByOperator>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          FilterByOperator> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<FilterByOperator>() {
              public FilterByOperator findValueByNumber(int number) {
                return FilterByOperator.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDescriptor().getEnumTypes().get(0);
      }

      private static final FilterByOperator[] VALUES = values();

      public static FilterByOperator valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private FilterByOperator(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.SlowLogResponseRequest.FilterByOperator)
    }

    /**
     * Protobuf enum {@code hbase.pb.SlowLogResponseRequest.LogType}
     */
    public enum LogType
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>SLOW_LOG = 0;</code>
       */
      SLOW_LOG(0),
      /**
       * <code>LARGE_LOG = 1;</code>
       */
      LARGE_LOG(1),
      ;

      /**
       * <code>SLOW_LOG = 0;</code>
       */
      public static final int SLOW_LOG_VALUE = 0;
      /**
       * <code>LARGE_LOG = 1;</code>
       */
      public static final int LARGE_LOG_VALUE = 1;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static LogType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static LogType forNumber(int value) {
        switch (value) {
          case 0: return SLOW_LOG;
          case 1: return LARGE_LOG;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<LogType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          LogType> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<LogType>() {
              public LogType findValueByNumber(int number) {
                return LogType.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDescriptor().getEnumTypes().get(1);
      }

      private static final LogType[] VALUES = values();

      public static LogType valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private LogType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.SlowLogResponseRequest.LogType)
    }

    private int bitField0_;
    public static final int REGION_NAME_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object regionName_ = "";
    /**
     * <code>optional string region_name = 1;</code>
     * @return Whether the regionName field is set.
     */
    @java.lang.Override
    public boolean hasRegionName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional string region_name = 1;</code>
     * @return The regionName.
     */
    @java.lang.Override
    public java.lang.String getRegionName() {
      java.lang.Object ref = regionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          regionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string region_name = 1;</code>
     * @return The bytes for regionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getRegionNameBytes() {
      java.lang.Object ref = regionName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        regionName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object tableName_ = "";
    /**
     * <code>optional string table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional string table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public java.lang.String getTableName() {
      java.lang.Object ref = tableName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          tableName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string table_name = 2;</code>
     * @return The bytes for tableName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getTableNameBytes() {
      java.lang.Object ref = tableName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        tableName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLIENT_ADDRESS_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object clientAddress_ = "";
    /**
     * <code>optional string client_address = 3;</code>
     * @return Whether the clientAddress field is set.
     */
    @java.lang.Override
    public boolean hasClientAddress() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional string client_address = 3;</code>
     * @return The clientAddress.
     */
    @java.lang.Override
    public java.lang.String getClientAddress() {
      java.lang.Object ref = clientAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          clientAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string client_address = 3;</code>
     * @return The bytes for clientAddress.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClientAddressBytes() {
      java.lang.Object ref = clientAddress_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clientAddress_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int USER_NAME_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object userName_ = "";
    /**
     * <code>optional string user_name = 4;</code>
     * @return Whether the userName field is set.
     */
    @java.lang.Override
    public boolean hasUserName() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional string user_name = 4;</code>
     * @return The userName.
     */
    @java.lang.Override
    public java.lang.String getUserName() {
      java.lang.Object ref = userName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          userName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user_name = 4;</code>
     * @return The bytes for userName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getUserNameBytes() {
      java.lang.Object ref = userName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        userName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LIMIT_FIELD_NUMBER = 5;
    private int limit_ = 10;
    /**
     * <code>optional uint32 limit = 5 [default = 10];</code>
     * @return Whether the limit field is set.
     */
    @java.lang.Override
    public boolean hasLimit() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional uint32 limit = 5 [default = 10];</code>
     * @return The limit.
     */
    @java.lang.Override
    public int getLimit() {
      return limit_;
    }

    public static final int FILTER_BY_OPERATOR_FIELD_NUMBER = 6;
    private int filterByOperator_ = 1;
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
     * @return Whether the filterByOperator field is set.
     */
    @java.lang.Override public boolean hasFilterByOperator() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
     * @return The filterByOperator.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator getFilterByOperator() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator.forNumber(filterByOperator_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator.OR : result;
    }

    public static final int LOG_TYPE_FIELD_NUMBER = 7;
    private int logType_ = 0;
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
     * @return Whether the logType field is set.
     */
    @java.lang.Override public boolean hasLogType() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
     * @return The logType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType getLogType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType.forNumber(logType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType.SLOW_LOG : result;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, regionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, clientAddress_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 4, userName_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeUInt32(5, limit_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeEnum(6, filterByOperator_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeEnum(7, logType_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, regionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(3, clientAddress_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(4, userName_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(5, limit_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, filterByOperator_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, logType_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest) obj;

      if (hasRegionName() != other.hasRegionName()) return false;
      if (hasRegionName()) {
        if (!getRegionName()
            .equals(other.getRegionName())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasClientAddress() != other.hasClientAddress()) return false;
      if (hasClientAddress()) {
        if (!getClientAddress()
            .equals(other.getClientAddress())) return false;
      }
      if (hasUserName() != other.hasUserName()) return false;
      if (hasUserName()) {
        if (!getUserName()
            .equals(other.getUserName())) return false;
      }
      if (hasLimit() != other.hasLimit()) return false;
      if (hasLimit()) {
        if (getLimit()
            != other.getLimit()) return false;
      }
      if (hasFilterByOperator() != other.hasFilterByOperator()) return false;
      if (hasFilterByOperator()) {
        if (filterByOperator_ != other.filterByOperator_) return false;
      }
      if (hasLogType() != other.hasLogType()) return false;
      if (hasLogType()) {
        if (logType_ != other.logType_) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasRegionName()) {
        hash = (37 * hash) + REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getRegionName().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasClientAddress()) {
        hash = (37 * hash) + CLIENT_ADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getClientAddress().hashCode();
      }
      if (hasUserName()) {
        hash = (37 * hash) + USER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getUserName().hashCode();
      }
      if (hasLimit()) {
        hash = (37 * hash) + LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getLimit();
      }
      if (hasFilterByOperator()) {
        hash = (37 * hash) + FILTER_BY_OPERATOR_FIELD_NUMBER;
        hash = (53 * hash) + filterByOperator_;
      }
      if (hasLogType()) {
        hash = (37 * hash) + LOG_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + logType_;
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Slow/Large log (LogRequest) use-case specific RPC request. This request payload will be
     * converted in bytes and sent to generic RPC API: GetLogEntries
     * LogRequest message has two params:
     * 1. log_class_name: SlowLogResponseRequest (for Slow/Large log use-case)
     * 2. log_message: SlowLogResponseRequest converted in bytes (for Slow/Large log use-case)
     * </pre>
     *
     * Protobuf type {@code hbase.pb.SlowLogResponseRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SlowLogResponseRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponseRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponseRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        regionName_ = "";
        tableName_ = "";
        clientAddress_ = "";
        userName_ = "";
        limit_ = 10;
        filterByOperator_ = 1;
        logType_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponseRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.regionName_ = regionName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.clientAddress_ = clientAddress_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.userName_ = userName_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.limit_ = limit_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.filterByOperator_ = filterByOperator_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.logType_ = logType_;
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance()) return this;
        if (other.hasRegionName()) {
          regionName_ = other.regionName_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasTableName()) {
          tableName_ = other.tableName_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.hasClientAddress()) {
          clientAddress_ = other.clientAddress_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.hasUserName()) {
          userName_ = other.userName_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        if (other.hasLimit()) {
          setLimit(other.getLimit());
        }
        if (other.hasFilterByOperator()) {
          setFilterByOperator(other.getFilterByOperator());
        }
        if (other.hasLogType()) {
          setLogType(other.getLogType());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                regionName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                tableName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                clientAddress_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                userName_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 40: {
                limit_ = input.readUInt32();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 48: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(6, tmpRaw);
                } else {
                  filterByOperator_ = tmpRaw;
                  bitField0_ |= 0x00000020;
                }
                break;
              } // case 48
              case 56: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(7, tmpRaw);
                } else {
                  logType_ = tmpRaw;
                  bitField0_ |= 0x00000040;
                }
                break;
              } // case 56
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object regionName_ = "";
      /**
       * <code>optional string region_name = 1;</code>
       * @return Whether the regionName field is set.
       */
      public boolean hasRegionName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional string region_name = 1;</code>
       * @return The regionName.
       */
      public java.lang.String getRegionName() {
        java.lang.Object ref = regionName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            regionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string region_name = 1;</code>
       * @return The bytes for regionName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getRegionNameBytes() {
        java.lang.Object ref = regionName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          regionName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string region_name = 1;</code>
       * @param value The regionName to set.
       * @return This builder for chaining.
       */
      public Builder setRegionName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        regionName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional string region_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionName() {
        regionName_ = getDefaultInstance().getRegionName();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>optional string region_name = 1;</code>
       * @param value The bytes for regionName to set.
       * @return This builder for chaining.
       */
      public Builder setRegionNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        regionName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private java.lang.Object tableName_ = "";
      /**
       * <code>optional string table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional string table_name = 2;</code>
       * @return The tableName.
       */
      public java.lang.String getTableName() {
        java.lang.Object ref = tableName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            tableName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string table_name = 2;</code>
       * @return The bytes for tableName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getTableNameBytes() {
        java.lang.Object ref = tableName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          tableName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string table_name = 2;</code>
       * @param value The tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional string table_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearTableName() {
        tableName_ = getDefaultInstance().getTableName();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>optional string table_name = 2;</code>
       * @param value The bytes for tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object clientAddress_ = "";
      /**
       * <code>optional string client_address = 3;</code>
       * @return Whether the clientAddress field is set.
       */
      public boolean hasClientAddress() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional string client_address = 3;</code>
       * @return The clientAddress.
       */
      public java.lang.String getClientAddress() {
        java.lang.Object ref = clientAddress_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            clientAddress_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string client_address = 3;</code>
       * @return The bytes for clientAddress.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getClientAddressBytes() {
        java.lang.Object ref = clientAddress_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clientAddress_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string client_address = 3;</code>
       * @param value The clientAddress to set.
       * @return This builder for chaining.
       */
      public Builder setClientAddress(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        clientAddress_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional string client_address = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearClientAddress() {
        clientAddress_ = getDefaultInstance().getClientAddress();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <code>optional string client_address = 3;</code>
       * @param value The bytes for clientAddress to set.
       * @return This builder for chaining.
       */
      public Builder setClientAddressBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        clientAddress_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private java.lang.Object userName_ = "";
      /**
       * <code>optional string user_name = 4;</code>
       * @return Whether the userName field is set.
       */
      public boolean hasUserName() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional string user_name = 4;</code>
       * @return The userName.
       */
      public java.lang.String getUserName() {
        java.lang.Object ref = userName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            userName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user_name = 4;</code>
       * @return The bytes for userName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getUserNameBytes() {
        java.lang.Object ref = userName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          userName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user_name = 4;</code>
       * @param value The userName to set.
       * @return This builder for chaining.
       */
      public Builder setUserName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        userName_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user_name = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearUserName() {
        userName_ = getDefaultInstance().getUserName();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <code>optional string user_name = 4;</code>
       * @param value The bytes for userName to set.
       * @return This builder for chaining.
       */
      public Builder setUserNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        userName_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }

      private int limit_ = 10;
      /**
       * <code>optional uint32 limit = 5 [default = 10];</code>
       * @return Whether the limit field is set.
       */
      @java.lang.Override
      public boolean hasLimit() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional uint32 limit = 5 [default = 10];</code>
       * @return The limit.
       */
      @java.lang.Override
      public int getLimit() {
        return limit_;
      }
      /**
       * <code>optional uint32 limit = 5 [default = 10];</code>
       * @param value The limit to set.
       * @return This builder for chaining.
       */
      public Builder setLimit(int value) {

        limit_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 limit = 5 [default = 10];</code>
       * @return This builder for chaining.
       */
      public Builder clearLimit() {
        bitField0_ = (bitField0_ & ~0x00000010);
        limit_ = 10;
        onChanged();
        return this;
      }

      private int filterByOperator_ = 1;
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
       * @return Whether the filterByOperator field is set.
       */
      @java.lang.Override public boolean hasFilterByOperator() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
       * @return The filterByOperator.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator getFilterByOperator() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator.forNumber(filterByOperator_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator.OR : result;
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
       * @param value The filterByOperator to set.
       * @return This builder for chaining.
       */
      public Builder setFilterByOperator(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.FilterByOperator value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        filterByOperator_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.FilterByOperator filter_by_operator = 6 [default = OR];</code>
       * @return This builder for chaining.
       */
      public Builder clearFilterByOperator() {
        bitField0_ = (bitField0_ & ~0x00000020);
        filterByOperator_ = 1;
        onChanged();
        return this;
      }

      private int logType_ = 0;
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
       * @return Whether the logType field is set.
       */
      @java.lang.Override public boolean hasLogType() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
       * @return The logType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType getLogType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType result = org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType.forNumber(logType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType.SLOW_LOG : result;
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
       * @param value The logType to set.
       * @return This builder for chaining.
       */
      public Builder setLogType(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.LogType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000040;
        logType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.SlowLogResponseRequest.LogType log_type = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearLogType() {
        bitField0_ = (bitField0_ & ~0x00000040);
        logType_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SlowLogResponseRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SlowLogResponseRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponseRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SlowLogResponseRequest>() {
      @java.lang.Override
      public SlowLogResponseRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponseRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponseRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SlowLogResponsesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.SlowLogResponses)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> 
        getSlowLogPayloadsList();
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload getSlowLogPayloads(int index);
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    int getSlowLogPayloadsCount();
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder> 
        getSlowLogPayloadsOrBuilderList();
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder getSlowLogPayloadsOrBuilder(
        int index);
  }
  /**
   * <pre>
   **
   * Slow/Large log (LogEntry) use-case specific RPC response. This response payload will be
   * converted in bytes by servers and sent as response to generic RPC API: GetLogEntries
   * LogEntry message has two params:
   * 1. log_class_name: SlowLogResponses (for Slow/Large log use-case)
   * 2. log_message: SlowLogResponses converted in bytes (for Slow/Large log use-case)
   * </pre>
   *
   * Protobuf type {@code hbase.pb.SlowLogResponses}
   */
  @javax.annotation.Generated("proto") public static final class SlowLogResponses extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.SlowLogResponses)
      SlowLogResponsesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SlowLogResponses.newBuilder() to construct.
    private SlowLogResponses(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SlowLogResponses() {
      slowLogPayloads_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SlowLogResponses();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponses_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponses_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.Builder.class);
    }

    public static final int SLOW_LOG_PAYLOADS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> slowLogPayloads_;
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> getSlowLogPayloadsList() {
      return slowLogPayloads_;
    }
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder> 
        getSlowLogPayloadsOrBuilderList() {
      return slowLogPayloads_;
    }
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    @java.lang.Override
    public int getSlowLogPayloadsCount() {
      return slowLogPayloads_.size();
    }
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload getSlowLogPayloads(int index) {
      return slowLogPayloads_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder getSlowLogPayloadsOrBuilder(
        int index) {
      return slowLogPayloads_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getSlowLogPayloadsCount(); i++) {
        if (!getSlowLogPayloads(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < slowLogPayloads_.size(); i++) {
        output.writeMessage(1, slowLogPayloads_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < slowLogPayloads_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, slowLogPayloads_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses) obj;

      if (!getSlowLogPayloadsList()
          .equals(other.getSlowLogPayloadsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getSlowLogPayloadsCount() > 0) {
        hash = (37 * hash) + SLOW_LOG_PAYLOADS_FIELD_NUMBER;
        hash = (53 * hash) + getSlowLogPayloadsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Slow/Large log (LogEntry) use-case specific RPC response. This response payload will be
     * converted in bytes by servers and sent as response to generic RPC API: GetLogEntries
     * LogEntry message has two params:
     * 1. log_class_name: SlowLogResponses (for Slow/Large log use-case)
     * 2. log_message: SlowLogResponses converted in bytes (for Slow/Large log use-case)
     * </pre>
     *
     * Protobuf type {@code hbase.pb.SlowLogResponses}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.SlowLogResponses)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponsesOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponses_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponses_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (slowLogPayloadsBuilder_ == null) {
          slowLogPayloads_ = java.util.Collections.emptyList();
        } else {
          slowLogPayloads_ = null;
          slowLogPayloadsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_SlowLogResponses_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses result) {
        if (slowLogPayloadsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            slowLogPayloads_ = java.util.Collections.unmodifiableList(slowLogPayloads_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.slowLogPayloads_ = slowLogPayloads_;
        } else {
          result.slowLogPayloads_ = slowLogPayloadsBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses result) {
        int from_bitField0_ = bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance()) return this;
        if (slowLogPayloadsBuilder_ == null) {
          if (!other.slowLogPayloads_.isEmpty()) {
            if (slowLogPayloads_.isEmpty()) {
              slowLogPayloads_ = other.slowLogPayloads_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureSlowLogPayloadsIsMutable();
              slowLogPayloads_.addAll(other.slowLogPayloads_);
            }
            onChanged();
          }
        } else {
          if (!other.slowLogPayloads_.isEmpty()) {
            if (slowLogPayloadsBuilder_.isEmpty()) {
              slowLogPayloadsBuilder_.dispose();
              slowLogPayloadsBuilder_ = null;
              slowLogPayloads_ = other.slowLogPayloads_;
              bitField0_ = (bitField0_ & ~0x00000001);
              slowLogPayloadsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSlowLogPayloadsFieldBuilder() : null;
            } else {
              slowLogPayloadsBuilder_.addAllMessages(other.slowLogPayloads_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getSlowLogPayloadsCount(); i++) {
          if (!getSlowLogPayloads(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.PARSER,
                        extensionRegistry);
                if (slowLogPayloadsBuilder_ == null) {
                  ensureSlowLogPayloadsIsMutable();
                  slowLogPayloads_.add(m);
                } else {
                  slowLogPayloadsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> slowLogPayloads_ =
        java.util.Collections.emptyList();
      private void ensureSlowLogPayloadsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          slowLogPayloads_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload>(slowLogPayloads_);
          bitField0_ |= 0x00000001;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder> slowLogPayloadsBuilder_;

      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> getSlowLogPayloadsList() {
        if (slowLogPayloadsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(slowLogPayloads_);
        } else {
          return slowLogPayloadsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public int getSlowLogPayloadsCount() {
        if (slowLogPayloadsBuilder_ == null) {
          return slowLogPayloads_.size();
        } else {
          return slowLogPayloadsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload getSlowLogPayloads(int index) {
        if (slowLogPayloadsBuilder_ == null) {
          return slowLogPayloads_.get(index);
        } else {
          return slowLogPayloadsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder setSlowLogPayloads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload value) {
        if (slowLogPayloadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.set(index, value);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder setSlowLogPayloads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder builderForValue) {
        if (slowLogPayloadsBuilder_ == null) {
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.set(index, builderForValue.build());
          onChanged();
        } else {
          slowLogPayloadsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder addSlowLogPayloads(org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload value) {
        if (slowLogPayloadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.add(value);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder addSlowLogPayloads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload value) {
        if (slowLogPayloadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.add(index, value);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder addSlowLogPayloads(
          org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder builderForValue) {
        if (slowLogPayloadsBuilder_ == null) {
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.add(builderForValue.build());
          onChanged();
        } else {
          slowLogPayloadsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder addSlowLogPayloads(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder builderForValue) {
        if (slowLogPayloadsBuilder_ == null) {
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.add(index, builderForValue.build());
          onChanged();
        } else {
          slowLogPayloadsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder addAllSlowLogPayloads(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload> values) {
        if (slowLogPayloadsBuilder_ == null) {
          ensureSlowLogPayloadsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, slowLogPayloads_);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder clearSlowLogPayloads() {
        if (slowLogPayloadsBuilder_ == null) {
          slowLogPayloads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public Builder removeSlowLogPayloads(int index) {
        if (slowLogPayloadsBuilder_ == null) {
          ensureSlowLogPayloadsIsMutable();
          slowLogPayloads_.remove(index);
          onChanged();
        } else {
          slowLogPayloadsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder getSlowLogPayloadsBuilder(
          int index) {
        return getSlowLogPayloadsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder getSlowLogPayloadsOrBuilder(
          int index) {
        if (slowLogPayloadsBuilder_ == null) {
          return slowLogPayloads_.get(index);  } else {
          return slowLogPayloadsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder> 
           getSlowLogPayloadsOrBuilderList() {
        if (slowLogPayloadsBuilder_ != null) {
          return slowLogPayloadsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(slowLogPayloads_);
        }
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder addSlowLogPayloadsBuilder() {
        return getSlowLogPayloadsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder addSlowLogPayloadsBuilder(
          int index) {
        return getSlowLogPayloadsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.SlowLogPayload slow_log_payloads = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder> 
           getSlowLogPayloadsBuilderList() {
        return getSlowLogPayloadsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder> 
          getSlowLogPayloadsFieldBuilder() {
        if (slowLogPayloadsBuilder_ == null) {
          slowLogPayloadsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayload.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.SlowLogPayloadOrBuilder>(
                  slowLogPayloads_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          slowLogPayloads_ = null;
        }
        return slowLogPayloadsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.SlowLogResponses)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.SlowLogResponses)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponses>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<SlowLogResponses>() {
      @java.lang.Override
      public SlowLogResponses parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponses> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<SlowLogResponses> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearSlowLogResponseRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearSlowLogResponseRequest)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.ClearSlowLogResponseRequest}
   */
  @javax.annotation.Generated("proto") public static final class ClearSlowLogResponseRequest extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearSlowLogResponseRequest)
      ClearSlowLogResponseRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearSlowLogResponseRequest.newBuilder() to construct.
    private ClearSlowLogResponseRequest(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearSlowLogResponseRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearSlowLogResponseRequest();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponseRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearSlowLogResponseRequest}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearSlowLogResponseRequest)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequestOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponseRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearSlowLogResponseRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearSlowLogResponseRequest)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponseRequest>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearSlowLogResponseRequest>() {
      @java.lang.Override
      public ClearSlowLogResponseRequest parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponseRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponseRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ClearSlowLogResponsesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ClearSlowLogResponses)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bool is_cleaned = 1;</code>
     * @return Whether the isCleaned field is set.
     */
    boolean hasIsCleaned();
    /**
     * <code>required bool is_cleaned = 1;</code>
     * @return The isCleaned.
     */
    boolean getIsCleaned();
  }
  /**
   * Protobuf type {@code hbase.pb.ClearSlowLogResponses}
   */
  @javax.annotation.Generated("proto") public static final class ClearSlowLogResponses extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ClearSlowLogResponses)
      ClearSlowLogResponsesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ClearSlowLogResponses.newBuilder() to construct.
    private ClearSlowLogResponses(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ClearSlowLogResponses() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ClearSlowLogResponses();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponses_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponses_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.Builder.class);
    }

    private int bitField0_;
    public static final int IS_CLEANED_FIELD_NUMBER = 1;
    private boolean isCleaned_ = false;
    /**
     * <code>required bool is_cleaned = 1;</code>
     * @return Whether the isCleaned field is set.
     */
    @java.lang.Override
    public boolean hasIsCleaned() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bool is_cleaned = 1;</code>
     * @return The isCleaned.
     */
    @java.lang.Override
    public boolean getIsCleaned() {
      return isCleaned_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasIsCleaned()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, isCleaned_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isCleaned_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses other = (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses) obj;

      if (hasIsCleaned() != other.hasIsCleaned()) return false;
      if (hasIsCleaned()) {
        if (getIsCleaned()
            != other.getIsCleaned()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasIsCleaned()) {
        hash = (37 * hash) + IS_CLEANED_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getIsCleaned());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ClearSlowLogResponses}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ClearSlowLogResponses)
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponsesOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponses_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponses_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.class, org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        isCleaned_ = false;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.internal_static_hbase_pb_ClearSlowLogResponses_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses result = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.isCleaned_ = isCleaned_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance()) return this;
        if (other.hasIsCleaned()) {
          setIsCleaned(other.getIsCleaned());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasIsCleaned()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                isCleaned_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean isCleaned_ ;
      /**
       * <code>required bool is_cleaned = 1;</code>
       * @return Whether the isCleaned field is set.
       */
      @java.lang.Override
      public boolean hasIsCleaned() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bool is_cleaned = 1;</code>
       * @return The isCleaned.
       */
      @java.lang.Override
      public boolean getIsCleaned() {
        return isCleaned_;
      }
      /**
       * <code>required bool is_cleaned = 1;</code>
       * @param value The isCleaned to set.
       * @return This builder for chaining.
       */
      public Builder setIsCleaned(boolean value) {

        isCleaned_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bool is_cleaned = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsCleaned() {
        bitField0_ = (bitField0_ & ~0x00000001);
        isCleaned_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ClearSlowLogResponses)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ClearSlowLogResponses)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponses>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<ClearSlowLogResponses>() {
      @java.lang.Override
      public ClearSlowLogResponses parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponses> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<ClearSlowLogResponses> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  /**
   * Protobuf service {@code hbase.pb.AdminService}
   */
  public static abstract class AdminService
      implements org.apache.hbase.thirdparty.com.google.protobuf.Service {
    protected AdminService() {}

    public interface Interface {
      /**
       * <code>rpc GetRegionInfo(.hbase.pb.GetRegionInfoRequest) returns (.hbase.pb.GetRegionInfoResponse);</code>
       */
      public abstract void getRegionInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse> done);

      /**
       * <code>rpc GetStoreFile(.hbase.pb.GetStoreFileRequest) returns (.hbase.pb.GetStoreFileResponse);</code>
       */
      public abstract void getStoreFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse> done);

      /**
       * <code>rpc GetOnlineRegion(.hbase.pb.GetOnlineRegionRequest) returns (.hbase.pb.GetOnlineRegionResponse);</code>
       */
      public abstract void getOnlineRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse> done);

      /**
       * <code>rpc OpenRegion(.hbase.pb.OpenRegionRequest) returns (.hbase.pb.OpenRegionResponse);</code>
       */
      public abstract void openRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse> done);

      /**
       * <code>rpc WarmupRegion(.hbase.pb.WarmupRegionRequest) returns (.hbase.pb.WarmupRegionResponse);</code>
       */
      public abstract void warmupRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse> done);

      /**
       * <code>rpc CloseRegion(.hbase.pb.CloseRegionRequest) returns (.hbase.pb.CloseRegionResponse);</code>
       */
      public abstract void closeRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse> done);

      /**
       * <code>rpc FlushRegion(.hbase.pb.FlushRegionRequest) returns (.hbase.pb.FlushRegionResponse);</code>
       */
      public abstract void flushRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse> done);

      /**
       * <code>rpc CompactionSwitch(.hbase.pb.CompactionSwitchRequest) returns (.hbase.pb.CompactionSwitchResponse);</code>
       */
      public abstract void compactionSwitch(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse> done);

      /**
       * <code>rpc CompactRegion(.hbase.pb.CompactRegionRequest) returns (.hbase.pb.CompactRegionResponse);</code>
       */
      public abstract void compactRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse> done);

      /**
       * <code>rpc ReplicateWALEntry(.hbase.pb.ReplicateWALEntryRequest) returns (.hbase.pb.ReplicateWALEntryResponse);</code>
       */
      public abstract void replicateWALEntry(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done);

      /**
       * <code>rpc Replay(.hbase.pb.ReplicateWALEntryRequest) returns (.hbase.pb.ReplicateWALEntryResponse);</code>
       */
      public abstract void replay(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done);

      /**
       * <code>rpc RollWALWriter(.hbase.pb.RollWALWriterRequest) returns (.hbase.pb.RollWALWriterResponse);</code>
       */
      public abstract void rollWALWriter(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse> done);

      /**
       * <code>rpc GetServerInfo(.hbase.pb.GetServerInfoRequest) returns (.hbase.pb.GetServerInfoResponse);</code>
       */
      public abstract void getServerInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse> done);

      /**
       * <code>rpc StopServer(.hbase.pb.StopServerRequest) returns (.hbase.pb.StopServerResponse);</code>
       */
      public abstract void stopServer(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse> done);

      /**
       * <code>rpc UpdateFavoredNodes(.hbase.pb.UpdateFavoredNodesRequest) returns (.hbase.pb.UpdateFavoredNodesResponse);</code>
       */
      public abstract void updateFavoredNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse> done);

      /**
       * <code>rpc UpdateConfiguration(.hbase.pb.UpdateConfigurationRequest) returns (.hbase.pb.UpdateConfigurationResponse);</code>
       */
      public abstract void updateConfiguration(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse> done);

      /**
       * <code>rpc GetRegionLoad(.hbase.pb.GetRegionLoadRequest) returns (.hbase.pb.GetRegionLoadResponse);</code>
       */
      public abstract void getRegionLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse> done);

      /**
       * <code>rpc ClearCompactionQueues(.hbase.pb.ClearCompactionQueuesRequest) returns (.hbase.pb.ClearCompactionQueuesResponse);</code>
       */
      public abstract void clearCompactionQueues(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse> done);

      /**
       * <code>rpc ClearRegionBlockCache(.hbase.pb.ClearRegionBlockCacheRequest) returns (.hbase.pb.ClearRegionBlockCacheResponse);</code>
       */
      public abstract void clearRegionBlockCache(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse> done);

      /**
       * <pre>
       ** Fetches the RegionServer's view of space quotas 
       * </pre>
       *
       * <code>rpc GetSpaceQuotaSnapshots(.hbase.pb.GetSpaceQuotaSnapshotsRequest) returns (.hbase.pb.GetSpaceQuotaSnapshotsResponse);</code>
       */
      public abstract void getSpaceQuotaSnapshots(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse> done);

      /**
       * <code>rpc ExecuteProcedures(.hbase.pb.ExecuteProceduresRequest) returns (.hbase.pb.ExecuteProceduresResponse);</code>
       */
      public abstract void executeProcedures(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse> done);

      /**
       * <code>rpc GetSlowLogResponses(.hbase.pb.SlowLogResponseRequest) returns (.hbase.pb.SlowLogResponses);</code>
       */
      public abstract void getSlowLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done);

      /**
       * <code>rpc GetLargeLogResponses(.hbase.pb.SlowLogResponseRequest) returns (.hbase.pb.SlowLogResponses);</code>
       */
      public abstract void getLargeLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done);

      /**
       * <code>rpc ClearSlowLogsResponses(.hbase.pb.ClearSlowLogResponseRequest) returns (.hbase.pb.ClearSlowLogResponses);</code>
       */
      public abstract void clearSlowLogsResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses> done);

      /**
       * <code>rpc GetLogEntries(.hbase.pb.LogRequest) returns (.hbase.pb.LogEntry);</code>
       */
      public abstract void getLogEntries(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry> done);

    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new AdminService() {
        @java.lang.Override
        public  void getRegionInfo(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse> done) {
          impl.getRegionInfo(controller, request, done);
        }

        @java.lang.Override
        public  void getStoreFile(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse> done) {
          impl.getStoreFile(controller, request, done);
        }

        @java.lang.Override
        public  void getOnlineRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse> done) {
          impl.getOnlineRegion(controller, request, done);
        }

        @java.lang.Override
        public  void openRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse> done) {
          impl.openRegion(controller, request, done);
        }

        @java.lang.Override
        public  void warmupRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse> done) {
          impl.warmupRegion(controller, request, done);
        }

        @java.lang.Override
        public  void closeRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse> done) {
          impl.closeRegion(controller, request, done);
        }

        @java.lang.Override
        public  void flushRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse> done) {
          impl.flushRegion(controller, request, done);
        }

        @java.lang.Override
        public  void compactionSwitch(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse> done) {
          impl.compactionSwitch(controller, request, done);
        }

        @java.lang.Override
        public  void compactRegion(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse> done) {
          impl.compactRegion(controller, request, done);
        }

        @java.lang.Override
        public  void replicateWALEntry(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done) {
          impl.replicateWALEntry(controller, request, done);
        }

        @java.lang.Override
        public  void replay(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done) {
          impl.replay(controller, request, done);
        }

        @java.lang.Override
        public  void rollWALWriter(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse> done) {
          impl.rollWALWriter(controller, request, done);
        }

        @java.lang.Override
        public  void getServerInfo(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse> done) {
          impl.getServerInfo(controller, request, done);
        }

        @java.lang.Override
        public  void stopServer(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse> done) {
          impl.stopServer(controller, request, done);
        }

        @java.lang.Override
        public  void updateFavoredNodes(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse> done) {
          impl.updateFavoredNodes(controller, request, done);
        }

        @java.lang.Override
        public  void updateConfiguration(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse> done) {
          impl.updateConfiguration(controller, request, done);
        }

        @java.lang.Override
        public  void getRegionLoad(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse> done) {
          impl.getRegionLoad(controller, request, done);
        }

        @java.lang.Override
        public  void clearCompactionQueues(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse> done) {
          impl.clearCompactionQueues(controller, request, done);
        }

        @java.lang.Override
        public  void clearRegionBlockCache(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse> done) {
          impl.clearRegionBlockCache(controller, request, done);
        }

        @java.lang.Override
        public  void getSpaceQuotaSnapshots(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse> done) {
          impl.getSpaceQuotaSnapshots(controller, request, done);
        }

        @java.lang.Override
        public  void executeProcedures(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse> done) {
          impl.executeProcedures(controller, request, done);
        }

        @java.lang.Override
        public  void getSlowLogResponses(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done) {
          impl.getSlowLogResponses(controller, request, done);
        }

        @java.lang.Override
        public  void getLargeLogResponses(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done) {
          impl.getLargeLogResponses(controller, request, done);
        }

        @java.lang.Override
        public  void clearSlowLogsResponses(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses> done) {
          impl.clearSlowLogsResponses(controller, request, done);
        }

        @java.lang.Override
        public  void getLogEntries(
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry> done) {
          impl.getLogEntries(controller, request, done);
        }

      };
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new org.apache.hbase.thirdparty.com.google.protobuf.BlockingService() {
        public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message callBlockingMethod(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
            org.apache.hbase.thirdparty.com.google.protobuf.Message request)
            throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.getRegionInfo(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest)request);
            case 1:
              return impl.getStoreFile(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest)request);
            case 2:
              return impl.getOnlineRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest)request);
            case 3:
              return impl.openRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest)request);
            case 4:
              return impl.warmupRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest)request);
            case 5:
              return impl.closeRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest)request);
            case 6:
              return impl.flushRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest)request);
            case 7:
              return impl.compactionSwitch(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest)request);
            case 8:
              return impl.compactRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest)request);
            case 9:
              return impl.replicateWALEntry(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)request);
            case 10:
              return impl.replay(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)request);
            case 11:
              return impl.rollWALWriter(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest)request);
            case 12:
              return impl.getServerInfo(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest)request);
            case 13:
              return impl.stopServer(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest)request);
            case 14:
              return impl.updateFavoredNodes(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest)request);
            case 15:
              return impl.updateConfiguration(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest)request);
            case 16:
              return impl.getRegionLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest)request);
            case 17:
              return impl.clearCompactionQueues(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest)request);
            case 18:
              return impl.clearRegionBlockCache(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest)request);
            case 19:
              return impl.getSpaceQuotaSnapshots(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest)request);
            case 20:
              return impl.executeProcedures(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest)request);
            case 21:
              return impl.getSlowLogResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)request);
            case 22:
              return impl.getLargeLogResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)request);
            case 23:
              return impl.clearSlowLogsResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest)request);
            case 24:
              return impl.getLogEntries(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getRequestPrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.getDefaultInstance();
            case 9:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance();
            case 10:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance();
            case 11:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.getDefaultInstance();
            case 12:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.getDefaultInstance();
            case 13:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.getDefaultInstance();
            case 14:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.getDefaultInstance();
            case 15:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.getDefaultInstance();
            case 16:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.getDefaultInstance();
            case 17:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.getDefaultInstance();
            case 18:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.getDefaultInstance();
            case 19:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest.getDefaultInstance();
            case 20:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.getDefaultInstance();
            case 21:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance();
            case 22:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance();
            case 23:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.getDefaultInstance();
            case 24:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final org.apache.hbase.thirdparty.com.google.protobuf.Message
            getResponsePrototype(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance();
            case 9:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance();
            case 10:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance();
            case 11:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance();
            case 12:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance();
            case 13:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance();
            case 14:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance();
            case 15:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance();
            case 16:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance();
            case 17:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance();
            case 18:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance();
            case 19:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.getDefaultInstance();
            case 20:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance();
            case 21:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance();
            case 22:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance();
            case 23:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance();
            case 24:
              return org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

      };
    }

    /**
     * <code>rpc GetRegionInfo(.hbase.pb.GetRegionInfoRequest) returns (.hbase.pb.GetRegionInfoResponse);</code>
     */
    public abstract void getRegionInfo(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse> done);

    /**
     * <code>rpc GetStoreFile(.hbase.pb.GetStoreFileRequest) returns (.hbase.pb.GetStoreFileResponse);</code>
     */
    public abstract void getStoreFile(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse> done);

    /**
     * <code>rpc GetOnlineRegion(.hbase.pb.GetOnlineRegionRequest) returns (.hbase.pb.GetOnlineRegionResponse);</code>
     */
    public abstract void getOnlineRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse> done);

    /**
     * <code>rpc OpenRegion(.hbase.pb.OpenRegionRequest) returns (.hbase.pb.OpenRegionResponse);</code>
     */
    public abstract void openRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse> done);

    /**
     * <code>rpc WarmupRegion(.hbase.pb.WarmupRegionRequest) returns (.hbase.pb.WarmupRegionResponse);</code>
     */
    public abstract void warmupRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse> done);

    /**
     * <code>rpc CloseRegion(.hbase.pb.CloseRegionRequest) returns (.hbase.pb.CloseRegionResponse);</code>
     */
    public abstract void closeRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse> done);

    /**
     * <code>rpc FlushRegion(.hbase.pb.FlushRegionRequest) returns (.hbase.pb.FlushRegionResponse);</code>
     */
    public abstract void flushRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse> done);

    /**
     * <code>rpc CompactionSwitch(.hbase.pb.CompactionSwitchRequest) returns (.hbase.pb.CompactionSwitchResponse);</code>
     */
    public abstract void compactionSwitch(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse> done);

    /**
     * <code>rpc CompactRegion(.hbase.pb.CompactRegionRequest) returns (.hbase.pb.CompactRegionResponse);</code>
     */
    public abstract void compactRegion(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse> done);

    /**
     * <code>rpc ReplicateWALEntry(.hbase.pb.ReplicateWALEntryRequest) returns (.hbase.pb.ReplicateWALEntryResponse);</code>
     */
    public abstract void replicateWALEntry(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done);

    /**
     * <code>rpc Replay(.hbase.pb.ReplicateWALEntryRequest) returns (.hbase.pb.ReplicateWALEntryResponse);</code>
     */
    public abstract void replay(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done);

    /**
     * <code>rpc RollWALWriter(.hbase.pb.RollWALWriterRequest) returns (.hbase.pb.RollWALWriterResponse);</code>
     */
    public abstract void rollWALWriter(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse> done);

    /**
     * <code>rpc GetServerInfo(.hbase.pb.GetServerInfoRequest) returns (.hbase.pb.GetServerInfoResponse);</code>
     */
    public abstract void getServerInfo(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse> done);

    /**
     * <code>rpc StopServer(.hbase.pb.StopServerRequest) returns (.hbase.pb.StopServerResponse);</code>
     */
    public abstract void stopServer(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse> done);

    /**
     * <code>rpc UpdateFavoredNodes(.hbase.pb.UpdateFavoredNodesRequest) returns (.hbase.pb.UpdateFavoredNodesResponse);</code>
     */
    public abstract void updateFavoredNodes(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse> done);

    /**
     * <code>rpc UpdateConfiguration(.hbase.pb.UpdateConfigurationRequest) returns (.hbase.pb.UpdateConfigurationResponse);</code>
     */
    public abstract void updateConfiguration(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse> done);

    /**
     * <code>rpc GetRegionLoad(.hbase.pb.GetRegionLoadRequest) returns (.hbase.pb.GetRegionLoadResponse);</code>
     */
    public abstract void getRegionLoad(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse> done);

    /**
     * <code>rpc ClearCompactionQueues(.hbase.pb.ClearCompactionQueuesRequest) returns (.hbase.pb.ClearCompactionQueuesResponse);</code>
     */
    public abstract void clearCompactionQueues(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse> done);

    /**
     * <code>rpc ClearRegionBlockCache(.hbase.pb.ClearRegionBlockCacheRequest) returns (.hbase.pb.ClearRegionBlockCacheResponse);</code>
     */
    public abstract void clearRegionBlockCache(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse> done);

    /**
     * <pre>
     ** Fetches the RegionServer's view of space quotas 
     * </pre>
     *
     * <code>rpc GetSpaceQuotaSnapshots(.hbase.pb.GetSpaceQuotaSnapshotsRequest) returns (.hbase.pb.GetSpaceQuotaSnapshotsResponse);</code>
     */
    public abstract void getSpaceQuotaSnapshots(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse> done);

    /**
     * <code>rpc ExecuteProcedures(.hbase.pb.ExecuteProceduresRequest) returns (.hbase.pb.ExecuteProceduresResponse);</code>
     */
    public abstract void executeProcedures(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse> done);

    /**
     * <code>rpc GetSlowLogResponses(.hbase.pb.SlowLogResponseRequest) returns (.hbase.pb.SlowLogResponses);</code>
     */
    public abstract void getSlowLogResponses(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done);

    /**
     * <code>rpc GetLargeLogResponses(.hbase.pb.SlowLogResponseRequest) returns (.hbase.pb.SlowLogResponses);</code>
     */
    public abstract void getLargeLogResponses(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done);

    /**
     * <code>rpc ClearSlowLogsResponses(.hbase.pb.ClearSlowLogResponseRequest) returns (.hbase.pb.ClearSlowLogResponses);</code>
     */
    public abstract void clearSlowLogsResponses(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses> done);

    /**
     * <code>rpc GetLogEntries(.hbase.pb.LogRequest) returns (.hbase.pb.LogEntry);</code>
     */
    public abstract void getLogEntries(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry> done);

    public static final
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.getDescriptor().getServices().get(0);
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }

    public final void callMethod(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
        org.apache.hbase.thirdparty.com.google.protobuf.Message request,
        org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<
          org.apache.hbase.thirdparty.com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.getRegionInfo(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse>specializeCallback(
              done));
          return;
        case 1:
          this.getStoreFile(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse>specializeCallback(
              done));
          return;
        case 2:
          this.getOnlineRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse>specializeCallback(
              done));
          return;
        case 3:
          this.openRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse>specializeCallback(
              done));
          return;
        case 4:
          this.warmupRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse>specializeCallback(
              done));
          return;
        case 5:
          this.closeRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse>specializeCallback(
              done));
          return;
        case 6:
          this.flushRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse>specializeCallback(
              done));
          return;
        case 7:
          this.compactionSwitch(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse>specializeCallback(
              done));
          return;
        case 8:
          this.compactRegion(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse>specializeCallback(
              done));
          return;
        case 9:
          this.replicateWALEntry(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse>specializeCallback(
              done));
          return;
        case 10:
          this.replay(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse>specializeCallback(
              done));
          return;
        case 11:
          this.rollWALWriter(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse>specializeCallback(
              done));
          return;
        case 12:
          this.getServerInfo(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse>specializeCallback(
              done));
          return;
        case 13:
          this.stopServer(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse>specializeCallback(
              done));
          return;
        case 14:
          this.updateFavoredNodes(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse>specializeCallback(
              done));
          return;
        case 15:
          this.updateConfiguration(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse>specializeCallback(
              done));
          return;
        case 16:
          this.getRegionLoad(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse>specializeCallback(
              done));
          return;
        case 17:
          this.clearCompactionQueues(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse>specializeCallback(
              done));
          return;
        case 18:
          this.clearRegionBlockCache(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse>specializeCallback(
              done));
          return;
        case 19:
          this.getSpaceQuotaSnapshots(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse>specializeCallback(
              done));
          return;
        case 20:
          this.executeProcedures(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse>specializeCallback(
              done));
          return;
        case 21:
          this.getSlowLogResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses>specializeCallback(
              done));
          return;
        case 22:
          this.getLargeLogResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses>specializeCallback(
              done));
          return;
        case 23:
          this.clearSlowLogsResponses(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses>specializeCallback(
              done));
          return;
        case 24:
          this.getLogEntries(controller, (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest)request,
            org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getRequestPrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest.getDefaultInstance();
        case 9:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance();
        case 10:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest.getDefaultInstance();
        case 11:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest.getDefaultInstance();
        case 12:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest.getDefaultInstance();
        case 13:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest.getDefaultInstance();
        case 14:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest.getDefaultInstance();
        case 15:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest.getDefaultInstance();
        case 16:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest.getDefaultInstance();
        case 17:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest.getDefaultInstance();
        case 18:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest.getDefaultInstance();
        case 19:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest.getDefaultInstance();
        case 20:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest.getDefaultInstance();
        case 21:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance();
        case 22:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest.getDefaultInstance();
        case 23:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest.getDefaultInstance();
        case 24:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final org.apache.hbase.thirdparty.com.google.protobuf.Message
        getResponsePrototype(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance();
        case 9:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance();
        case 10:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance();
        case 11:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance();
        case 12:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance();
        case 13:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance();
        case 14:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance();
        case 15:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance();
        case 16:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance();
        case 17:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance();
        case 18:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance();
        case 19:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.getDefaultInstance();
        case 20:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance();
        case 21:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance();
        case 22:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance();
        case 23:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance();
        case 24:
          return org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public static Stub newStub(
        org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }

    @javax.annotation.Generated("proto") public static final class Stub extends org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.AdminService implements Interface {
      private Stub(org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel channel;

      public org.apache.hbase.thirdparty.com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }

      public  void getRegionInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance()));
      }

      public  void getStoreFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance()));
      }

      public  void getOnlineRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance()));
      }

      public  void openRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance()));
      }

      public  void warmupRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance()));
      }

      public  void closeRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance()));
      }

      public  void flushRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance()));
      }

      public  void compactionSwitch(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance()));
      }

      public  void compactRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance()));
      }

      public  void replicateWALEntry(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(9),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance()));
      }

      public  void replay(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(10),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance()));
      }

      public  void rollWALWriter(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(11),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance()));
      }

      public  void getServerInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(12),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance()));
      }

      public  void stopServer(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(13),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance()));
      }

      public  void updateFavoredNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(14),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance()));
      }

      public  void updateConfiguration(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(15),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance()));
      }

      public  void getRegionLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(16),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance()));
      }

      public  void clearCompactionQueues(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(17),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance()));
      }

      public  void clearRegionBlockCache(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(18),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance()));
      }

      public  void getSpaceQuotaSnapshots(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(19),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.getDefaultInstance()));
      }

      public  void executeProcedures(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(20),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance()));
      }

      public  void getSlowLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(21),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance()));
      }

      public  void getLargeLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(22),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance()));
      }

      public  void clearSlowLogsResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(23),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance()));
      }

      public  void getLogEntries(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request,
          org.apache.hbase.thirdparty.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(24),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.getDefaultInstance(),
          org.apache.hbase.thirdparty.com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.class,
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.getDefaultInstance()));
      }
    }

    public static BlockingInterface newBlockingStub(
        org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }

    public interface BlockingInterface {
      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse getRegionInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse getStoreFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse getOnlineRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse openRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse warmupRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse closeRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse flushRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse compactionSwitch(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse compactRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse replicateWALEntry(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse replay(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse rollWALWriter(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse getServerInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse stopServer(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse updateFavoredNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse updateConfiguration(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse getRegionLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse clearCompactionQueues(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse clearRegionBlockCache(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse getSpaceQuotaSnapshots(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse executeProcedures(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getSlowLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getLargeLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses clearSlowLogsResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry getLogEntries(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;
    }

    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }

      private final org.apache.hbase.thirdparty.com.google.protobuf.BlockingRpcChannel channel;

      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse getRegionInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionInfoResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse getStoreFile(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetStoreFileResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse getOnlineRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetOnlineRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse openRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.OpenRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse warmupRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.WarmupRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse closeRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CloseRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse flushRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.FlushRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse compactionSwitch(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactionSwitchResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse compactRegion(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.CompactRegionResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse replicateWALEntry(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(9),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse replay(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(10),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ReplicateWALEntryResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse rollWALWriter(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(11),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.RollWALWriterResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse getServerInfo(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(12),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetServerInfoResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse stopServer(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(13),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.StopServerResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse updateFavoredNodes(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(14),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateFavoredNodesResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse updateConfiguration(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(15),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.UpdateConfigurationResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse getRegionLoad(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(16),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.GetRegionLoadResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse clearCompactionQueues(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(17),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearCompactionQueuesResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse clearRegionBlockCache(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(18),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearRegionBlockCacheResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse getSpaceQuotaSnapshots(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(19),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.GetSpaceQuotaSnapshotsResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse executeProcedures(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(20),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ExecuteProceduresResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getSlowLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses) channel.callBlockingMethod(
          getDescriptor().getMethods().get(21),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses getLargeLogResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses) channel.callBlockingMethod(
          getDescriptor().getMethods().get(22),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.SlowLogResponses.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses clearSlowLogsResponses(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponseRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses) channel.callBlockingMethod(
          getDescriptor().getMethods().get(23),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.AdminProtos.ClearSlowLogResponses.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry getLogEntries(
          org.apache.hbase.thirdparty.com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogRequest request)
          throws org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry) channel.callBlockingMethod(
          getDescriptor().getMethods().get(24),
          controller,
          request,
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.LogEntry.getDefaultInstance());
      }

    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AdminService)
  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetRegionInfoRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetRegionInfoRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetRegionInfoResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetRegionInfoResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetStoreFileRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetStoreFileRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetStoreFileResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetStoreFileResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetOnlineRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetOnlineRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetOnlineRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetOnlineRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_OpenRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_OpenRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_OpenRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_OpenRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WarmupRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WarmupRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WarmupRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WarmupRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CloseRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CloseRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FlushRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FlushRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FlushRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FlushRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompactRegionRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompactRegionRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompactRegionResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompactRegionResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompactionSwitchRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompactionSwitchRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompactionSwitchResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompactionSwitchResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdateFavoredNodesRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdateFavoredNodesResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WALEntry_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WALEntry_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ReplicateWALEntryRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ReplicateWALEntryResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RollWALWriterRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RollWALWriterRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RollWALWriterResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RollWALWriterResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_StopServerRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_StopServerRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_StopServerResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_StopServerResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetServerInfoRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetServerInfoRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ServerInfo_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ServerInfo_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetServerInfoResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetServerInfoResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdateConfigurationRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdateConfigurationRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UpdateConfigurationResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_UpdateConfigurationResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetRegionLoadRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetRegionLoadRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetRegionLoadResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_GetRegionLoadResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearCompactionQueuesRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearCompactionQueuesResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearRegionBlockCacheRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearRegionBlockCacheResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RemoteProcedureRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RemoteProcedureRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ExecuteProceduresRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ExecuteProceduresRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ExecuteProceduresResponse_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ExecuteProceduresResponse_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SlowLogResponseRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SlowLogResponseRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_SlowLogResponses_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_SlowLogResponses_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearSlowLogResponseRequest_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ClearSlowLogResponses_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ClearSlowLogResponses_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\013Admin.proto\022\010hbase.pb\032\023ClusterStatus.p" +
      "roto\032\013HBase.proto\032\tWAL.proto\032\013Quota.prot" +
      "o\032\020TooSlowLog.proto\"s\n\024GetRegionInfoRequ" +
      "est\022)\n\006region\030\001 \002(\0132\031.hbase.pb.RegionSpe" +
      "cifier\022\030\n\020compaction_state\030\002 \001(\010\022\026\n\016best" +
      "_split_row\030\003 \001(\010\"\224\002\n\025GetRegionInfoRespon" +
      "se\022)\n\013region_info\030\001 \002(\0132\024.hbase.pb.Regio" +
      "nInfo\022I\n\020compaction_state\030\002 \001(\0162/.hbase." +
      "pb.GetRegionInfoResponse.CompactionState" +
      "\022\022\n\nsplittable\030\004 \001(\010\022\021\n\tmergeable\030\005 \001(\010\022" +
      "\026\n\016best_split_row\030\006 \001(\014\"F\n\017CompactionSta" +
      "te\022\010\n\004NONE\020\000\022\t\n\005MINOR\020\001\022\t\n\005MAJOR\020\002\022\023\n\017MA" +
      "JOR_AND_MINOR\020\003\"P\n\023GetStoreFileRequest\022)" +
      "\n\006region\030\001 \002(\0132\031.hbase.pb.RegionSpecifie" +
      "r\022\016\n\006family\030\002 \003(\014\"*\n\024GetStoreFileRespons" +
      "e\022\022\n\nstore_file\030\001 \003(\t\"\030\n\026GetOnlineRegion" +
      "Request\"D\n\027GetOnlineRegionResponse\022)\n\013re" +
      "gion_info\030\001 \003(\0132\024.hbase.pb.RegionInfo\"\317\002" +
      "\n\021OpenRegionRequest\022=\n\topen_info\030\001 \003(\0132*" +
      ".hbase.pb.OpenRegionRequest.RegionOpenIn" +
      "fo\022\027\n\017serverStartCode\030\002 \001(\004\022%\n\035initiatin" +
      "g_master_active_time\030\003 \001(\003\022\032\n\022master_sys" +
      "tem_time\030\005 \001(\004\032\236\001\n\016RegionOpenInfo\022$\n\006reg" +
      "ion\030\001 \002(\0132\024.hbase.pb.RegionInfo\022\037\n\027versi" +
      "on_of_offline_node\030\002 \001(\r\022+\n\rfavored_node" +
      "s\030\003 \003(\0132\024.hbase.pb.ServerName\022\030\n\014open_pr" +
      "oc_id\030\005 \001(\003:\002-1\"\246\001\n\022OpenRegionResponse\022F" +
      "\n\ropening_state\030\001 \003(\0162/.hbase.pb.OpenReg" +
      "ionResponse.RegionOpeningState\"H\n\022Region" +
      "OpeningState\022\n\n\006OPENED\020\000\022\022\n\016ALREADY_OPEN" +
      "ED\020\001\022\022\n\016FAILED_OPENING\020\002\"?\n\023WarmupRegion" +
      "Request\022(\n\nregionInfo\030\001 \002(\0132\024.hbase.pb.R" +
      "egionInfo\"\026\n\024WarmupRegionResponse\"\215\002\n\022Cl" +
      "oseRegionRequest\022)\n\006region\030\001 \002(\0132\031.hbase" +
      ".pb.RegionSpecifier\022\037\n\027version_of_closin" +
      "g_node\030\002 \001(\r\022\036\n\020transition_in_ZK\030\003 \001(\010:\004" +
      "true\0220\n\022destination_server\030\004 \001(\0132\024.hbase" +
      ".pb.ServerName\022\027\n\017serverStartCode\030\005 \001(\004\022" +
      "\031\n\rclose_proc_id\030\006 \001(\003:\002-1\022%\n\035initiating" +
      "_master_active_time\030\010 \001(\003\"%\n\023CloseRegion" +
      "Response\022\016\n\006closed\030\001 \002(\010\"\211\001\n\022FlushRegion" +
      "Request\022)\n\006region\030\001 \002(\0132\031.hbase.pb.Regio" +
      "nSpecifier\022\030\n\020if_older_than_ts\030\002 \001(\004\022\036\n\026" +
      "write_flush_wal_marker\030\003 \001(\010\022\016\n\006family\030\004" +
      " \001(\014\"_\n\023FlushRegionResponse\022\027\n\017last_flus" +
      "h_time\030\001 \002(\004\022\017\n\007flushed\030\002 \001(\010\022\036\n\026wrote_f" +
      "lush_wal_marker\030\003 \001(\010\"`\n\024CompactRegionRe" +
      "quest\022)\n\006region\030\001 \002(\0132\031.hbase.pb.RegionS" +
      "pecifier\022\r\n\005major\030\002 \001(\010\022\016\n\006family\030\003 \001(\014\"" +
      "\027\n\025CompactRegionResponse\"*\n\027CompactionSw" +
      "itchRequest\022\017\n\007enabled\030\001 \002(\010\".\n\030Compacti" +
      "onSwitchResponse\022\022\n\nprev_state\030\001 \002(\010\"\315\001\n" +
      "\031UpdateFavoredNodesRequest\022I\n\013update_inf" +
      "o\030\001 \003(\01324.hbase.pb.UpdateFavoredNodesReq" +
      "uest.RegionUpdateInfo\032e\n\020RegionUpdateInf" +
      "o\022$\n\006region\030\001 \002(\0132\024.hbase.pb.RegionInfo\022" +
      "+\n\rfavored_nodes\030\002 \003(\0132\024.hbase.pb.Server" +
      "Name\".\n\032UpdateFavoredNodesResponse\022\020\n\010re" +
      "sponse\030\001 \001(\r\"a\n\010WALEntry\022\035\n\003key\030\001 \002(\0132\020." +
      "hbase.pb.WALKey\022\027\n\017key_value_bytes\030\002 \003(\014" +
      "\022\035\n\025associated_cell_count\030\003 \001(\005\"\242\001\n\030Repl" +
      "icateWALEntryRequest\022!\n\005entry\030\001 \003(\0132\022.hb" +
      "ase.pb.WALEntry\022\034\n\024replicationClusterId\030" +
      "\002 \001(\t\022\"\n\032sourceBaseNamespaceDirPath\030\003 \001(" +
      "\t\022!\n\031sourceHFileArchiveDirPath\030\004 \001(\t\"\033\n\031" +
      "ReplicateWALEntryResponse\"\026\n\024RollWALWrit" +
      "erRequest\"0\n\025RollWALWriterResponse\022\027\n\017re" +
      "gion_to_flush\030\001 \003(\014\"#\n\021StopServerRequest" +
      "\022\016\n\006reason\030\001 \002(\t\"\024\n\022StopServerResponse\"\026" +
      "\n\024GetServerInfoRequest\"K\n\nServerInfo\022)\n\013" +
      "server_name\030\001 \002(\0132\024.hbase.pb.ServerName\022" +
      "\022\n\nwebui_port\030\002 \001(\r\"B\n\025GetServerInfoResp" +
      "onse\022)\n\013server_info\030\001 \002(\0132\024.hbase.pb.Ser" +
      "verInfo\"\034\n\032UpdateConfigurationRequest\"\035\n" +
      "\033UpdateConfigurationResponse\"?\n\024GetRegio" +
      "nLoadRequest\022\'\n\ntable_name\030\001 \001(\0132\023.hbase" +
      ".pb.TableName\"C\n\025GetRegionLoadResponse\022*" +
      "\n\014region_loads\030\001 \003(\0132\024.hbase.pb.RegionLo" +
      "ad\"2\n\034ClearCompactionQueuesRequest\022\022\n\nqu" +
      "eue_name\030\001 \003(\t\"\037\n\035ClearCompactionQueuesR" +
      "esponse\"I\n\034ClearRegionBlockCacheRequest\022" +
      ")\n\006region\030\001 \003(\0132\031.hbase.pb.RegionSpecifi" +
      "er\"L\n\035ClearRegionBlockCacheResponse\022+\n\005s" +
      "tats\030\001 \002(\0132\034.hbase.pb.CacheEvictionStats" +
      "\"w\n\026RemoteProcedureRequest\022\017\n\007proc_id\030\001 " +
      "\002(\004\022\022\n\nproc_class\030\002 \002(\t\022\021\n\tproc_data\030\003 \001" +
      "(\014\022%\n\035initiating_master_active_time\030\004 \001(" +
      "\003\"\260\001\n\030ExecuteProceduresRequest\0220\n\013open_r" +
      "egion\030\001 \003(\0132\033.hbase.pb.OpenRegionRequest" +
      "\0222\n\014close_region\030\002 \003(\0132\034.hbase.pb.CloseR" +
      "egionRequest\022.\n\004proc\030\003 \003(\0132 .hbase.pb.Re" +
      "moteProcedureRequest\"\033\n\031ExecuteProcedure" +
      "sResponse\"\333\002\n\026SlowLogResponseRequest\022\023\n\013" +
      "region_name\030\001 \001(\t\022\022\n\ntable_name\030\002 \001(\t\022\026\n" +
      "\016client_address\030\003 \001(\t\022\021\n\tuser_name\030\004 \001(\t" +
      "\022\021\n\005limit\030\005 \001(\r:\00210\022Q\n\022filter_by_operato" +
      "r\030\006 \001(\01621.hbase.pb.SlowLogResponseReques" +
      "t.FilterByOperator:\002OR\022:\n\010log_type\030\007 \001(\016" +
      "2(.hbase.pb.SlowLogResponseRequest.LogTy" +
      "pe\"#\n\020FilterByOperator\022\007\n\003AND\020\000\022\006\n\002OR\020\001\"" +
      "&\n\007LogType\022\014\n\010SLOW_LOG\020\000\022\r\n\tLARGE_LOG\020\001\"" +
      "G\n\020SlowLogResponses\0223\n\021slow_log_payloads" +
      "\030\001 \003(\0132\030.hbase.pb.SlowLogPayload\"\035\n\033Clea" +
      "rSlowLogResponseRequest\"+\n\025ClearSlowLogR" +
      "esponses\022\022\n\nis_cleaned\030\001 \002(\0102\200\021\n\014AdminSe" +
      "rvice\022P\n\rGetRegionInfo\022\036.hbase.pb.GetReg" +
      "ionInfoRequest\032\037.hbase.pb.GetRegionInfoR" +
      "esponse\022M\n\014GetStoreFile\022\035.hbase.pb.GetSt" +
      "oreFileRequest\032\036.hbase.pb.GetStoreFileRe" +
      "sponse\022V\n\017GetOnlineRegion\022 .hbase.pb.Get" +
      "OnlineRegionRequest\032!.hbase.pb.GetOnline" +
      "RegionResponse\022G\n\nOpenRegion\022\033.hbase.pb." +
      "OpenRegionRequest\032\034.hbase.pb.OpenRegionR" +
      "esponse\022M\n\014WarmupRegion\022\035.hbase.pb.Warmu" +
      "pRegionRequest\032\036.hbase.pb.WarmupRegionRe" +
      "sponse\022J\n\013CloseRegion\022\034.hbase.pb.CloseRe" +
      "gionRequest\032\035.hbase.pb.CloseRegionRespon" +
      "se\022J\n\013FlushRegion\022\034.hbase.pb.FlushRegion" +
      "Request\032\035.hbase.pb.FlushRegionResponse\022Y" +
      "\n\020CompactionSwitch\022!.hbase.pb.Compaction" +
      "SwitchRequest\032\".hbase.pb.CompactionSwitc" +
      "hResponse\022P\n\rCompactRegion\022\036.hbase.pb.Co" +
      "mpactRegionRequest\032\037.hbase.pb.CompactReg" +
      "ionResponse\022\\\n\021ReplicateWALEntry\022\".hbase" +
      ".pb.ReplicateWALEntryRequest\032#.hbase.pb." +
      "ReplicateWALEntryResponse\022Q\n\006Replay\022\".hb" +
      "ase.pb.ReplicateWALEntryRequest\032#.hbase." +
      "pb.ReplicateWALEntryResponse\022P\n\rRollWALW" +
      "riter\022\036.hbase.pb.RollWALWriterRequest\032\037." +
      "hbase.pb.RollWALWriterResponse\022P\n\rGetSer" +
      "verInfo\022\036.hbase.pb.GetServerInfoRequest\032" +
      "\037.hbase.pb.GetServerInfoResponse\022G\n\nStop" +
      "Server\022\033.hbase.pb.StopServerRequest\032\034.hb" +
      "ase.pb.StopServerResponse\022_\n\022UpdateFavor" +
      "edNodes\022#.hbase.pb.UpdateFavoredNodesReq" +
      "uest\032$.hbase.pb.UpdateFavoredNodesRespon" +
      "se\022b\n\023UpdateConfiguration\022$.hbase.pb.Upd" +
      "ateConfigurationRequest\032%.hbase.pb.Updat" +
      "eConfigurationResponse\022P\n\rGetRegionLoad\022" +
      "\036.hbase.pb.GetRegionLoadRequest\032\037.hbase." +
      "pb.GetRegionLoadResponse\022h\n\025ClearCompact" +
      "ionQueues\022&.hbase.pb.ClearCompactionQueu" +
      "esRequest\032\'.hbase.pb.ClearCompactionQueu" +
      "esResponse\022h\n\025ClearRegionBlockCache\022&.hb" +
      "ase.pb.ClearRegionBlockCacheRequest\032\'.hb" +
      "ase.pb.ClearRegionBlockCacheResponse\022k\n\026" +
      "GetSpaceQuotaSnapshots\022\'.hbase.pb.GetSpa" +
      "ceQuotaSnapshotsRequest\032(.hbase.pb.GetSp" +
      "aceQuotaSnapshotsResponse\022\\\n\021ExecuteProc" +
      "edures\022\".hbase.pb.ExecuteProceduresReque" +
      "st\032#.hbase.pb.ExecuteProceduresResponse\022" +
      "S\n\023GetSlowLogResponses\022 .hbase.pb.SlowLo" +
      "gResponseRequest\032\032.hbase.pb.SlowLogRespo" +
      "nses\022T\n\024GetLargeLogResponses\022 .hbase.pb." +
      "SlowLogResponseRequest\032\032.hbase.pb.SlowLo" +
      "gResponses\022`\n\026ClearSlowLogsResponses\022%.h" +
      "base.pb.ClearSlowLogResponseRequest\032\037.hb" +
      "ase.pb.ClearSlowLogResponses\0229\n\rGetLogEn" +
      "tries\022\024.hbase.pb.LogRequest\032\022.hbase.pb.L" +
      "ogEntryBH\n1org.apache.hadoop.hbase.shade" +
      "d.protobuf.generatedB\013AdminProtosH\001\210\001\001\240\001" +
      "\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.getDescriptor(),
          org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.getDescriptor(),
        });
    internal_static_hbase_pb_GetRegionInfoRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_GetRegionInfoRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetRegionInfoRequest_descriptor,
        new java.lang.String[] { "Region", "CompactionState", "BestSplitRow", });
    internal_static_hbase_pb_GetRegionInfoResponse_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_GetRegionInfoResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetRegionInfoResponse_descriptor,
        new java.lang.String[] { "RegionInfo", "CompactionState", "Splittable", "Mergeable", "BestSplitRow", });
    internal_static_hbase_pb_GetStoreFileRequest_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_GetStoreFileRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetStoreFileRequest_descriptor,
        new java.lang.String[] { "Region", "Family", });
    internal_static_hbase_pb_GetStoreFileResponse_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_GetStoreFileResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetStoreFileResponse_descriptor,
        new java.lang.String[] { "StoreFile", });
    internal_static_hbase_pb_GetOnlineRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_GetOnlineRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetOnlineRegionRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetOnlineRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_GetOnlineRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetOnlineRegionResponse_descriptor,
        new java.lang.String[] { "RegionInfo", });
    internal_static_hbase_pb_OpenRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_OpenRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_OpenRegionRequest_descriptor,
        new java.lang.String[] { "OpenInfo", "ServerStartCode", "InitiatingMasterActiveTime", "MasterSystemTime", });
    internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor =
      internal_static_hbase_pb_OpenRegionRequest_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_OpenRegionRequest_RegionOpenInfo_descriptor,
        new java.lang.String[] { "Region", "VersionOfOfflineNode", "FavoredNodes", "OpenProcId", });
    internal_static_hbase_pb_OpenRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_OpenRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_OpenRegionResponse_descriptor,
        new java.lang.String[] { "OpeningState", });
    internal_static_hbase_pb_WarmupRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_WarmupRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WarmupRegionRequest_descriptor,
        new java.lang.String[] { "RegionInfo", });
    internal_static_hbase_pb_WarmupRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_WarmupRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WarmupRegionResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_CloseRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_CloseRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseRegionRequest_descriptor,
        new java.lang.String[] { "Region", "VersionOfClosingNode", "TransitionInZK", "DestinationServer", "ServerStartCode", "CloseProcId", "InitiatingMasterActiveTime", });
    internal_static_hbase_pb_CloseRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_CloseRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CloseRegionResponse_descriptor,
        new java.lang.String[] { "Closed", });
    internal_static_hbase_pb_FlushRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_FlushRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FlushRegionRequest_descriptor,
        new java.lang.String[] { "Region", "IfOlderThanTs", "WriteFlushWalMarker", "Family", });
    internal_static_hbase_pb_FlushRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hbase_pb_FlushRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FlushRegionResponse_descriptor,
        new java.lang.String[] { "LastFlushTime", "Flushed", "WroteFlushWalMarker", });
    internal_static_hbase_pb_CompactRegionRequest_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hbase_pb_CompactRegionRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompactRegionRequest_descriptor,
        new java.lang.String[] { "Region", "Major", "Family", });
    internal_static_hbase_pb_CompactRegionResponse_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hbase_pb_CompactRegionResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompactRegionResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_CompactionSwitchRequest_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hbase_pb_CompactionSwitchRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompactionSwitchRequest_descriptor,
        new java.lang.String[] { "Enabled", });
    internal_static_hbase_pb_CompactionSwitchResponse_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hbase_pb_CompactionSwitchResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompactionSwitchResponse_descriptor,
        new java.lang.String[] { "PrevState", });
    internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hbase_pb_UpdateFavoredNodesRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor,
        new java.lang.String[] { "UpdateInfo", });
    internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor =
      internal_static_hbase_pb_UpdateFavoredNodesRequest_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdateFavoredNodesRequest_RegionUpdateInfo_descriptor,
        new java.lang.String[] { "Region", "FavoredNodes", });
    internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hbase_pb_UpdateFavoredNodesResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdateFavoredNodesResponse_descriptor,
        new java.lang.String[] { "Response", });
    internal_static_hbase_pb_WALEntry_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hbase_pb_WALEntry_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WALEntry_descriptor,
        new java.lang.String[] { "Key", "KeyValueBytes", "AssociatedCellCount", });
    internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hbase_pb_ReplicateWALEntryRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ReplicateWALEntryRequest_descriptor,
        new java.lang.String[] { "Entry", "ReplicationClusterId", "SourceBaseNamespaceDirPath", "SourceHFileArchiveDirPath", });
    internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hbase_pb_ReplicateWALEntryResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ReplicateWALEntryResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_RollWALWriterRequest_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hbase_pb_RollWALWriterRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RollWALWriterRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_RollWALWriterResponse_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hbase_pb_RollWALWriterResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RollWALWriterResponse_descriptor,
        new java.lang.String[] { "RegionToFlush", });
    internal_static_hbase_pb_StopServerRequest_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hbase_pb_StopServerRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_StopServerRequest_descriptor,
        new java.lang.String[] { "Reason", });
    internal_static_hbase_pb_StopServerResponse_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hbase_pb_StopServerResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_StopServerResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetServerInfoRequest_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hbase_pb_GetServerInfoRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetServerInfoRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_ServerInfo_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hbase_pb_ServerInfo_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ServerInfo_descriptor,
        new java.lang.String[] { "ServerName", "WebuiPort", });
    internal_static_hbase_pb_GetServerInfoResponse_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hbase_pb_GetServerInfoResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetServerInfoResponse_descriptor,
        new java.lang.String[] { "ServerInfo", });
    internal_static_hbase_pb_UpdateConfigurationRequest_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hbase_pb_UpdateConfigurationRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdateConfigurationRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_UpdateConfigurationResponse_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hbase_pb_UpdateConfigurationResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_UpdateConfigurationResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_GetRegionLoadRequest_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hbase_pb_GetRegionLoadRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetRegionLoadRequest_descriptor,
        new java.lang.String[] { "TableName", });
    internal_static_hbase_pb_GetRegionLoadResponse_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hbase_pb_GetRegionLoadResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_GetRegionLoadResponse_descriptor,
        new java.lang.String[] { "RegionLoads", });
    internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor =
      getDescriptor().getMessageTypes().get(34);
    internal_static_hbase_pb_ClearCompactionQueuesRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearCompactionQueuesRequest_descriptor,
        new java.lang.String[] { "QueueName", });
    internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor =
      getDescriptor().getMessageTypes().get(35);
    internal_static_hbase_pb_ClearCompactionQueuesResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearCompactionQueuesResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor =
      getDescriptor().getMessageTypes().get(36);
    internal_static_hbase_pb_ClearRegionBlockCacheRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearRegionBlockCacheRequest_descriptor,
        new java.lang.String[] { "Region", });
    internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor =
      getDescriptor().getMessageTypes().get(37);
    internal_static_hbase_pb_ClearRegionBlockCacheResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearRegionBlockCacheResponse_descriptor,
        new java.lang.String[] { "Stats", });
    internal_static_hbase_pb_RemoteProcedureRequest_descriptor =
      getDescriptor().getMessageTypes().get(38);
    internal_static_hbase_pb_RemoteProcedureRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RemoteProcedureRequest_descriptor,
        new java.lang.String[] { "ProcId", "ProcClass", "ProcData", "InitiatingMasterActiveTime", });
    internal_static_hbase_pb_ExecuteProceduresRequest_descriptor =
      getDescriptor().getMessageTypes().get(39);
    internal_static_hbase_pb_ExecuteProceduresRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ExecuteProceduresRequest_descriptor,
        new java.lang.String[] { "OpenRegion", "CloseRegion", "Proc", });
    internal_static_hbase_pb_ExecuteProceduresResponse_descriptor =
      getDescriptor().getMessageTypes().get(40);
    internal_static_hbase_pb_ExecuteProceduresResponse_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ExecuteProceduresResponse_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_SlowLogResponseRequest_descriptor =
      getDescriptor().getMessageTypes().get(41);
    internal_static_hbase_pb_SlowLogResponseRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SlowLogResponseRequest_descriptor,
        new java.lang.String[] { "RegionName", "TableName", "ClientAddress", "UserName", "Limit", "FilterByOperator", "LogType", });
    internal_static_hbase_pb_SlowLogResponses_descriptor =
      getDescriptor().getMessageTypes().get(42);
    internal_static_hbase_pb_SlowLogResponses_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_SlowLogResponses_descriptor,
        new java.lang.String[] { "SlowLogPayloads", });
    internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor =
      getDescriptor().getMessageTypes().get(43);
    internal_static_hbase_pb_ClearSlowLogResponseRequest_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearSlowLogResponseRequest_descriptor,
        new java.lang.String[] { });
    internal_static_hbase_pb_ClearSlowLogResponses_descriptor =
      getDescriptor().getMessageTypes().get(44);
    internal_static_hbase_pb_ClearSlowLogResponses_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ClearSlowLogResponses_descriptor,
        new java.lang.String[] { "IsCleaned", });
    org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.getDescriptor();
    org.apache.hadoop.hbase.shaded.protobuf.generated.TooSlowLog.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
