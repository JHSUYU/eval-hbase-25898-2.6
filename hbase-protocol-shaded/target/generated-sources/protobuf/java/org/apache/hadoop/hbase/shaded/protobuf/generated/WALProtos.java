// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: WAL.proto

package org.apache.hadoop.hbase.shaded.protobuf.generated;

@javax.annotation.Generated("proto") public final class WALProtos {
  private WALProtos() {}
  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.ScopeType}
   */
  public enum ScopeType
      implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REPLICATION_SCOPE_LOCAL = 0;</code>
     */
    REPLICATION_SCOPE_LOCAL(0),
    /**
     * <code>REPLICATION_SCOPE_GLOBAL = 1;</code>
     */
    REPLICATION_SCOPE_GLOBAL(1),
    /**
     * <code>REPLICATION_SCOPE_SERIAL = 2;</code>
     */
    REPLICATION_SCOPE_SERIAL(2),
    ;

    /**
     * <code>REPLICATION_SCOPE_LOCAL = 0;</code>
     */
    public static final int REPLICATION_SCOPE_LOCAL_VALUE = 0;
    /**
     * <code>REPLICATION_SCOPE_GLOBAL = 1;</code>
     */
    public static final int REPLICATION_SCOPE_GLOBAL_VALUE = 1;
    /**
     * <code>REPLICATION_SCOPE_SERIAL = 2;</code>
     */
    public static final int REPLICATION_SCOPE_SERIAL_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ScopeType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ScopeType forNumber(int value) {
      switch (value) {
        case 0: return REPLICATION_SCOPE_LOCAL;
        case 1: return REPLICATION_SCOPE_GLOBAL;
        case 2: return REPLICATION_SCOPE_SERIAL;
        default: return null;
      }
    }

    public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ScopeType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
        ScopeType> internalValueMap =
          new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<ScopeType>() {
            public ScopeType findValueByNumber(int number) {
              return ScopeType.forNumber(number);
            }
          };

    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final ScopeType[] VALUES = values();

    public static ScopeType valueOf(
        org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ScopeType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ScopeType)
  }

  public interface WALHeaderOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WALHeader)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bool has_compression = 1;</code>
     * @return Whether the hasCompression field is set.
     */
    boolean hasHasCompression();
    /**
     * <code>optional bool has_compression = 1;</code>
     * @return The hasCompression.
     */
    boolean getHasCompression();

    /**
     * <code>optional bytes encryption_key = 2;</code>
     * @return Whether the encryptionKey field is set.
     */
    boolean hasEncryptionKey();
    /**
     * <code>optional bytes encryption_key = 2;</code>
     * @return The encryptionKey.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncryptionKey();

    /**
     * <code>optional bool has_tag_compression = 3;</code>
     * @return Whether the hasTagCompression field is set.
     */
    boolean hasHasTagCompression();
    /**
     * <code>optional bool has_tag_compression = 3;</code>
     * @return The hasTagCompression.
     */
    boolean getHasTagCompression();

    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return Whether the writerClsName field is set.
     */
    boolean hasWriterClsName();
    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return The writerClsName.
     */
    java.lang.String getWriterClsName();
    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return The bytes for writerClsName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWriterClsNameBytes();

    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return Whether the cellCodecClsName field is set.
     */
    boolean hasCellCodecClsName();
    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return The cellCodecClsName.
     */
    java.lang.String getCellCodecClsName();
    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return The bytes for cellCodecClsName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCellCodecClsNameBytes();

    /**
     * <code>optional bool has_value_compression = 6;</code>
     * @return Whether the hasValueCompression field is set.
     */
    boolean hasHasValueCompression();
    /**
     * <code>optional bool has_value_compression = 6;</code>
     * @return The hasValueCompression.
     */
    boolean getHasValueCompression();

    /**
     * <code>optional uint32 value_compression_algorithm = 7;</code>
     * @return Whether the valueCompressionAlgorithm field is set.
     */
    boolean hasValueCompressionAlgorithm();
    /**
     * <code>optional uint32 value_compression_algorithm = 7;</code>
     * @return The valueCompressionAlgorithm.
     */
    int getValueCompressionAlgorithm();
  }
  /**
   * Protobuf type {@code hbase.pb.WALHeader}
   */
  @javax.annotation.Generated("proto") public static final class WALHeader extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WALHeader)
      WALHeaderOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WALHeader.newBuilder() to construct.
    private WALHeader(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WALHeader() {
      encryptionKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      writerClsName_ = "";
      cellCodecClsName_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WALHeader();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALHeader_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALHeader_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.Builder.class);
    }

    private int bitField0_;
    public static final int HAS_COMPRESSION_FIELD_NUMBER = 1;
    private boolean hasCompression_ = false;
    /**
     * <code>optional bool has_compression = 1;</code>
     * @return Whether the hasCompression field is set.
     */
    @java.lang.Override
    public boolean hasHasCompression() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bool has_compression = 1;</code>
     * @return The hasCompression.
     */
    @java.lang.Override
    public boolean getHasCompression() {
      return hasCompression_;
    }

    public static final int ENCRYPTION_KEY_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encryptionKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>optional bytes encryption_key = 2;</code>
     * @return Whether the encryptionKey field is set.
     */
    @java.lang.Override
    public boolean hasEncryptionKey() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes encryption_key = 2;</code>
     * @return The encryptionKey.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncryptionKey() {
      return encryptionKey_;
    }

    public static final int HAS_TAG_COMPRESSION_FIELD_NUMBER = 3;
    private boolean hasTagCompression_ = false;
    /**
     * <code>optional bool has_tag_compression = 3;</code>
     * @return Whether the hasTagCompression field is set.
     */
    @java.lang.Override
    public boolean hasHasTagCompression() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool has_tag_compression = 3;</code>
     * @return The hasTagCompression.
     */
    @java.lang.Override
    public boolean getHasTagCompression() {
      return hasTagCompression_;
    }

    public static final int WRITER_CLS_NAME_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object writerClsName_ = "";
    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return Whether the writerClsName field is set.
     */
    @java.lang.Override
    public boolean hasWriterClsName() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return The writerClsName.
     */
    @java.lang.Override
    public java.lang.String getWriterClsName() {
      java.lang.Object ref = writerClsName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          writerClsName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string writer_cls_name = 4;</code>
     * @return The bytes for writerClsName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getWriterClsNameBytes() {
      java.lang.Object ref = writerClsName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        writerClsName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CELL_CODEC_CLS_NAME_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private volatile java.lang.Object cellCodecClsName_ = "";
    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return Whether the cellCodecClsName field is set.
     */
    @java.lang.Override
    public boolean hasCellCodecClsName() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return The cellCodecClsName.
     */
    @java.lang.Override
    public java.lang.String getCellCodecClsName() {
      java.lang.Object ref = cellCodecClsName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          cellCodecClsName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string cell_codec_cls_name = 5;</code>
     * @return The bytes for cellCodecClsName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCellCodecClsNameBytes() {
      java.lang.Object ref = cellCodecClsName_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        cellCodecClsName_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HAS_VALUE_COMPRESSION_FIELD_NUMBER = 6;
    private boolean hasValueCompression_ = false;
    /**
     * <code>optional bool has_value_compression = 6;</code>
     * @return Whether the hasValueCompression field is set.
     */
    @java.lang.Override
    public boolean hasHasValueCompression() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional bool has_value_compression = 6;</code>
     * @return The hasValueCompression.
     */
    @java.lang.Override
    public boolean getHasValueCompression() {
      return hasValueCompression_;
    }

    public static final int VALUE_COMPRESSION_ALGORITHM_FIELD_NUMBER = 7;
    private int valueCompressionAlgorithm_ = 0;
    /**
     * <code>optional uint32 value_compression_algorithm = 7;</code>
     * @return Whether the valueCompressionAlgorithm field is set.
     */
    @java.lang.Override
    public boolean hasValueCompressionAlgorithm() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional uint32 value_compression_algorithm = 7;</code>
     * @return The valueCompressionAlgorithm.
     */
    @java.lang.Override
    public int getValueCompressionAlgorithm() {
      return valueCompressionAlgorithm_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, hasCompression_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, encryptionKey_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, hasTagCompression_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 4, writerClsName_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 5, cellCodecClsName_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBool(6, hasValueCompression_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeUInt32(7, valueCompressionAlgorithm_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, hasCompression_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, encryptionKey_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, hasTagCompression_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(4, writerClsName_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(5, cellCodecClsName_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, hasValueCompression_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, valueCompressionAlgorithm_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader) obj;

      if (hasHasCompression() != other.hasHasCompression()) return false;
      if (hasHasCompression()) {
        if (getHasCompression()
            != other.getHasCompression()) return false;
      }
      if (hasEncryptionKey() != other.hasEncryptionKey()) return false;
      if (hasEncryptionKey()) {
        if (!getEncryptionKey()
            .equals(other.getEncryptionKey())) return false;
      }
      if (hasHasTagCompression() != other.hasHasTagCompression()) return false;
      if (hasHasTagCompression()) {
        if (getHasTagCompression()
            != other.getHasTagCompression()) return false;
      }
      if (hasWriterClsName() != other.hasWriterClsName()) return false;
      if (hasWriterClsName()) {
        if (!getWriterClsName()
            .equals(other.getWriterClsName())) return false;
      }
      if (hasCellCodecClsName() != other.hasCellCodecClsName()) return false;
      if (hasCellCodecClsName()) {
        if (!getCellCodecClsName()
            .equals(other.getCellCodecClsName())) return false;
      }
      if (hasHasValueCompression() != other.hasHasValueCompression()) return false;
      if (hasHasValueCompression()) {
        if (getHasValueCompression()
            != other.getHasValueCompression()) return false;
      }
      if (hasValueCompressionAlgorithm() != other.hasValueCompressionAlgorithm()) return false;
      if (hasValueCompressionAlgorithm()) {
        if (getValueCompressionAlgorithm()
            != other.getValueCompressionAlgorithm()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasHasCompression()) {
        hash = (37 * hash) + HAS_COMPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getHasCompression());
      }
      if (hasEncryptionKey()) {
        hash = (37 * hash) + ENCRYPTION_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getEncryptionKey().hashCode();
      }
      if (hasHasTagCompression()) {
        hash = (37 * hash) + HAS_TAG_COMPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getHasTagCompression());
      }
      if (hasWriterClsName()) {
        hash = (37 * hash) + WRITER_CLS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getWriterClsName().hashCode();
      }
      if (hasCellCodecClsName()) {
        hash = (37 * hash) + CELL_CODEC_CLS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getCellCodecClsName().hashCode();
      }
      if (hasHasValueCompression()) {
        hash = (37 * hash) + HAS_VALUE_COMPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getHasValueCompression());
      }
      if (hasValueCompressionAlgorithm()) {
        hash = (37 * hash) + VALUE_COMPRESSION_ALGORITHM_FIELD_NUMBER;
        hash = (53 * hash) + getValueCompressionAlgorithm();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.WALHeader}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WALHeader)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeaderOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALHeader_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALHeader_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        hasCompression_ = false;
        encryptionKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        hasTagCompression_ = false;
        writerClsName_ = "";
        cellCodecClsName_ = "";
        hasValueCompression_ = false;
        valueCompressionAlgorithm_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALHeader_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.hasCompression_ = hasCompression_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.encryptionKey_ = encryptionKey_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.hasTagCompression_ = hasTagCompression_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.writerClsName_ = writerClsName_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.cellCodecClsName_ = cellCodecClsName_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.hasValueCompression_ = hasValueCompression_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.valueCompressionAlgorithm_ = valueCompressionAlgorithm_;
          to_bitField0_ |= 0x00000040;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader.getDefaultInstance()) return this;
        if (other.hasHasCompression()) {
          setHasCompression(other.getHasCompression());
        }
        if (other.hasEncryptionKey()) {
          setEncryptionKey(other.getEncryptionKey());
        }
        if (other.hasHasTagCompression()) {
          setHasTagCompression(other.getHasTagCompression());
        }
        if (other.hasWriterClsName()) {
          writerClsName_ = other.writerClsName_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        if (other.hasCellCodecClsName()) {
          cellCodecClsName_ = other.cellCodecClsName_;
          bitField0_ |= 0x00000010;
          onChanged();
        }
        if (other.hasHasValueCompression()) {
          setHasValueCompression(other.getHasValueCompression());
        }
        if (other.hasValueCompressionAlgorithm()) {
          setValueCompressionAlgorithm(other.getValueCompressionAlgorithm());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                hasCompression_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 18: {
                encryptionKey_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                hasTagCompression_ = input.readBool();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 34: {
                writerClsName_ = input.readBytes();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 42: {
                cellCodecClsName_ = input.readBytes();
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 48: {
                hasValueCompression_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              case 56: {
                valueCompressionAlgorithm_ = input.readUInt32();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean hasCompression_ ;
      /**
       * <code>optional bool has_compression = 1;</code>
       * @return Whether the hasCompression field is set.
       */
      @java.lang.Override
      public boolean hasHasCompression() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bool has_compression = 1;</code>
       * @return The hasCompression.
       */
      @java.lang.Override
      public boolean getHasCompression() {
        return hasCompression_;
      }
      /**
       * <code>optional bool has_compression = 1;</code>
       * @param value The hasCompression to set.
       * @return This builder for chaining.
       */
      public Builder setHasCompression(boolean value) {

        hasCompression_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool has_compression = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearHasCompression() {
        bitField0_ = (bitField0_ & ~0x00000001);
        hasCompression_ = false;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encryptionKey_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes encryption_key = 2;</code>
       * @return Whether the encryptionKey field is set.
       */
      @java.lang.Override
      public boolean hasEncryptionKey() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes encryption_key = 2;</code>
       * @return The encryptionKey.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncryptionKey() {
        return encryptionKey_;
      }
      /**
       * <code>optional bytes encryption_key = 2;</code>
       * @param value The encryptionKey to set.
       * @return This builder for chaining.
       */
      public Builder setEncryptionKey(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encryptionKey_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes encryption_key = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncryptionKey() {
        bitField0_ = (bitField0_ & ~0x00000002);
        encryptionKey_ = getDefaultInstance().getEncryptionKey();
        onChanged();
        return this;
      }

      private boolean hasTagCompression_ ;
      /**
       * <code>optional bool has_tag_compression = 3;</code>
       * @return Whether the hasTagCompression field is set.
       */
      @java.lang.Override
      public boolean hasHasTagCompression() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional bool has_tag_compression = 3;</code>
       * @return The hasTagCompression.
       */
      @java.lang.Override
      public boolean getHasTagCompression() {
        return hasTagCompression_;
      }
      /**
       * <code>optional bool has_tag_compression = 3;</code>
       * @param value The hasTagCompression to set.
       * @return This builder for chaining.
       */
      public Builder setHasTagCompression(boolean value) {

        hasTagCompression_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool has_tag_compression = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearHasTagCompression() {
        bitField0_ = (bitField0_ & ~0x00000004);
        hasTagCompression_ = false;
        onChanged();
        return this;
      }

      private java.lang.Object writerClsName_ = "";
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @return Whether the writerClsName field is set.
       */
      public boolean hasWriterClsName() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @return The writerClsName.
       */
      public java.lang.String getWriterClsName() {
        java.lang.Object ref = writerClsName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            writerClsName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @return The bytes for writerClsName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getWriterClsNameBytes() {
        java.lang.Object ref = writerClsName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          writerClsName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @param value The writerClsName to set.
       * @return This builder for chaining.
       */
      public Builder setWriterClsName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        writerClsName_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearWriterClsName() {
        writerClsName_ = getDefaultInstance().getWriterClsName();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <code>optional string writer_cls_name = 4;</code>
       * @param value The bytes for writerClsName to set.
       * @return This builder for chaining.
       */
      public Builder setWriterClsNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        writerClsName_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }

      private java.lang.Object cellCodecClsName_ = "";
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @return Whether the cellCodecClsName field is set.
       */
      public boolean hasCellCodecClsName() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @return The cellCodecClsName.
       */
      public java.lang.String getCellCodecClsName() {
        java.lang.Object ref = cellCodecClsName_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            cellCodecClsName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @return The bytes for cellCodecClsName.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getCellCodecClsNameBytes() {
        java.lang.Object ref = cellCodecClsName_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          cellCodecClsName_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @param value The cellCodecClsName to set.
       * @return This builder for chaining.
       */
      public Builder setCellCodecClsName(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        cellCodecClsName_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearCellCodecClsName() {
        cellCodecClsName_ = getDefaultInstance().getCellCodecClsName();
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <code>optional string cell_codec_cls_name = 5;</code>
       * @param value The bytes for cellCodecClsName to set.
       * @return This builder for chaining.
       */
      public Builder setCellCodecClsNameBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        cellCodecClsName_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }

      private boolean hasValueCompression_ ;
      /**
       * <code>optional bool has_value_compression = 6;</code>
       * @return Whether the hasValueCompression field is set.
       */
      @java.lang.Override
      public boolean hasHasValueCompression() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool has_value_compression = 6;</code>
       * @return The hasValueCompression.
       */
      @java.lang.Override
      public boolean getHasValueCompression() {
        return hasValueCompression_;
      }
      /**
       * <code>optional bool has_value_compression = 6;</code>
       * @param value The hasValueCompression to set.
       * @return This builder for chaining.
       */
      public Builder setHasValueCompression(boolean value) {

        hasValueCompression_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool has_value_compression = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearHasValueCompression() {
        bitField0_ = (bitField0_ & ~0x00000020);
        hasValueCompression_ = false;
        onChanged();
        return this;
      }

      private int valueCompressionAlgorithm_ ;
      /**
       * <code>optional uint32 value_compression_algorithm = 7;</code>
       * @return Whether the valueCompressionAlgorithm field is set.
       */
      @java.lang.Override
      public boolean hasValueCompressionAlgorithm() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional uint32 value_compression_algorithm = 7;</code>
       * @return The valueCompressionAlgorithm.
       */
      @java.lang.Override
      public int getValueCompressionAlgorithm() {
        return valueCompressionAlgorithm_;
      }
      /**
       * <code>optional uint32 value_compression_algorithm = 7;</code>
       * @param value The valueCompressionAlgorithm to set.
       * @return This builder for chaining.
       */
      public Builder setValueCompressionAlgorithm(int value) {

        valueCompressionAlgorithm_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 value_compression_algorithm = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearValueCompressionAlgorithm() {
        bitField0_ = (bitField0_ & ~0x00000040);
        valueCompressionAlgorithm_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WALHeader)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WALHeader)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALHeader>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WALHeader>() {
      @java.lang.Override
      public WALHeader parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALHeader> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALHeader> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALHeader getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WALKeyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WALKey)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes encoded_region_name = 1;</code>
     * @return Whether the encodedRegionName field is set.
     */
    boolean hasEncodedRegionName();
    /**
     * <code>required bytes encoded_region_name = 1;</code>
     * @return The encodedRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName();

    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName();

    /**
     * <code>required uint64 log_sequence_number = 3;</code>
     * @return Whether the logSequenceNumber field is set.
     */
    boolean hasLogSequenceNumber();
    /**
     * <code>required uint64 log_sequence_number = 3;</code>
     * @return The logSequenceNumber.
     */
    long getLogSequenceNumber();

    /**
     * <code>required uint64 write_time = 4;</code>
     * @return Whether the writeTime field is set.
     */
    boolean hasWriteTime();
    /**
     * <code>required uint64 write_time = 4;</code>
     * @return The writeTime.
     */
    long getWriteTime();

    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
     *     See WAL.proto;l=53
     * @return Whether the clusterId field is set.
     */
    @java.lang.Deprecated boolean hasClusterId();
    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
     *     See WAL.proto;l=53
     * @return The clusterId.
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterId();
    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     */
    @java.lang.Deprecated org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdOrBuilder();

    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> 
        getScopesList();
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getScopes(int index);
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    int getScopesCount();
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder> 
        getScopesOrBuilderList();
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder getScopesOrBuilder(
        int index);

    /**
     * <code>optional uint32 following_kv_count = 7;</code>
     * @return Whether the followingKvCount field is set.
     */
    boolean hasFollowingKvCount();
    /**
     * <code>optional uint32 following_kv_count = 7;</code>
     * @return The followingKvCount.
     */
    int getFollowingKvCount();

    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> 
        getClusterIdsList();
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterIds(int index);
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    int getClusterIdsCount();
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> 
        getClusterIdsOrBuilderList();
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdsOrBuilder(
        int index);

    /**
     * <code>optional uint64 nonceGroup = 9;</code>
     * @return Whether the nonceGroup field is set.
     */
    boolean hasNonceGroup();
    /**
     * <code>optional uint64 nonceGroup = 9;</code>
     * @return The nonceGroup.
     */
    long getNonceGroup();

    /**
     * <code>optional uint64 nonce = 10;</code>
     * @return Whether the nonce field is set.
     */
    boolean hasNonce();
    /**
     * <code>optional uint64 nonce = 10;</code>
     * @return The nonce.
     */
    long getNonce();

    /**
     * <code>optional uint64 orig_sequence_number = 11;</code>
     * @return Whether the origSequenceNumber field is set.
     */
    boolean hasOrigSequenceNumber();
    /**
     * <code>optional uint64 orig_sequence_number = 11;</code>
     * @return The origSequenceNumber.
     */
    long getOrigSequenceNumber();

    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> 
        getExtendedAttributesList();
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getExtendedAttributes(int index);
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    int getExtendedAttributesCount();
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder> 
        getExtendedAttributesOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder getExtendedAttributesOrBuilder(
        int index);
  }
  /**
   * <pre>
   *
   * Protocol buffer version of WALKey; see WALKey comment, not really a key but WALEdit header
   * for some KVs
   * </pre>
   *
   * Protobuf type {@code hbase.pb.WALKey}
   */
  @javax.annotation.Generated("proto") public static final class WALKey extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WALKey)
      WALKeyOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WALKey.newBuilder() to construct.
    private WALKey(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WALKey() {
      encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      scopes_ = java.util.Collections.emptyList();
      clusterIds_ = java.util.Collections.emptyList();
      extendedAttributes_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WALKey();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALKey_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALKey_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder.class);
    }

    private int bitField0_;
    public static final int ENCODED_REGION_NAME_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes encoded_region_name = 1;</code>
     * @return Whether the encodedRegionName field is set.
     */
    @java.lang.Override
    public boolean hasEncodedRegionName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes encoded_region_name = 1;</code>
     * @return The encodedRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
      return encodedRegionName_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
      return tableName_;
    }

    public static final int LOG_SEQUENCE_NUMBER_FIELD_NUMBER = 3;
    private long logSequenceNumber_ = 0L;
    /**
     * <code>required uint64 log_sequence_number = 3;</code>
     * @return Whether the logSequenceNumber field is set.
     */
    @java.lang.Override
    public boolean hasLogSequenceNumber() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required uint64 log_sequence_number = 3;</code>
     * @return The logSequenceNumber.
     */
    @java.lang.Override
    public long getLogSequenceNumber() {
      return logSequenceNumber_;
    }

    public static final int WRITE_TIME_FIELD_NUMBER = 4;
    private long writeTime_ = 0L;
    /**
     * <code>required uint64 write_time = 4;</code>
     * @return Whether the writeTime field is set.
     */
    @java.lang.Override
    public boolean hasWriteTime() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required uint64 write_time = 4;</code>
     * @return The writeTime.
     */
    @java.lang.Override
    public long getWriteTime() {
      return writeTime_;
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID clusterId_;
    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
     *     See WAL.proto;l=53
     * @return Whether the clusterId field is set.
     */
    @java.lang.Override
    @java.lang.Deprecated public boolean hasClusterId() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
     *     See WAL.proto;l=53
     * @return The clusterId.
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterId() {
      return clusterId_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance() : clusterId_;
    }
    /**
     * <pre>
     *
     *This parameter is deprecated in favor of clusters which
     *contains the list of clusters that have consumed the change.
     *It is retained so that the log created by earlier releases (0.94)
     *can be read by the newer releases.
     * </pre>
     *
     * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
     */
    @java.lang.Override
    @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdOrBuilder() {
      return clusterId_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance() : clusterId_;
    }

    public static final int SCOPES_FIELD_NUMBER = 6;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> scopes_;
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> getScopesList() {
      return scopes_;
    }
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder> 
        getScopesOrBuilderList() {
      return scopes_;
    }
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    @java.lang.Override
    public int getScopesCount() {
      return scopes_.size();
    }
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getScopes(int index) {
      return scopes_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder getScopesOrBuilder(
        int index) {
      return scopes_.get(index);
    }

    public static final int FOLLOWING_KV_COUNT_FIELD_NUMBER = 7;
    private int followingKvCount_ = 0;
    /**
     * <code>optional uint32 following_kv_count = 7;</code>
     * @return Whether the followingKvCount field is set.
     */
    @java.lang.Override
    public boolean hasFollowingKvCount() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional uint32 following_kv_count = 7;</code>
     * @return The followingKvCount.
     */
    @java.lang.Override
    public int getFollowingKvCount() {
      return followingKvCount_;
    }

    public static final int CLUSTER_IDS_FIELD_NUMBER = 8;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> clusterIds_;
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> getClusterIdsList() {
      return clusterIds_;
    }
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> 
        getClusterIdsOrBuilderList() {
      return clusterIds_;
    }
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    @java.lang.Override
    public int getClusterIdsCount() {
      return clusterIds_.size();
    }
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterIds(int index) {
      return clusterIds_.get(index);
    }
    /**
     * <pre>
     *
     *This field contains the list of clusters that have
     *consumed the change
     * </pre>
     *
     * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdsOrBuilder(
        int index) {
      return clusterIds_.get(index);
    }

    public static final int NONCEGROUP_FIELD_NUMBER = 9;
    private long nonceGroup_ = 0L;
    /**
     * <code>optional uint64 nonceGroup = 9;</code>
     * @return Whether the nonceGroup field is set.
     */
    @java.lang.Override
    public boolean hasNonceGroup() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional uint64 nonceGroup = 9;</code>
     * @return The nonceGroup.
     */
    @java.lang.Override
    public long getNonceGroup() {
      return nonceGroup_;
    }

    public static final int NONCE_FIELD_NUMBER = 10;
    private long nonce_ = 0L;
    /**
     * <code>optional uint64 nonce = 10;</code>
     * @return Whether the nonce field is set.
     */
    @java.lang.Override
    public boolean hasNonce() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <code>optional uint64 nonce = 10;</code>
     * @return The nonce.
     */
    @java.lang.Override
    public long getNonce() {
      return nonce_;
    }

    public static final int ORIG_SEQUENCE_NUMBER_FIELD_NUMBER = 11;
    private long origSequenceNumber_ = 0L;
    /**
     * <code>optional uint64 orig_sequence_number = 11;</code>
     * @return Whether the origSequenceNumber field is set.
     */
    @java.lang.Override
    public boolean hasOrigSequenceNumber() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <code>optional uint64 orig_sequence_number = 11;</code>
     * @return The origSequenceNumber.
     */
    @java.lang.Override
    public long getOrigSequenceNumber() {
      return origSequenceNumber_;
    }

    public static final int EXTENDED_ATTRIBUTES_FIELD_NUMBER = 12;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> extendedAttributes_;
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> getExtendedAttributesList() {
      return extendedAttributes_;
    }
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder> 
        getExtendedAttributesOrBuilderList() {
      return extendedAttributes_;
    }
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    @java.lang.Override
    public int getExtendedAttributesCount() {
      return extendedAttributes_.size();
    }
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getExtendedAttributes(int index) {
      return extendedAttributes_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder getExtendedAttributesOrBuilder(
        int index) {
      return extendedAttributes_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasEncodedRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasLogSequenceNumber()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasWriteTime()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasClusterId()) {
        if (!getClusterId().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getScopesCount(); i++) {
        if (!getScopes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getClusterIdsCount(); i++) {
        if (!getClusterIds(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getExtendedAttributesCount(); i++) {
        if (!getExtendedAttributes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(3, logSequenceNumber_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt64(4, writeTime_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(5, getClusterId());
      }
      for (int i = 0; i < scopes_.size(); i++) {
        output.writeMessage(6, scopes_.get(i));
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeUInt32(7, followingKvCount_);
      }
      for (int i = 0; i < clusterIds_.size(); i++) {
        output.writeMessage(8, clusterIds_.get(i));
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeUInt64(9, nonceGroup_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeUInt64(10, nonce_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeUInt64(11, origSequenceNumber_);
      }
      for (int i = 0; i < extendedAttributes_.size(); i++) {
        output.writeMessage(12, extendedAttributes_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, logSequenceNumber_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, writeTime_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getClusterId());
      }
      for (int i = 0; i < scopes_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, scopes_.get(i));
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, followingKvCount_);
      }
      for (int i = 0; i < clusterIds_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, clusterIds_.get(i));
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(9, nonceGroup_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, nonce_);
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(11, origSequenceNumber_);
      }
      for (int i = 0; i < extendedAttributes_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, extendedAttributes_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey) obj;

      if (hasEncodedRegionName() != other.hasEncodedRegionName()) return false;
      if (hasEncodedRegionName()) {
        if (!getEncodedRegionName()
            .equals(other.getEncodedRegionName())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasLogSequenceNumber() != other.hasLogSequenceNumber()) return false;
      if (hasLogSequenceNumber()) {
        if (getLogSequenceNumber()
            != other.getLogSequenceNumber()) return false;
      }
      if (hasWriteTime() != other.hasWriteTime()) return false;
      if (hasWriteTime()) {
        if (getWriteTime()
            != other.getWriteTime()) return false;
      }
      if (hasClusterId() != other.hasClusterId()) return false;
      if (hasClusterId()) {
        if (!getClusterId()
            .equals(other.getClusterId())) return false;
      }
      if (!getScopesList()
          .equals(other.getScopesList())) return false;
      if (hasFollowingKvCount() != other.hasFollowingKvCount()) return false;
      if (hasFollowingKvCount()) {
        if (getFollowingKvCount()
            != other.getFollowingKvCount()) return false;
      }
      if (!getClusterIdsList()
          .equals(other.getClusterIdsList())) return false;
      if (hasNonceGroup() != other.hasNonceGroup()) return false;
      if (hasNonceGroup()) {
        if (getNonceGroup()
            != other.getNonceGroup()) return false;
      }
      if (hasNonce() != other.hasNonce()) return false;
      if (hasNonce()) {
        if (getNonce()
            != other.getNonce()) return false;
      }
      if (hasOrigSequenceNumber() != other.hasOrigSequenceNumber()) return false;
      if (hasOrigSequenceNumber()) {
        if (getOrigSequenceNumber()
            != other.getOrigSequenceNumber()) return false;
      }
      if (!getExtendedAttributesList()
          .equals(other.getExtendedAttributesList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasEncodedRegionName()) {
        hash = (37 * hash) + ENCODED_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getEncodedRegionName().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasLogSequenceNumber()) {
        hash = (37 * hash) + LOG_SEQUENCE_NUMBER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getLogSequenceNumber());
      }
      if (hasWriteTime()) {
        hash = (37 * hash) + WRITE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getWriteTime());
      }
      if (hasClusterId()) {
        hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getClusterId().hashCode();
      }
      if (getScopesCount() > 0) {
        hash = (37 * hash) + SCOPES_FIELD_NUMBER;
        hash = (53 * hash) + getScopesList().hashCode();
      }
      if (hasFollowingKvCount()) {
        hash = (37 * hash) + FOLLOWING_KV_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getFollowingKvCount();
      }
      if (getClusterIdsCount() > 0) {
        hash = (37 * hash) + CLUSTER_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getClusterIdsList().hashCode();
      }
      if (hasNonceGroup()) {
        hash = (37 * hash) + NONCEGROUP_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNonceGroup());
      }
      if (hasNonce()) {
        hash = (37 * hash) + NONCE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getNonce());
      }
      if (hasOrigSequenceNumber()) {
        hash = (37 * hash) + ORIG_SEQUENCE_NUMBER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getOrigSequenceNumber());
      }
      if (getExtendedAttributesCount() > 0) {
        hash = (37 * hash) + EXTENDED_ATTRIBUTES_FIELD_NUMBER;
        hash = (53 * hash) + getExtendedAttributesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *
     * Protocol buffer version of WALKey; see WALKey comment, not really a key but WALEdit header
     * for some KVs
     * </pre>
     *
     * Protobuf type {@code hbase.pb.WALKey}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WALKey)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKeyOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALKey_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALKey_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getClusterIdFieldBuilder();
          getScopesFieldBuilder();
          getClusterIdsFieldBuilder();
          getExtendedAttributesFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        logSequenceNumber_ = 0L;
        writeTime_ = 0L;
        clusterId_ = null;
        if (clusterIdBuilder_ != null) {
          clusterIdBuilder_.dispose();
          clusterIdBuilder_ = null;
        }
        if (scopesBuilder_ == null) {
          scopes_ = java.util.Collections.emptyList();
        } else {
          scopes_ = null;
          scopesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        followingKvCount_ = 0;
        if (clusterIdsBuilder_ == null) {
          clusterIds_ = java.util.Collections.emptyList();
        } else {
          clusterIds_ = null;
          clusterIdsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        nonceGroup_ = 0L;
        nonce_ = 0L;
        origSequenceNumber_ = 0L;
        if (extendedAttributesBuilder_ == null) {
          extendedAttributes_ = java.util.Collections.emptyList();
        } else {
          extendedAttributes_ = null;
          extendedAttributesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALKey_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey result) {
        if (scopesBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0)) {
            scopes_ = java.util.Collections.unmodifiableList(scopes_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.scopes_ = scopes_;
        } else {
          result.scopes_ = scopesBuilder_.build();
        }
        if (clusterIdsBuilder_ == null) {
          if (((bitField0_ & 0x00000080) != 0)) {
            clusterIds_ = java.util.Collections.unmodifiableList(clusterIds_);
            bitField0_ = (bitField0_ & ~0x00000080);
          }
          result.clusterIds_ = clusterIds_;
        } else {
          result.clusterIds_ = clusterIdsBuilder_.build();
        }
        if (extendedAttributesBuilder_ == null) {
          if (((bitField0_ & 0x00000800) != 0)) {
            extendedAttributes_ = java.util.Collections.unmodifiableList(extendedAttributes_);
            bitField0_ = (bitField0_ & ~0x00000800);
          }
          result.extendedAttributes_ = extendedAttributes_;
        } else {
          result.extendedAttributes_ = extendedAttributesBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.encodedRegionName_ = encodedRegionName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.logSequenceNumber_ = logSequenceNumber_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.writeTime_ = writeTime_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.clusterId_ = clusterIdBuilder_ == null
              ? clusterId_
              : clusterIdBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.followingKvCount_ = followingKvCount_;
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.nonceGroup_ = nonceGroup_;
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.nonce_ = nonce_;
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.origSequenceNumber_ = origSequenceNumber_;
          to_bitField0_ |= 0x00000100;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey.getDefaultInstance()) return this;
        if (other.hasEncodedRegionName()) {
          setEncodedRegionName(other.getEncodedRegionName());
        }
        if (other.hasTableName()) {
          setTableName(other.getTableName());
        }
        if (other.hasLogSequenceNumber()) {
          setLogSequenceNumber(other.getLogSequenceNumber());
        }
        if (other.hasWriteTime()) {
          setWriteTime(other.getWriteTime());
        }
        if (other.hasClusterId()) {
          mergeClusterId(other.getClusterId());
        }
        if (scopesBuilder_ == null) {
          if (!other.scopes_.isEmpty()) {
            if (scopes_.isEmpty()) {
              scopes_ = other.scopes_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureScopesIsMutable();
              scopes_.addAll(other.scopes_);
            }
            onChanged();
          }
        } else {
          if (!other.scopes_.isEmpty()) {
            if (scopesBuilder_.isEmpty()) {
              scopesBuilder_.dispose();
              scopesBuilder_ = null;
              scopes_ = other.scopes_;
              bitField0_ = (bitField0_ & ~0x00000020);
              scopesBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getScopesFieldBuilder() : null;
            } else {
              scopesBuilder_.addAllMessages(other.scopes_);
            }
          }
        }
        if (other.hasFollowingKvCount()) {
          setFollowingKvCount(other.getFollowingKvCount());
        }
        if (clusterIdsBuilder_ == null) {
          if (!other.clusterIds_.isEmpty()) {
            if (clusterIds_.isEmpty()) {
              clusterIds_ = other.clusterIds_;
              bitField0_ = (bitField0_ & ~0x00000080);
            } else {
              ensureClusterIdsIsMutable();
              clusterIds_.addAll(other.clusterIds_);
            }
            onChanged();
          }
        } else {
          if (!other.clusterIds_.isEmpty()) {
            if (clusterIdsBuilder_.isEmpty()) {
              clusterIdsBuilder_.dispose();
              clusterIdsBuilder_ = null;
              clusterIds_ = other.clusterIds_;
              bitField0_ = (bitField0_ & ~0x00000080);
              clusterIdsBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getClusterIdsFieldBuilder() : null;
            } else {
              clusterIdsBuilder_.addAllMessages(other.clusterIds_);
            }
          }
        }
        if (other.hasNonceGroup()) {
          setNonceGroup(other.getNonceGroup());
        }
        if (other.hasNonce()) {
          setNonce(other.getNonce());
        }
        if (other.hasOrigSequenceNumber()) {
          setOrigSequenceNumber(other.getOrigSequenceNumber());
        }
        if (extendedAttributesBuilder_ == null) {
          if (!other.extendedAttributes_.isEmpty()) {
            if (extendedAttributes_.isEmpty()) {
              extendedAttributes_ = other.extendedAttributes_;
              bitField0_ = (bitField0_ & ~0x00000800);
            } else {
              ensureExtendedAttributesIsMutable();
              extendedAttributes_.addAll(other.extendedAttributes_);
            }
            onChanged();
          }
        } else {
          if (!other.extendedAttributes_.isEmpty()) {
            if (extendedAttributesBuilder_.isEmpty()) {
              extendedAttributesBuilder_.dispose();
              extendedAttributesBuilder_ = null;
              extendedAttributes_ = other.extendedAttributes_;
              bitField0_ = (bitField0_ & ~0x00000800);
              extendedAttributesBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getExtendedAttributesFieldBuilder() : null;
            } else {
              extendedAttributesBuilder_.addAllMessages(other.extendedAttributes_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasEncodedRegionName()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasLogSequenceNumber()) {
          return false;
        }
        if (!hasWriteTime()) {
          return false;
        }
        if (hasClusterId()) {
          if (!getClusterId().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getScopesCount(); i++) {
          if (!getScopes(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getClusterIdsCount(); i++) {
          if (!getClusterIds(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getExtendedAttributesCount(); i++) {
          if (!getExtendedAttributes(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                encodedRegionName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                tableName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                logSequenceNumber_ = input.readUInt64();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              case 32: {
                writeTime_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                input.readMessage(
                    getClusterIdFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000010;
                break;
              } // case 42
              case 50: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.PARSER,
                        extensionRegistry);
                if (scopesBuilder_ == null) {
                  ensureScopesIsMutable();
                  scopes_.add(m);
                } else {
                  scopesBuilder_.addMessage(m);
                }
                break;
              } // case 50
              case 56: {
                followingKvCount_ = input.readUInt32();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              case 66: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.PARSER,
                        extensionRegistry);
                if (clusterIdsBuilder_ == null) {
                  ensureClusterIdsIsMutable();
                  clusterIds_.add(m);
                } else {
                  clusterIdsBuilder_.addMessage(m);
                }
                break;
              } // case 66
              case 72: {
                nonceGroup_ = input.readUInt64();
                bitField0_ |= 0x00000100;
                break;
              } // case 72
              case 80: {
                nonce_ = input.readUInt64();
                bitField0_ |= 0x00000200;
                break;
              } // case 80
              case 88: {
                origSequenceNumber_ = input.readUInt64();
                bitField0_ |= 0x00000400;
                break;
              } // case 88
              case 98: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.PARSER,
                        extensionRegistry);
                if (extendedAttributesBuilder_ == null) {
                  ensureExtendedAttributesIsMutable();
                  extendedAttributes_.add(m);
                } else {
                  extendedAttributesBuilder_.addMessage(m);
                }
                break;
              } // case 98
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes encoded_region_name = 1;</code>
       * @return Whether the encodedRegionName field is set.
       */
      @java.lang.Override
      public boolean hasEncodedRegionName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes encoded_region_name = 1;</code>
       * @return The encodedRegionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
        return encodedRegionName_;
      }
      /**
       * <code>required bytes encoded_region_name = 1;</code>
       * @param value The encodedRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setEncodedRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encodedRegionName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes encoded_region_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncodedRegionName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        encodedRegionName_ = getDefaultInstance().getEncodedRegionName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      @java.lang.Override
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return The tableName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
        return tableName_;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @param value The tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = getDefaultInstance().getTableName();
        onChanged();
        return this;
      }

      private long logSequenceNumber_ ;
      /**
       * <code>required uint64 log_sequence_number = 3;</code>
       * @return Whether the logSequenceNumber field is set.
       */
      @java.lang.Override
      public boolean hasLogSequenceNumber() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required uint64 log_sequence_number = 3;</code>
       * @return The logSequenceNumber.
       */
      @java.lang.Override
      public long getLogSequenceNumber() {
        return logSequenceNumber_;
      }
      /**
       * <code>required uint64 log_sequence_number = 3;</code>
       * @param value The logSequenceNumber to set.
       * @return This builder for chaining.
       */
      public Builder setLogSequenceNumber(long value) {

        logSequenceNumber_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required uint64 log_sequence_number = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearLogSequenceNumber() {
        bitField0_ = (bitField0_ & ~0x00000004);
        logSequenceNumber_ = 0L;
        onChanged();
        return this;
      }

      private long writeTime_ ;
      /**
       * <code>required uint64 write_time = 4;</code>
       * @return Whether the writeTime field is set.
       */
      @java.lang.Override
      public boolean hasWriteTime() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required uint64 write_time = 4;</code>
       * @return The writeTime.
       */
      @java.lang.Override
      public long getWriteTime() {
        return writeTime_;
      }
      /**
       * <code>required uint64 write_time = 4;</code>
       * @param value The writeTime to set.
       * @return This builder for chaining.
       */
      public Builder setWriteTime(long value) {

        writeTime_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required uint64 write_time = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearWriteTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        writeTime_ = 0L;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID clusterId_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> clusterIdBuilder_;
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
       *     See WAL.proto;l=53
       * @return Whether the clusterId field is set.
       */
      @java.lang.Deprecated public boolean hasClusterId() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       * @deprecated hbase.pb.WALKey.cluster_id is deprecated.
       *     See WAL.proto;l=53
       * @return The clusterId.
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterId() {
        if (clusterIdBuilder_ == null) {
          return clusterId_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance() : clusterId_;
        } else {
          return clusterIdBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setClusterId(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID value) {
        if (clusterIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clusterId_ = value;
        } else {
          clusterIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder setClusterId(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder builderForValue) {
        if (clusterIdBuilder_ == null) {
          clusterId_ = builderForValue.build();
        } else {
          clusterIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder mergeClusterId(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID value) {
        if (clusterIdBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
            clusterId_ != null &&
            clusterId_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance()) {
            getClusterIdBuilder().mergeFrom(value);
          } else {
            clusterId_ = value;
          }
        } else {
          clusterIdBuilder_.mergeFrom(value);
        }
        if (clusterId_ != null) {
          bitField0_ |= 0x00000010;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public Builder clearClusterId() {
        bitField0_ = (bitField0_ & ~0x00000010);
        clusterId_ = null;
        if (clusterIdBuilder_ != null) {
          clusterIdBuilder_.dispose();
          clusterIdBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder getClusterIdBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getClusterIdFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      @java.lang.Deprecated public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdOrBuilder() {
        if (clusterIdBuilder_ != null) {
          return clusterIdBuilder_.getMessageOrBuilder();
        } else {
          return clusterId_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance() : clusterId_;
        }
      }
      /**
       * <pre>
       *
       *This parameter is deprecated in favor of clusters which
       *contains the list of clusters that have consumed the change.
       *It is retained so that the log created by earlier releases (0.94)
       *can be read by the newer releases.
       * </pre>
       *
       * <code>optional .hbase.pb.UUID cluster_id = 5 [deprecated = true];</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> 
          getClusterIdFieldBuilder() {
        if (clusterIdBuilder_ == null) {
          clusterIdBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder>(
                  getClusterId(),
                  getParentForChildren(),
                  isClean());
          clusterId_ = null;
        }
        return clusterIdBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> scopes_ =
        java.util.Collections.emptyList();
      private void ensureScopesIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          scopes_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope>(scopes_);
          bitField0_ |= 0x00000020;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder> scopesBuilder_;

      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> getScopesList() {
        if (scopesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(scopes_);
        } else {
          return scopesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public int getScopesCount() {
        if (scopesBuilder_ == null) {
          return scopes_.size();
        } else {
          return scopesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getScopes(int index) {
        if (scopesBuilder_ == null) {
          return scopes_.get(index);
        } else {
          return scopesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder setScopes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope value) {
        if (scopesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureScopesIsMutable();
          scopes_.set(index, value);
          onChanged();
        } else {
          scopesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder setScopes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder builderForValue) {
        if (scopesBuilder_ == null) {
          ensureScopesIsMutable();
          scopes_.set(index, builderForValue.build());
          onChanged();
        } else {
          scopesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder addScopes(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope value) {
        if (scopesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureScopesIsMutable();
          scopes_.add(value);
          onChanged();
        } else {
          scopesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder addScopes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope value) {
        if (scopesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureScopesIsMutable();
          scopes_.add(index, value);
          onChanged();
        } else {
          scopesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder addScopes(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder builderForValue) {
        if (scopesBuilder_ == null) {
          ensureScopesIsMutable();
          scopes_.add(builderForValue.build());
          onChanged();
        } else {
          scopesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder addScopes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder builderForValue) {
        if (scopesBuilder_ == null) {
          ensureScopesIsMutable();
          scopes_.add(index, builderForValue.build());
          onChanged();
        } else {
          scopesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder addAllScopes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope> values) {
        if (scopesBuilder_ == null) {
          ensureScopesIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, scopes_);
          onChanged();
        } else {
          scopesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder clearScopes() {
        if (scopesBuilder_ == null) {
          scopes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          scopesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public Builder removeScopes(int index) {
        if (scopesBuilder_ == null) {
          ensureScopesIsMutable();
          scopes_.remove(index);
          onChanged();
        } else {
          scopesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder getScopesBuilder(
          int index) {
        return getScopesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder getScopesOrBuilder(
          int index) {
        if (scopesBuilder_ == null) {
          return scopes_.get(index);  } else {
          return scopesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder> 
           getScopesOrBuilderList() {
        if (scopesBuilder_ != null) {
          return scopesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(scopes_);
        }
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder addScopesBuilder() {
        return getScopesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder addScopesBuilder(
          int index) {
        return getScopesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.FamilyScope scopes = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder> 
           getScopesBuilderList() {
        return getScopesFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder> 
          getScopesFieldBuilder() {
        if (scopesBuilder_ == null) {
          scopesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder>(
                  scopes_,
                  ((bitField0_ & 0x00000020) != 0),
                  getParentForChildren(),
                  isClean());
          scopes_ = null;
        }
        return scopesBuilder_;
      }

      private int followingKvCount_ ;
      /**
       * <code>optional uint32 following_kv_count = 7;</code>
       * @return Whether the followingKvCount field is set.
       */
      @java.lang.Override
      public boolean hasFollowingKvCount() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional uint32 following_kv_count = 7;</code>
       * @return The followingKvCount.
       */
      @java.lang.Override
      public int getFollowingKvCount() {
        return followingKvCount_;
      }
      /**
       * <code>optional uint32 following_kv_count = 7;</code>
       * @param value The followingKvCount to set.
       * @return This builder for chaining.
       */
      public Builder setFollowingKvCount(int value) {

        followingKvCount_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 following_kv_count = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearFollowingKvCount() {
        bitField0_ = (bitField0_ & ~0x00000040);
        followingKvCount_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> clusterIds_ =
        java.util.Collections.emptyList();
      private void ensureClusterIdsIsMutable() {
        if (!((bitField0_ & 0x00000080) != 0)) {
          clusterIds_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID>(clusterIds_);
          bitField0_ |= 0x00000080;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> clusterIdsBuilder_;

      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> getClusterIdsList() {
        if (clusterIdsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(clusterIds_);
        } else {
          return clusterIdsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public int getClusterIdsCount() {
        if (clusterIdsBuilder_ == null) {
          return clusterIds_.size();
        } else {
          return clusterIdsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID getClusterIds(int index) {
        if (clusterIdsBuilder_ == null) {
          return clusterIds_.get(index);
        } else {
          return clusterIdsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder setClusterIds(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID value) {
        if (clusterIdsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureClusterIdsIsMutable();
          clusterIds_.set(index, value);
          onChanged();
        } else {
          clusterIdsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder setClusterIds(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder builderForValue) {
        if (clusterIdsBuilder_ == null) {
          ensureClusterIdsIsMutable();
          clusterIds_.set(index, builderForValue.build());
          onChanged();
        } else {
          clusterIdsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder addClusterIds(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID value) {
        if (clusterIdsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureClusterIdsIsMutable();
          clusterIds_.add(value);
          onChanged();
        } else {
          clusterIdsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder addClusterIds(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID value) {
        if (clusterIdsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureClusterIdsIsMutable();
          clusterIds_.add(index, value);
          onChanged();
        } else {
          clusterIdsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder addClusterIds(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder builderForValue) {
        if (clusterIdsBuilder_ == null) {
          ensureClusterIdsIsMutable();
          clusterIds_.add(builderForValue.build());
          onChanged();
        } else {
          clusterIdsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder addClusterIds(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder builderForValue) {
        if (clusterIdsBuilder_ == null) {
          ensureClusterIdsIsMutable();
          clusterIds_.add(index, builderForValue.build());
          onChanged();
        } else {
          clusterIdsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder addAllClusterIds(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID> values) {
        if (clusterIdsBuilder_ == null) {
          ensureClusterIdsIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, clusterIds_);
          onChanged();
        } else {
          clusterIdsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder clearClusterIds() {
        if (clusterIdsBuilder_ == null) {
          clusterIds_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
          onChanged();
        } else {
          clusterIdsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public Builder removeClusterIds(int index) {
        if (clusterIdsBuilder_ == null) {
          ensureClusterIdsIsMutable();
          clusterIds_.remove(index);
          onChanged();
        } else {
          clusterIdsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder getClusterIdsBuilder(
          int index) {
        return getClusterIdsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder getClusterIdsOrBuilder(
          int index) {
        if (clusterIdsBuilder_ == null) {
          return clusterIds_.get(index);  } else {
          return clusterIdsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> 
           getClusterIdsOrBuilderList() {
        if (clusterIdsBuilder_ != null) {
          return clusterIdsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(clusterIds_);
        }
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder addClusterIdsBuilder() {
        return getClusterIdsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance());
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder addClusterIdsBuilder(
          int index) {
        return getClusterIdsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.getDefaultInstance());
      }
      /**
       * <pre>
       *
       *This field contains the list of clusters that have
       *consumed the change
       * </pre>
       *
       * <code>repeated .hbase.pb.UUID cluster_ids = 8;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder> 
           getClusterIdsBuilderList() {
        return getClusterIdsFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder> 
          getClusterIdsFieldBuilder() {
        if (clusterIdsBuilder_ == null) {
          clusterIdsBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUID.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.UUIDOrBuilder>(
                  clusterIds_,
                  ((bitField0_ & 0x00000080) != 0),
                  getParentForChildren(),
                  isClean());
          clusterIds_ = null;
        }
        return clusterIdsBuilder_;
      }

      private long nonceGroup_ ;
      /**
       * <code>optional uint64 nonceGroup = 9;</code>
       * @return Whether the nonceGroup field is set.
       */
      @java.lang.Override
      public boolean hasNonceGroup() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional uint64 nonceGroup = 9;</code>
       * @return The nonceGroup.
       */
      @java.lang.Override
      public long getNonceGroup() {
        return nonceGroup_;
      }
      /**
       * <code>optional uint64 nonceGroup = 9;</code>
       * @param value The nonceGroup to set.
       * @return This builder for chaining.
       */
      public Builder setNonceGroup(long value) {

        nonceGroup_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 nonceGroup = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearNonceGroup() {
        bitField0_ = (bitField0_ & ~0x00000100);
        nonceGroup_ = 0L;
        onChanged();
        return this;
      }

      private long nonce_ ;
      /**
       * <code>optional uint64 nonce = 10;</code>
       * @return Whether the nonce field is set.
       */
      @java.lang.Override
      public boolean hasNonce() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <code>optional uint64 nonce = 10;</code>
       * @return The nonce.
       */
      @java.lang.Override
      public long getNonce() {
        return nonce_;
      }
      /**
       * <code>optional uint64 nonce = 10;</code>
       * @param value The nonce to set.
       * @return This builder for chaining.
       */
      public Builder setNonce(long value) {

        nonce_ = value;
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 nonce = 10;</code>
       * @return This builder for chaining.
       */
      public Builder clearNonce() {
        bitField0_ = (bitField0_ & ~0x00000200);
        nonce_ = 0L;
        onChanged();
        return this;
      }

      private long origSequenceNumber_ ;
      /**
       * <code>optional uint64 orig_sequence_number = 11;</code>
       * @return Whether the origSequenceNumber field is set.
       */
      @java.lang.Override
      public boolean hasOrigSequenceNumber() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <code>optional uint64 orig_sequence_number = 11;</code>
       * @return The origSequenceNumber.
       */
      @java.lang.Override
      public long getOrigSequenceNumber() {
        return origSequenceNumber_;
      }
      /**
       * <code>optional uint64 orig_sequence_number = 11;</code>
       * @param value The origSequenceNumber to set.
       * @return This builder for chaining.
       */
      public Builder setOrigSequenceNumber(long value) {

        origSequenceNumber_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 orig_sequence_number = 11;</code>
       * @return This builder for chaining.
       */
      public Builder clearOrigSequenceNumber() {
        bitField0_ = (bitField0_ & ~0x00000400);
        origSequenceNumber_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> extendedAttributes_ =
        java.util.Collections.emptyList();
      private void ensureExtendedAttributesIsMutable() {
        if (!((bitField0_ & 0x00000800) != 0)) {
          extendedAttributes_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute>(extendedAttributes_);
          bitField0_ |= 0x00000800;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder> extendedAttributesBuilder_;

      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> getExtendedAttributesList() {
        if (extendedAttributesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(extendedAttributes_);
        } else {
          return extendedAttributesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public int getExtendedAttributesCount() {
        if (extendedAttributesBuilder_ == null) {
          return extendedAttributes_.size();
        } else {
          return extendedAttributesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getExtendedAttributes(int index) {
        if (extendedAttributesBuilder_ == null) {
          return extendedAttributes_.get(index);
        } else {
          return extendedAttributesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder setExtendedAttributes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute value) {
        if (extendedAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.set(index, value);
          onChanged();
        } else {
          extendedAttributesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder setExtendedAttributes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder builderForValue) {
        if (extendedAttributesBuilder_ == null) {
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.set(index, builderForValue.build());
          onChanged();
        } else {
          extendedAttributesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder addExtendedAttributes(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute value) {
        if (extendedAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.add(value);
          onChanged();
        } else {
          extendedAttributesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder addExtendedAttributes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute value) {
        if (extendedAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.add(index, value);
          onChanged();
        } else {
          extendedAttributesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder addExtendedAttributes(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder builderForValue) {
        if (extendedAttributesBuilder_ == null) {
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.add(builderForValue.build());
          onChanged();
        } else {
          extendedAttributesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder addExtendedAttributes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder builderForValue) {
        if (extendedAttributesBuilder_ == null) {
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.add(index, builderForValue.build());
          onChanged();
        } else {
          extendedAttributesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder addAllExtendedAttributes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute> values) {
        if (extendedAttributesBuilder_ == null) {
          ensureExtendedAttributesIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, extendedAttributes_);
          onChanged();
        } else {
          extendedAttributesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder clearExtendedAttributes() {
        if (extendedAttributesBuilder_ == null) {
          extendedAttributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
          onChanged();
        } else {
          extendedAttributesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public Builder removeExtendedAttributes(int index) {
        if (extendedAttributesBuilder_ == null) {
          ensureExtendedAttributesIsMutable();
          extendedAttributes_.remove(index);
          onChanged();
        } else {
          extendedAttributesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder getExtendedAttributesBuilder(
          int index) {
        return getExtendedAttributesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder getExtendedAttributesOrBuilder(
          int index) {
        if (extendedAttributesBuilder_ == null) {
          return extendedAttributes_.get(index);  } else {
          return extendedAttributesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder> 
           getExtendedAttributesOrBuilderList() {
        if (extendedAttributesBuilder_ != null) {
          return extendedAttributesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(extendedAttributes_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder addExtendedAttributesBuilder() {
        return getExtendedAttributesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder addExtendedAttributesBuilder(
          int index) {
        return getExtendedAttributesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Attribute extended_attributes = 12;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder> 
           getExtendedAttributesBuilderList() {
        return getExtendedAttributesFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder> 
          getExtendedAttributesFieldBuilder() {
        if (extendedAttributesBuilder_ == null) {
          extendedAttributesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder>(
                  extendedAttributes_,
                  ((bitField0_ & 0x00000800) != 0),
                  getParentForChildren(),
                  isClean());
          extendedAttributes_ = null;
        }
        return extendedAttributesBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WALKey)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WALKey)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALKey>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WALKey>() {
      @java.lang.Override
      public WALKey parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALKey> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALKey> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALKey getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AttributeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Attribute)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string key = 1;</code>
     * @return Whether the key field is set.
     */
    boolean hasKey();
    /**
     * <code>required string key = 1;</code>
     * @return The key.
     */
    java.lang.String getKey();
    /**
     * <code>required string key = 1;</code>
     * @return The bytes for key.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getKeyBytes();

    /**
     * <code>required bytes value = 2;</code>
     * @return Whether the value field is set.
     */
    boolean hasValue();
    /**
     * <code>required bytes value = 2;</code>
     * @return The value.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code hbase.pb.Attribute}
   */
  @javax.annotation.Generated("proto") public static final class Attribute extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Attribute)
      AttributeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Attribute.newBuilder() to construct.
    private Attribute(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Attribute() {
      key_ = "";
      value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Attribute();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_Attribute_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_Attribute_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object key_ = "";
    /**
     * <code>required string key = 1;</code>
     * @return Whether the key field is set.
     */
    @java.lang.Override
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string key = 1;</code>
     * @return The key.
     */
    @java.lang.Override
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string key = 1;</code>
     * @return The bytes for key.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes value = 2;</code>
     * @return Whether the value field is set.
     */
    @java.lang.Override
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes value = 2;</code>
     * @return The value.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasKey()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 1, key_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(1, key_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute) obj;

      if (hasKey() != other.hasKey()) return false;
      if (hasKey()) {
        if (!getKey()
            .equals(other.getKey())) return false;
      }
      if (hasValue() != other.hasValue()) return false;
      if (hasValue()) {
        if (!getValue()
            .equals(other.getValue())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Attribute}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Attribute)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.AttributeOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_Attribute_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_Attribute_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        key_ = "";
        value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_Attribute_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.key_ = key_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.value_ = value_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute.getDefaultInstance()) return this;
        if (other.hasKey()) {
          key_ = other.key_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasKey()) {
          return false;
        }
        if (!hasValue()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                key_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                value_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object key_ = "";
      /**
       * <code>required string key = 1;</code>
       * @return Whether the key field is set.
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string key = 1;</code>
       * @return The key.
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            key_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string key = 1;</code>
       * @return The bytes for key.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string key = 1;</code>
       * @param value The key to set.
       * @return This builder for chaining.
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        key_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required string key = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearKey() {
        key_ = getDefaultInstance().getKey();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>required string key = 1;</code>
       * @param value The bytes for key to set.
       * @return This builder for chaining.
       */
      public Builder setKeyBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        key_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString value_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes value = 2;</code>
       * @return Whether the value field is set.
       */
      @java.lang.Override
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes value = 2;</code>
       * @return The value.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>required bytes value = 2;</code>
       * @param value The value to set.
       * @return This builder for chaining.
       */
      public Builder setValue(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        value_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes value = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Attribute)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Attribute)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<Attribute>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<Attribute>() {
      @java.lang.Override
      public Attribute parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<Attribute> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<Attribute> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.Attribute getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FamilyScopeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FamilyScope)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily();

    /**
     * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
     * @return Whether the scopeType field is set.
     */
    boolean hasScopeType();
    /**
     * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
     * @return The scopeType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType getScopeType();
  }
  /**
   * Protobuf type {@code hbase.pb.FamilyScope}
   */
  @javax.annotation.Generated("proto") public static final class FamilyScope extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FamilyScope)
      FamilyScopeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FamilyScope.newBuilder() to construct.
    private FamilyScope(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FamilyScope() {
      family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      scopeType_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FamilyScope();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FamilyScope_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FamilyScope_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder.class);
    }

    private int bitField0_;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family = 1;</code>
     * @return Whether the family field is set.
     */
    @java.lang.Override
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes family = 1;</code>
     * @return The family.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    public static final int SCOPE_TYPE_FIELD_NUMBER = 2;
    private int scopeType_ = 0;
    /**
     * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
     * @return Whether the scopeType field is set.
     */
    @java.lang.Override public boolean hasScopeType() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
     * @return The scopeType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType getScopeType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType.forNumber(scopeType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType.REPLICATION_SCOPE_LOCAL : result;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasScopeType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, family_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeEnum(2, scopeType_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, scopeType_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope) obj;

      if (hasFamily() != other.hasFamily()) return false;
      if (hasFamily()) {
        if (!getFamily()
            .equals(other.getFamily())) return false;
      }
      if (hasScopeType() != other.hasScopeType()) return false;
      if (hasScopeType()) {
        if (scopeType_ != other.scopeType_) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasScopeType()) {
        hash = (37 * hash) + SCOPE_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + scopeType_;
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.FamilyScope}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FamilyScope)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScopeOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FamilyScope_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FamilyScope_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        scopeType_ = 0;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FamilyScope_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.family_ = family_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.scopeType_ = scopeType_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasScopeType()) {
          setScopeType(other.getScopeType());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFamily()) {
          return false;
        }
        if (!hasScopeType()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                family_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(2, tmpRaw);
                } else {
                  scopeType_ = tmpRaw;
                  bitField0_ |= 0x00000002;
                }
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString family_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       * @return Whether the family field is set.
       */
      @java.lang.Override
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return The family.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @param value The family to set.
       * @return This builder for chaining.
       */
      public Builder setFamily(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        family_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      private int scopeType_ = 0;
      /**
       * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
       * @return Whether the scopeType field is set.
       */
      @java.lang.Override public boolean hasScopeType() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
       * @return The scopeType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType getScopeType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType.forNumber(scopeType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType.REPLICATION_SCOPE_LOCAL : result;
      }
      /**
       * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
       * @param value The scopeType to set.
       * @return This builder for chaining.
       */
      public Builder setScopeType(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.ScopeType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        scopeType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.ScopeType scope_type = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearScopeType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        scopeType_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FamilyScope)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FamilyScope)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyScope>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FamilyScope>() {
      @java.lang.Override
      public FamilyScope parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyScope> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FamilyScope> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FamilyScope getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CompactionDescriptorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CompactionDescriptor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * TODO: WALKey already stores these, might remove
     * </pre>
     *
     * <code>required bytes table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <pre>
     * TODO: WALKey already stores these, might remove
     * </pre>
     *
     * <code>required bytes table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName();

    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return Whether the encodedRegionName field is set.
     */
    boolean hasEncodedRegionName();
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return The encodedRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName();

    /**
     * <code>required bytes family_name = 3;</code>
     * @return Whether the familyName field is set.
     */
    boolean hasFamilyName();
    /**
     * <code>required bytes family_name = 3;</code>
     * @return The familyName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName();

    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @return A list containing the compactionInput.
     */
    java.util.List<java.lang.String>
        getCompactionInputList();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @return The count of compactionInput.
     */
    int getCompactionInputCount();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @param index The index of the element to return.
     * @return The compactionInput at the given index.
     */
    java.lang.String getCompactionInput(int index);
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the compactionInput at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCompactionInputBytes(int index);

    /**
     * <code>repeated string compaction_output = 5;</code>
     * @return A list containing the compactionOutput.
     */
    java.util.List<java.lang.String>
        getCompactionOutputList();
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @return The count of compactionOutput.
     */
    int getCompactionOutputCount();
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @param index The index of the element to return.
     * @return The compactionOutput at the given index.
     */
    java.lang.String getCompactionOutput(int index);
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @param index The index of the value to return.
     * @return The bytes of the compactionOutput at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCompactionOutputBytes(int index);

    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return Whether the storeHomeDir field is set.
     */
    boolean hasStoreHomeDir();
    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return The storeHomeDir.
     */
    java.lang.String getStoreHomeDir();
    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return The bytes for storeHomeDir.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreHomeDirBytes();

    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return Whether the regionName field is set.
     */
    boolean hasRegionName();
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return The regionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName();
  }
  /**
   * <pre>
   **
   * Special WAL entry to hold all related to a compaction.
   * Written to WAL before completing compaction.  There is
   * sufficient info in the below message to complete later
   * the * compaction should we fail the WAL write.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.CompactionDescriptor}
   */
  @javax.annotation.Generated("proto") public static final class CompactionDescriptor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CompactionDescriptor)
      CompactionDescriptorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CompactionDescriptor.newBuilder() to construct.
    private CompactionDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CompactionDescriptor() {
      tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      compactionInput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      compactionOutput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      storeHomeDir_ = "";
      regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CompactionDescriptor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_CompactionDescriptor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_CompactionDescriptor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * TODO: WALKey already stores these, might remove
     * </pre>
     *
     * <code>required bytes table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * TODO: WALKey already stores these, might remove
     * </pre>
     *
     * <code>required bytes table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
      return tableName_;
    }

    public static final int ENCODED_REGION_NAME_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return Whether the encodedRegionName field is set.
     */
    @java.lang.Override
    public boolean hasEncodedRegionName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return The encodedRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
      return encodedRegionName_;
    }

    public static final int FAMILY_NAME_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family_name = 3;</code>
     * @return Whether the familyName field is set.
     */
    @java.lang.Override
    public boolean hasFamilyName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bytes family_name = 3;</code>
     * @return The familyName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
      return familyName_;
    }

    public static final int COMPACTION_INPUT_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList compactionInput_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @return A list containing the compactionInput.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getCompactionInputList() {
      return compactionInput_;
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @return The count of compactionInput.
     */
    public int getCompactionInputCount() {
      return compactionInput_.size();
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @param index The index of the element to return.
     * @return The compactionInput at the given index.
     */
    public java.lang.String getCompactionInput(int index) {
      return compactionInput_.get(index);
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string compaction_input = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the compactionInput at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCompactionInputBytes(int index) {
      return compactionInput_.getByteString(index);
    }

    public static final int COMPACTION_OUTPUT_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList compactionOutput_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @return A list containing the compactionOutput.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getCompactionOutputList() {
      return compactionOutput_;
    }
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @return The count of compactionOutput.
     */
    public int getCompactionOutputCount() {
      return compactionOutput_.size();
    }
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @param index The index of the element to return.
     * @return The compactionOutput at the given index.
     */
    public java.lang.String getCompactionOutput(int index) {
      return compactionOutput_.get(index);
    }
    /**
     * <code>repeated string compaction_output = 5;</code>
     * @param index The index of the value to return.
     * @return The bytes of the compactionOutput at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getCompactionOutputBytes(int index) {
      return compactionOutput_.getByteString(index);
    }

    public static final int STORE_HOME_DIR_FIELD_NUMBER = 6;
    @SuppressWarnings("serial")
    private volatile java.lang.Object storeHomeDir_ = "";
    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return Whether the storeHomeDir field is set.
     */
    @java.lang.Override
    public boolean hasStoreHomeDir() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return The storeHomeDir.
     */
    @java.lang.Override
    public java.lang.String getStoreHomeDir() {
      java.lang.Object ref = storeHomeDir_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          storeHomeDir_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 6;</code>
     * @return The bytes for storeHomeDir.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreHomeDirBytes() {
      java.lang.Object ref = storeHomeDir_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        storeHomeDir_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int REGION_NAME_FIELD_NUMBER = 7;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return Whether the regionName field is set.
     */
    @java.lang.Override
    public boolean hasRegionName() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return The regionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
      return regionName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEncodedRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasFamilyName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasStoreHomeDir()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, tableName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, familyName_);
      }
      for (int i = 0; i < compactionInput_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 4, compactionInput_.getRaw(i));
      }
      for (int i = 0; i < compactionOutput_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 5, compactionOutput_.getRaw(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 6, storeHomeDir_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBytes(7, regionName_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, tableName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, familyName_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < compactionInput_.size(); i++) {
          dataSize += computeStringSizeNoTag(compactionInput_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getCompactionInputList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < compactionOutput_.size(); i++) {
          dataSize += computeStringSizeNoTag(compactionOutput_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getCompactionOutputList().size();
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(6, storeHomeDir_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(7, regionName_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasEncodedRegionName() != other.hasEncodedRegionName()) return false;
      if (hasEncodedRegionName()) {
        if (!getEncodedRegionName()
            .equals(other.getEncodedRegionName())) return false;
      }
      if (hasFamilyName() != other.hasFamilyName()) return false;
      if (hasFamilyName()) {
        if (!getFamilyName()
            .equals(other.getFamilyName())) return false;
      }
      if (!getCompactionInputList()
          .equals(other.getCompactionInputList())) return false;
      if (!getCompactionOutputList()
          .equals(other.getCompactionOutputList())) return false;
      if (hasStoreHomeDir() != other.hasStoreHomeDir()) return false;
      if (hasStoreHomeDir()) {
        if (!getStoreHomeDir()
            .equals(other.getStoreHomeDir())) return false;
      }
      if (hasRegionName() != other.hasRegionName()) return false;
      if (hasRegionName()) {
        if (!getRegionName()
            .equals(other.getRegionName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasEncodedRegionName()) {
        hash = (37 * hash) + ENCODED_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getEncodedRegionName().hashCode();
      }
      if (hasFamilyName()) {
        hash = (37 * hash) + FAMILY_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyName().hashCode();
      }
      if (getCompactionInputCount() > 0) {
        hash = (37 * hash) + COMPACTION_INPUT_FIELD_NUMBER;
        hash = (53 * hash) + getCompactionInputList().hashCode();
      }
      if (getCompactionOutputCount() > 0) {
        hash = (37 * hash) + COMPACTION_OUTPUT_FIELD_NUMBER;
        hash = (53 * hash) + getCompactionOutputList().hashCode();
      }
      if (hasStoreHomeDir()) {
        hash = (37 * hash) + STORE_HOME_DIR_FIELD_NUMBER;
        hash = (53 * hash) + getStoreHomeDir().hashCode();
      }
      if (hasRegionName()) {
        hash = (37 * hash) + REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getRegionName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Special WAL entry to hold all related to a compaction.
     * Written to WAL before completing compaction.  There is
     * sufficient info in the below message to complete later
     * the * compaction should we fail the WAL write.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.CompactionDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CompactionDescriptor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_CompactionDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_CompactionDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        compactionInput_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        compactionOutput_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        storeHomeDir_ = "";
        regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_CompactionDescriptor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.encodedRegionName_ = encodedRegionName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.familyName_ = familyName_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          compactionInput_.makeImmutable();
          result.compactionInput_ = compactionInput_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          compactionOutput_.makeImmutable();
          result.compactionOutput_ = compactionOutput_;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.storeHomeDir_ = storeHomeDir_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.regionName_ = regionName_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          setTableName(other.getTableName());
        }
        if (other.hasEncodedRegionName()) {
          setEncodedRegionName(other.getEncodedRegionName());
        }
        if (other.hasFamilyName()) {
          setFamilyName(other.getFamilyName());
        }
        if (!other.compactionInput_.isEmpty()) {
          if (compactionInput_.isEmpty()) {
            compactionInput_ = other.compactionInput_;
            bitField0_ |= 0x00000008;
          } else {
            ensureCompactionInputIsMutable();
            compactionInput_.addAll(other.compactionInput_);
          }
          onChanged();
        }
        if (!other.compactionOutput_.isEmpty()) {
          if (compactionOutput_.isEmpty()) {
            compactionOutput_ = other.compactionOutput_;
            bitField0_ |= 0x00000010;
          } else {
            ensureCompactionOutputIsMutable();
            compactionOutput_.addAll(other.compactionOutput_);
          }
          onChanged();
        }
        if (other.hasStoreHomeDir()) {
          storeHomeDir_ = other.storeHomeDir_;
          bitField0_ |= 0x00000020;
          onChanged();
        }
        if (other.hasRegionName()) {
          setRegionName(other.getRegionName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!hasEncodedRegionName()) {
          return false;
        }
        if (!hasFamilyName()) {
          return false;
        }
        if (!hasStoreHomeDir()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                tableName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                encodedRegionName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                familyName_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureCompactionInputIsMutable();
                compactionInput_.add(bs);
                break;
              } // case 34
              case 42: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureCompactionOutputIsMutable();
                compactionOutput_.add(bs);
                break;
              } // case 42
              case 50: {
                storeHomeDir_ = input.readBytes();
                bitField0_ |= 0x00000020;
                break;
              } // case 50
              case 58: {
                regionName_ = input.readBytes();
                bitField0_ |= 0x00000040;
                break;
              } // case 58
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * TODO: WALKey already stores these, might remove
       * </pre>
       *
       * <code>required bytes table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      @java.lang.Override
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * TODO: WALKey already stores these, might remove
       * </pre>
       *
       * <code>required bytes table_name = 1;</code>
       * @return The tableName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
        return tableName_;
      }
      /**
       * <pre>
       * TODO: WALKey already stores these, might remove
       * </pre>
       *
       * <code>required bytes table_name = 1;</code>
       * @param value The tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * TODO: WALKey already stores these, might remove
       * </pre>
       *
       * <code>required bytes table_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = getDefaultInstance().getTableName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return Whether the encodedRegionName field is set.
       */
      @java.lang.Override
      public boolean hasEncodedRegionName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return The encodedRegionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
        return encodedRegionName_;
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @param value The encodedRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setEncodedRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encodedRegionName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncodedRegionName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        encodedRegionName_ = getDefaultInstance().getEncodedRegionName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family_name = 3;</code>
       * @return Whether the familyName field is set.
       */
      @java.lang.Override
      public boolean hasFamilyName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bytes family_name = 3;</code>
       * @return The familyName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
        return familyName_;
      }
      /**
       * <code>required bytes family_name = 3;</code>
       * @param value The familyName to set.
       * @return This builder for chaining.
       */
      public Builder setFamilyName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        familyName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamilyName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        familyName_ = getDefaultInstance().getFamilyName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList compactionInput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureCompactionInputIsMutable() {
        if (!compactionInput_.isModifiable()) {
          compactionInput_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(compactionInput_);
        }
        bitField0_ |= 0x00000008;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @return A list containing the compactionInput.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getCompactionInputList() {
        compactionInput_.makeImmutable();
        return compactionInput_;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @return The count of compactionInput.
       */
      public int getCompactionInputCount() {
        return compactionInput_.size();
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param index The index of the element to return.
       * @return The compactionInput at the given index.
       */
      public java.lang.String getCompactionInput(int index) {
        return compactionInput_.get(index);
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param index The index of the value to return.
       * @return The bytes of the compactionInput at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getCompactionInputBytes(int index) {
        return compactionInput_.getByteString(index);
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param index The index to set the value at.
       * @param value The compactionInput to set.
       * @return This builder for chaining.
       */
      public Builder setCompactionInput(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionInputIsMutable();
        compactionInput_.set(index, value);
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param value The compactionInput to add.
       * @return This builder for chaining.
       */
      public Builder addCompactionInput(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionInputIsMutable();
        compactionInput_.add(value);
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param values The compactionInput to add.
       * @return This builder for chaining.
       */
      public Builder addAllCompactionInput(
          java.lang.Iterable<java.lang.String> values) {
        ensureCompactionInputIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, compactionInput_);
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompactionInput() {
        compactionInput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string compaction_input = 4;</code>
       * @param value The bytes of the compactionInput to add.
       * @return This builder for chaining.
       */
      public Builder addCompactionInputBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionInputIsMutable();
        compactionInput_.add(value);
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList compactionOutput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureCompactionOutputIsMutable() {
        if (!compactionOutput_.isModifiable()) {
          compactionOutput_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(compactionOutput_);
        }
        bitField0_ |= 0x00000010;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @return A list containing the compactionOutput.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getCompactionOutputList() {
        compactionOutput_.makeImmutable();
        return compactionOutput_;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @return The count of compactionOutput.
       */
      public int getCompactionOutputCount() {
        return compactionOutput_.size();
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param index The index of the element to return.
       * @return The compactionOutput at the given index.
       */
      public java.lang.String getCompactionOutput(int index) {
        return compactionOutput_.get(index);
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param index The index of the value to return.
       * @return The bytes of the compactionOutput at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getCompactionOutputBytes(int index) {
        return compactionOutput_.getByteString(index);
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param index The index to set the value at.
       * @param value The compactionOutput to set.
       * @return This builder for chaining.
       */
      public Builder setCompactionOutput(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionOutputIsMutable();
        compactionOutput_.set(index, value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param value The compactionOutput to add.
       * @return This builder for chaining.
       */
      public Builder addCompactionOutput(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionOutputIsMutable();
        compactionOutput_.add(value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param values The compactionOutput to add.
       * @return This builder for chaining.
       */
      public Builder addAllCompactionOutput(
          java.lang.Iterable<java.lang.String> values) {
        ensureCompactionOutputIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, compactionOutput_);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompactionOutput() {
        compactionOutput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000010);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string compaction_output = 5;</code>
       * @param value The bytes of the compactionOutput to add.
       * @return This builder for chaining.
       */
      public Builder addCompactionOutputBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureCompactionOutputIsMutable();
        compactionOutput_.add(value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }

      private java.lang.Object storeHomeDir_ = "";
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @return Whether the storeHomeDir field is set.
       */
      public boolean hasStoreHomeDir() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @return The storeHomeDir.
       */
      public java.lang.String getStoreHomeDir() {
        java.lang.Object ref = storeHomeDir_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            storeHomeDir_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @return The bytes for storeHomeDir.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreHomeDirBytes() {
        java.lang.Object ref = storeHomeDir_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          storeHomeDir_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @param value The storeHomeDir to set.
       * @return This builder for chaining.
       */
      public Builder setStoreHomeDir(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        storeHomeDir_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreHomeDir() {
        storeHomeDir_ = getDefaultInstance().getStoreHomeDir();
        bitField0_ = (bitField0_ & ~0x00000020);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 6;</code>
       * @param value The bytes for storeHomeDir to set.
       * @return This builder for chaining.
       */
      public Builder setStoreHomeDirBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        storeHomeDir_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return Whether the regionName field is set.
       */
      @java.lang.Override
      public boolean hasRegionName() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return The regionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
        return regionName_;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @param value The regionName to set.
       * @return This builder for chaining.
       */
      public Builder setRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        regionName_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionName() {
        bitField0_ = (bitField0_ & ~0x00000040);
        regionName_ = getDefaultInstance().getRegionName();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CompactionDescriptor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CompactionDescriptor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionDescriptor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<CompactionDescriptor>() {
      @java.lang.Override
      public CompactionDescriptor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionDescriptor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<CompactionDescriptor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface FlushDescriptorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.FlushDescriptor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
     * @return Whether the action field is set.
     */
    boolean hasAction();
    /**
     * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
     * @return The action.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction getAction();

    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName();

    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return Whether the encodedRegionName field is set.
     */
    boolean hasEncodedRegionName();
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return The encodedRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName();

    /**
     * <code>optional uint64 flush_sequence_number = 4;</code>
     * @return Whether the flushSequenceNumber field is set.
     */
    boolean hasFlushSequenceNumber();
    /**
     * <code>optional uint64 flush_sequence_number = 4;</code>
     * @return The flushSequenceNumber.
     */
    long getFlushSequenceNumber();

    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> 
        getStoreFlushesList();
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getStoreFlushes(int index);
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    int getStoreFlushesCount();
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder> 
        getStoreFlushesOrBuilderList();
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder getStoreFlushesOrBuilder(
        int index);

    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 6;</code>
     * @return Whether the regionName field is set.
     */
    boolean hasRegionName();
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 6;</code>
     * @return The regionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName();
  }
  /**
   * <pre>
   **
   * Special WAL entry to hold all related to a flush.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.FlushDescriptor}
   */
  @javax.annotation.Generated("proto") public static final class FlushDescriptor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.FlushDescriptor)
      FlushDescriptorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use FlushDescriptor.newBuilder() to construct.
    private FlushDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private FlushDescriptor() {
      action_ = 0;
      tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      storeFlushes_ = java.util.Collections.emptyList();
      regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new FlushDescriptor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.FlushDescriptor.FlushAction}
     */
    public enum FlushAction
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>START_FLUSH = 0;</code>
       */
      START_FLUSH(0),
      /**
       * <code>COMMIT_FLUSH = 1;</code>
       */
      COMMIT_FLUSH(1),
      /**
       * <code>ABORT_FLUSH = 2;</code>
       */
      ABORT_FLUSH(2),
      /**
       * <pre>
       * marker for indicating that a flush has been requested but cannot complete
       * </pre>
       *
       * <code>CANNOT_FLUSH = 3;</code>
       */
      CANNOT_FLUSH(3),
      ;

      /**
       * <code>START_FLUSH = 0;</code>
       */
      public static final int START_FLUSH_VALUE = 0;
      /**
       * <code>COMMIT_FLUSH = 1;</code>
       */
      public static final int COMMIT_FLUSH_VALUE = 1;
      /**
       * <code>ABORT_FLUSH = 2;</code>
       */
      public static final int ABORT_FLUSH_VALUE = 2;
      /**
       * <pre>
       * marker for indicating that a flush has been requested but cannot complete
       * </pre>
       *
       * <code>CANNOT_FLUSH = 3;</code>
       */
      public static final int CANNOT_FLUSH_VALUE = 3;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static FlushAction valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static FlushAction forNumber(int value) {
        switch (value) {
          case 0: return START_FLUSH;
          case 1: return COMMIT_FLUSH;
          case 2: return ABORT_FLUSH;
          case 3: return CANNOT_FLUSH;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<FlushAction>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          FlushAction> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<FlushAction>() {
              public FlushAction findValueByNumber(int number) {
                return FlushAction.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.getDescriptor().getEnumTypes().get(0);
      }

      private static final FlushAction[] VALUES = values();

      public static FlushAction valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private FlushAction(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.FlushDescriptor.FlushAction)
    }

    public interface StoreFlushDescriptorOrBuilder extends
        // @@protoc_insertion_point(interface_extends:hbase.pb.FlushDescriptor.StoreFlushDescriptor)
        org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required bytes family_name = 1;</code>
       * @return Whether the familyName field is set.
       */
      boolean hasFamilyName();
      /**
       * <code>required bytes family_name = 1;</code>
       * @return The familyName.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName();

      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return Whether the storeHomeDir field is set.
       */
      boolean hasStoreHomeDir();
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The storeHomeDir.
       */
      java.lang.String getStoreHomeDir();
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The bytes for storeHomeDir.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreHomeDirBytes();

      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @return A list containing the flushOutput.
       */
      java.util.List<java.lang.String>
          getFlushOutputList();
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @return The count of flushOutput.
       */
      int getFlushOutputCount();
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @param index The index of the element to return.
       * @return The flushOutput at the given index.
       */
      java.lang.String getFlushOutput(int index);
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the flushOutput at the given index.
       */
      org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getFlushOutputBytes(int index);
    }
    /**
     * Protobuf type {@code hbase.pb.FlushDescriptor.StoreFlushDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class StoreFlushDescriptor extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:hbase.pb.FlushDescriptor.StoreFlushDescriptor)
        StoreFlushDescriptorOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use StoreFlushDescriptor.newBuilder() to construct.
      private StoreFlushDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private StoreFlushDescriptor() {
        familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        storeHomeDir_ = "";
        flushOutput_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new StoreFlushDescriptor();
      }

      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder.class);
      }

      private int bitField0_;
      public static final int FAMILY_NAME_FIELD_NUMBER = 1;
      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family_name = 1;</code>
       * @return Whether the familyName field is set.
       */
      @java.lang.Override
      public boolean hasFamilyName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family_name = 1;</code>
       * @return The familyName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
        return familyName_;
      }

      public static final int STORE_HOME_DIR_FIELD_NUMBER = 2;
      @SuppressWarnings("serial")
      private volatile java.lang.Object storeHomeDir_ = "";
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return Whether the storeHomeDir field is set.
       */
      @java.lang.Override
      public boolean hasStoreHomeDir() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The storeHomeDir.
       */
      @java.lang.Override
      public java.lang.String getStoreHomeDir() {
        java.lang.Object ref = storeHomeDir_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            storeHomeDir_ = s;
          }
          return s;
        }
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The bytes for storeHomeDir.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreHomeDirBytes() {
        java.lang.Object ref = storeHomeDir_;
        if (ref instanceof java.lang.String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          storeHomeDir_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }

      public static final int FLUSH_OUTPUT_FIELD_NUMBER = 3;
      @SuppressWarnings("serial")
      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList flushOutput_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @return A list containing the flushOutput.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getFlushOutputList() {
        return flushOutput_;
      }
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @return The count of flushOutput.
       */
      public int getFlushOutputCount() {
        return flushOutput_.size();
      }
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @param index The index of the element to return.
       * @return The flushOutput at the given index.
       */
      public java.lang.String getFlushOutput(int index) {
        return flushOutput_.get(index);
      }
      /**
       * <pre>
       * relative to store dir (if this is a COMMIT_FLUSH)
       * </pre>
       *
       * <code>repeated string flush_output = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the flushOutput at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getFlushOutputBytes(int index) {
        return flushOutput_.getByteString(index);
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasFamilyName()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!hasStoreHomeDir()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeBytes(1, familyName_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, storeHomeDir_);
        }
        for (int i = 0; i < flushOutput_.size(); i++) {
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, flushOutput_.getRaw(i));
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, familyName_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, storeHomeDir_);
        }
        {
          int dataSize = 0;
          for (int i = 0; i < flushOutput_.size(); i++) {
            dataSize += computeStringSizeNoTag(flushOutput_.getRaw(i));
          }
          size += dataSize;
          size += 1 * getFlushOutputList().size();
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor) obj;

        if (hasFamilyName() != other.hasFamilyName()) return false;
        if (hasFamilyName()) {
          if (!getFamilyName()
              .equals(other.getFamilyName())) return false;
        }
        if (hasStoreHomeDir() != other.hasStoreHomeDir()) return false;
        if (hasStoreHomeDir()) {
          if (!getStoreHomeDir()
              .equals(other.getStoreHomeDir())) return false;
        }
        if (!getFlushOutputList()
            .equals(other.getFlushOutputList())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasFamilyName()) {
          hash = (37 * hash) + FAMILY_NAME_FIELD_NUMBER;
          hash = (53 * hash) + getFamilyName().hashCode();
        }
        if (hasStoreHomeDir()) {
          hash = (37 * hash) + STORE_HOME_DIR_FIELD_NUMBER;
          hash = (53 * hash) + getStoreHomeDir().hashCode();
        }
        if (getFlushOutputCount() > 0) {
          hash = (37 * hash) + FLUSH_OUTPUT_FIELD_NUMBER;
          hash = (53 * hash) + getFlushOutputList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          java.nio.ByteBuffer data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          java.nio.ByteBuffer data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(byte[] data)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          byte[] data,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseDelimitedFrom(
          java.io.InputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor parseFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.FlushDescriptor.StoreFlushDescriptor}
       */
      @javax.annotation.Generated("proto") public static final class Builder extends
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:hbase.pb.FlushDescriptor.StoreFlushDescriptor)
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder {
        public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor;
        }

        @java.lang.Override
        protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.newBuilder()
        private Builder() {

        }

        private Builder(
            org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);

        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
          storeHomeDir_ = "";
          flushOutput_ =
              org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
          return this;
        }

        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor build() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor buildPartial() {
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor(this);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor result) {
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.familyName_ = familyName_;
            to_bitField0_ |= 0x00000001;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.storeHomeDir_ = storeHomeDir_;
            to_bitField0_ |= 0x00000002;
          }
          if (((from_bitField0_ & 0x00000004) != 0)) {
            flushOutput_.makeImmutable();
            result.flushOutput_ = flushOutput_;
          }
          result.bitField0_ |= to_bitField0_;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor) {
            return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor other) {
          if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.getDefaultInstance()) return this;
          if (other.hasFamilyName()) {
            setFamilyName(other.getFamilyName());
          }
          if (other.hasStoreHomeDir()) {
            storeHomeDir_ = other.storeHomeDir_;
            bitField0_ |= 0x00000002;
            onChanged();
          }
          if (!other.flushOutput_.isEmpty()) {
            if (flushOutput_.isEmpty()) {
              flushOutput_ = other.flushOutput_;
              bitField0_ |= 0x00000004;
            } else {
              ensureFlushOutputIsMutable();
              flushOutput_.addAll(other.flushOutput_);
            }
            onChanged();
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasFamilyName()) {
            return false;
          }
          if (!hasStoreHomeDir()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  familyName_ = input.readBytes();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 18: {
                  storeHomeDir_ = input.readBytes();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 18
                case 26: {
                  org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                  ensureFlushOutputIsMutable();
                  flushOutput_.add(bs);
                  break;
                } // case 26
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes family_name = 1;</code>
         * @return Whether the familyName field is set.
         */
        @java.lang.Override
        public boolean hasFamilyName() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required bytes family_name = 1;</code>
         * @return The familyName.
         */
        @java.lang.Override
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
          return familyName_;
        }
        /**
         * <code>required bytes family_name = 1;</code>
         * @param value The familyName to set.
         * @return This builder for chaining.
         */
        public Builder setFamilyName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          familyName_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes family_name = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearFamilyName() {
          bitField0_ = (bitField0_ & ~0x00000001);
          familyName_ = getDefaultInstance().getFamilyName();
          onChanged();
          return this;
        }

        private java.lang.Object storeHomeDir_ = "";
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @return Whether the storeHomeDir field is set.
         */
        public boolean hasStoreHomeDir() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @return The storeHomeDir.
         */
        public java.lang.String getStoreHomeDir() {
          java.lang.Object ref = storeHomeDir_;
          if (!(ref instanceof java.lang.String)) {
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
                (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            if (bs.isValidUtf8()) {
              storeHomeDir_ = s;
            }
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @return The bytes for storeHomeDir.
         */
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
            getStoreHomeDirBytes() {
          java.lang.Object ref = storeHomeDir_;
          if (ref instanceof String) {
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            storeHomeDir_ = b;
            return b;
          } else {
            return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @param value The storeHomeDir to set.
         * @return This builder for chaining.
         */
        public Builder setStoreHomeDir(
            java.lang.String value) {
          if (value == null) { throw new NullPointerException(); }
          storeHomeDir_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearStoreHomeDir() {
          storeHomeDir_ = getDefaultInstance().getStoreHomeDir();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *relative to region dir
         * </pre>
         *
         * <code>required string store_home_dir = 2;</code>
         * @param value The bytes for storeHomeDir to set.
         * @return This builder for chaining.
         */
        public Builder setStoreHomeDirBytes(
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          storeHomeDir_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }

        private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList flushOutput_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        private void ensureFlushOutputIsMutable() {
          if (!flushOutput_.isModifiable()) {
            flushOutput_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(flushOutput_);
          }
          bitField0_ |= 0x00000004;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @return A list containing the flushOutput.
         */
        public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
            getFlushOutputList() {
          flushOutput_.makeImmutable();
          return flushOutput_;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @return The count of flushOutput.
         */
        public int getFlushOutputCount() {
          return flushOutput_.size();
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param index The index of the element to return.
         * @return The flushOutput at the given index.
         */
        public java.lang.String getFlushOutput(int index) {
          return flushOutput_.get(index);
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param index The index of the value to return.
         * @return The bytes of the flushOutput at the given index.
         */
        public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
            getFlushOutputBytes(int index) {
          return flushOutput_.getByteString(index);
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param index The index to set the value at.
         * @param value The flushOutput to set.
         * @return This builder for chaining.
         */
        public Builder setFlushOutput(
            int index, java.lang.String value) {
          if (value == null) { throw new NullPointerException(); }
          ensureFlushOutputIsMutable();
          flushOutput_.set(index, value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param value The flushOutput to add.
         * @return This builder for chaining.
         */
        public Builder addFlushOutput(
            java.lang.String value) {
          if (value == null) { throw new NullPointerException(); }
          ensureFlushOutputIsMutable();
          flushOutput_.add(value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param values The flushOutput to add.
         * @return This builder for chaining.
         */
        public Builder addAllFlushOutput(
            java.lang.Iterable<java.lang.String> values) {
          ensureFlushOutputIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, flushOutput_);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @return This builder for chaining.
         */
        public Builder clearFlushOutput() {
          flushOutput_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * relative to store dir (if this is a COMMIT_FLUSH)
         * </pre>
         *
         * <code>repeated string flush_output = 3;</code>
         * @param value The bytes of the flushOutput to add.
         * @return This builder for chaining.
         */
        public Builder addFlushOutputBytes(
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          ensureFlushOutputIsMutable();
          flushOutput_.add(value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:hbase.pb.FlushDescriptor.StoreFlushDescriptor)
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.FlushDescriptor.StoreFlushDescriptor)
      private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor();
      }

      public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreFlushDescriptor>
          PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<StoreFlushDescriptor>() {
        @java.lang.Override
        public StoreFlushDescriptor parsePartialFrom(
            org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
            org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreFlushDescriptor> parser() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreFlushDescriptor> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int ACTION_FIELD_NUMBER = 1;
    private int action_ = 0;
    /**
     * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
     * @return Whether the action field is set.
     */
    @java.lang.Override public boolean hasAction() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
     * @return The action.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction getAction() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction.forNumber(action_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction.START_FLUSH : result;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
      return tableName_;
    }

    public static final int ENCODED_REGION_NAME_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return Whether the encodedRegionName field is set.
     */
    @java.lang.Override
    public boolean hasEncodedRegionName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return The encodedRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
      return encodedRegionName_;
    }

    public static final int FLUSH_SEQUENCE_NUMBER_FIELD_NUMBER = 4;
    private long flushSequenceNumber_ = 0L;
    /**
     * <code>optional uint64 flush_sequence_number = 4;</code>
     * @return Whether the flushSequenceNumber field is set.
     */
    @java.lang.Override
    public boolean hasFlushSequenceNumber() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional uint64 flush_sequence_number = 4;</code>
     * @return The flushSequenceNumber.
     */
    @java.lang.Override
    public long getFlushSequenceNumber() {
      return flushSequenceNumber_;
    }

    public static final int STORE_FLUSHES_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> storeFlushes_;
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> getStoreFlushesList() {
      return storeFlushes_;
    }
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder> 
        getStoreFlushesOrBuilderList() {
      return storeFlushes_;
    }
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    @java.lang.Override
    public int getStoreFlushesCount() {
      return storeFlushes_.size();
    }
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getStoreFlushes(int index) {
      return storeFlushes_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder getStoreFlushesOrBuilder(
        int index) {
      return storeFlushes_.get(index);
    }

    public static final int REGION_NAME_FIELD_NUMBER = 6;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 6;</code>
     * @return Whether the regionName field is set.
     */
    @java.lang.Override
    public boolean hasRegionName() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 6;</code>
     * @return The regionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
      return regionName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasAction()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEncodedRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getStoreFlushesCount(); i++) {
        if (!getStoreFlushes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, action_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt64(4, flushSequenceNumber_);
      }
      for (int i = 0; i < storeFlushes_.size(); i++) {
        output.writeMessage(5, storeFlushes_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeBytes(6, regionName_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, action_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, flushSequenceNumber_);
      }
      for (int i = 0; i < storeFlushes_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, storeFlushes_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, regionName_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor) obj;

      if (hasAction() != other.hasAction()) return false;
      if (hasAction()) {
        if (action_ != other.action_) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasEncodedRegionName() != other.hasEncodedRegionName()) return false;
      if (hasEncodedRegionName()) {
        if (!getEncodedRegionName()
            .equals(other.getEncodedRegionName())) return false;
      }
      if (hasFlushSequenceNumber() != other.hasFlushSequenceNumber()) return false;
      if (hasFlushSequenceNumber()) {
        if (getFlushSequenceNumber()
            != other.getFlushSequenceNumber()) return false;
      }
      if (!getStoreFlushesList()
          .equals(other.getStoreFlushesList())) return false;
      if (hasRegionName() != other.hasRegionName()) return false;
      if (hasRegionName()) {
        if (!getRegionName()
            .equals(other.getRegionName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAction()) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + action_;
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasEncodedRegionName()) {
        hash = (37 * hash) + ENCODED_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getEncodedRegionName().hashCode();
      }
      if (hasFlushSequenceNumber()) {
        hash = (37 * hash) + FLUSH_SEQUENCE_NUMBER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getFlushSequenceNumber());
      }
      if (getStoreFlushesCount() > 0) {
        hash = (37 * hash) + STORE_FLUSHES_FIELD_NUMBER;
        hash = (53 * hash) + getStoreFlushesList().hashCode();
      }
      if (hasRegionName()) {
        hash = (37 * hash) + REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getRegionName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Special WAL entry to hold all related to a flush.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.FlushDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.FlushDescriptor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        action_ = 0;
        tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        flushSequenceNumber_ = 0L;
        if (storeFlushesBuilder_ == null) {
          storeFlushes_ = java.util.Collections.emptyList();
        } else {
          storeFlushes_ = null;
          storeFlushesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_FlushDescriptor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor result) {
        if (storeFlushesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            storeFlushes_ = java.util.Collections.unmodifiableList(storeFlushes_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.storeFlushes_ = storeFlushes_;
        } else {
          result.storeFlushes_ = storeFlushesBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.action_ = action_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.encodedRegionName_ = encodedRegionName_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.flushSequenceNumber_ = flushSequenceNumber_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.regionName_ = regionName_;
          to_bitField0_ |= 0x00000010;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.getDefaultInstance()) return this;
        if (other.hasAction()) {
          setAction(other.getAction());
        }
        if (other.hasTableName()) {
          setTableName(other.getTableName());
        }
        if (other.hasEncodedRegionName()) {
          setEncodedRegionName(other.getEncodedRegionName());
        }
        if (other.hasFlushSequenceNumber()) {
          setFlushSequenceNumber(other.getFlushSequenceNumber());
        }
        if (storeFlushesBuilder_ == null) {
          if (!other.storeFlushes_.isEmpty()) {
            if (storeFlushes_.isEmpty()) {
              storeFlushes_ = other.storeFlushes_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureStoreFlushesIsMutable();
              storeFlushes_.addAll(other.storeFlushes_);
            }
            onChanged();
          }
        } else {
          if (!other.storeFlushes_.isEmpty()) {
            if (storeFlushesBuilder_.isEmpty()) {
              storeFlushesBuilder_.dispose();
              storeFlushesBuilder_ = null;
              storeFlushes_ = other.storeFlushes_;
              bitField0_ = (bitField0_ & ~0x00000010);
              storeFlushesBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStoreFlushesFieldBuilder() : null;
            } else {
              storeFlushesBuilder_.addAllMessages(other.storeFlushes_);
            }
          }
        }
        if (other.hasRegionName()) {
          setRegionName(other.getRegionName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasAction()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasEncodedRegionName()) {
          return false;
        }
        for (int i = 0; i < getStoreFlushesCount(); i++) {
          if (!getStoreFlushes(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  action_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                tableName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                encodedRegionName_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                flushSequenceNumber_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.PARSER,
                        extensionRegistry);
                if (storeFlushesBuilder_ == null) {
                  ensureStoreFlushesIsMutable();
                  storeFlushes_.add(m);
                } else {
                  storeFlushesBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 50: {
                regionName_ = input.readBytes();
                bitField0_ |= 0x00000020;
                break;
              } // case 50
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int action_ = 0;
      /**
       * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
       * @return Whether the action field is set.
       */
      @java.lang.Override public boolean hasAction() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
       * @return The action.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction getAction() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction.forNumber(action_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction.START_FLUSH : result;
      }
      /**
       * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
       * @param value The action to set.
       * @return This builder for chaining.
       */
      public Builder setAction(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.FlushAction value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        action_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.FlushDescriptor.FlushAction action = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearAction() {
        bitField0_ = (bitField0_ & ~0x00000001);
        action_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      @java.lang.Override
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return The tableName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
        return tableName_;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @param value The tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = getDefaultInstance().getTableName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return Whether the encodedRegionName field is set.
       */
      @java.lang.Override
      public boolean hasEncodedRegionName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return The encodedRegionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
        return encodedRegionName_;
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @param value The encodedRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setEncodedRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encodedRegionName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncodedRegionName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        encodedRegionName_ = getDefaultInstance().getEncodedRegionName();
        onChanged();
        return this;
      }

      private long flushSequenceNumber_ ;
      /**
       * <code>optional uint64 flush_sequence_number = 4;</code>
       * @return Whether the flushSequenceNumber field is set.
       */
      @java.lang.Override
      public boolean hasFlushSequenceNumber() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint64 flush_sequence_number = 4;</code>
       * @return The flushSequenceNumber.
       */
      @java.lang.Override
      public long getFlushSequenceNumber() {
        return flushSequenceNumber_;
      }
      /**
       * <code>optional uint64 flush_sequence_number = 4;</code>
       * @param value The flushSequenceNumber to set.
       * @return This builder for chaining.
       */
      public Builder setFlushSequenceNumber(long value) {

        flushSequenceNumber_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 flush_sequence_number = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearFlushSequenceNumber() {
        bitField0_ = (bitField0_ & ~0x00000008);
        flushSequenceNumber_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> storeFlushes_ =
        java.util.Collections.emptyList();
      private void ensureStoreFlushesIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          storeFlushes_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor>(storeFlushes_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder> storeFlushesBuilder_;

      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> getStoreFlushesList() {
        if (storeFlushesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(storeFlushes_);
        } else {
          return storeFlushesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public int getStoreFlushesCount() {
        if (storeFlushesBuilder_ == null) {
          return storeFlushes_.size();
        } else {
          return storeFlushesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor getStoreFlushes(int index) {
        if (storeFlushesBuilder_ == null) {
          return storeFlushes_.get(index);
        } else {
          return storeFlushesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder setStoreFlushes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor value) {
        if (storeFlushesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoreFlushesIsMutable();
          storeFlushes_.set(index, value);
          onChanged();
        } else {
          storeFlushesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder setStoreFlushes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder builderForValue) {
        if (storeFlushesBuilder_ == null) {
          ensureStoreFlushesIsMutable();
          storeFlushes_.set(index, builderForValue.build());
          onChanged();
        } else {
          storeFlushesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder addStoreFlushes(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor value) {
        if (storeFlushesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoreFlushesIsMutable();
          storeFlushes_.add(value);
          onChanged();
        } else {
          storeFlushesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder addStoreFlushes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor value) {
        if (storeFlushesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoreFlushesIsMutable();
          storeFlushes_.add(index, value);
          onChanged();
        } else {
          storeFlushesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder addStoreFlushes(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder builderForValue) {
        if (storeFlushesBuilder_ == null) {
          ensureStoreFlushesIsMutable();
          storeFlushes_.add(builderForValue.build());
          onChanged();
        } else {
          storeFlushesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder addStoreFlushes(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder builderForValue) {
        if (storeFlushesBuilder_ == null) {
          ensureStoreFlushesIsMutable();
          storeFlushes_.add(index, builderForValue.build());
          onChanged();
        } else {
          storeFlushesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder addAllStoreFlushes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor> values) {
        if (storeFlushesBuilder_ == null) {
          ensureStoreFlushesIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, storeFlushes_);
          onChanged();
        } else {
          storeFlushesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder clearStoreFlushes() {
        if (storeFlushesBuilder_ == null) {
          storeFlushes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          storeFlushesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public Builder removeStoreFlushes(int index) {
        if (storeFlushesBuilder_ == null) {
          ensureStoreFlushesIsMutable();
          storeFlushes_.remove(index);
          onChanged();
        } else {
          storeFlushesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder getStoreFlushesBuilder(
          int index) {
        return getStoreFlushesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder getStoreFlushesOrBuilder(
          int index) {
        if (storeFlushesBuilder_ == null) {
          return storeFlushes_.get(index);  } else {
          return storeFlushesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder> 
           getStoreFlushesOrBuilderList() {
        if (storeFlushesBuilder_ != null) {
          return storeFlushesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(storeFlushes_);
        }
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder addStoreFlushesBuilder() {
        return getStoreFlushesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder addStoreFlushesBuilder(
          int index) {
        return getStoreFlushesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.FlushDescriptor.StoreFlushDescriptor store_flushes = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder> 
           getStoreFlushesBuilderList() {
        return getStoreFlushesFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder> 
          getStoreFlushesFieldBuilder() {
        if (storeFlushesBuilder_ == null) {
          storeFlushesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor.StoreFlushDescriptorOrBuilder>(
                  storeFlushes_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          storeFlushes_ = null;
        }
        return storeFlushesBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 6;</code>
       * @return Whether the regionName field is set.
       */
      @java.lang.Override
      public boolean hasRegionName() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 6;</code>
       * @return The regionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
        return regionName_;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 6;</code>
       * @param value The regionName to set.
       * @return This builder for chaining.
       */
      public Builder setRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        regionName_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionName() {
        bitField0_ = (bitField0_ & ~0x00000020);
        regionName_ = getDefaultInstance().getRegionName();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.FlushDescriptor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.FlushDescriptor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushDescriptor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<FlushDescriptor>() {
      @java.lang.Override
      public FlushDescriptor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushDescriptor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<FlushDescriptor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StoreDescriptorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.StoreDescriptor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required bytes family_name = 1;</code>
     * @return Whether the familyName field is set.
     */
    boolean hasFamilyName();
    /**
     * <code>required bytes family_name = 1;</code>
     * @return The familyName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName();

    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return Whether the storeHomeDir field is set.
     */
    boolean hasStoreHomeDir();
    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return The storeHomeDir.
     */
    java.lang.String getStoreHomeDir();
    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return The bytes for storeHomeDir.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreHomeDirBytes();

    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @return A list containing the storeFile.
     */
    java.util.List<java.lang.String>
        getStoreFileList();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @return The count of storeFile.
     */
    int getStoreFileCount();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @param index The index of the element to return.
     * @return The storeFile at the given index.
     */
    java.lang.String getStoreFile(int index);
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the storeFile at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreFileBytes(int index);

    /**
     * <pre>
     * size of store file
     * </pre>
     *
     * <code>optional uint64 store_file_size_bytes = 4;</code>
     * @return Whether the storeFileSizeBytes field is set.
     */
    boolean hasStoreFileSizeBytes();
    /**
     * <pre>
     * size of store file
     * </pre>
     *
     * <code>optional uint64 store_file_size_bytes = 4;</code>
     * @return The storeFileSizeBytes.
     */
    long getStoreFileSizeBytes();
  }
  /**
   * Protobuf type {@code hbase.pb.StoreDescriptor}
   */
  @javax.annotation.Generated("proto") public static final class StoreDescriptor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.StoreDescriptor)
      StoreDescriptorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StoreDescriptor.newBuilder() to construct.
    private StoreDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StoreDescriptor() {
      familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      storeHomeDir_ = "";
      storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StoreDescriptor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_StoreDescriptor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_StoreDescriptor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder.class);
    }

    private int bitField0_;
    public static final int FAMILY_NAME_FIELD_NUMBER = 1;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes family_name = 1;</code>
     * @return Whether the familyName field is set.
     */
    @java.lang.Override
    public boolean hasFamilyName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required bytes family_name = 1;</code>
     * @return The familyName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
      return familyName_;
    }

    public static final int STORE_HOME_DIR_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object storeHomeDir_ = "";
    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return Whether the storeHomeDir field is set.
     */
    @java.lang.Override
    public boolean hasStoreHomeDir() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return The storeHomeDir.
     */
    @java.lang.Override
    public java.lang.String getStoreHomeDir() {
      java.lang.Object ref = storeHomeDir_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = 
            (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          storeHomeDir_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     *relative to region dir
     * </pre>
     *
     * <code>required string store_home_dir = 2;</code>
     * @return The bytes for storeHomeDir.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreHomeDirBytes() {
      java.lang.Object ref = storeHomeDir_;
      if (ref instanceof java.lang.String) {
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
            org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        storeHomeDir_ = b;
        return b;
      } else {
        return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
      }
    }

    public static final int STORE_FILE_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList storeFile_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @return A list containing the storeFile.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getStoreFileList() {
      return storeFile_;
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @return The count of storeFile.
     */
    public int getStoreFileCount() {
      return storeFile_.size();
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @param index The index of the element to return.
     * @return The storeFile at the given index.
     */
    public java.lang.String getStoreFile(int index) {
      return storeFile_.get(index);
    }
    /**
     * <pre>
     * relative to store dir
     * </pre>
     *
     * <code>repeated string store_file = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the storeFile at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getStoreFileBytes(int index) {
      return storeFile_.getByteString(index);
    }

    public static final int STORE_FILE_SIZE_BYTES_FIELD_NUMBER = 4;
    private long storeFileSizeBytes_ = 0L;
    /**
     * <pre>
     * size of store file
     * </pre>
     *
     * <code>optional uint64 store_file_size_bytes = 4;</code>
     * @return Whether the storeFileSizeBytes field is set.
     */
    @java.lang.Override
    public boolean hasStoreFileSizeBytes() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * size of store file
     * </pre>
     *
     * <code>optional uint64 store_file_size_bytes = 4;</code>
     * @return The storeFileSizeBytes.
     */
    @java.lang.Override
    public long getStoreFileSizeBytes() {
      return storeFileSizeBytes_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasFamilyName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasStoreHomeDir()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBytes(1, familyName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 2, storeHomeDir_);
      }
      for (int i = 0; i < storeFile_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 3, storeFile_.getRaw(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(4, storeFileSizeBytes_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, familyName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.computeStringSize(2, storeHomeDir_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < storeFile_.size(); i++) {
          dataSize += computeStringSizeNoTag(storeFile_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getStoreFileList().size();
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, storeFileSizeBytes_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor) obj;

      if (hasFamilyName() != other.hasFamilyName()) return false;
      if (hasFamilyName()) {
        if (!getFamilyName()
            .equals(other.getFamilyName())) return false;
      }
      if (hasStoreHomeDir() != other.hasStoreHomeDir()) return false;
      if (hasStoreHomeDir()) {
        if (!getStoreHomeDir()
            .equals(other.getStoreHomeDir())) return false;
      }
      if (!getStoreFileList()
          .equals(other.getStoreFileList())) return false;
      if (hasStoreFileSizeBytes() != other.hasStoreFileSizeBytes()) return false;
      if (hasStoreFileSizeBytes()) {
        if (getStoreFileSizeBytes()
            != other.getStoreFileSizeBytes()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasFamilyName()) {
        hash = (37 * hash) + FAMILY_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyName().hashCode();
      }
      if (hasStoreHomeDir()) {
        hash = (37 * hash) + STORE_HOME_DIR_FIELD_NUMBER;
        hash = (53 * hash) + getStoreHomeDir().hashCode();
      }
      if (getStoreFileCount() > 0) {
        hash = (37 * hash) + STORE_FILE_FIELD_NUMBER;
        hash = (53 * hash) + getStoreFileList().hashCode();
      }
      if (hasStoreFileSizeBytes()) {
        hash = (37 * hash) + STORE_FILE_SIZE_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getStoreFileSizeBytes());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.StoreDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.StoreDescriptor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_StoreDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_StoreDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        storeHomeDir_ = "";
        storeFile_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        storeFileSizeBytes_ = 0L;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_StoreDescriptor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.familyName_ = familyName_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.storeHomeDir_ = storeHomeDir_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          storeFile_.makeImmutable();
          result.storeFile_ = storeFile_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.storeFileSizeBytes_ = storeFileSizeBytes_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance()) return this;
        if (other.hasFamilyName()) {
          setFamilyName(other.getFamilyName());
        }
        if (other.hasStoreHomeDir()) {
          storeHomeDir_ = other.storeHomeDir_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (!other.storeFile_.isEmpty()) {
          if (storeFile_.isEmpty()) {
            storeFile_ = other.storeFile_;
            bitField0_ |= 0x00000004;
          } else {
            ensureStoreFileIsMutable();
            storeFile_.addAll(other.storeFile_);
          }
          onChanged();
        }
        if (other.hasStoreFileSizeBytes()) {
          setStoreFileSizeBytes(other.getStoreFileSizeBytes());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasFamilyName()) {
          return false;
        }
        if (!hasStoreHomeDir()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                familyName_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                storeHomeDir_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureStoreFileIsMutable();
                storeFile_.add(bs);
                break;
              } // case 26
              case 32: {
                storeFileSizeBytes_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString familyName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family_name = 1;</code>
       * @return Whether the familyName field is set.
       */
      @java.lang.Override
      public boolean hasFamilyName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes family_name = 1;</code>
       * @return The familyName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getFamilyName() {
        return familyName_;
      }
      /**
       * <code>required bytes family_name = 1;</code>
       * @param value The familyName to set.
       * @return This builder for chaining.
       */
      public Builder setFamilyName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        familyName_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFamilyName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        familyName_ = getDefaultInstance().getFamilyName();
        onChanged();
        return this;
      }

      private java.lang.Object storeHomeDir_ = "";
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return Whether the storeHomeDir field is set.
       */
      public boolean hasStoreHomeDir() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The storeHomeDir.
       */
      public java.lang.String getStoreHomeDir() {
        java.lang.Object ref = storeHomeDir_;
        if (!(ref instanceof java.lang.String)) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs =
              (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            storeHomeDir_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return The bytes for storeHomeDir.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreHomeDirBytes() {
        java.lang.Object ref = storeHomeDir_;
        if (ref instanceof String) {
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString b = 
              org.apache.hbase.thirdparty.com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          storeHomeDir_ = b;
          return b;
        } else {
          return (org.apache.hbase.thirdparty.com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @param value The storeHomeDir to set.
       * @return This builder for chaining.
       */
      public Builder setStoreHomeDir(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        storeHomeDir_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreHomeDir() {
        storeHomeDir_ = getDefaultInstance().getStoreHomeDir();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *relative to region dir
       * </pre>
       *
       * <code>required string store_home_dir = 2;</code>
       * @param value The bytes for storeHomeDir to set.
       * @return This builder for chaining.
       */
      public Builder setStoreHomeDirBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        storeHomeDir_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureStoreFileIsMutable() {
        if (!storeFile_.isModifiable()) {
          storeFile_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(storeFile_);
        }
        bitField0_ |= 0x00000004;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @return A list containing the storeFile.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getStoreFileList() {
        storeFile_.makeImmutable();
        return storeFile_;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @return The count of storeFile.
       */
      public int getStoreFileCount() {
        return storeFile_.size();
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param index The index of the element to return.
       * @return The storeFile at the given index.
       */
      public java.lang.String getStoreFile(int index) {
        return storeFile_.get(index);
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the storeFile at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getStoreFileBytes(int index) {
        return storeFile_.getByteString(index);
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param index The index to set the value at.
       * @param value The storeFile to set.
       * @return This builder for chaining.
       */
      public Builder setStoreFile(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.set(index, value);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param value The storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addStoreFile(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.add(value);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param values The storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addAllStoreFile(
          java.lang.Iterable<java.lang.String> values) {
        ensureStoreFileIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, storeFile_);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreFile() {
        storeFile_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * relative to store dir
       * </pre>
       *
       * <code>repeated string store_file = 3;</code>
       * @param value The bytes of the storeFile to add.
       * @return This builder for chaining.
       */
      public Builder addStoreFileBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureStoreFileIsMutable();
        storeFile_.add(value);
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private long storeFileSizeBytes_ ;
      /**
       * <pre>
       * size of store file
       * </pre>
       *
       * <code>optional uint64 store_file_size_bytes = 4;</code>
       * @return Whether the storeFileSizeBytes field is set.
       */
      @java.lang.Override
      public boolean hasStoreFileSizeBytes() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * size of store file
       * </pre>
       *
       * <code>optional uint64 store_file_size_bytes = 4;</code>
       * @return The storeFileSizeBytes.
       */
      @java.lang.Override
      public long getStoreFileSizeBytes() {
        return storeFileSizeBytes_;
      }
      /**
       * <pre>
       * size of store file
       * </pre>
       *
       * <code>optional uint64 store_file_size_bytes = 4;</code>
       * @param value The storeFileSizeBytes to set.
       * @return This builder for chaining.
       */
      public Builder setStoreFileSizeBytes(long value) {

        storeFileSizeBytes_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * size of store file
       * </pre>
       *
       * <code>optional uint64 store_file_size_bytes = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearStoreFileSizeBytes() {
        bitField0_ = (bitField0_ & ~0x00000008);
        storeFileSizeBytes_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.StoreDescriptor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.StoreDescriptor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreDescriptor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<StoreDescriptor>() {
      @java.lang.Override
      public StoreDescriptor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreDescriptor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<StoreDescriptor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface BulkLoadDescriptorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.BulkLoadDescriptor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return Whether the encodedRegionName field is set.
     */
    boolean hasEncodedRegionName();
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return The encodedRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName();

    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> 
        getStoresList();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index);
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    int getStoresCount();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
        getStoresOrBuilderList();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
        int index);

    /**
     * <code>required int64 bulkload_seq_num = 4;</code>
     * @return Whether the bulkloadSeqNum field is set.
     */
    boolean hasBulkloadSeqNum();
    /**
     * <code>required int64 bulkload_seq_num = 4;</code>
     * @return The bulkloadSeqNum.
     */
    long getBulkloadSeqNum();

    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @return A list containing the clusterIds.
     */
    java.util.List<java.lang.String>
        getClusterIdsList();
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @return The count of clusterIds.
     */
    int getClusterIdsCount();
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @param index The index of the element to return.
     * @return The clusterIds at the given index.
     */
    java.lang.String getClusterIds(int index);
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @param index The index of the value to return.
     * @return The bytes of the clusterIds at the given index.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdsBytes(int index);

    /**
     * <code>optional bool replicate = 6 [default = true];</code>
     * @return Whether the replicate field is set.
     */
    boolean hasReplicate();
    /**
     * <code>optional bool replicate = 6 [default = true];</code>
     * @return The replicate.
     */
    boolean getReplicate();
  }
  /**
   * <pre>
   **
   * Special WAL entry used for writing bulk load events to WAL
   * </pre>
   *
   * Protobuf type {@code hbase.pb.BulkLoadDescriptor}
   */
  @javax.annotation.Generated("proto") public static final class BulkLoadDescriptor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.BulkLoadDescriptor)
      BulkLoadDescriptorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use BulkLoadDescriptor.newBuilder() to construct.
    private BulkLoadDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private BulkLoadDescriptor() {
      encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      stores_ = java.util.Collections.emptyList();
      clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      replicate_ = true;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new BulkLoadDescriptor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_BulkLoadDescriptor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_BulkLoadDescriptor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.Builder.class);
    }

    private int bitField0_;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 1;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int ENCODED_REGION_NAME_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return Whether the encodedRegionName field is set.
     */
    @java.lang.Override
    public boolean hasEncodedRegionName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes encoded_region_name = 2;</code>
     * @return The encodedRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
      return encodedRegionName_;
    }

    public static final int STORES_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> stores_;
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> getStoresList() {
      return stores_;
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
        getStoresOrBuilderList() {
      return stores_;
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    @java.lang.Override
    public int getStoresCount() {
      return stores_.size();
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index) {
      return stores_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
        int index) {
      return stores_.get(index);
    }

    public static final int BULKLOAD_SEQ_NUM_FIELD_NUMBER = 4;
    private long bulkloadSeqNum_ = 0L;
    /**
     * <code>required int64 bulkload_seq_num = 4;</code>
     * @return Whether the bulkloadSeqNum field is set.
     */
    @java.lang.Override
    public boolean hasBulkloadSeqNum() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required int64 bulkload_seq_num = 4;</code>
     * @return The bulkloadSeqNum.
     */
    @java.lang.Override
    public long getBulkloadSeqNum() {
      return bulkloadSeqNum_;
    }

    public static final int CLUSTER_IDS_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList clusterIds_ =
        org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @return A list containing the clusterIds.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
        getClusterIdsList() {
      return clusterIds_;
    }
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @return The count of clusterIds.
     */
    public int getClusterIdsCount() {
      return clusterIds_.size();
    }
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @param index The index of the element to return.
     * @return The clusterIds at the given index.
     */
    public java.lang.String getClusterIds(int index) {
      return clusterIds_.get(index);
    }
    /**
     * <code>repeated string cluster_ids = 5;</code>
     * @param index The index of the value to return.
     * @return The bytes of the clusterIds at the given index.
     */
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
        getClusterIdsBytes(int index) {
      return clusterIds_.getByteString(index);
    }

    public static final int REPLICATE_FIELD_NUMBER = 6;
    private boolean replicate_ = true;
    /**
     * <code>optional bool replicate = 6 [default = true];</code>
     * @return Whether the replicate field is set.
     */
    @java.lang.Override
    public boolean hasReplicate() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool replicate = 6 [default = true];</code>
     * @return The replicate.
     */
    @java.lang.Override
    public boolean getReplicate() {
      return replicate_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEncodedRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasBulkloadSeqNum()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getStoresCount(); i++) {
        if (!getStores(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, encodedRegionName_);
      }
      for (int i = 0; i < stores_.size(); i++) {
        output.writeMessage(3, stores_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeInt64(4, bulkloadSeqNum_);
      }
      for (int i = 0; i < clusterIds_.size(); i++) {
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.writeString(output, 5, clusterIds_.getRaw(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(6, replicate_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTableName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, encodedRegionName_);
      }
      for (int i = 0; i < stores_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, stores_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, bulkloadSeqNum_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < clusterIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(clusterIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getClusterIdsList().size();
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, replicate_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor) obj;

      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasEncodedRegionName() != other.hasEncodedRegionName()) return false;
      if (hasEncodedRegionName()) {
        if (!getEncodedRegionName()
            .equals(other.getEncodedRegionName())) return false;
      }
      if (!getStoresList()
          .equals(other.getStoresList())) return false;
      if (hasBulkloadSeqNum() != other.hasBulkloadSeqNum()) return false;
      if (hasBulkloadSeqNum()) {
        if (getBulkloadSeqNum()
            != other.getBulkloadSeqNum()) return false;
      }
      if (!getClusterIdsList()
          .equals(other.getClusterIdsList())) return false;
      if (hasReplicate() != other.hasReplicate()) return false;
      if (hasReplicate()) {
        if (getReplicate()
            != other.getReplicate()) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasEncodedRegionName()) {
        hash = (37 * hash) + ENCODED_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getEncodedRegionName().hashCode();
      }
      if (getStoresCount() > 0) {
        hash = (37 * hash) + STORES_FIELD_NUMBER;
        hash = (53 * hash) + getStoresList().hashCode();
      }
      if (hasBulkloadSeqNum()) {
        hash = (37 * hash) + BULKLOAD_SEQ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getBulkloadSeqNum());
      }
      if (getClusterIdsCount() > 0) {
        hash = (37 * hash) + CLUSTER_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getClusterIdsList().hashCode();
      }
      if (hasReplicate()) {
        hash = (37 * hash) + REPLICATE_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashBoolean(
            getReplicate());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Special WAL entry used for writing bulk load events to WAL
     * </pre>
     *
     * Protobuf type {@code hbase.pb.BulkLoadDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.BulkLoadDescriptor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_BulkLoadDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_BulkLoadDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
          getStoresFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        if (storesBuilder_ == null) {
          stores_ = java.util.Collections.emptyList();
        } else {
          stores_ = null;
          storesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        bulkloadSeqNum_ = 0L;
        clusterIds_ =
            org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        replicate_ = true;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_BulkLoadDescriptor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor result) {
        if (storesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            stores_ = java.util.Collections.unmodifiableList(stores_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.stores_ = stores_;
        } else {
          result.stores_ = storesBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableName_ = tableNameBuilder_ == null
              ? tableName_
              : tableNameBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.encodedRegionName_ = encodedRegionName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.bulkloadSeqNum_ = bulkloadSeqNum_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          clusterIds_.makeImmutable();
          result.clusterIds_ = clusterIds_;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.replicate_ = replicate_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasEncodedRegionName()) {
          setEncodedRegionName(other.getEncodedRegionName());
        }
        if (storesBuilder_ == null) {
          if (!other.stores_.isEmpty()) {
            if (stores_.isEmpty()) {
              stores_ = other.stores_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureStoresIsMutable();
              stores_.addAll(other.stores_);
            }
            onChanged();
          }
        } else {
          if (!other.stores_.isEmpty()) {
            if (storesBuilder_.isEmpty()) {
              storesBuilder_.dispose();
              storesBuilder_ = null;
              stores_ = other.stores_;
              bitField0_ = (bitField0_ & ~0x00000004);
              storesBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStoresFieldBuilder() : null;
            } else {
              storesBuilder_.addAllMessages(other.stores_);
            }
          }
        }
        if (other.hasBulkloadSeqNum()) {
          setBulkloadSeqNum(other.getBulkloadSeqNum());
        }
        if (!other.clusterIds_.isEmpty()) {
          if (clusterIds_.isEmpty()) {
            clusterIds_ = other.clusterIds_;
            bitField0_ |= 0x00000010;
          } else {
            ensureClusterIdsIsMutable();
            clusterIds_.addAll(other.clusterIds_);
          }
          onChanged();
        }
        if (other.hasReplicate()) {
          setReplicate(other.getReplicate());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTableName()) {
          return false;
        }
        if (!hasEncodedRegionName()) {
          return false;
        }
        if (!hasBulkloadSeqNum()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getStoresCount(); i++) {
          if (!getStores(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTableNameFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                encodedRegionName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.PARSER,
                        extensionRegistry);
                if (storesBuilder_ == null) {
                  ensureStoresIsMutable();
                  stores_.add(m);
                } else {
                  storesBuilder_.addMessage(m);
                }
                break;
              } // case 26
              case 32: {
                bulkloadSeqNum_ = input.readInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                org.apache.hbase.thirdparty.com.google.protobuf.ByteString bs = input.readBytes();
                ensureClusterIdsIsMutable();
                clusterIds_.add(bs);
                break;
              } // case 42
              case 48: {
                replicate_ = input.readBool();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName tableName_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            tableName_ != null &&
            tableName_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            getTableNameBuilder().mergeFrom(value);
          } else {
            tableName_ = value;
          }
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        if (tableName_ != null) {
          bitField0_ |= 0x00000001;
          onChanged();
        }
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = null;
        if (tableNameBuilder_ != null) {
          tableNameBuilder_.dispose();
          tableNameBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 1;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return Whether the encodedRegionName field is set.
       */
      @java.lang.Override
      public boolean hasEncodedRegionName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return The encodedRegionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
        return encodedRegionName_;
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @param value The encodedRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setEncodedRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encodedRegionName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes encoded_region_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncodedRegionName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        encodedRegionName_ = getDefaultInstance().getEncodedRegionName();
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> stores_ =
        java.util.Collections.emptyList();
      private void ensureStoresIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          stores_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor>(stores_);
          bitField0_ |= 0x00000004;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> storesBuilder_;

      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> getStoresList() {
        if (storesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(stores_);
        } else {
          return storesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public int getStoresCount() {
        if (storesBuilder_ == null) {
          return stores_.size();
        } else {
          return storesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index) {
        if (storesBuilder_ == null) {
          return stores_.get(index);
        } else {
          return storesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder setStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.set(index, value);
          onChanged();
        } else {
          storesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder setStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.set(index, builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder addStores(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.add(value);
          onChanged();
        } else {
          storesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder addStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.add(index, value);
          onChanged();
        } else {
          storesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder addStores(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.add(builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder addStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.add(index, builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder addAllStores(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> values) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, stores_);
          onChanged();
        } else {
          storesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder clearStores() {
        if (storesBuilder_ == null) {
          stores_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          storesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public Builder removeStores(int index) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.remove(index);
          onChanged();
        } else {
          storesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder getStoresBuilder(
          int index) {
        return getStoresFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
          int index) {
        if (storesBuilder_ == null) {
          return stores_.get(index);  } else {
          return storesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
           getStoresOrBuilderList() {
        if (storesBuilder_ != null) {
          return storesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(stores_);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder addStoresBuilder() {
        return getStoresFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder addStoresBuilder(
          int index) {
        return getStoresFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder> 
           getStoresBuilderList() {
        return getStoresFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
          getStoresFieldBuilder() {
        if (storesBuilder_ == null) {
          storesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder>(
                  stores_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          stores_ = null;
        }
        return storesBuilder_;
      }

      private long bulkloadSeqNum_ ;
      /**
       * <code>required int64 bulkload_seq_num = 4;</code>
       * @return Whether the bulkloadSeqNum field is set.
       */
      @java.lang.Override
      public boolean hasBulkloadSeqNum() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required int64 bulkload_seq_num = 4;</code>
       * @return The bulkloadSeqNum.
       */
      @java.lang.Override
      public long getBulkloadSeqNum() {
        return bulkloadSeqNum_;
      }
      /**
       * <code>required int64 bulkload_seq_num = 4;</code>
       * @param value The bulkloadSeqNum to set.
       * @return This builder for chaining.
       */
      public Builder setBulkloadSeqNum(long value) {

        bulkloadSeqNum_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 bulkload_seq_num = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearBulkloadSeqNum() {
        bitField0_ = (bitField0_ & ~0x00000008);
        bulkloadSeqNum_ = 0L;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureClusterIdsIsMutable() {
        if (!clusterIds_.isModifiable()) {
          clusterIds_ = new org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList(clusterIds_);
        }
        bitField0_ |= 0x00000010;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @return A list containing the clusterIds.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ProtocolStringList
          getClusterIdsList() {
        clusterIds_.makeImmutable();
        return clusterIds_;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @return The count of clusterIds.
       */
      public int getClusterIdsCount() {
        return clusterIds_.size();
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param index The index of the element to return.
       * @return The clusterIds at the given index.
       */
      public java.lang.String getClusterIds(int index) {
        return clusterIds_.get(index);
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param index The index of the value to return.
       * @return The bytes of the clusterIds at the given index.
       */
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString
          getClusterIdsBytes(int index) {
        return clusterIds_.getByteString(index);
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param index The index to set the value at.
       * @param value The clusterIds to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIds(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.set(index, value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param value The clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addClusterIds(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.add(value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param values The clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addAllClusterIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureClusterIdsIsMutable();
        org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, clusterIds_);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterIds() {
        clusterIds_ =
          org.apache.hbase.thirdparty.com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000010);;
        onChanged();
        return this;
      }
      /**
       * <code>repeated string cluster_ids = 5;</code>
       * @param value The bytes of the clusterIds to add.
       * @return This builder for chaining.
       */
      public Builder addClusterIdsBytes(
          org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        ensureClusterIdsIsMutable();
        clusterIds_.add(value);
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }

      private boolean replicate_ = true;
      /**
       * <code>optional bool replicate = 6 [default = true];</code>
       * @return Whether the replicate field is set.
       */
      @java.lang.Override
      public boolean hasReplicate() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool replicate = 6 [default = true];</code>
       * @return The replicate.
       */
      @java.lang.Override
      public boolean getReplicate() {
        return replicate_;
      }
      /**
       * <code>optional bool replicate = 6 [default = true];</code>
       * @param value The replicate to set.
       * @return This builder for chaining.
       */
      public Builder setReplicate(boolean value) {

        replicate_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool replicate = 6 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearReplicate() {
        bitField0_ = (bitField0_ & ~0x00000020);
        replicate_ = true;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.BulkLoadDescriptor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.BulkLoadDescriptor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadDescriptor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<BulkLoadDescriptor>() {
      @java.lang.Override
      public BulkLoadDescriptor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadDescriptor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<BulkLoadDescriptor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.BulkLoadDescriptor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RegionEventDescriptorOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.RegionEventDescriptor)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
     * @return Whether the eventType field is set.
     */
    boolean hasEventType();
    /**
     * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
     * @return The eventType.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType getEventType();

    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName();

    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return Whether the encodedRegionName field is set.
     */
    boolean hasEncodedRegionName();
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return The encodedRegionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName();

    /**
     * <code>optional uint64 log_sequence_number = 4;</code>
     * @return Whether the logSequenceNumber field is set.
     */
    boolean hasLogSequenceNumber();
    /**
     * <code>optional uint64 log_sequence_number = 4;</code>
     * @return The logSequenceNumber.
     */
    long getLogSequenceNumber();

    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> 
        getStoresList();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index);
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    int getStoresCount();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
        getStoresOrBuilderList();
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
        int index);

    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     * @return Whether the server field is set.
     */
    boolean hasServer();
    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     * @return The server.
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServer();
    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     */
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder();

    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return Whether the regionName field is set.
     */
    boolean hasRegionName();
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return The regionName.
     */
    org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName();
  }
  /**
   * <pre>
   **
   * Special WAL entry to hold all related to a region event (open/close).
   * </pre>
   *
   * Protobuf type {@code hbase.pb.RegionEventDescriptor}
   */
  @javax.annotation.Generated("proto") public static final class RegionEventDescriptor extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.RegionEventDescriptor)
      RegionEventDescriptorOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RegionEventDescriptor.newBuilder() to construct.
    private RegionEventDescriptor(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RegionEventDescriptor() {
      eventType_ = 0;
      tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      stores_ = java.util.Collections.emptyList();
      regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new RegionEventDescriptor();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_RegionEventDescriptor_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_RegionEventDescriptor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.Builder.class);
    }

    /**
     * Protobuf enum {@code hbase.pb.RegionEventDescriptor.EventType}
     */
    public enum EventType
        implements org.apache.hbase.thirdparty.com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>REGION_OPEN = 0;</code>
       */
      REGION_OPEN(0),
      /**
       * <code>REGION_CLOSE = 1;</code>
       */
      REGION_CLOSE(1),
      ;

      /**
       * <code>REGION_OPEN = 0;</code>
       */
      public static final int REGION_OPEN_VALUE = 0;
      /**
       * <code>REGION_CLOSE = 1;</code>
       */
      public static final int REGION_CLOSE_VALUE = 1;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static EventType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static EventType forNumber(int value) {
        switch (value) {
          case 0: return REGION_OPEN;
          case 1: return REGION_CLOSE;
          default: return null;
        }
      }

      public static org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EventType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<
          EventType> internalValueMap =
            new org.apache.hbase.thirdparty.com.google.protobuf.Internal.EnumLiteMap<EventType>() {
              public EventType findValueByNumber(int number) {
                return EventType.forNumber(number);
              }
            };

      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.getDescriptor().getEnumTypes().get(0);
      }

      private static final EventType[] VALUES = values();

      public static EventType valueOf(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private EventType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.RegionEventDescriptor.EventType)
    }

    private int bitField0_;
    public static final int EVENT_TYPE_FIELD_NUMBER = 1;
    private int eventType_ = 0;
    /**
     * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
     * @return Whether the eventType field is set.
     */
    @java.lang.Override public boolean hasEventType() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
     * @return The eventType.
     */
    @java.lang.Override public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType getEventType() {
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType.forNumber(eventType_);
      return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType.REGION_OPEN : result;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    @java.lang.Override
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bytes table_name = 2;</code>
     * @return The tableName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
      return tableName_;
    }

    public static final int ENCODED_REGION_NAME_FIELD_NUMBER = 3;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return Whether the encodedRegionName field is set.
     */
    @java.lang.Override
    public boolean hasEncodedRegionName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bytes encoded_region_name = 3;</code>
     * @return The encodedRegionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
      return encodedRegionName_;
    }

    public static final int LOG_SEQUENCE_NUMBER_FIELD_NUMBER = 4;
    private long logSequenceNumber_ = 0L;
    /**
     * <code>optional uint64 log_sequence_number = 4;</code>
     * @return Whether the logSequenceNumber field is set.
     */
    @java.lang.Override
    public boolean hasLogSequenceNumber() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional uint64 log_sequence_number = 4;</code>
     * @return The logSequenceNumber.
     */
    @java.lang.Override
    public long getLogSequenceNumber() {
      return logSequenceNumber_;
    }

    public static final int STORES_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> stores_;
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    @java.lang.Override
    public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> getStoresList() {
      return stores_;
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
        getStoresOrBuilderList() {
      return stores_;
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    @java.lang.Override
    public int getStoresCount() {
      return stores_.size();
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index) {
      return stores_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
        int index) {
      return stores_.get(index);
    }

    public static final int SERVER_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName server_;
    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     * @return Whether the server field is set.
     */
    @java.lang.Override
    public boolean hasServer() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     * @return The server.
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServer() {
      return server_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : server_;
    }
    /**
     * <pre>
     * Server who opened the region
     * </pre>
     *
     * <code>optional .hbase.pb.ServerName server = 6;</code>
     */
    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder() {
      return server_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : server_;
    }

    public static final int REGION_NAME_FIELD_NUMBER = 7;
    private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return Whether the regionName field is set.
     */
    @java.lang.Override
    public boolean hasRegionName() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <pre>
     * full region name
     * </pre>
     *
     * <code>optional bytes region_name = 7;</code>
     * @return The regionName.
     */
    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
      return regionName_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasEventType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasEncodedRegionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getStoresCount(); i++) {
        if (!getStores(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasServer()) {
        if (!getServer().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, eventType_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt64(4, logSequenceNumber_);
      }
      for (int i = 0; i < stores_.size(); i++) {
        output.writeMessage(5, stores_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(6, getServer());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBytes(7, regionName_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, eventType_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, encodedRegionName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, logSequenceNumber_);
      }
      for (int i = 0; i < stores_.size(); i++) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, stores_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getServer());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream
          .computeBytesSize(7, regionName_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor) obj;

      if (hasEventType() != other.hasEventType()) return false;
      if (hasEventType()) {
        if (eventType_ != other.eventType_) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasEncodedRegionName() != other.hasEncodedRegionName()) return false;
      if (hasEncodedRegionName()) {
        if (!getEncodedRegionName()
            .equals(other.getEncodedRegionName())) return false;
      }
      if (hasLogSequenceNumber() != other.hasLogSequenceNumber()) return false;
      if (hasLogSequenceNumber()) {
        if (getLogSequenceNumber()
            != other.getLogSequenceNumber()) return false;
      }
      if (!getStoresList()
          .equals(other.getStoresList())) return false;
      if (hasServer() != other.hasServer()) return false;
      if (hasServer()) {
        if (!getServer()
            .equals(other.getServer())) return false;
      }
      if (hasRegionName() != other.hasRegionName()) return false;
      if (hasRegionName()) {
        if (!getRegionName()
            .equals(other.getRegionName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasEventType()) {
        hash = (37 * hash) + EVENT_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + eventType_;
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasEncodedRegionName()) {
        hash = (37 * hash) + ENCODED_REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getEncodedRegionName().hashCode();
      }
      if (hasLogSequenceNumber()) {
        hash = (37 * hash) + LOG_SEQUENCE_NUMBER_FIELD_NUMBER;
        hash = (53 * hash) + org.apache.hbase.thirdparty.com.google.protobuf.Internal.hashLong(
            getLogSequenceNumber());
      }
      if (getStoresCount() > 0) {
        hash = (37 * hash) + STORES_FIELD_NUMBER;
        hash = (53 * hash) + getStoresList().hashCode();
      }
      if (hasServer()) {
        hash = (37 * hash) + SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getServer().hashCode();
      }
      if (hasRegionName()) {
        hash = (37 * hash) + REGION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getRegionName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * Special WAL entry to hold all related to a region event (open/close).
     * </pre>
     *
     * Protobuf type {@code hbase.pb.RegionEventDescriptor}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.RegionEventDescriptor)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptorOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_RegionEventDescriptor_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_RegionEventDescriptor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStoresFieldBuilder();
          getServerFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        eventType_ = 0;
        tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        logSequenceNumber_ = 0L;
        if (storesBuilder_ == null) {
          stores_ = java.util.Collections.emptyList();
        } else {
          stores_ = null;
          storesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        server_ = null;
        if (serverBuilder_ != null) {
          serverBuilder_.dispose();
          serverBuilder_ = null;
        }
        regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_RegionEventDescriptor_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor result) {
        if (storesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            stores_ = java.util.Collections.unmodifiableList(stores_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.stores_ = stores_;
        } else {
          result.stores_ = storesBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor result) {
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.eventType_ = eventType_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.tableName_ = tableName_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.encodedRegionName_ = encodedRegionName_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.logSequenceNumber_ = logSequenceNumber_;
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.server_ = serverBuilder_ == null
              ? server_
              : serverBuilder_.build();
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.regionName_ = regionName_;
          to_bitField0_ |= 0x00000020;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.getDefaultInstance()) return this;
        if (other.hasEventType()) {
          setEventType(other.getEventType());
        }
        if (other.hasTableName()) {
          setTableName(other.getTableName());
        }
        if (other.hasEncodedRegionName()) {
          setEncodedRegionName(other.getEncodedRegionName());
        }
        if (other.hasLogSequenceNumber()) {
          setLogSequenceNumber(other.getLogSequenceNumber());
        }
        if (storesBuilder_ == null) {
          if (!other.stores_.isEmpty()) {
            if (stores_.isEmpty()) {
              stores_ = other.stores_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureStoresIsMutable();
              stores_.addAll(other.stores_);
            }
            onChanged();
          }
        } else {
          if (!other.stores_.isEmpty()) {
            if (storesBuilder_.isEmpty()) {
              storesBuilder_.dispose();
              storesBuilder_ = null;
              stores_ = other.stores_;
              bitField0_ = (bitField0_ & ~0x00000010);
              storesBuilder_ = 
                org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStoresFieldBuilder() : null;
            } else {
              storesBuilder_.addAllMessages(other.stores_);
            }
          }
        }
        if (other.hasServer()) {
          mergeServer(other.getServer());
        }
        if (other.hasRegionName()) {
          setRegionName(other.getRegionName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasEventType()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasEncodedRegionName()) {
          return false;
        }
        for (int i = 0; i < getStoresCount(); i++) {
          if (!getStores(i).isInitialized()) {
            return false;
          }
        }
        if (hasServer()) {
          if (!getServer().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                int tmpRaw = input.readEnum();
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType tmpValue =
                    org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType.forNumber(tmpRaw);
                if (tmpValue == null) {
                  mergeUnknownVarintField(1, tmpRaw);
                } else {
                  eventType_ = tmpRaw;
                  bitField0_ |= 0x00000001;
                }
                break;
              } // case 8
              case 18: {
                tableName_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                encodedRegionName_ = input.readBytes();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                logSequenceNumber_ = input.readUInt64();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 42: {
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor m =
                    input.readMessage(
                        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.PARSER,
                        extensionRegistry);
                if (storesBuilder_ == null) {
                  ensureStoresIsMutable();
                  stores_.add(m);
                } else {
                  storesBuilder_.addMessage(m);
                }
                break;
              } // case 42
              case 50: {
                input.readMessage(
                    getServerFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000020;
                break;
              } // case 50
              case 58: {
                regionName_ = input.readBytes();
                bitField0_ |= 0x00000040;
                break;
              } // case 58
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int eventType_ = 0;
      /**
       * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
       * @return Whether the eventType field is set.
       */
      @java.lang.Override public boolean hasEventType() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
       * @return The eventType.
       */
      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType getEventType() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType result = org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType.forNumber(eventType_);
        return result == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType.REGION_OPEN : result;
      }
      /**
       * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
       * @param value The eventType to set.
       * @return This builder for chaining.
       */
      public Builder setEventType(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor.EventType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        eventType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.RegionEventDescriptor.EventType event_type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearEventType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        eventType_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString tableName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      @java.lang.Override
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return The tableName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getTableName() {
        return tableName_;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @param value The tableName to set.
       * @return This builder for chaining.
       */
      public Builder setTableName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        tableName_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes table_name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = getDefaultInstance().getTableName();
        onChanged();
        return this;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString encodedRegionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return Whether the encodedRegionName field is set.
       */
      @java.lang.Override
      public boolean hasEncodedRegionName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return The encodedRegionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getEncodedRegionName() {
        return encodedRegionName_;
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @param value The encodedRegionName to set.
       * @return This builder for chaining.
       */
      public Builder setEncodedRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        encodedRegionName_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes encoded_region_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncodedRegionName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        encodedRegionName_ = getDefaultInstance().getEncodedRegionName();
        onChanged();
        return this;
      }

      private long logSequenceNumber_ ;
      /**
       * <code>optional uint64 log_sequence_number = 4;</code>
       * @return Whether the logSequenceNumber field is set.
       */
      @java.lang.Override
      public boolean hasLogSequenceNumber() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional uint64 log_sequence_number = 4;</code>
       * @return The logSequenceNumber.
       */
      @java.lang.Override
      public long getLogSequenceNumber() {
        return logSequenceNumber_;
      }
      /**
       * <code>optional uint64 log_sequence_number = 4;</code>
       * @param value The logSequenceNumber to set.
       * @return This builder for chaining.
       */
      public Builder setLogSequenceNumber(long value) {

        logSequenceNumber_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 log_sequence_number = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearLogSequenceNumber() {
        bitField0_ = (bitField0_ & ~0x00000008);
        logSequenceNumber_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> stores_ =
        java.util.Collections.emptyList();
      private void ensureStoresIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          stores_ = new java.util.ArrayList<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor>(stores_);
          bitField0_ |= 0x00000010;
         }
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> storesBuilder_;

      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> getStoresList() {
        if (storesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(stores_);
        } else {
          return storesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public int getStoresCount() {
        if (storesBuilder_ == null) {
          return stores_.size();
        } else {
          return storesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor getStores(int index) {
        if (storesBuilder_ == null) {
          return stores_.get(index);
        } else {
          return storesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder setStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.set(index, value);
          onChanged();
        } else {
          storesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder setStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.set(index, builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder addStores(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.add(value);
          onChanged();
        } else {
          storesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder addStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor value) {
        if (storesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStoresIsMutable();
          stores_.add(index, value);
          onChanged();
        } else {
          storesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder addStores(
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.add(builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder addStores(
          int index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder builderForValue) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.add(index, builderForValue.build());
          onChanged();
        } else {
          storesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder addAllStores(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor> values) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, stores_);
          onChanged();
        } else {
          storesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder clearStores() {
        if (storesBuilder_ == null) {
          stores_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          storesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public Builder removeStores(int index) {
        if (storesBuilder_ == null) {
          ensureStoresIsMutable();
          stores_.remove(index);
          onChanged();
        } else {
          storesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder getStoresBuilder(
          int index) {
        return getStoresFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder getStoresOrBuilder(
          int index) {
        if (storesBuilder_ == null) {
          return stores_.get(index);  } else {
          return storesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
           getStoresOrBuilderList() {
        if (storesBuilder_ != null) {
          return storesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(stores_);
        }
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder addStoresBuilder() {
        return getStoresFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder addStoresBuilder(
          int index) {
        return getStoresFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.StoreDescriptor stores = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder> 
           getStoresBuilderList() {
        return getStoresFieldBuilder().getBuilderList();
      }
      private org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder> 
          getStoresFieldBuilder() {
        if (storesBuilder_ == null) {
          storesBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptor.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.StoreDescriptorOrBuilder>(
                  stores_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          stores_ = null;
        }
        return storesBuilder_;
      }

      private org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName server_;
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverBuilder_;
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       * @return Whether the server field is set.
       */
      public boolean hasServer() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       * @return The server.
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName getServer() {
        if (serverBuilder_ == null) {
          return server_ == null ? org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : server_;
        } else {
          return serverBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public Builder setServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          server_ = value;
        } else {
          serverBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public Builder setServer(
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverBuilder_ == null) {
          server_ = builderForValue.build();
        } else {
          serverBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public Builder mergeServer(org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
            server_ != null &&
            server_ != org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            getServerBuilder().mergeFrom(value);
          } else {
            server_ = value;
          }
        } else {
          serverBuilder_.mergeFrom(value);
        }
        if (server_ != null) {
          bitField0_ |= 0x00000020;
          onChanged();
        }
        return this;
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public Builder clearServer() {
        bitField0_ = (bitField0_ & ~0x00000020);
        server_ = null;
        if (serverBuilder_ != null) {
          serverBuilder_.dispose();
          serverBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder getServerBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getServerFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      public org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder() {
        if (serverBuilder_ != null) {
          return serverBuilder_.getMessageOrBuilder();
        } else {
          return server_ == null ?
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : server_;
        }
      }
      /**
       * <pre>
       * Server who opened the region
       * </pre>
       *
       * <code>optional .hbase.pb.ServerName server = 6;</code>
       */
      private org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerFieldBuilder() {
        if (serverBuilder_ == null) {
          serverBuilder_ = new org.apache.hbase.thirdparty.com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServer(),
                  getParentForChildren(),
                  isClean());
          server_ = null;
        }
        return serverBuilder_;
      }

      private org.apache.hbase.thirdparty.com.google.protobuf.ByteString regionName_ = org.apache.hbase.thirdparty.com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return Whether the regionName field is set.
       */
      @java.lang.Override
      public boolean hasRegionName() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return The regionName.
       */
      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.ByteString getRegionName() {
        return regionName_;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @param value The regionName to set.
       * @return This builder for chaining.
       */
      public Builder setRegionName(org.apache.hbase.thirdparty.com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        regionName_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * full region name
       * </pre>
       *
       * <code>optional bytes region_name = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegionName() {
        bitField0_ = (bitField0_ & ~0x00000040);
        regionName_ = getDefaultInstance().getRegionName();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.RegionEventDescriptor)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RegionEventDescriptor)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionEventDescriptor>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<RegionEventDescriptor>() {
      @java.lang.Override
      public RegionEventDescriptor parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionEventDescriptor> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<RegionEventDescriptor> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WALTrailerOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.WALTrailer)
      org.apache.hbase.thirdparty.com.google.protobuf.MessageOrBuilder {
  }
  /**
   * <pre>
   **
   * A trailer that is appended to the end of a properly closed WAL file.
   * If missing, this is either a legacy or a corrupted WAL file.
   * N.B. This trailer currently doesn't contain any information and we
   * purposefully don't expose it in the WAL APIs. It's for future growth.
   * </pre>
   *
   * Protobuf type {@code hbase.pb.WALTrailer}
   */
  @javax.annotation.Generated("proto") public static final class WALTrailer extends
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.WALTrailer)
      WALTrailerOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WALTrailer.newBuilder() to construct.
    private WALTrailer(org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WALTrailer() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new WALTrailer();
    }

    public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALTrailer_descriptor;
    }

    @java.lang.Override
    protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALTrailer_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(org.apache.hbase.thirdparty.com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer other = (org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        java.nio.ByteBuffer data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        java.nio.ByteBuffer data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.ByteString data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(byte[] data)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        byte[] data,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseDelimitedFrom(
        java.io.InputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer parseFrom(
        org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
        org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     **
     * A trailer that is appended to the end of a properly closed WAL file.
     * If missing, this is either a legacy or a corrupted WAL file.
     * N.B. This trailer currently doesn't contain any information and we
     * purposefully don't expose it in the WAL APIs. It's for future growth.
     * </pre>
     *
     * Protobuf type {@code hbase.pb.WALTrailer}
     */
    @javax.annotation.Generated("proto") public static final class Builder extends
        org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.WALTrailer)
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailerOrBuilder {
      public static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALTrailer_descriptor;
      }

      @java.lang.Override
      protected org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALTrailer_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.class, org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.newBuilder()
      private Builder() {

      }

      private Builder(
          org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.internal_static_hbase_pb_WALTrailer_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer build() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer buildPartial() {
        org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer result = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(org.apache.hbase.thirdparty.com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer) {
          return mergeFrom((org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer other) {
        if (other == org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.WALTrailer)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.WALTrailer)
    private static final org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer();
    }

    public static org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALTrailer>
        PARSER = new org.apache.hbase.thirdparty.com.google.protobuf.AbstractParser<WALTrailer>() {
      @java.lang.Override
      public WALTrailer parsePartialFrom(
          org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream input,
          org.apache.hbase.thirdparty.com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (org.apache.hbase.thirdparty.com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALTrailer> parser() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hbase.thirdparty.com.google.protobuf.Parser<WALTrailer> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.WALTrailer getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WALHeader_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WALHeader_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WALKey_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WALKey_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Attribute_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Attribute_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FamilyScope_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FamilyScope_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CompactionDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CompactionDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FlushDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FlushDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_StoreDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_StoreDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_BulkLoadDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_BulkLoadDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RegionEventDescriptor_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_RegionEventDescriptor_fieldAccessorTable;
  private static final org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_WALTrailer_descriptor;
  private static final 
    org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_WALTrailer_fieldAccessorTable;

  public static org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\tWAL.proto\022\010hbase.pb\032\013HBase.proto\"\323\001\n\tW" +
      "ALHeader\022\027\n\017has_compression\030\001 \001(\010\022\026\n\016enc" +
      "ryption_key\030\002 \001(\014\022\033\n\023has_tag_compression" +
      "\030\003 \001(\010\022\027\n\017writer_cls_name\030\004 \001(\t\022\033\n\023cell_" +
      "codec_cls_name\030\005 \001(\t\022\035\n\025has_value_compre" +
      "ssion\030\006 \001(\010\022#\n\033value_compression_algorit" +
      "hm\030\007 \001(\r\"\355\002\n\006WALKey\022\033\n\023encoded_region_na" +
      "me\030\001 \002(\014\022\022\n\ntable_name\030\002 \002(\014\022\033\n\023log_sequ" +
      "ence_number\030\003 \002(\004\022\022\n\nwrite_time\030\004 \002(\004\022&\n" +
      "\ncluster_id\030\005 \001(\0132\016.hbase.pb.UUIDB\002\030\001\022%\n" +
      "\006scopes\030\006 \003(\0132\025.hbase.pb.FamilyScope\022\032\n\022" +
      "following_kv_count\030\007 \001(\r\022#\n\013cluster_ids\030" +
      "\010 \003(\0132\016.hbase.pb.UUID\022\022\n\nnonceGroup\030\t \001(" +
      "\004\022\r\n\005nonce\030\n \001(\004\022\034\n\024orig_sequence_number" +
      "\030\013 \001(\004\0220\n\023extended_attributes\030\014 \003(\0132\023.hb" +
      "ase.pb.Attribute\"\'\n\tAttribute\022\013\n\003key\030\001 \002" +
      "(\t\022\r\n\005value\030\002 \002(\014\"F\n\013FamilyScope\022\016\n\006fami" +
      "ly\030\001 \002(\014\022\'\n\nscope_type\030\002 \002(\0162\023.hbase.pb." +
      "ScopeType\"\276\001\n\024CompactionDescriptor\022\022\n\nta" +
      "ble_name\030\001 \002(\014\022\033\n\023encoded_region_name\030\002 " +
      "\002(\014\022\023\n\013family_name\030\003 \002(\014\022\030\n\020compaction_i" +
      "nput\030\004 \003(\t\022\031\n\021compaction_output\030\005 \003(\t\022\026\n" +
      "\016store_home_dir\030\006 \002(\t\022\023\n\013region_name\030\007 \001" +
      "(\014\"\244\003\n\017FlushDescriptor\0225\n\006action\030\001 \002(\0162%" +
      ".hbase.pb.FlushDescriptor.FlushAction\022\022\n" +
      "\ntable_name\030\002 \002(\014\022\033\n\023encoded_region_name" +
      "\030\003 \002(\014\022\035\n\025flush_sequence_number\030\004 \001(\004\022E\n" +
      "\rstore_flushes\030\005 \003(\0132..hbase.pb.FlushDes" +
      "criptor.StoreFlushDescriptor\022\023\n\013region_n" +
      "ame\030\006 \001(\014\032Y\n\024StoreFlushDescriptor\022\023\n\013fam" +
      "ily_name\030\001 \002(\014\022\026\n\016store_home_dir\030\002 \002(\t\022\024" +
      "\n\014flush_output\030\003 \003(\t\"S\n\013FlushAction\022\017\n\013S" +
      "TART_FLUSH\020\000\022\020\n\014COMMIT_FLUSH\020\001\022\017\n\013ABORT_" +
      "FLUSH\020\002\022\020\n\014CANNOT_FLUSH\020\003\"q\n\017StoreDescri" +
      "ptor\022\023\n\013family_name\030\001 \002(\014\022\026\n\016store_home_" +
      "dir\030\002 \002(\t\022\022\n\nstore_file\030\003 \003(\t\022\035\n\025store_f" +
      "ile_size_bytes\030\004 \001(\004\"\315\001\n\022BulkLoadDescrip" +
      "tor\022\'\n\ntable_name\030\001 \002(\0132\023.hbase.pb.Table" +
      "Name\022\033\n\023encoded_region_name\030\002 \002(\014\022)\n\006sto" +
      "res\030\003 \003(\0132\031.hbase.pb.StoreDescriptor\022\030\n\020" +
      "bulkload_seq_num\030\004 \002(\003\022\023\n\013cluster_ids\030\005 " +
      "\003(\t\022\027\n\treplicate\030\006 \001(\010:\004true\"\272\002\n\025RegionE" +
      "ventDescriptor\022=\n\nevent_type\030\001 \002(\0162).hba" +
      "se.pb.RegionEventDescriptor.EventType\022\022\n" +
      "\ntable_name\030\002 \002(\014\022\033\n\023encoded_region_name" +
      "\030\003 \002(\014\022\033\n\023log_sequence_number\030\004 \001(\004\022)\n\006s" +
      "tores\030\005 \003(\0132\031.hbase.pb.StoreDescriptor\022$" +
      "\n\006server\030\006 \001(\0132\024.hbase.pb.ServerName\022\023\n\013" +
      "region_name\030\007 \001(\014\".\n\tEventType\022\017\n\013REGION" +
      "_OPEN\020\000\022\020\n\014REGION_CLOSE\020\001\"\014\n\nWALTrailer*" +
      "d\n\tScopeType\022\033\n\027REPLICATION_SCOPE_LOCAL\020" +
      "\000\022\034\n\030REPLICATION_SCOPE_GLOBAL\020\001\022\034\n\030REPLI" +
      "CATION_SCOPE_SERIAL\020\002BF\n1org.apache.hado" +
      "op.hbase.shaded.protobuf.generatedB\tWALP" +
      "rotosH\001\210\001\000\240\001\001"
    };
    descriptor = org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new org.apache.hbase.thirdparty.com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor(),
        });
    internal_static_hbase_pb_WALHeader_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_WALHeader_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WALHeader_descriptor,
        new java.lang.String[] { "HasCompression", "EncryptionKey", "HasTagCompression", "WriterClsName", "CellCodecClsName", "HasValueCompression", "ValueCompressionAlgorithm", });
    internal_static_hbase_pb_WALKey_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_WALKey_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WALKey_descriptor,
        new java.lang.String[] { "EncodedRegionName", "TableName", "LogSequenceNumber", "WriteTime", "ClusterId", "Scopes", "FollowingKvCount", "ClusterIds", "NonceGroup", "Nonce", "OrigSequenceNumber", "ExtendedAttributes", });
    internal_static_hbase_pb_Attribute_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_Attribute_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Attribute_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_hbase_pb_FamilyScope_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_FamilyScope_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FamilyScope_descriptor,
        new java.lang.String[] { "Family", "ScopeType", });
    internal_static_hbase_pb_CompactionDescriptor_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_CompactionDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CompactionDescriptor_descriptor,
        new java.lang.String[] { "TableName", "EncodedRegionName", "FamilyName", "CompactionInput", "CompactionOutput", "StoreHomeDir", "RegionName", });
    internal_static_hbase_pb_FlushDescriptor_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_FlushDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FlushDescriptor_descriptor,
        new java.lang.String[] { "Action", "TableName", "EncodedRegionName", "FlushSequenceNumber", "StoreFlushes", "RegionName", });
    internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor =
      internal_static_hbase_pb_FlushDescriptor_descriptor.getNestedTypes().get(0);
    internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_FlushDescriptor_StoreFlushDescriptor_descriptor,
        new java.lang.String[] { "FamilyName", "StoreHomeDir", "FlushOutput", });
    internal_static_hbase_pb_StoreDescriptor_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_StoreDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_StoreDescriptor_descriptor,
        new java.lang.String[] { "FamilyName", "StoreHomeDir", "StoreFile", "StoreFileSizeBytes", });
    internal_static_hbase_pb_BulkLoadDescriptor_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_BulkLoadDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_BulkLoadDescriptor_descriptor,
        new java.lang.String[] { "TableName", "EncodedRegionName", "Stores", "BulkloadSeqNum", "ClusterIds", "Replicate", });
    internal_static_hbase_pb_RegionEventDescriptor_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_RegionEventDescriptor_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_RegionEventDescriptor_descriptor,
        new java.lang.String[] { "EventType", "TableName", "EncodedRegionName", "LogSequenceNumber", "Stores", "Server", "RegionName", });
    internal_static_hbase_pb_WALTrailer_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_WALTrailer_fieldAccessorTable = new
      org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_WALTrailer_descriptor,
        new java.lang.String[] { });
    org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
